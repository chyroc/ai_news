<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"


>
    <channel>
        <title><![CDATA[Huggingface Daily Papers]]></title>
        <link>https://huggingface.co/papers</link>
        <atom:link href="https://rsshub.app/huggingface/daily-papers" rel="self" type="application/rss+xml" />
        <description><![CDATA[Huggingface Daily Papers - Made with love by RSSHub(https://github.com/DIYgod/RSSHub)]]></description>
        <generator>RSSHub</generator>
        <webMaster>i@diygod.me (DIYgod)</webMaster>
        
        
        
        <language>zh-cn</language>
        
        <lastBuildDate>Tue, 12 Dec 2023 03:53:44 GMT</lastBuildDate>
        <ttl>120</ttl>
        
        <item>
            <title><![CDATA[Unlocking Anticipatory Text Generation: A Constrained Approach for Faithful Decoding with Large Language Models]]></title>
            <description><![CDATA[Large Language Models (LLMs) have demonstrated a powerful ability for text generation. However, achieving optimal results with a given prompt or instruction can be challenging, especially for billion-sized models. Additionally, undesired behaviors such as toxicity or hallucinations can manifest. While much larger models (e.g., ChatGPT) may demonstrate strength in mitigating these issues, there is still no guarantee of complete prevention. In this work, we propose formalizing text generation as a future-constrained generation problem to minimize undesirable behaviors and enforce faithfulness to instructions. The estimation of future constraint satisfaction, accomplished using LLMs, guides the text generation process. Our extensive experiments demonstrate the effectiveness of the proposed approach across three distinct text generation tasks: keyword-constrained generation (Lin et al., 2020), toxicity reduction (Gehman et al., 2020), and factual correctness in question-answering (Gao et al., 2023).]]></description>
            <pubDate>Tue, 12 Dec 2023 03:51:45 GMT</pubDate>
            <guid isPermaLink="false">https://arxiv.org/abs/2312.06149</guid>
            <link>https://arxiv.org/abs/2312.06149</link>
            
            
            
            <author><![CDATA[Lifu Tu, Semih Yavuz, Jin Qu, Jiacheng Xu, Rui Meng, Caiming Xiong, Yingbo Zhou]]></author>
            
                
            
            
        </item>
        
        <item>
            <title><![CDATA[From Text to Motion: Grounding GPT-4 in a Humanoid Robot "Alter3"]]></title>
            <description><![CDATA[We report the development of Alter3, a humanoid robot capable of generating spontaneous motion using a Large Language Model (LLM), specifically GPT-4. This achievement was realized by integrating GPT-4 into our proprietary android, Alter3, thereby effectively grounding the LLM with Alter's bodily movement. Typically, low-level robot control is hardware-dependent and falls outside the scope of LLM corpora, presenting challenges for direct LLM-based robot control. However, in the case of humanoid robots like Alter3, direct control is feasible by mapping the linguistic expressions of human actions onto the robot's body through program code. Remarkably, this approach enables Alter3 to adopt various poses, such as a 'selfie' stance or 'pretending to be a ghost,' and generate sequences of actions over time without explicit programming for each body part. This demonstrates the robot's zero-shot learning capabilities. Additionally, verbal feedback can adjust poses, obviating the need for fine-tuning. A video of Alter3's generated motions is available at https://tnoinkwms.github.io/ALTER-LLM/]]></description>
            <pubDate>Tue, 12 Dec 2023 03:07:45 GMT</pubDate>
            <guid isPermaLink="false">https://arxiv.org/abs/2312.06571</guid>
            <link>https://arxiv.org/abs/2312.06571</link>
            
            
            
            <author><![CDATA[Takahide Yoshida, Atsushi Masumori, Takashi Ikegami]]></author>
            
                
            
            
        </item>
        
        <item>
            <title><![CDATA[Context Tuning for Retrieval Augmented Generation]]></title>
            <description><![CDATA[Large language models (LLMs) have the remarkable ability to solve new tasks with just a few examples, but they need access to the right tools. Retrieval Augmented Generation (RAG) addresses this problem by retrieving a list of relevant tools for a given task. However, RAG's tool retrieval step requires all the required information to be explicitly present in the query. This is a limitation, as semantic search, the widely adopted tool retrieval method, can fail when the query is incomplete or lacks context. To address this limitation, we propose Context Tuning for RAG, which employs a smart context retrieval system to fetch relevant information that improves both tool retrieval and plan generation. Our lightweight context retrieval model uses numerical, categorical, and habitual usage signals to retrieve and rank context items. Our empirical results demonstrate that context tuning significantly enhances semantic search, achieving a 3.5-fold and 1.5-fold improvement in Recall@K for context retrieval and tool retrieval tasks respectively, and resulting in an 11.6% increase in LLM-based planner accuracy. Additionally, we show that our proposed lightweight model using Reciprocal Rank Fusion (RRF) with LambdaMART outperforms GPT-4 based retrieval. Moreover, we observe context augmentation at plan generation, even after tool retrieval, reduces hallucination.]]></description>
            <pubDate>Tue, 12 Dec 2023 03:02:28 GMT</pubDate>
            <guid isPermaLink="false">https://arxiv.org/abs/2312.05708</guid>
            <link>https://arxiv.org/abs/2312.05708</link>
            
            
            
            <author><![CDATA[Raviteja Anantha, Tharun Bethi, Danil Vodianik, Srinivas Chappidi]]></author>
            
                
            
            
        </item>
        
    </channel>
</rss>
