<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-03T22:06:24+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/JimZerChapirov</name><uri>https://www.reddit.com/user/JimZerChapirov</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj7j7y/using_lowerlevel_tools_makes_better_genai_apps_an/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/uWX5oFoKEnjBx53i5EEmGlw1iSAsf2On7x5mBJCG3ws.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2eb07213afc1aa854d453368c168981164872406&quot; alt=&quot;Using lower-level tools makes better GenAI apps: an alternative to the LangChain way&quot; title=&quot;Using lower-level tools makes better GenAI apps: an alternative to the LangChain way&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/JimZerChapirov&quot;&gt; /u/JimZerChapirov &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/VSfehUJUWQY&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj7j7y/using_lowerlevel_tools_makes_better_genai_apps_an/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cj7j7y</id><media:thumbnail url="https://external-preview.redd.it/uWX5oFoKEnjBx53i5EEmGlw1iSAsf2On7x5mBJCG3ws.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2eb07213afc1aa854d453368c168981164872406" /><link href="https://www.reddit.com/r/LangChain/comments/1cj7j7y/using_lowerlevel_tools_makes_better_genai_apps_an/" /><updated>2024-05-03T12:32:16+00:00</updated><published>2024-05-03T12:32:16+00:00</published><title>Using lower-level tools makes better GenAI apps: an alternative to the LangChain way</title></entry><entry><author><name>/u/hasteiswaste</name><uri>https://www.reddit.com/user/hasteiswaste</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m more or less completely new to LangChain, but I envision it as the best tool to solve the following task. What I&amp;#39;m trying to create is a script that takes two PDF documents, where one is the application criteria and the other is the application itself, and compares the content to determine what is omitted in one document and addressed in the other. It concerns a fairly extensive application procedure where it would be very useful to have autogenerated insights into what the application lacks.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve attempted to modify the script here with various prompts (&lt;a href=&quot;https://python.langchain.com/docs/integrations/toolkits/document%5C_comparison%5C_toolkit/&quot;&gt;https://python.langchain.com/docs/integrations/toolkits/document\_comparison\_toolkit/&lt;/a&gt;), and while I get somewhat useful responses, none of them manage to list the deficiencies in the application comprehensively. The document outlining the application criteria is structured with points, whereas the application document may have responses that overlap and are arranged in a way that makes it difficult to compare point by point.&lt;/p&gt; &lt;p&gt;Suggestions for approach or how to tackle the challenge would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hasteiswaste&quot;&gt; /u/hasteiswaste &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjkchx/comparing_two_documents_and_finding_the_diff/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjkchx/comparing_two_documents_and_finding_the_diff/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjkchx</id><link href="https://www.reddit.com/r/LangChain/comments/1cjkchx/comparing_two_documents_and_finding_the_diff/" /><updated>2024-05-03T21:57:44+00:00</updated><published>2024-05-03T21:57:44+00:00</published><title>Comparing two documents and finding the diff</title></entry><entry><author><name>/u/Designer_Athlete7286</name><uri>https://www.reddit.com/user/Designer_Athlete7286</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve tried to look for this in docs but couldn&amp;#39;t find any examples on how to do so. Is this possible in the first place? &lt;/p&gt; &lt;p&gt;My plan if to deploy a chatbot with tool access including a rag using LangServe. Do I need to make my cahtbot into a runnable chain using LCEL?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Designer_Athlete7286&quot;&gt; /u/Designer_Athlete7286 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjgce9/openai_tool_calling_agent_as_an_lcel_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjgce9/openai_tool_calling_agent_as_an_lcel_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjgce9</id><link href="https://www.reddit.com/r/LangChain/comments/1cjgce9/openai_tool_calling_agent_as_an_lcel_chain/" /><updated>2024-05-03T18:52:14+00:00</updated><published>2024-05-03T18:52:14+00:00</published><title>OpenAI Tool Calling Agent as an LCEL chain?</title></entry><entry><author><name>/u/Only-Requirement619</name><uri>https://www.reddit.com/user/Only-Requirement619</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I came across a gpt in OpenAI called stoic gpt. It’s based off the words of Marcus Ariellius, Seneca and a couple other prominent legends. I wanted to create a similar gpt with the words of some prominent athletes. I know the simple way would be to collect as much data and embed it into a custom gpt, but is there a better way to capture all data including from podcasts, yt etc &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Only-Requirement619&quot;&gt; /u/Only-Requirement619 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjfrvr/embedding_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjfrvr/embedding_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjfrvr</id><link href="https://www.reddit.com/r/LangChain/comments/1cjfrvr/embedding_data/" /><updated>2024-05-03T18:27:49+00:00</updated><published>2024-05-03T18:27:49+00:00</published><title>EMBEDDING data</title></entry><entry><author><name>/u/Calm-Number5851</name><uri>https://www.reddit.com/user/Calm-Number5851</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m sad to admit it, but the facts answer in the negative: AI devices are useless and unnecessary. At least not right now. I love unusual gadgets, actively follow what&amp;#39;s happening in the AR and VR world, and love testing new form factors. But the problem with AI devices is that our smartphones are very good, and it&amp;#39;s too hard to compete with them for a place in our pockets.&lt;/p&gt; &lt;p&gt;I see it this way: developers should think about how to create a gadget that goes beyond the devices we&amp;#39;re familiar with. Something similar is being done by Apple with the Vision Pro, as well as companies developing AR glasses and lenses. With these devices, we (well, sometimes) see clear advantages over smartphones and understand why we should buy them.&lt;/p&gt; &lt;blockquote&gt; &lt;/blockquote&gt; &lt;p&gt;Let&amp;#39;s wait a bit. Sooner or later, we&amp;#39;ll surely see someone who will change the way we think about AI devices. Again, I just hope so.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm-Number5851&quot;&gt; /u/Calm-Number5851 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjf7q8/ai_devices_will_never_be_useful/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjf7q8/ai_devices_will_never_be_useful/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjf7q8</id><link href="https://www.reddit.com/r/LangChain/comments/1cjf7q8/ai_devices_will_never_be_useful/" /><updated>2024-05-03T18:03:56+00:00</updated><published>2024-05-03T18:03:56+00:00</published><title>AI Devices Will Never be Useful?</title></entry><entry><author><name>/u/wiseduckling</name><uri>https://www.reddit.com/user/wiseduckling</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So I have a RAG app that&amp;#39;s working but I need to optimize it. &lt;/p&gt; &lt;p&gt;Right now I take a doc --&amp;gt; chunk it --&amp;gt; summarize chunks --&amp;gt; build page summaries and doc summarize from those chunks --&amp;gt; vectorize everything. &lt;/p&gt; &lt;p&gt;The docs are stored in an S3 bucket and the chunks + their vectors in redis. &lt;/p&gt; &lt;p&gt;I need to reduce the content I m storing in redis as it won&amp;#39;t scale in terms of cost so my plan is to only store the summaries and their vectors for each chunk, page, doc. &lt;/p&gt; &lt;p&gt;My question is then, after identifying the where the relevant content is, where should I pull that content from. Are you guys pulling it directly from PDF docs or storing it in a seperate SQL db somewhere else? I think a db will ultimately be less resource intensive but I m not sure thats the best approach. &lt;/p&gt; &lt;p&gt;db process would be:&lt;br/&gt; Identify where relevant content is through vector search on redis.&lt;br/&gt; Pull rows in the db referenced by redis with the content. &lt;/p&gt; &lt;p&gt;accessing document directly:&lt;/p&gt; &lt;p&gt;Identify relevant content (doc, page, paragraphs)&lt;br/&gt; Get pdf from s3, pull relevant content&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/wiseduckling&quot;&gt; /u/wiseduckling &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj5fbp/where_do_you_pull_your_content_from_for_feeding/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj5fbp/where_do_you_pull_your_content_from_for_feeding/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cj5fbp</id><link href="https://www.reddit.com/r/LangChain/comments/1cj5fbp/where_do_you_pull_your_content_from_for_feeding/" /><updated>2024-05-03T10:35:57+00:00</updated><published>2024-05-03T10:35:57+00:00</published><title>Where do you pull your content from for feeding context in your RAG app?</title></entry><entry><author><name>/u/the-room-is-on-fire</name><uri>https://www.reddit.com/user/the-room-is-on-fire</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’m interested in building a RAG tool for internal company documents, and I intend on using a locally hosted LLM using ollama or LMstudio. From what I can tell, there wouldn’t be any data privacy concerns so long as I’m not using an API key for some LLM, but I’m not completely sure. Would my company’s data be secure?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/the-room-is-on-fire&quot;&gt; /u/the-room-is-on-fire &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj9nbx/langchain_for_data_privacy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj9nbx/langchain_for_data_privacy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cj9nbx</id><link href="https://www.reddit.com/r/LangChain/comments/1cj9nbx/langchain_for_data_privacy/" /><updated>2024-05-03T14:10:49+00:00</updated><published>2024-05-03T14:10:49+00:00</published><title>Langchain for data privacy?</title></entry><entry><author><name>/u/MidnightCS172</name><uri>https://www.reddit.com/user/MidnightCS172</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; If you&amp;#39;re a founder / enthusiast / just curious about the AI space, you can try using Llama 3 to automate your work.&lt;/p&gt; &lt;p&gt;Hey everyone! Launched my SaaS a few months back that helps businesses integrate AI.&lt;/p&gt; &lt;p&gt;Just wanted to share that we&amp;#39;re now housing Llama 3 for free thanks to a recent partnership!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;For those who are new to AI and ask why Llama 3? Why not GPT?&lt;/strong&gt;- open-sourced (you essentially can&amp;#39;t get locked out / censored)- higher standard benchmark than GPT 4 &lt;a href=&quot;https://www.techrepublic.com/article/what-is-llama-3/#&quot;&gt;(81.7 vs 67)&lt;/a&gt;- better code generation / lower misinformation rate- affordable / cost-efficient&lt;/p&gt; &lt;p&gt;Weave was made to be intuitive to non-coders, so don&amp;#39;t be too worried if coding isn&amp;#39;t your thing. Just select Llama 3 in the LLM library and input your instructions as you would in GPT 4 to test it out.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the link if anyone&amp;#39;s interested,&lt;a href=&quot;https://weave.chasm.net/&quot;&gt;https://weave.chasm.net/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MidnightCS172&quot;&gt; /u/MidnightCS172 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj9hbt/free_llama_3_workflow_builder/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj9hbt/free_llama_3_workflow_builder/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cj9hbt</id><link href="https://www.reddit.com/r/LangChain/comments/1cj9hbt/free_llama_3_workflow_builder/" /><updated>2024-05-03T14:03:33+00:00</updated><published>2024-05-03T14:03:33+00:00</published><title>Free Llama 3 Workflow Builder</title></entry><entry><author><name>/u/Unrealnooob</name><uri>https://www.reddit.com/user/Unrealnooob</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to build a chatbot with Langchain ,Flask and angular, How do I stream the data with the source documents?&lt;br/&gt; this is my chain&lt;/p&gt; &lt;pre&gt;&lt;code&gt; chain = ConversationalRetrievalChain.from_llm( llm=llm, retriever=retriever, combine_docs_chain_kwargs={&amp;quot;prompt&amp;quot;: qa_prompt}, verbose=True, memory=memory, return_source_documents=True ) result= chain.invoke({&amp;quot;question&amp;quot;: question}) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I tried with SSE, couldn&amp;#39;t make it work,ig its better to go with flask socket io, dk how to go with that, any help will be appreciated&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Unrealnooob&quot;&gt; /u/Unrealnooob &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj349m/how_do_i_stream_with_flask_and_langchain_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj349m/how_do_i_stream_with_flask_and_langchain_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cj349m</id><link href="https://www.reddit.com/r/LangChain/comments/1cj349m/how_do_i_stream_with_flask_and_langchain_with/" /><updated>2024-05-03T07:55:05+00:00</updated><published>2024-05-03T07:55:05+00:00</published><title>How do i stream with Flask and Langchain with Socket.io</title></entry><entry><author><name>/u/help-me-grow</name><uri>https://www.reddit.com/user/help-me-grow</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/help-me-grow&quot;&gt; /u/help-me-grow &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/AI_Agents/comments/1ciraov/seven_starter_notebooks_for_ai_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cirbgb/seven_starter_notebooks_for_ai_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cirbgb</id><link href="https://www.reddit.com/r/LangChain/comments/1cirbgb/seven_starter_notebooks_for_ai_agents/" /><updated>2024-05-02T21:25:47+00:00</updated><published>2024-05-02T21:25:47+00:00</published><title>Seven starter notebooks for AI Agents</title></entry><entry><author><name>/u/Wild_Plantain528</name><uri>https://www.reddit.com/user/Wild_Plantain528</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I made an open-source tool (k8sAI) using langchain agents. One of the issues I’ve seen is that the agent pretty often responds to users that it can’t perform an action that one of its tools clearly states that it can. And then if asked to do it, it will do it. &lt;/p&gt; &lt;p&gt;Has anyone else seen this come up? Is it mainly down to the system prompt or the tool description? Or are there other things to tweak?&lt;/p&gt; &lt;p&gt;Appreciate any advice and if you do any work with k8s, feel free to give the tool a go! It’s on GitHub.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Wild_Plantain528&quot;&gt; /u/Wild_Plantain528 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1civdv4/suggestions_for_improving_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1civdv4/suggestions_for_improving_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1civdv4</id><link href="https://www.reddit.com/r/LangChain/comments/1civdv4/suggestions_for_improving_agents/" /><updated>2024-05-03T00:29:56+00:00</updated><published>2024-05-03T00:29:56+00:00</published><title>Suggestions for improving agents</title></entry><entry><author><name>/u/OGbeeper99</name><uri>https://www.reddit.com/user/OGbeeper99</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, I have built a RAG application using llama-index, GPT3.5 and LanceDB. I want to integrate it into my company’s website. I wanted to know how can I do this? I’m open to using AWS if required for deploying it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OGbeeper99&quot;&gt; /u/OGbeeper99 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cimzf9/integrating_rag_app_into_an_existing_html_website/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cimzf9/integrating_rag_app_into_an_existing_html_website/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cimzf9</id><link href="https://www.reddit.com/r/LangChain/comments/1cimzf9/integrating_rag_app_into_an_existing_html_website/" /><updated>2024-05-02T18:29:33+00:00</updated><published>2024-05-02T18:29:33+00:00</published><title>Integrating RAG app into an existing HTML website</title></entry><entry><author><name>/u/Binary-Blue</name><uri>https://www.reddit.com/user/Binary-Blue</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciz0n1/issue_with_tool_naming_in_nlatoolkit/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/evqW4t9IDxVptNQFkghbNiP1zkIa8PQfSM5Qkv3eTTk.jpg&quot; alt=&quot;Issue with tool naming in NLA-Toolkit&quot; title=&quot;Issue with tool naming in NLA-Toolkit&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi I&amp;#39;m trying to use an open-api spec with the NLA toolkit but i get the below error: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;openai.BadRequestError: Error code: 400 - {&amp;#39;error&amp;#39;: {&amp;#39;message&amp;#39;: &amp;quot;&amp;#39;Ingress_API_v1.events&amp;#39; does not match &amp;#39;^[a-zA-Z0-9_-]{1,64}$&amp;#39; - &amp;#39;tools.1.function.name&amp;#39;&amp;quot;, &amp;#39;type&amp;#39;: &amp;#39;invalid_request_error&amp;#39;, &amp;#39;param&amp;#39;: None, &amp;#39;code&amp;#39;: None}} &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I believe this is because there is a &lt;/p&gt; &lt;pre&gt;&lt;code&gt;. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;in the tool name and that does not match the validation regex &lt;/p&gt; &lt;pre&gt;&lt;code&gt;^[a-zA-Z0-9_-]{1,64}$ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;? But when i did do some digging i found that the period is added intentionally by one of the tool creator functions , not sure if we need to update the regex or the naming str template?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/axm51v8dt4yc1.png?width=2228&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ad0d90e441d8ebb61611a1fe6f761543a5b22dfc&quot;&gt;https://preview.redd.it/axm51v8dt4yc1.png?width=2228&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ad0d90e441d8ebb61611a1fe6f761543a5b22dfc&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Binary-Blue&quot;&gt; /u/Binary-Blue &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciz0n1/issue_with_tool_naming_in_nlatoolkit/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciz0n1/issue_with_tool_naming_in_nlatoolkit/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ciz0n1</id><media:thumbnail url="https://b.thumbs.redditmedia.com/evqW4t9IDxVptNQFkghbNiP1zkIa8PQfSM5Qkv3eTTk.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1ciz0n1/issue_with_tool_naming_in_nlatoolkit/" /><updated>2024-05-03T03:36:44+00:00</updated><published>2024-05-03T03:36:44+00:00</published><title>Issue with tool naming in NLA-Toolkit</title></entry><entry><author><name>/u/mathieumaxime</name><uri>https://www.reddit.com/user/mathieumaxime</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m wondering if Langchain is made to build a chatbot with own trained data. I want to train a chabot with my company data. Similaire to GPTs, is it the good solution ? Thank you&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mathieumaxime&quot;&gt; /u/mathieumaxime &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciqzuc/building_chatbot_with_own_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciqzuc/building_chatbot_with_own_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ciqzuc</id><link href="https://www.reddit.com/r/LangChain/comments/1ciqzuc/building_chatbot_with_own_data/" /><updated>2024-05-02T21:12:10+00:00</updated><published>2024-05-02T21:12:10+00:00</published><title>Building chatbot with own data</title></entry><entry><author><name>/u/Healthy-Succotash458</name><uri>https://www.reddit.com/user/Healthy-Succotash458</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;br/&gt; I am creating an Agent RAG chatbot application which uses Tools.&lt;br/&gt; An example of the documents I expect to retrieve: &lt;/p&gt; &lt;p&gt;&lt;code&gt;Document(page_content=&amp;#39;Contents of lecture 1&amp;#39;, metadata={&amp;#39;source&amp;#39;: &amp;#39;Lecture-1.pdf&amp;#39;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;and the user&amp;#39;s request will look something like:&lt;/p&gt; &lt;p&gt;&lt;code&gt;Input(query=&amp;#39;summarize this lecture&amp;#39;,document_chosen=&amp;#39;Lecture-1.pdf&amp;#39;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;and I need to search ONLY on documents with the metadata source equal to &amp;#39;Lecture-1.pdf&amp;#39;.&lt;/p&gt; &lt;p&gt;I have seen in tutorials about VectorStoreRetrievers having this filtering functionality this way:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Use a filter to only retrieve documents from a specific metadata field db.as_retriever( search_kwargs={&amp;#39;filter&amp;#39;: {&amp;#39;source&amp;#39;:&amp;#39;Lecture-1.pdf&amp;#39;}} ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and this would solve the issue if I was directly invoking the retrievers. However for Agent, I cannot use the retrievers directly, and I need to wrap the retriever in a Tool (using create_retriever_tool) in order to use the agent and run a query: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain.tools.retriever import create_retriever_tool search_tool = create_retriever_tool( lecture_retriever, &amp;quot;search_lecture_database&amp;quot;, &amp;quot;&amp;quot;&amp;quot;Searches and returns lecture information.&amp;quot;&amp;quot;&amp;quot;, ) tools = [search_tool] agent = create_react_agent(llm,tools,prompt) agent_executor = AgentExecutor(agent=agent, tools=tools) response = agent_executor.invoke({&amp;quot;input&amp;quot;:&amp;quot;Summarise this lecture&amp;quot;}) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;So with my setup, how can I pass the metadata (in this case, the name of the file) filter to the retrievers from the Agent, when the retrievers are converted to Tools? &lt;/p&gt; &lt;p&gt;Any help or comments would be much appreciated&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Healthy-Succotash458&quot;&gt; /u/Healthy-Succotash458 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciizv7/agents_rag_search_with_tools_using_metadata/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciizv7/agents_rag_search_with_tools_using_metadata/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ciizv7</id><link href="https://www.reddit.com/r/LangChain/comments/1ciizv7/agents_rag_search_with_tools_using_metadata/" /><updated>2024-05-02T15:47:25+00:00</updated><published>2024-05-02T15:47:25+00:00</published><title>Agents: RAG search with tools using Metadata Filtering</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for a vectorDB for a RAG that am building. Needs to ingest a lot of data and should be optimized for retrieval. What are my options ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cijx8f</id><link href="https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/" /><updated>2024-05-02T16:24:21+00:00</updated><published>2024-05-02T16:24:21+00:00</published><title>What vectorDB do you all use?</title></entry><entry><author><name>/u/Standard_Vehicle_29</name><uri>https://www.reddit.com/user/Standard_Vehicle_29</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building a RAG based chatbot for some geographical data, can someone suggested me what kind of testing can I do to validate the chatbot &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Standard_Vehicle_29&quot;&gt; /u/Standard_Vehicle_29 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cisa8u/testing_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cisa8u/testing_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cisa8u</id><link href="https://www.reddit.com/r/LangChain/comments/1cisa8u/testing_rag_chatbot/" /><updated>2024-05-02T22:06:42+00:00</updated><published>2024-05-02T22:06:42+00:00</published><title>Testing RAG chatbot</title></entry><entry><author><name>/u/Junior_Reward2594</name><uri>https://www.reddit.com/user/Junior_Reward2594</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building an RAG system with over 100,000 startup pitch decks, and I want to be able to ask questions related to the graphs, diagrams, and illustrations in the pitch deck. For example, if I have a competitor slide with an x- and y-axis, I want my RAG system to understand that.&lt;/p&gt; &lt;p&gt;Is there something like a visual parser that can extract the visual meaning from each slide, chunk + embed it?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Junior_Reward2594&quot;&gt; /u/Junior_Reward2594 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciryrj/help_how_do_you_parse_visual_content_from_pitch/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciryrj/help_how_do_you_parse_visual_content_from_pitch/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ciryrj</id><link href="https://www.reddit.com/r/LangChain/comments/1ciryrj/help_how_do_you_parse_visual_content_from_pitch/" /><updated>2024-05-02T21:53:19+00:00</updated><published>2024-05-02T21:53:19+00:00</published><title>Help: How do you parse visual content from pitch decks for RAG?</title></entry><entry><author><name>/u/Brave-Guide-7470</name><uri>https://www.reddit.com/user/Brave-Guide-7470</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/e41kBpbrClfdwFjhQbFO0lBPyR2D-CYfc9oUqEt2ksQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3aa90a5396a7a8ad789e42874ec0066d7974dc44&quot; alt=&quot;Test your prompts through the terminal&quot; title=&quot;Test your prompts through the terminal&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys!&lt;/p&gt; &lt;p&gt;I&amp;#39;ve developed a helper CLI tool that allows you to test prompts on both ChatGPT and Anthropic models through a simple API.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/56s9aibuc0yc1.png?width=1597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d5408e2cd05ff382ea671c0816b67567cd53cbf0&quot;&gt;https://preview.redd.it/56s9aibuc0yc1.png?width=1597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d5408e2cd05ff382ea671c0816b67567cd53cbf0&lt;/a&gt;&lt;/p&gt; &lt;p&gt;To test it, just run:&lt;/p&gt; &lt;p&gt;pip install dialog-lib&lt;/p&gt; &lt;p&gt;export OPENAI_API_KEY=sk-YOUR_API_KEY&lt;/p&gt; &lt;p&gt;dialog openai --prompt &amp;quot;Your prompt that you want to test, here!&amp;quot;&lt;/p&gt; &lt;p&gt;Here is a link to a quick demo: &lt;a href=&quot;https://www.linkedin.com/feed/update/urn:li:activity:7191776208651489282/&quot;&gt;https://www.linkedin.com/feed/update/urn:li:activity:7191776208651489282/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Brave-Guide-7470&quot;&gt; /u/Brave-Guide-7470 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cielku</id><media:thumbnail url="https://external-preview.redd.it/e41kBpbrClfdwFjhQbFO0lBPyR2D-CYfc9oUqEt2ksQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3aa90a5396a7a8ad789e42874ec0066d7974dc44" /><link href="https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/" /><updated>2024-05-02T12:37:09+00:00</updated><published>2024-05-02T12:37:09+00:00</published><title>Test your prompts through the terminal</title></entry><entry><author><name>/u/PinstripePride97</name><uri>https://www.reddit.com/user/PinstripePride97</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Connection does work well as it print db dialect, but the get_usable_table_names method returns an empty list. Any idea?&lt;/p&gt; &lt;pre&gt;&lt;code&gt;db = SQLDatabase.from_uri(f&amp;quot;postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{5432}/{db_name}&amp;quot;) print(db.dialect) print(db.get_usable_table_names()) print(db.table_info) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/PinstripePride97&quot;&gt; /u/PinstripePride97 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cioz1a/get_usable_table_names_is_returning_me_nothing/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cioz1a/get_usable_table_names_is_returning_me_nothing/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cioz1a</id><link href="https://www.reddit.com/r/LangChain/comments/1cioz1a/get_usable_table_names_is_returning_me_nothing/" /><updated>2024-05-02T19:50:14+00:00</updated><published>2024-05-02T19:50:14+00:00</published><title>get_usable_table_names is returning me nothing. Also, in the database there are multiple schemas and I want one in specific.</title></entry><entry><author><name>/u/ThickDoctor007</name><uri>https://www.reddit.com/user/ThickDoctor007</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How does reindexing a vector store impact the addition of new records and their subsequent retrieval? What are the key differences between reindexing and not reindexing when new records are added?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ThickDoctor007&quot;&gt; /u/ThickDoctor007 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cioq40/vectorstore_reindexing/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cioq40/vectorstore_reindexing/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cioq40</id><link href="https://www.reddit.com/r/LangChain/comments/1cioq40/vectorstore_reindexing/" /><updated>2024-05-02T19:40:25+00:00</updated><published>2024-05-02T19:40:25+00:00</published><title>Vectorstore reindexing</title></entry><entry><author><name>/u/machka_nip</name><uri>https://www.reddit.com/user/machka_nip</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’ve been researching Langchain Agents and really interested in the verbose feature to show chain of thought when script is running. The thing is, I’m lost over tools/toolkits and the examples I found seem to be just for tool/toolkits with an LLM. I didn’t find any examples that encompass loading documents (eg PDF, CSV, etc.), embedding and vectorizing with FAISS, using OpenAI to ask questions with the retriever. &lt;/p&gt; &lt;p&gt;Does Langchain Agents only do LLM and tool(/kits)? I’ve tried simple keyword search in Google. ChatGPT was not great because it doesn’t know the Langchain library. It would give a code snippet that wasn’t even valid when ran (like modules not existent). &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/machka_nip&quot;&gt; /u/machka_nip &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cilwu1/creating_agent_with_document_loader_retriever_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cilwu1/creating_agent_with_document_loader_retriever_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cilwu1</id><link href="https://www.reddit.com/r/LangChain/comments/1cilwu1/creating_agent_with_document_loader_retriever_llm/" /><updated>2024-05-02T17:46:35+00:00</updated><published>2024-05-02T17:46:35+00:00</published><title>Creating Agent with document loader, retriever, LLM, output parser?</title></entry><entry><author><name>/u/yadgire7</name><uri>https://www.reddit.com/user/yadgire7</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Task: Query a CSV file (without using built-in agents)&lt;/p&gt; &lt;p&gt;Input: CSV file&lt;/p&gt; &lt;p&gt;Output: JSON object like{&amp;quot;column&amp;quot;: , &amp;quot;value&amp;quot; , &amp;quot;row_ids&amp;quot;:}&lt;/p&gt; &lt;p&gt;If I embed the data and use a retriever on the vectorestore using similarity_search, I do not get all the matching instances in my result (as I cannot just use a very large k value). I used the &amp;#39;parser&amp;#39; approach and got decent results. Can anyone suggest a better approach to get more accurate results?&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/yadgire7&quot;&gt; /u/yadgire7 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciltz6/chunk_csv_data_to_create_a_vectorstore/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciltz6/chunk_csv_data_to_create_a_vectorstore/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ciltz6</id><link href="https://www.reddit.com/r/LangChain/comments/1ciltz6/chunk_csv_data_to_create_a_vectorstore/" /><updated>2024-05-02T17:43:17+00:00</updated><published>2024-05-02T17:43:17+00:00</published><title>Chunk CSV Data to create a vectorstore</title></entry><entry><author><name>/u/AnEdgeLordWeeb</name><uri>https://www.reddit.com/user/AnEdgeLordWeeb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! So for context, I&amp;#39;m trying to develop a simple chatbot the offers personalized video games recommendations based on user input, by searching the internet for the top results and then use them as an answer to the user. Initially, I started this using one single agent, but as more ideas came into my mind, I think sticking with only one agent and try to implement those into code my result in some issues, specifically when it comes to the number of tokens. So I&amp;#39;ve decided instead to leverage LangGraph in order to adopt the multi-agent way and thus some myself from some trouble. Here is what I was thinking about when it comes to the agents I have thought of and their objective: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Input Agent (Agent 1)&lt;/strong&gt;: This agent receives the initial user input, interprets the user&amp;#39;s query, and dispatches tasks to other specialized agents.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Search Agent (Agent 2)&lt;/strong&gt;: Receives tasks from Agent 1 to perform initial searches for game titles.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Details Agent (Agent 3)&lt;/strong&gt;: Fetches detailed information for each game identified by Agent 2.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Posters and Trailers Agents (Agent 4 and 5)&lt;/strong&gt;: Responsible for fetching official posters and official video trailers for the games identified.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Then I was thinking of sending all the details from Agent 2, 3, 4 and 5 to a core agent responsible for formatting a response based on them and then display them to the user.&lt;/p&gt; &lt;p&gt;Problem is, so far, I keep failing in my attempt to move from LangChain to LangGraph whilst trying to implement these ideas into code.&lt;/p&gt; &lt;p&gt;Can anyone please help? I would really, really, appreciate some help with the implementation of this.&lt;/p&gt; &lt;p&gt;This is how my current LangChain code looks right now:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import os from dotenv import load_dotenv from langchain_openai import ChatOpenAI from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain.agents import AgentExecutor, create_openai_tools_agent, Tool from langchain_core.runnables.history import RunnableWithMessageHistory from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory from serpapi import GoogleSearch # Load environment variables for API keys load_dotenv() # SerpAPI and MongoDB configuration serpapi_key = os.getenv(&amp;quot;SERPAPI_API_KEY&amp;quot;) mongo_connection_string = &amp;quot;mongodb://localhost:27017&amp;quot; database_name = &amp;quot;chatbot_db&amp;quot; collection_name = &amp;quot;chat_histories&amp;quot; # Define the function that will use SerpApi to perform searches def perform_serpapi_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key, &amp;quot;num&amp;quot;: 5, } search = GoogleSearch(params) results = search.get_dict() return results # Create the SerpApi tool to pass to an agent serpapi_tool = Tool( name=&amp;quot;serpapi_search&amp;quot;, description=&amp;quot;Performs Google searches using SerpApi.&amp;quot;, func=perform_serpapi_search ) # Setup the ChatOpenAI model for conversational interactions chat = ChatOpenAI( model=&amp;#39;gpt-3.5-turbo-1106&amp;#39;, temperature=0 ) # Define a comprehensive prompt template for handling game recommendations game_recommendation_prompt = ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, &amp;quot;&amp;quot;&amp;quot; You are a sophisticated AI trained to recommend video games. Your tasks include: - Provide game suggestions similar to ones the user enjoys or mentions, covering various genres and platforms. - Recommend games based on specific genres or mentioned developers/publishers. - Identify and suggest top-trending and highly rated video games, including acclaimed titles from specific time periods. - Tailor recommendations according to user-defined preferences, such as complexity, time investment, and progression style. - Recommend games suitable for specified platforms (e.g., PlayStation, Xbox, PC, Switch) or fitting certain age ratings (e.g., E, T, M). - Replace played or unappealing games with suitable alternatives. - For each recommended game, provide: title, brief description, genre, platform, developer, publisher, release date, Metacritic score (if available), and purchase links from digital storefronts. - Politely request more specific information for ambiguous queries. - Guide users back to gaming-related topics for unrelated queries. - Maintain a friendly and engaging tone throughout interactions. - Utilize the SerpAPI search tool for up-to-date and accurate recommendations in each response to user queries. (VERY IMPORTANT!!!) Ensure clarity, conciseness, and engagement in your responses to enhance the user experience. &amp;quot;&amp;quot;&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;chat_history&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;), ] ) # Setup tools for agent tools = [serpapi_tool] # Create an OpenAI tools agent for handling game recommendations game_recommendation_agent = create_openai_tools_agent(chat, tools, game_recommendation_prompt) # Setup the agent executor for managing operations agent_executor = AgentExecutor(agent=game_recommendation_agent, tools=tools, verbose=True) # Function to manage MongoDB-based message history for each session def get_message_history(session_id): return MongoDBChatMessageHistory( session_id=session_id, connection_string=mongo_connection_string, database_name=database_name, collection_name=collection_name, ) # Function to handle user queries def handle_user_query(session_id, user_input): &amp;quot;&amp;quot;&amp;quot; Process user queries by wrapping the executor with RunnableWithMessageHistory which processes various types of game recommendation requests and manages user interaction, maintaining a history of the conversation in MongoDB. &amp;quot;&amp;quot;&amp;quot; history_manager = RunnableWithMessageHistory( agent_executor, lambda session_id: get_message_history(session_id), input_messages_key=&amp;quot;input&amp;quot;, output_messages_key=&amp;quot;output&amp;quot;, history_messages_key=&amp;quot;chat_history&amp;quot;, ) # Execute the query with history management response = history_manager.invoke( {&amp;quot;input&amp;quot;: user_input}, {&amp;quot;configurable&amp;quot;: {&amp;quot;session_id&amp;quot;: session_id}} ) return response[&amp;#39;output&amp;#39;] def main(): session_id = &amp;quot;unique_user_session_id&amp;quot; # This should be uniquely generated for each user session print(&amp;quot;Welcome to the Game Recommendation Chatbot!&amp;quot;) while True: user_input = input(&amp;quot;You: &amp;quot;) if user_input.lower() == &amp;#39;exit&amp;#39;: print(&amp;quot;Exiting chatbot...&amp;quot;) break response = handle_user_query(session_id, user_input) print(&amp;quot;Bot:&amp;quot;, response) if __name__ == &amp;quot;__main__&amp;quot;: main() import os from dotenv import load_dotenv from langchain_openai import ChatOpenAI from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain.agents import AgentExecutor, create_openai_tools_agent, Tool from langchain_core.runnables.history import RunnableWithMessageHistory from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory from serpapi import GoogleSearch # Load environment variables for API keys load_dotenv() # SerpAPI and MongoDB configuration serpapi_key = os.getenv(&amp;quot;SERPAPI_API_KEY&amp;quot;) mongo_connection_string = &amp;quot;mongodb://localhost:27017&amp;quot; database_name = &amp;quot;chatbot_db&amp;quot; collection_name = &amp;quot;chat_histories&amp;quot; # Define the function that will use SerpApi to perform searches def perform_serpapi_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key, &amp;quot;num&amp;quot;: 5, } search = GoogleSearch(params) results = search.get_dict() return results # Create the SerpApi tool to pass to an agent serpapi_tool = Tool( name=&amp;quot;serpapi_search&amp;quot;, description=&amp;quot;Performs Google searches using SerpApi.&amp;quot;, func=perform_serpapi_search ) # Setup the ChatOpenAI model for conversational interactions chat = ChatOpenAI( model=&amp;#39;gpt-3.5-turbo-1106&amp;#39;, temperature=0 ) # Define a comprehensive prompt template for handling game recommendations game_recommendation_prompt = ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, &amp;quot;&amp;quot;&amp;quot; You are a sophisticated AI trained to recommend video games. Your tasks include: - Provide game suggestions similar to ones the user enjoys or mentions, covering various genres and platforms. - Recommend games based on specific genres or mentioned developers/publishers. - Identify and suggest top-trending and highly rated video games, including acclaimed titles from specific time periods. - Tailor recommendations according to user-defined preferences, such as complexity, time investment, and progression style. - Recommend games suitable for specified platforms (e.g., PlayStation, Xbox, PC, Switch) or fitting certain age ratings (e.g., E, T, M). - Replace played or unappealing games with suitable alternatives. - For each recommended game, provide: title, brief description, genre, platform, developer, publisher, release date, Metacritic score (if available), and purchase links from digital storefronts. - Politely request more specific information for ambiguous queries. - Guide users back to gaming-related topics for unrelated queries. - Maintain a friendly and engaging tone throughout interactions. - Utilize the SerpAPI search tool for up-to-date and accurate recommendations in each response to user queries. (VERY IMPORTANT!!!) Ensure clarity, conciseness, and engagement in your responses to enhance the user experience. &amp;quot;&amp;quot;&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;chat_history&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;), ] ) # Setup tools for agent tools = [serpapi_tool] # Create an OpenAI tools agent for handling game recommendations game_recommendation_agent = create_openai_tools_agent(chat, tools, game_recommendation_prompt) # Setup the agent executor for managing operations agent_executor = AgentExecutor(agent=game_recommendation_agent, tools=tools, verbose=True) # Function to manage MongoDB-based message history for each session def get_message_history(session_id): return MongoDBChatMessageHistory( session_id=session_id, connection_string=mongo_connection_string, database_name=database_name, collection_name=collection_name, ) # Function to handle user queries def handle_user_query(session_id, user_input): &amp;quot;&amp;quot;&amp;quot; Process user queries by wrapping the executor with RunnableWithMessageHistory which processes various types of game recommendation requests and manages user interaction, maintaining a history of the conversation in MongoDB. &amp;quot;&amp;quot;&amp;quot; history_manager = RunnableWithMessageHistory( agent_executor, lambda session_id: get_message_history(session_id), input_messages_key=&amp;quot;input&amp;quot;, output_messages_key=&amp;quot;output&amp;quot;, history_messages_key=&amp;quot;chat_history&amp;quot;, ) # Execute the query with history management response = history_manager.invoke( {&amp;quot;input&amp;quot;: user_input}, {&amp;quot;configurable&amp;quot;: {&amp;quot;session_id&amp;quot;: session_id}} ) return response[&amp;#39;output&amp;#39;] def main(): session_id = &amp;quot;unique_user_session_id&amp;quot; # This should be uniquely generated for each user session print(&amp;quot;Welcome to the Game Recommendation Chatbot!&amp;quot;) while True: user_input = input(&amp;quot;You: &amp;quot;) if user_input.lower() == &amp;#39;exit&amp;#39;: print(&amp;quot;Exiting chatbot...&amp;quot;) break response = handle_user_query(session_id, user_input) print(&amp;quot;Bot:&amp;quot;, response) if __name__ == &amp;quot;__main__&amp;quot;: main() &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnEdgeLordWeeb&quot;&gt; /u/AnEdgeLordWeeb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cilpbt/need_help_to_convert_my_singleagent_project_into/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cilpbt/need_help_to_convert_my_singleagent_project_into/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cilpbt</id><link href="https://www.reddit.com/r/LangChain/comments/1cilpbt/need_help_to_convert_my_singleagent_project_into/" /><updated>2024-05-02T17:37:40+00:00</updated><published>2024-05-02T17:37:40+00:00</published><title>Need help to convert my single-agent project into a multi-agent one</title></entry><entry><author><name>/u/aryanmadhavverma</name><uri>https://www.reddit.com/user/aryanmadhavverma</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have an agent with two tools. The tools are being used in a sequential way. The second tool queries the database and returns in a pydantic format I&amp;#39;ve defined myself. Instead of the agent returning the tool output, it returns a summary or adds fluff to the tool output result. I only want it to return the tool output! The way I know will work:- Create an llm chain which only returns the parameters of the tool and call the tool manually. But this reduces the agentic behaviour of my functionality.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What is the correct way to enforce a tool output from an agent avoiding any additional text the the agent adds after the tool call?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;EDIT: return_direct = true doesn&amp;#39;t work. Gives error &lt;/p&gt; &lt;pre&gt;&lt;code&gt;Tools that have `return_direct=True` are not allowed in multi-action agents (type=value_error) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/aryanmadhavverma&quot;&gt; /u/aryanmadhavverma &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cibpk9/correct_way_to_return_tool_output_of_an_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cibpk9/correct_way_to_return_tool_output_of_an_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cibpk9</id><link href="https://www.reddit.com/r/LangChain/comments/1cibpk9/correct_way_to_return_tool_output_of_an_agent/" /><updated>2024-05-02T09:55:29+00:00</updated><published>2024-05-02T09:55:29+00:00</published><title>Correct way to return tool output of an agent executor instance?</title></entry></feed>