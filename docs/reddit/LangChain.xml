<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-18T18:43:20+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/AbbreviationsPale867</name><uri>https://www.reddit.com/user/AbbreviationsPale867</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey I was using langhchain before the 0.1.0 update and I&amp;#39;m using it in a project that will go live soon, however I want to move to 0.1.0 but my custom agent completely breaks and I feel like LangSmith is my only option. Is there a way to get an invite code as I have been on the wait list for a bit.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AbbreviationsPale867&quot;&gt; /u/AbbreviationsPale867 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199nbwa/langsmith/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199nbwa/langsmith/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199nbwa</id><link href="https://www.reddit.com/r/LangChain/comments/199nbwa/langsmith/" /><updated>2024-01-18T10:42:18+00:00</updated><published>2024-01-18T10:42:18+00:00</published><title>Langsmith</title></entry><entry><author><name>/u/Vegetable-Scene-6365</name><uri>https://www.reddit.com/user/Vegetable-Scene-6365</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199rxcn/getting_value_is_not_a_valid_dict_typetype/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/oc4Odb2FOMKa_qTu6wou2wUQQRVu7UknFFCnFuB93sQ.jpg&quot; alt=&quot;Getting &amp;quot;value is not a valid dict (type=type_error.dict)&amp;quot;&quot; title=&quot;Getting &amp;quot;value is not a valid dict (type=type_error.dict)&amp;quot;&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;docsearch_in_os = OpenSearchVectorSearch( &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;opensearch_url=os.environ.get(&amp;quot;OPENSEARCH_URL&amp;quot;), index_name=index_name, embedding_function=bedrock_embeddings, http_auth=auth, timeout=30, use_ssl=True, verify_certs=True, connection_class=RequestsHttpConnection, is_aoss=True, ) print(user_input) print(docsearch_in_os) chain = RetrievalQA.from_chain_type( llm=llm, chain_type=&amp;quot;stuff&amp;quot;, retriever=docsearch_in_os.as_retriever(), return_source_documents=False, chain_type_kwargs={&amp;quot;prompt&amp;quot;: PROMPT}, ) result = chain({&amp;quot;query&amp;quot;: user_input}) print(result) answer = result[&amp;quot;result&amp;quot;]&lt;/p&gt; &lt;p&gt;The above block of code is working fine with the opensearch vector store I created manually via Sagemaker. But somehow, the same piece of code isn&amp;#39;t working when the Opensearch vector store is created via The AWS Bedrock Console. I am getting error:&lt;br/&gt; &amp;quot;value is not a valid dict (type=type_error.dict)&amp;quot;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/qd5en8unp7dc1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=af4809165591a12514aa05ade0a8eef29de23e1d&quot;&gt;https://preview.redd.it/qd5en8unp7dc1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=af4809165591a12514aa05ade0a8eef29de23e1d&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Vegetable-Scene-6365&quot;&gt; /u/Vegetable-Scene-6365 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199rxcn/getting_value_is_not_a_valid_dict_typetype/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199rxcn/getting_value_is_not_a_valid_dict_typetype/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_199rxcn</id><media:thumbnail url="https://b.thumbs.redditmedia.com/oc4Odb2FOMKa_qTu6wou2wUQQRVu7UknFFCnFuB93sQ.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/199rxcn/getting_value_is_not_a_valid_dict_typetype/" /><updated>2024-01-18T14:54:13+00:00</updated><published>2024-01-18T14:54:13+00:00</published><title>Getting &quot;value is not a valid dict (type=type_error.dict)&quot;</title></entry><entry><author><name>/u/Icy-Employee6667</name><uri>https://www.reddit.com/user/Icy-Employee6667</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m reaching out because I&amp;#39;m having a frustrating issue with LangChain and ChromaDB, and I could really use some help from those more experienced than myself. Here&amp;#39;s my situation:&lt;/p&gt; &lt;p&gt;I have thousands of text documents that contain detailed information, and I&amp;#39;m trying to utilize LangChain and ChromaDB (BAAI/bge-large-en-v1.5) to extract meaningful insights from them. The problem I&amp;#39;m encountering is that when I run the pipeline, it keeps fetching the wrong details for certain cases.&lt;/p&gt; &lt;p&gt;For example, let&amp;#39;s say I have a case number &amp;quot;P L D 1949 Dacca 13&amp;quot;. Instead of retrieving the relevant information for that specific case, the model returns the details for &amp;quot;P L D 1949 Dacca 30&amp;quot; instead. This is happening consistently across many documents, and I&amp;#39;m at a loss as to why this is occurrcing.&lt;/p&gt; &lt;p&gt;Here are some additional details about my setup and process:&lt;/p&gt; &lt;p&gt;* I&amp;#39;m relatively new to LangChain, so please bear with me if my mistake is obvious.&lt;/p&gt; &lt;p&gt;* I&amp;#39;ve followed the instructions provided by the LangChain team for setting up the environment and running the pipeline.&lt;/p&gt; &lt;p&gt;* My dataset consists of plain text files containing various types of legal documents.&lt;/p&gt; &lt;p&gt;* I&amp;#39;m using the BAAI/bge-large-en-v1.5 model for text embedding&lt;/p&gt; &lt;p&gt;Thank you in advance for taking the time to read through my post and offer assistance. Your expertise means a lot to me, and I look forward to hearing your thoughts and suggestions.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Icy-Employee6667&quot;&gt; /u/Icy-Employee6667 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199ne8a/struggling_with_langchain_and_chromadb_help_needed/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199ne8a/struggling_with_langchain_and_chromadb_help_needed/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199ne8a</id><link href="https://www.reddit.com/r/LangChain/comments/199ne8a/struggling_with_langchain_and_chromadb_help_needed/" /><updated>2024-01-18T10:46:28+00:00</updated><published>2024-01-18T10:46:28+00:00</published><title>Struggling with LangChain and ChromaDB - Help Needed!</title></entry><entry><author><name>/u/confidant_dude</name><uri>https://www.reddit.com/user/confidant_dude</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;from langchain_community.vectorstores import Pinecone from langchain_openai import OpenAIEmbeddings from pinecone import Pinecone as PineconeClient pinecone=PineconeClient( api_key= {API KEY} ) embeddings = OpenAIEmbeddings( model=&amp;quot;text-embedding-ada-002&amp;quot;, openai_api_key={open_ai_api_key} ) vectorstore = Pinecone.from_existing_index(index_name, embeddings) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This gives the following error: &lt;/p&gt; &lt;p&gt;raise PineconeConfigurationError(&amp;quot;You haven&amp;#39;t specified an Api-Key.&amp;quot;)&lt;/p&gt; &lt;p&gt;pinecone.exceptions.PineconeConfigurationError: You haven&amp;#39;t specified an Api-Key. &lt;/p&gt; &lt;p&gt;Although I provided all the required api keys in line #5 and line #9&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/confidant_dude&quot;&gt; /u/confidant_dude &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199mklo/langchain_011_is_not_working_with_pineconeclient/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199mklo/langchain_011_is_not_working_with_pineconeclient/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199mklo</id><link href="https://www.reddit.com/r/LangChain/comments/199mklo/langchain_011_is_not_working_with_pineconeclient/" /><updated>2024-01-18T09:51:14+00:00</updated><published>2024-01-18T09:51:14+00:00</published><title>Langchain 0.1.1 is not working with pinecone-client 3.0.0</title></entry><entry><author><name>/u/3RiversAINexus</name><uri>https://www.reddit.com/user/3RiversAINexus</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I noticed that in the langchain documentation there was no happy medium where it&amp;#39;s explained how to add a memory to both the AgentExecutor and the chat itself. If you don&amp;#39;t have it in the AgentExecutor, it doesn&amp;#39;t see previous steps. In the custom agent example, it has you managing the chat history manually.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve created an example based on the langchain docs that does this here: &lt;a href=&quot;https://github.com/ThreeRiversAINexus/sample-langchain-agents/blob/main/structured_chat.py&quot;&gt;https://github.com/ThreeRiversAINexus/sample-langchain-agents/blob/main/structured_chat.py&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Please let me know what you think and if there are any other agents you need help with.&lt;/p&gt; &lt;p&gt;Edit: I&amp;#39;ve added a string splitting tool and gave an example using it to prove that it has memory of the chats as well as the agent executor steps.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/3RiversAINexus&quot;&gt; /u/3RiversAINexus &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199edvi/example_structured_chat_agent_with_complete/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199edvi/example_structured_chat_agent_with_complete/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199edvi</id><link href="https://www.reddit.com/r/LangChain/comments/199edvi/example_structured_chat_agent_with_complete/" /><updated>2024-01-18T01:52:35+00:00</updated><published>2024-01-18T01:52:35+00:00</published><title>Example Structured Chat Agent with Complete History</title></entry><entry><author><name>/u/Dealwap1337</name><uri>https://www.reddit.com/user/Dealwap1337</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am building a RAG app with langhain, how do you ensure you get the optimal results from your vector store so that the extracted documents and prompt sent to the LLM contain all the relevant information? I had to increase topK to as high as 50 before getting a good result.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Dealwap1337&quot;&gt; /u/Dealwap1337 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199ejhc/how_do_i_improve_rag_extracted_document_list/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199ejhc/how_do_i_improve_rag_extracted_document_list/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199ejhc</id><link href="https://www.reddit.com/r/LangChain/comments/199ejhc/how_do_i_improve_rag_extracted_document_list/" /><updated>2024-01-18T01:59:58+00:00</updated><published>2024-01-18T01:59:58+00:00</published><title>How do I improve RAG extracted document list</title></entry><entry><author><name>/u/Classic_essays</name><uri>https://www.reddit.com/user/Classic_essays</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello. &lt;/p&gt; &lt;p&gt;I&amp;#39;m creating a social media app and I intend to use AI for post recommendations. How do I use Lang Chain to achieve that? Any suggestions?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Classic_essays&quot;&gt; /u/Classic_essays &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1995ips/how_do_i_use_lang_chain_for_ai_recommendations_on/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1995ips/how_do_i_use_lang_chain_for_ai_recommendations_on/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1995ips</id><link href="https://www.reddit.com/r/LangChain/comments/1995ips/how_do_i_use_lang_chain_for_ai_recommendations_on/" /><updated>2024-01-17T19:38:08+00:00</updated><published>2024-01-17T19:38:08+00:00</published><title>How do I use Lang Chain for AI Recommendations on my app?</title></entry><entry><author><name>/u/DBAdvice123</name><uri>https://www.reddit.com/user/DBAdvice123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I saw that DataStax/Astra DB &lt;a href=&quot;https://www.datastax.com/blog/general-availability-data-api-for-enhanced-developer-experience&quot;&gt;just released a new Data API to help with building production GenAI and RAG applications&lt;/a&gt;. This API makes the proven petabyte-scale of Apache Cassandra easy to use and available to any JavaScript, Python, or full-stack application developer.&lt;/p&gt; &lt;p&gt;There will also be a joint webinar with LangChain available for registration here: &lt;a href=&quot;https://www.datastax.com/events/wikichat-build-a-real-time-rag-app-on-wikipedia-with-langchain-and-vercel&quot;&gt;https://www.datastax.com/events/wikichat-build-a-real-time-rag-app-on-wikipedia-with-langchain-and-vercel&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DBAdvice123&quot;&gt; /u/DBAdvice123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1990scx/new_data_api_for_astra/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1990scx/new_data_api_for_astra/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1990scx</id><link href="https://www.reddit.com/r/LangChain/comments/1990scx/new_data_api_for_astra/" /><updated>2024-01-17T16:33:54+00:00</updated><published>2024-01-17T16:33:54+00:00</published><title>New Data API for Astra</title></entry><entry><author><name>/u/Ok-Image-8343</name><uri>https://www.reddit.com/user/Ok-Image-8343</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Im struggling to understand a massive code base with not many comments. &lt;/p&gt; &lt;p&gt;Could lang chain plus gpt4 actually be useful for asking things like &amp;quot;what do you think this data structure does in the context its in?&amp;quot; Or &amp;quot;can you describe what this code block is doing in plain English?&amp;quot;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ok-Image-8343&quot;&gt; /u/Ok-Image-8343 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1993938/is_langchain_useful_for_code_bases/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1993938/is_langchain_useful_for_code_bases/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1993938</id><link href="https://www.reddit.com/r/LangChain/comments/1993938/is_langchain_useful_for_code_bases/" /><updated>2024-01-17T18:08:17+00:00</updated><published>2024-01-17T18:08:17+00:00</published><title>Is langchain useful for code bases?</title></entry><entry><author><name>/u/thewhitelynx</name><uri>https://www.reddit.com/user/thewhitelynx</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks-&lt;/p&gt; &lt;p&gt;I&amp;#39;m building an agent with memory and authentication. &lt;/p&gt; &lt;p&gt;I have a solution for chat memory and would rather not use a platform which also manages memory to avoid data synchronization complexity.&lt;/p&gt; &lt;p&gt;I tried ChainLit first, but didn&amp;#39;t like that it largely requires using ChainLit&amp;#39;s own data model and preferably ChainLit cloud.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently using StreamLit, and it&amp;#39;s OK - I like the flexibility, but it&amp;#39;s kinda slow for rendering and getting persistent authentication is proving challenging due to limited cookie support. It also seems like it was acquired by Snowflake and it&amp;#39;s maybe not as well supported as pre-acquisition.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Ideally, I want something where I can host with a single Python application binary like these two using some standard but customizable React components and just have a relatively simple interface for providing data (e.g. chat history, chat response, etc) as needed.&lt;/p&gt; &lt;p&gt;Any recommended solutions here? One thing I&amp;#39;m starting to wonder is if I should just switch over to pure TypeScript with NextJS and the JS version of LangChain so I can use React more natively &amp;amp; directly without having to maintain a bunch of distinct Python business logic &amp;amp; serving code.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thewhitelynx&quot;&gt; /u/thewhitelynx &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199299c/modern_chat_frontend_for_pythonpowered_llm_chat/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199299c/modern_chat_frontend_for_pythonpowered_llm_chat/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199299c</id><link href="https://www.reddit.com/r/LangChain/comments/199299c/modern_chat_frontend_for_pythonpowered_llm_chat/" /><updated>2024-01-17T17:29:39+00:00</updated><published>2024-01-17T17:29:39+00:00</published><title>Modern chat frontend for Python-powered LLM Chat apps?</title></entry><entry><author><name>/u/Fr4nkWh1te</name><uri>https://www.reddit.com/user/Fr4nkWh1te</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Any idea why the &lt;code&gt;page_url&lt;/code&gt; is not available? According to the documentation of &lt;code&gt;createStuffDocumentsChain&lt;/code&gt;, this should automatically be populated from the documents&amp;#39; metadata. And the value definitely exists in the metadata.&lt;/p&gt; &lt;p&gt;``&lt;code&gt; const historyAwareCombineDocsChain = await createStuffDocumentsChain({ llm: streamingModel, prompt: ChatPromptTemplate.fromMessages([ [ &amp;quot;system&amp;quot;, &lt;/code&gt;Answer the user&amp;#39;s questions based on the below context. When it makes sense, provide a link to the source in markdown format.&lt;/p&gt; &lt;pre&gt;&lt;code&gt; Context: {context}`, ], new MessagesPlaceholder(&amp;quot;chat_history&amp;quot;), [&amp;quot;user&amp;quot;, &amp;quot;{input}&amp;quot;], &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;]), documentPrompt: PromptTemplate.fromTemplate( &amp;quot;Source: {page_url}\n\nPage content:\n{page_content}&amp;quot; ), documentSeparator: &amp;quot;\n------\n&amp;quot;, });&lt;/p&gt; &lt;p&gt;const retriever = (await getVectorStore()).asRetriever();&lt;/p&gt; &lt;p&gt;const historyAwareRetrieverChain = await createHistoryAwareRetriever({ llm: nonStreamingModel, retriever, rephrasePrompt: ChatPromptTemplate.fromMessages([ new MessagesPlaceholder(&amp;quot;chat_history&amp;quot;), [&amp;quot;user&amp;quot;, &amp;quot;{input}&amp;quot;], [ &amp;quot;user&amp;quot;, &amp;quot;Given the above conversation, generate a search query to look up in order to get information relevant to the conversation&amp;quot;, ], ]), });&lt;/p&gt; &lt;p&gt;const conversationalRetrievalChain = await createRetrievalChain({ retriever: historyAwareRetrieverChain, combineDocsChain: historyAwareCombineDocsChain, }); ```&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fr4nkWh1te&quot;&gt; /u/Fr4nkWh1te &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1990ckx/inject_metadata_into_the_prompt_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1990ckx/inject_metadata_into_the_prompt_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1990ckx</id><link href="https://www.reddit.com/r/LangChain/comments/1990ckx/inject_metadata_into_the_prompt_with/" /><updated>2024-01-17T16:17:07+00:00</updated><published>2024-01-17T16:17:07+00:00</published><title>Inject metadata into the prompt with createStuffDocumentsChain</title></entry><entry><author><name>/u/smileymileycoin</name><uri>https://www.reddit.com/user/smileymileycoin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198qs86/use_wasm_as_a_crossplatform_llm_backend_for/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/yJQP8pCNK0zOtma-sQ1ZaVaMIWpxxr5u9_rIilBu3l4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0b2cedb5e76a0adae93d1a250fdb2c076324b6be&quot; alt=&quot;Use WASM as a cross-platform LLM backend for LangChain: Any LLMs on any device&quot; title=&quot;Use WASM as a cross-platform LLM backend for LangChain: Any LLMs on any device&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/smileymileycoin&quot;&gt; /u/smileymileycoin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/langchain-ai/langchain/pull/14787&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198qs86/use_wasm_as_a_crossplatform_llm_backend_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_198qs86</id><media:thumbnail url="https://external-preview.redd.it/yJQP8pCNK0zOtma-sQ1ZaVaMIWpxxr5u9_rIilBu3l4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0b2cedb5e76a0adae93d1a250fdb2c076324b6be" /><link href="https://www.reddit.com/r/LangChain/comments/198qs86/use_wasm_as_a_crossplatform_llm_backend_for/" /><updated>2024-01-17T07:16:24+00:00</updated><published>2024-01-17T07:16:24+00:00</published><title>Use WASM as a cross-platform LLM backend for LangChain: Any LLMs on any device</title></entry><entry><author><name>/u/theodormarcu</name><uri>https://www.reddit.com/user/theodormarcu</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi there! We were early users of LangChain (in March 2023), but we ended up moving away from it because we felt it was too early to support more complex use cases. We&amp;#39;re looking at it again and it looks like it&amp;#39;s come a long way! &lt;/p&gt; &lt;p&gt;What are the pros/cons of using LangChain in January 2024 vs going vanilla? What does LangChain help you the most with vs going vanilla? &lt;/p&gt; &lt;p&gt;Our use cases are:&lt;br/&gt; - Using multiple models using hosted and on-prem LLMs (both OSS and OpenAI/Anthropic/etc.)&lt;br/&gt; - Support for complex RAG.&lt;br/&gt; - Support chat and non-chat use cases.&lt;br/&gt; - Support for both private and non-private endpoints.&lt;br/&gt; - Outputting both structured and unstructured data. &lt;/p&gt; &lt;p&gt;We&amp;#39;re a quite experienced dev team, and it feels like we could get away without using LangChain. That being said, we hear a lot about it, so we&amp;#39;re curious if we&amp;#39;re missing out! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/theodormarcu&quot;&gt; /u/theodormarcu &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198csjd/why_should_i_use_langchain_for_my_new_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198csjd/why_should_i_use_langchain_for_my_new_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198csjd</id><link href="https://www.reddit.com/r/LangChain/comments/198csjd/why_should_i_use_langchain_for_my_new_app/" /><updated>2024-01-16T20:20:59+00:00</updated><published>2024-01-16T20:20:59+00:00</published><title>Why should I use LangChain for my new app?</title></entry><entry><author><name>/u/qa_anaaq</name><uri>https://www.reddit.com/user/qa_anaaq</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all--&lt;/p&gt; &lt;p&gt;I want to design a chatbot that:&lt;/p&gt; &lt;p&gt;A) has a set of guidelines (via a long pdf) that it &amp;quot;uses&amp;quot; to inform its&lt;/p&gt; &lt;p&gt;B) Analysis of website content&lt;/p&gt; &lt;p&gt;Basically, a user would submit (website) content via the chat interface, and the bot would analyze it based on the guidelines to which it has access. The user can ask questions in order to understand why the bot analyzed the content the way that it did. &lt;/p&gt; &lt;p&gt;I thought embedding the guidelines and using a retriever would be suitable, but it doesn&amp;#39;t seem like it&amp;#39;s the right way to go. When I ask it, &amp;quot;Provide examples from the text where negative language is being used,&amp;quot; it returns a list of negative language from the guidelines rather than applying the question to the website content and &lt;em&gt;using&lt;/em&gt; the guidelines to inform its answer.&lt;/p&gt; &lt;p&gt;I think some type of chain might be ideal, but I&amp;#39;m not sure what this would look like. &lt;/p&gt; &lt;p&gt;Really appreciate the ideas. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/qa_anaaq&quot;&gt; /u/qa_anaaq &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198mbhg/trying_to_figure_out_design_for_different_kind_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198mbhg/trying_to_figure_out_design_for_different_kind_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198mbhg</id><link href="https://www.reddit.com/r/LangChain/comments/198mbhg/trying_to_figure_out_design_for_different_kind_of/" /><updated>2024-01-17T03:08:56+00:00</updated><published>2024-01-17T03:08:56+00:00</published><title>Trying to figure out design for different kind of chatbot</title></entry><entry><author><name>/u/K0N1GST1G3R</name><uri>https://www.reddit.com/user/K0N1GST1G3R</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey there.&lt;/p&gt; &lt;p&gt;(Tell me if this is not the right place to ask such questions)&lt;/p&gt; &lt;p&gt;I tried out langchain for a little project, nothing too big. My goal was to be able to use langchain to ask LLMs to generate stuff for my project, and maybe implement some stuff like answers based on local documents.&lt;/p&gt; &lt;p&gt;But I&amp;#39;ve had a very hard time to find a free llm, and when I found how I can make this stuff work with some hugging face models (that I didn&amp;#39;t run locally) I was so disappointed how bad their answer were.&lt;/p&gt; &lt;p&gt;That&amp;#39;s why I am asking for suggestions and answer:&lt;/p&gt; &lt;p&gt;- should I run locally the llms ? which ones ?&lt;/p&gt; &lt;p&gt;- how can I manage all the settings of the llm. I don&amp;#39;t get what token and temperature are, and I wonder if they are the reason why the llm doesn&amp;#39;t respond as I would want it to.&lt;/p&gt; &lt;p&gt;- is hugging face a good choice ?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thanks a lot by advance, don&amp;#39;t hesitate to tell me if I was not specific enough.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/K0N1GST1G3R&quot;&gt; /u/K0N1GST1G3R &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198dky0/want_to_use_langchain_with_a_free_llm_model_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198dky0/want_to_use_langchain_with_a_free_llm_model_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198dky0</id><link href="https://www.reddit.com/r/LangChain/comments/198dky0/want_to_use_langchain_with_a_free_llm_model_and/" /><updated>2024-01-16T20:52:32+00:00</updated><published>2024-01-16T20:52:32+00:00</published><title>Want to use langchain with a free llm model ... and strugling</title></entry><entry><author><name>/u/Apart-Damage143</name><uri>https://www.reddit.com/user/Apart-Damage143</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m currently using &lt;code&gt;get_openai_callback()&lt;/code&gt; to monitor token consumption per call. However, when streaming the response, I&amp;#39;m receiving all zeros. I&amp;#39;m curious if anyone utilizing streaming in their application has successfully tracked token usage. Any insights?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Apart-Damage143&quot;&gt; /u/Apart-Damage143 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198g73w/struggling_to_track_token_usage_with_get_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198g73w/struggling_to_track_token_usage_with_get_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198g73w</id><link href="https://www.reddit.com/r/LangChain/comments/198g73w/struggling_to_track_token_usage_with_get_openai/" /><updated>2024-01-16T22:36:57+00:00</updated><published>2024-01-16T22:36:57+00:00</published><title>Struggling to Track Token Usage with get_openai_callback() in Streaming ‚Äì Seeking Advice from Fellow Developers</title></entry><entry><author><name>/u/effervesense</name><uri>https://www.reddit.com/user/effervesense</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I&amp;#39;m wondering how to create a feedback loop / response mechanism to collect responses from users to improve the model. Any insights on how to go about this would be greatly appreciated. &lt;/p&gt; &lt;p&gt;For instance, I want to ask &amp;quot;how helpful did you find this response?&amp;quot; (rating on a scale of 1 to 5). Or a simple thumbs up/down. Either after every message or every few.&lt;/p&gt; &lt;p&gt;From what I understand I will need to design a script to automatically prompt the user for feedback after the chatbot sends a response. Then the feedback will be collected to the database. I am not sure if mongoDB is the best to store both feedback and chat logs together. Is there a simple way to do all this within langchain?&lt;/p&gt; &lt;p&gt;If anyone has done something similar or has any ideas or resources please let me know. üôè&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/effervesense&quot;&gt; /u/effervesense &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198alqy/building_feedback_loop/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198alqy/building_feedback_loop/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198alqy</id><link href="https://www.reddit.com/r/LangChain/comments/198alqy/building_feedback_loop/" /><updated>2024-01-16T18:52:51+00:00</updated><published>2024-01-16T18:52:51+00:00</published><title>Building feedback loop</title></entry><entry><author><name>/u/2BucChuck</name><uri>https://www.reddit.com/user/2BucChuck</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been able to connect Pinecone directly through API without issue when not using Langchain vectorstore as retriever (and even using Langchain when a namespace is not implemented). However this is causing me a lot of angst now to the point I may be about ready to give LangChain the boot from codebase all together‚Ä¶ why won‚Äôt why won‚Äôt this connect with namespace involved (while working fine without namespaces)‚Ä¶ just says ‚Äòfailed to connect‚Äô and accuses me of using the wrong index name which is confirmed correct many times over and with straight API code testing : &lt;/p&gt; &lt;p&gt;index=pinecone.Index(‚Äúagent‚Äù) vectorstore= Pinecone(index, embeddings.embed_query, ‚Äútext‚Äù) retriever = vectorstore.as_retriever(search_kwargs={‚Äòk‚Äô:3, ‚Äònamespace‚Äô: 1000})&lt;/p&gt; &lt;p&gt;Docs = retriever .get_relevant_documents(msg)&lt;/p&gt; &lt;p&gt;For all the time spent tinkering on this I am thinking to just remove Langchain layers and deal with these functions directly ,but hoping this is something dumb on my end. I have this code working elsewhere without namespace argument no problem so seems specific to that argument and Langchain call to Pinecone index. &lt;/p&gt; &lt;p&gt;Thanks for any pointers&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/2BucChuck&quot;&gt; /u/2BucChuck &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198cs3e/vector_store_connect_to_pinecone_namespace_fails/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198cs3e/vector_store_connect_to_pinecone_namespace_fails/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198cs3e</id><link href="https://www.reddit.com/r/LangChain/comments/198cs3e/vector_store_connect_to_pinecone_namespace_fails/" /><updated>2024-01-16T20:20:32+00:00</updated><published>2024-01-16T20:20:32+00:00</published><title>Vector store connect to pinecone namespace fails</title></entry><entry><author><name>/u/XariZaru</name><uri>https://www.reddit.com/user/XariZaru</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Have any of you guys successfully implemented a system that fetches the latest documents based on the user query?&lt;/p&gt; &lt;p&gt;For example, I have three documents.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;095 Rate Sheet 01.01.2023.pdf&lt;/li&gt; &lt;li&gt;010 Rate Sheet 02.03.2023.pdf&lt;/li&gt; &lt;li&gt;28468 Rate Sheet Update 12.12.2023.pdf&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Each one of these contains rates information for various loans that month. These rates change each month. &lt;/p&gt; &lt;p&gt;I want to query &amp;quot;get me the latest auto loan rates.&amp;quot;&lt;/p&gt; &lt;p&gt;The expected result is that all three documents match, but only the latest document (12.12.2023) is filtered through. Any ideas on how to achieve this type of granularity?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/XariZaru&quot;&gt; /u/XariZaru &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198i3pz/best_practice_for_fetching_latest_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198i3pz/best_practice_for_fetching_latest_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198i3pz</id><link href="https://www.reddit.com/r/LangChain/comments/198i3pz/best_practice_for_fetching_latest_documents/" /><updated>2024-01-16T23:57:05+00:00</updated><published>2024-01-16T23:57:05+00:00</published><title>Best Practice for Fetching Latest Documents?</title></entry><entry><author><name>/u/Difficult-Card767</name><uri>https://www.reddit.com/user/Difficult-Card767</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;As a newcomer to LangChain, I&amp;#39;m finding the learning curve to be quite steep. I&amp;#39;ve been sifting through the documentation and various forums for guidance, but it feels like I&amp;#39;m piecing together a puzzle without all the pieces.&lt;/p&gt; &lt;p&gt;I&amp;#39;m curious to know if there are others out there who feel the same way. Is there a better way to approach learning LangChain that I&amp;#39;m missing? Any resources or tips would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Difficult-Card767&quot;&gt; /u/Difficult-Card767 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197u4wp/struggling_with_langchains_learning_curve/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197u4wp/struggling_with_langchains_learning_curve/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_197u4wp</id><link href="https://www.reddit.com/r/LangChain/comments/197u4wp/struggling_with_langchains_learning_curve/" /><updated>2024-01-16T04:38:01+00:00</updated><published>2024-01-16T04:38:01+00:00</published><title>Struggling with LangChain's learning curve</title></entry><entry><author><name>/u/CodingButStillAlive</name><uri>https://www.reddit.com/user/CodingButStillAlive</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using a combination of a BM25 keyword and Chroma vectorstore based retrievers.&lt;/p&gt; &lt;p&gt;get_relevant_documents() works pretty well most of the times, but sometimes the results are off.&lt;/p&gt; &lt;p&gt;For example, testing with only two documents results in wrong results. While larger document sets work pretty well.&lt;/p&gt; &lt;p&gt;Anyone observed something similar?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CodingButStillAlive&quot;&gt; /u/CodingButStillAlive &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1981tcr/retriever_results_are_sometimes_off/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1981tcr/retriever_results_are_sometimes_off/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1981tcr</id><link href="https://www.reddit.com/r/LangChain/comments/1981tcr/retriever_results_are_sometimes_off/" /><updated>2024-01-16T12:30:02+00:00</updated><published>2024-01-16T12:30:02+00:00</published><title>Retriever results are sometimes off</title></entry><entry><author><name>/u/zainulabd786</name><uri>https://www.reddit.com/user/zainulabd786</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I am using langchain.js &lt;a href=&quot;https://js.langchain.com/docs/integrations/vectorstores/qdrant&quot;&gt;QdrantVectorStore&lt;/a&gt; to perform CRUD operations in Qdrant collection. I see that there are many options available in js QdrantVectorStore&lt;br/&gt; to add data to Qdrant but I don&amp;#39;t see any method to update points in a cluster using langchain.js. I know I can use &lt;a href=&quot;https://github.com/qdrant/qdrant-js&quot;&gt;Qdrant js sdk&lt;/a&gt; to perform Updates to points but I prefer doing it using QdrantVectorStore&lt;br/&gt; for the following reasons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;it simply takes the text and Embedding model and do the rest. we don&amp;#39;t have to manually convert text to embeddings or vectors.&lt;/li&gt; &lt;li&gt;Qdrant has different APIs to update &lt;a href=&quot;https://qdrant.tech/documentation/concepts/points/&quot;&gt;vectors&lt;/a&gt; and &lt;a href=&quot;https://qdrant.tech/documentation/concepts/payload/#update-payload&quot;&gt;payload&lt;/a&gt;, Since QdrantVectorStore&lt;br/&gt; stores the actual text in payload.content&lt;br/&gt; along with the vectors so using qdrant sdk I will have to perfrom the vector and payload updates seperately with two API calls.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Although using Qdrant vector stores allows writing a clean code.&lt;/p&gt; &lt;p&gt;This &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/17bc1ij/update_collection_in_qdrantdont_want_to_create/&quot;&gt;reddit post&lt;/a&gt; suggests using add_documents&lt;br/&gt; even for update but that suggestion is for langchain.py not for js. But I tried something similar in langchain.js, I tried to use QdrantVectorStore.addDocuments()&lt;br/&gt; to update data but I couldn&amp;#39;t find a way to pass pointId[]&lt;br/&gt; to specify which point to update. I also checked the types and interfaces for QdrantVectorStore.addDocuments()&lt;br/&gt; so I found this&lt;/p&gt; &lt;pre&gt;&lt;code&gt;type QdrantAddDocumentOptions = { customPayload: Record&amp;lt;string, any&amp;gt;[]; }; addDocuments(documents: Document[], documentOptions?: QdrantAddDocumentOptions): Promise&amp;lt;void&amp;gt;; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As a last resort I also tried passing an array of pointIds in customPayload&lt;br/&gt; but that didn&amp;#39;t work. it was simply creating a point in cluster with the ids I passed in customPayload.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zainulabd786&quot;&gt; /u/zainulabd786 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1983iyf/how_to_update_data_in_qdrant_using_langchainjs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1983iyf/how_to_update_data_in_qdrant_using_langchainjs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1983iyf</id><link href="https://www.reddit.com/r/LangChain/comments/1983iyf/how_to_update_data_in_qdrant_using_langchainjs/" /><updated>2024-01-16T14:00:34+00:00</updated><published>2024-01-16T14:00:34+00:00</published><title>How to update data in Qdrant using langchain.js?</title></entry><entry><author><name>/u/Trick-Asparagus-9260</name><uri>https://www.reddit.com/user/Trick-Asparagus-9260</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to get the similarity scores using below func. My vector index is FAISS. I get an error: &lt;/p&gt; &lt;p&gt;retriever = local_db.as_retriever(&lt;/p&gt; &lt;p&gt;search_type=&amp;quot;similarity_search_with_relevant_score&amp;quot;&lt;/p&gt; &lt;p&gt;)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;ValidationError&lt;/strong&gt;: 1 validation error for VectorStoreRetriever __root__ search_type of similarity_search_with_score not allowed. Valid values are: (&amp;#39;similarity&amp;#39;, &amp;#39;similarity_score_threshold&amp;#39;, &amp;#39;mmr&amp;#39;) (type=value_error)[26]: &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Trick-Asparagus-9260&quot;&gt; /u/Trick-Asparagus-9260 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197wxp9/doesnt_langchain_retriever_support_similarity/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197wxp9/doesnt_langchain_retriever_support_similarity/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_197wxp9</id><link href="https://www.reddit.com/r/LangChain/comments/197wxp9/doesnt_langchain_retriever_support_similarity/" /><updated>2024-01-16T07:14:09+00:00</updated><published>2024-01-16T07:14:09+00:00</published><title>Doesn't langchain retriever support 'similarity_search_with_relevant_scores' using FAISS?</title></entry><entry><author><name>/u/Rorororerere</name><uri>https://www.reddit.com/user/Rorororerere</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi&lt;/p&gt; &lt;p&gt;I want to start using Agent/stream &lt;a href=&quot;https://python.langchain.com/docs/modules/agents/how_to/streaming&quot;&gt;here&lt;/a&gt;, more specifically this part:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;path_status = {} async for chunk in agent_executor.astream_log( {&amp;quot;input&amp;quot;: &amp;quot;what is the weather in sf&amp;quot;, &amp;quot;chat_history&amp;quot;: []}, include_names=[&amp;quot;ChatOpenAI&amp;quot;], ): for op in chunk.ops: if op[&amp;quot;op&amp;quot;] == &amp;quot;add&amp;quot;: if op[&amp;quot;path&amp;quot;] not in path_status: path_status[op[&amp;quot;path&amp;quot;]] = op[&amp;quot;value&amp;quot;] else: path_status[op[&amp;quot;path&amp;quot;]] += op[&amp;quot;value&amp;quot;] print(op[&amp;quot;path&amp;quot;]) print(path_status.get(op[&amp;quot;path&amp;quot;])) print(&amp;quot;----&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I&amp;#39;d like to know how I can continue the conversation*(continue from the same point &amp;quot;last token&amp;quot; received)*, in case I lose connection with OpenAI or it&amp;#39;s down...&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Rorororerere&quot;&gt; /u/Rorororerere &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1984eyd/stream_continue_same_conversation_in_case_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1984eyd/stream_continue_same_conversation_in_case_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1984eyd</id><link href="https://www.reddit.com/r/LangChain/comments/1984eyd/stream_continue_same_conversation_in_case_openai/" /><updated>2024-01-16T14:41:23+00:00</updated><published>2024-01-16T14:41:23+00:00</published><title>Stream continue same conversation in case OpenAI errors</title></entry><entry><author><name>/u/BadriMLJ</name><uri>https://www.reddit.com/user/BadriMLJ</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How should I load the one pdf at a time and get the embeddings of it in loop. If I used the PyPDFLoader it will load all the pdfs together in the form of Document. I want to load the pdfs one by one the store it in VectoreStore like FAISS, Chroma&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BadriMLJ&quot;&gt; /u/BadriMLJ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197zyqw/iterate_pdfs_in_loop_to_store_the_embeddings/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197zyqw/iterate_pdfs_in_loop_to_store_the_embeddings/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_197zyqw</id><link href="https://www.reddit.com/r/LangChain/comments/197zyqw/iterate_pdfs_in_loop_to_store_the_embeddings/" /><updated>2024-01-16T10:38:56+00:00</updated><published>2024-01-16T10:38:56+00:00</published><title>Iterate PDFs in loop to store the embeddings separately in vectorestore</title></entry></feed>