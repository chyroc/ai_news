<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-08-01T07:01:16+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/g_pal</name><uri>https://www.reddit.com/user/g_pal</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I recently had our AI interviewer speak with 22 developers who are building with LangGraph. The interviews covered various topics, including how they&amp;#39;re using LangGraph, what they like about it, and areas for improvement. I wanted to share the key findings because I thought you might find it interesting.&lt;/p&gt; &lt;h1&gt;Use Cases and Attractions&lt;/h1&gt; &lt;p&gt;LangGraph is attracting developers from a wide range of industries due to its versatility in managing complex AI workflows. Here are some interesting use cases:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Content Generation:&lt;/strong&gt; Teams are using LangGraph to create systems where multiple AI agents collaborate to draft, fact-check, and refine research papers in real-time.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Customer Service:&lt;/strong&gt; Developers are building dynamic response systems that analyze sentiment, retrieve relevant information, and generate personalized replies with built-in clarification mechanisms.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Financial Modeling:&lt;/strong&gt; Some are building valuation models in real estate that adapt in real-time based on market fluctuations and simulated scenarios.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Academic Research&lt;/strong&gt;: Institutions are developing adaptive research assistants capable of gathering data, synthesizing insights, and proposing new hypotheses within a single integrated system.&lt;/li&gt; &lt;/ol&gt; &lt;h1&gt;What Attracts Developers to LangGraph?&lt;/h1&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Multi-Agent System Orchestration&lt;/strong&gt;: LangGraph excels at managing multiple AI agents, allowing for a divide-and-conquer approach to complex problems.&amp;quot;We are working on a project that requires multiple AI agents to communicate and talk to one another. LangGraph helps with thinking through the problem using a divide-and-conquer approach with graphs, nodes, and edges.&amp;quot; - Founder, Property Technology Startup&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Workflow Visualization and Debugging&lt;/strong&gt;: The platform&amp;#39;s visualization capabilities are highly valued for development and debugging.&amp;quot;LangGraph can visualize all the requests and all the payloads instantly, and I can debug by taking LangGraph. It&amp;#39;s very convenient for the development experience.&amp;quot; - Cloud Solutions Architect, Microsoft&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Complex Problem-Solving&lt;/strong&gt;: Developers appreciate LangGraph&amp;#39;s ability to tackle intricate challenges that traditional programming struggles with.&amp;quot;Solving complex problems that are not, um, possible with traditional programming.&amp;quot; - AI Researcher, Nokia&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Abstraction of Flow Logic&lt;/strong&gt;: LangGraph simplifies the implementation of complex workflows by abstracting flow logic.&amp;quot;[LangGraph helped] abstract the flow logic and avoid having to write all of the boilerplate code to get started with the project.&amp;quot; - AI Researcher, Nokia&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Flexible Agentic Workflows&lt;/strong&gt;: The tool&amp;#39;s adaptability for various AI agent scenarios is a key attraction.&amp;quot;Being able to create an agentic workflow that is easy to visualize abstractly with graphs, nodes, and edges.&amp;quot; - Founder, Property Technology Startup&lt;/li&gt; &lt;/ol&gt; &lt;h1&gt;LangGraph vs Alternatives&lt;/h1&gt; &lt;p&gt;The most commonly considered alternatives were CrewAI and Microsoft&amp;#39;s Autogen. However, developers noted several areas where LangGraph stands out:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Handling Complex Workflows:&lt;/strong&gt; Unlike some competitors limited to simple, linear processes, LangGraph can handle complex graph flows, including cycles.&amp;quot;CrewAI can only handle DAGs and cannot handle cycles, whereas LangGraph can handle complex graph flows, including cycles.&amp;quot; - Developer&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Developer Control:&lt;/strong&gt; LangGraph offers a level of control that many find unmatched, especially for custom use cases.&amp;quot;We did tinker a bit with CrewAI and Meta GPT. But those could not come even near as powerful as LangGraph. And we did combine with LangChain because we have very custom use cases, and we need to have a lot of control. And the competitor frameworks just don&amp;#39;t offer that amount of, control over the code.&amp;quot; - Founder, GenAI Startup&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Mature Ecosystem:&lt;/strong&gt; LangGraph&amp;#39;s longer market presence has resulted in more resources, tools, and infrastructure.&amp;quot;LangGraph has the advantage of being in the market longer, offering more resources, tools, and infrastructure. The ability to use LangSmith in conjunction with LangGraph for debugging and performance analysis is a significant differentiator.&amp;quot; - Developer&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Market Leadership:&lt;/strong&gt; Despite a volatile market, LangGraph is currently seen as a leader in functionality and tooling for developing workflows.&amp;quot;Currently, LangGraph is one of the leaders in terms of functionality and tooling for developing workflows. The market is volatile, and I hope LangGraph continues to innovate and create more tools to facilitate developers&amp;#39; work.&amp;quot; - Developer&lt;/li&gt; &lt;/ol&gt; &lt;h1&gt;Areas for Improvement&lt;/h1&gt; &lt;p&gt;While LangGraph has garnered praise, developers also identified several areas for improvement:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Simplify Syntax and Reduce Complexity:&lt;/strong&gt; Some developers noted that the graph-based approach, while powerful, can be complex to maintain.&amp;quot;Some syntax can be made a lot simpler.&amp;quot; - Senior Engineering Director, BlackRock&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Enhance Documentation and Community Resources:&lt;/strong&gt; There&amp;#39;s a need for more in-depth, complex examples and community-driven documentation.&amp;quot;The lack of how-to articles and community-driven documentation... There&amp;#39;s a lot of entry-level stuff, but nothing really in-depth or complex.&amp;quot; - Research Assistant, BYU&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Improve Debugging Capabilities:&lt;/strong&gt; Developers expressed a need for more detailed debugging information, especially for tracking state within the graph.&amp;quot;There is a need for more debugging information. Sometimes, the bug information starts from the instantiation of the workflow, and it&amp;#39;s hard to track the state within the graph.&amp;quot; - Senior Software Engineer, Canadian Government Agency&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Better Human-in-the-Loop Integration:&lt;/strong&gt; Some users aren&amp;#39;t satisfied with the current implementation of human-in-the-loop concepts.&amp;quot;More options around the human-in-the-loop concept. I&amp;#39;m not a very big fan of their current implementation of that.&amp;quot; - AI Researcher, Nokia&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Enhanced Subgraph Integration:&lt;/strong&gt; Multiple developers mentioned issues with integrating and combining subgraphs.&amp;quot;The possibility to integrate subgraphs isn&amp;#39;t compatible with [graph drawing].&amp;quot; - Engineer, IT Consulting Company &amp;quot;I wish you could combine smaller graphs into bigger graphs more easily.&amp;quot; - Research Assistant, BYU&lt;/li&gt; &lt;li&gt;&lt;strong&gt;More Complex Examples:&lt;/strong&gt; There&amp;#39;s a desire for more complex examples that developers can use as starting points.&amp;quot;Creating more examples online that people can use as inspiration would be fantastic.&amp;quot; - Senior Engineering Director, BlackRock&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;____&lt;br/&gt; You can check out the interview transcripts here: &lt;a href=&quot;http://kgrid.ai/company/langgraph&quot;&gt;kgrid.ai/company/langgraph&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Curious to know whether this aligns with your experience? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/g_pal&quot;&gt; /u/g_pal &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eh0ly3/spoke_to_22_langgraph_devs_and_heres_what_we_found/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eh0ly3/spoke_to_22_langgraph_devs_and_heres_what_we_found/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eh0ly3</id><link href="https://www.reddit.com/r/LangChain/comments/1eh0ly3/spoke_to_22_langgraph_devs_and_heres_what_we_found/" /><updated>2024-07-31T22:36:11+00:00</updated><published>2024-07-31T22:36:11+00:00</published><title>Spoke to 22 LangGraph devs and here's what we found</title></entry><entry><author><name>/u/maniac_runner</name><uri>https://www.reddit.com/user/maniac_runner</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eh73u7/github_pytorchtorchchat_run_pytorch_llms_locally/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/KnyLvUQLSlhqwDrJ5al_7_sHY4CasKEA7RvCEIrbcO0.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=70859b752fa3814100646807363b0b2e1ac8d99c&quot; alt=&quot;GitHub - pytorch/torchchat: Run PyTorch LLMs locally on servers, desktop and mobile&quot; title=&quot;GitHub - pytorch/torchchat: Run PyTorch LLMs locally on servers, desktop and mobile&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/maniac_runner&quot;&gt; /u/maniac_runner &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/pytorch/torchchat&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eh73u7/github_pytorchtorchchat_run_pytorch_llms_locally/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1eh73u7</id><media:thumbnail url="https://external-preview.redd.it/KnyLvUQLSlhqwDrJ5al_7_sHY4CasKEA7RvCEIrbcO0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=70859b752fa3814100646807363b0b2e1ac8d99c" /><link href="https://www.reddit.com/r/LangChain/comments/1eh73u7/github_pytorchtorchchat_run_pytorch_llms_locally/" /><updated>2024-08-01T03:48:53+00:00</updated><published>2024-08-01T03:48:53+00:00</published><title>GitHub - pytorch/torchchat: Run PyTorch LLMs locally on servers, desktop and mobile</title></entry><entry><author><name>/u/Traditional_Art_6943</name><uri>https://www.reddit.com/user/Traditional_Art_6943</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys I have created a PDF Chat/ Web Search RAG application deployed on Hugging Face Spaces &lt;a href=&quot;https://shreyas094-searchgpt.hf.space&quot;&gt;https://shreyas094-searchgpt.hf.space&lt;/a&gt;. Providing the model documentation below please feel free to contribute.&lt;/p&gt; &lt;h1&gt;AI-powered Web Search and PDF Chat Assistant&lt;/h1&gt; &lt;p&gt;This project combines the power of large language models with web search capabilities and PDF document analysis to create a versatile chat assistant. Users can interact with their uploaded PDF documents or leverage web search to get informative responses to their queries.&lt;/p&gt; &lt;h2&gt;Features&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;PDF Document Chat&lt;/strong&gt;: Upload and interact with multiple PDF documents.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Web Search Integration&lt;/strong&gt;: Option to use web search for answering queries.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Multiple AI Models&lt;/strong&gt;: Choose from a selection of powerful language models.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Customizable Responses&lt;/strong&gt;: Adjust temperature and API call settings for fine-tuned outputs.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;User-friendly Interface&lt;/strong&gt;: Built with Gradio for an intuitive chat experience.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Document Selection&lt;/strong&gt;: Choose which uploaded documents to include in your queries.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;How It Works&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Document Processing&lt;/strong&gt;: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Upload PDF documents using either PyPDF or LlamaParse.&lt;/li&gt; &lt;li&gt;Documents are processed and stored in a FAISS vector database for efficient retrieval.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Embedding&lt;/strong&gt;: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Utilizes HuggingFace embeddings (default: &amp;#39;sentence-transformers/all-mpnet-base-v2&amp;#39;) for document indexing and query matching.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Query Processing&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;For PDF queries, relevant document sections are retrieved from the FAISS database.&lt;/li&gt; &lt;li&gt;For web searches, results are fetched using the DuckDuckGo search API.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Response Generation&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Queries are processed using the selected AI model (options include Mistral, Mixtral, and others).&lt;/li&gt; &lt;li&gt;Responses are generated based on the retrieved context (from PDFs or web search).&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;User Interaction&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Users can chat with the AI, asking questions about uploaded documents or general queries.&lt;/li&gt; &lt;li&gt;The interface allows for adjusting model parameters and switching between PDF and web search modes.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Setup and Usage&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;Install the required dependencies (list of dependencies to be added).&lt;/li&gt; &lt;li&gt;Set up the necessary API keys and tokens in your environment variables.&lt;/li&gt; &lt;li&gt;Run the main script to launch the Gradio interface.&lt;/li&gt; &lt;li&gt;Upload PDF documents using the file input at the top of the interface.&lt;/li&gt; &lt;li&gt;Select documents to query using the checkboxes.&lt;/li&gt; &lt;li&gt;Toggle between PDF chat and web search modes as needed.&lt;/li&gt; &lt;li&gt;Adjust temperature and number of API calls to fine-tune responses.&lt;/li&gt; &lt;li&gt;Start chatting and asking questions!&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Models&lt;/h2&gt; &lt;p&gt;The project supports multiple AI models, including: - mistralai/Mistral-7B-Instruct-v0.3 - mistralai/Mixtral-8x7B-Instruct-v0.1 - meta/llama-3.1-8b-instruct - mistralai/Mistral-Nemo-Instruct-2407&lt;/p&gt; &lt;h2&gt;Future Improvements&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Integration of more embedding models for improved performance.&lt;/li&gt; &lt;li&gt;Enhanced PDF parsing capabilities.&lt;/li&gt; &lt;li&gt;Support for additional file formats beyond PDF.&lt;/li&gt; &lt;li&gt;Improved caching for faster response times.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Contribution&lt;/h2&gt; &lt;p&gt;Contributions to this project are welcome!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Traditional_Art_6943&quot;&gt; /u/Traditional_Art_6943 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egyn3g/rag_pdf_chat_web_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egyn3g/rag_pdf_chat_web_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egyn3g</id><link href="https://www.reddit.com/r/LangChain/comments/1egyn3g/rag_pdf_chat_web_search/" /><updated>2024-07-31T21:14:26+00:00</updated><published>2024-07-31T21:14:26+00:00</published><title>RAG PDF Chat + Web Search</title></entry><entry><author><name>/u/No_Storm5504</name><uri>https://www.reddit.com/user/No_Storm5504</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been deloyed an langgraph app which running at LangServe. One question is that I have a feature which required human-in-the-loop that&amp;#39;s send a None Type to the langgraph, that&amp;#39;s the way to continue langgraph execution. I know how to do it in Python SDK but still no clues in LangServe client wayÔºåwhich I mimic request with Python &lt;code&gt;requests&lt;/code&gt; through payloads. &lt;/p&gt; &lt;p&gt;Any good ideas?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No_Storm5504&quot;&gt; /u/No_Storm5504 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eh9wwv/how_to_pass_none_type_as_an_input_to_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eh9wwv/how_to_pass_none_type_as_an_input_to_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eh9wwv</id><link href="https://www.reddit.com/r/LangChain/comments/1eh9wwv/how_to_pass_none_type_as_an_input_to_langgraph/" /><updated>2024-08-01T06:39:08+00:00</updated><published>2024-08-01T06:39:08+00:00</published><title>How to pass None Type as an input to LangGraph which deployed in LangServe</title></entry><entry><author><name>/u/Alternative_Spell981</name><uri>https://www.reddit.com/user/Alternative_Spell981</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In building RAG systems, there&amp;#39;s a consensus that when documents have clear and accurate titles and hierarchies, it&amp;#39;s better to segment based on semantic understanding using subtitles and paragraphs rather than traditional chunking by length. &lt;/p&gt; &lt;p&gt;This enhances the system&amp;#39;s retrieval and overall performance in QA tasks.&lt;/p&gt; &lt;p&gt;Currently, accurately and consistently identifying primary, secondary, tertiary, and other subtitles is challenging in document parsing, due to varying title formats across different long document types and the semantic ambiguity of some titles.&lt;/p&gt; &lt;p&gt;For instance, TextIn&amp;#39;s achieved good results in title hierarchy recognition and directory tree construction for documents like annual reports, financial statements, and research reports. However, performance still needs optimization for documents with less consistent formats.&lt;/p&gt; &lt;p&gt;Accurately reconstructing title hierarchies is a difficult yet highly beneficial task for downstream processes. Therefore, recognizing document directory trees is a key focus in our parsing efforts. &lt;/p&gt; &lt;p&gt;We welcome users with high precision requirements to discuss application scenarios and try TextIn&amp;#39;s doc parser to experience the latest advancements firsthand!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Alternative_Spell981&quot;&gt; /u/Alternative_Spell981 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eh66kc/how_to_better_recognize_hierarchical_titles_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eh66kc/how_to_better_recognize_hierarchical_titles_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eh66kc</id><link href="https://www.reddit.com/r/LangChain/comments/1eh66kc/how_to_better_recognize_hierarchical_titles_in/" /><updated>2024-08-01T02:59:24+00:00</updated><published>2024-08-01T02:59:24+00:00</published><title>How to Better Recognize Hierarchical Titles in Document ParsingÔºü</title></entry><entry><author><name>/u/jscraft</name><uri>https://www.reddit.com/user/jscraft</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks,&lt;/p&gt; &lt;p&gt;Exciting news! Two weeks ago, I had the pleasure of recording a podcast interview with Jacob Lee, the lead maintainer of LangChain.js. &lt;/p&gt; &lt;p&gt;Check it out here: &lt;a href=&quot;https://www.js-craft.io/blog/interview-jacob-lee-langchain-js/&quot;&gt;https://www.js-craft.io/blog/interview-jacob-lee-langchain-js/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;During this short talk, we go through topics such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The advantages of using LangChain&lt;/li&gt; &lt;li&gt;A good roadmap for learning LangChain&lt;/li&gt; &lt;li&gt;How all the Langs work together (LangGraph, LangSmith, LangServe, LangChain itself)&lt;/li&gt; &lt;li&gt;Using LangChain.js with or without TypeScript &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;... and much more.&lt;/p&gt; &lt;p&gt;Listen now:: &lt;a href=&quot;https://www.js-craft.io/blog/interview-jacob-lee-langchain-js/&quot;&gt;https://www.js-craft.io/blog/interview-jacob-lee-langchain-js/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Hope you will like it, and happy to hear your opinions! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jscraft&quot;&gt; /u/jscraft &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egmw06/interview_with_jacob_lee_lead_maintainer_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egmw06/interview_with_jacob_lee_lead_maintainer_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egmw06</id><link href="https://www.reddit.com/r/LangChain/comments/1egmw06/interview_with_jacob_lee_lead_maintainer_of/" /><updated>2024-07-31T13:14:34+00:00</updated><published>2024-07-31T13:14:34+00:00</published><title>Interview with Jacob Lee, lead maintainer of LangChain.js</title></entry><entry><author><name>/u/bferreira85</name><uri>https://www.reddit.com/user/bferreira85</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, right now my graph is not displaying to the user most of the messages that AI generate as it goes through the graph. This is specially bad in steps when I am getting the user confirmation for something, but it would be nice to display some messages as the llm moves from one node to another.&lt;br/&gt; What is the best practice for that? I&amp;#39;ve been doing console.print for displaying the last message in the message array in certain parts of the code, but I guess that&amp;#39;s not the best way to solve it. How do you usually do it? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bferreira85&quot;&gt; /u/bferreira85 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egjtsg/langgraph_what_is_the_best_practice_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egjtsg/langgraph_what_is_the_best_practice_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egjtsg</id><link href="https://www.reddit.com/r/LangChain/comments/1egjtsg/langgraph_what_is_the_best_practice_for/" /><updated>2024-07-31T10:32:36+00:00</updated><published>2024-07-31T10:32:36+00:00</published><title>Langgraph: What is the best practice for displaying messages to the user as the we move through the graph?</title></entry><entry><author><name>/u/unreal_4567</name><uri>https://www.reddit.com/user/unreal_4567</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone. Im building an application using the langchain create_sql_agent constructor: langchain_community.agent_toolkits.sql.base.create_sql_agent, for a strange use case that requires finding out which table in an SQL database a particular dataset(which I feed in the prompt as key value pairs of column headers and corresponding 5 values as a list) most resembles. Ive written prompts asking the agent to use the column headers to guess which table the dataset resembles. This is happening with llama 3 8b running via ollama. &lt;/p&gt; &lt;p&gt;The problem is I keep getting an error message which im recalling from my memory like:&lt;/p&gt; &lt;p&gt;ValueError: An outputparsing error occured. In order to pass this back to the agent and have it try again, pass handle_parsing_errors = True to the Agent executor. &lt;/p&gt; &lt;p&gt;However, the create_sql_agent constructor does not even have handle_parsing_errors as a parameter! Anyone have any idea how to resolve this? Im sure i must be getting something wrong. &lt;/p&gt; &lt;p&gt;For context, I&amp;#39;ve worked with the AgentExecutor class before which has a parameter handle_parsing_errors, which worked well, but for this specific use case, I need the sql agent. Is there a way to call the sql agent using the AgentExecutor? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/unreal_4567&quot;&gt; /u/unreal_4567 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egub1z/create_sql_agent_issue/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egub1z/create_sql_agent_issue/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egub1z</id><link href="https://www.reddit.com/r/LangChain/comments/1egub1z/create_sql_agent_issue/" /><updated>2024-07-31T18:19:22+00:00</updated><published>2024-07-31T18:19:22+00:00</published><title>Create_sql_agent issue</title></entry><entry><author><name>/u/sidtalesara01</name><uri>https://www.reddit.com/user/sidtalesara01</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So I am creating a software it scrapes the website, cleans the unwanted html like img, meta tags, script, style etc. and now I have a clean html file. Now I have a user description on what he wants from that url for example he want to submit a form. then only the form and login form component is important and significant. now I don&amp;#39;t want to send the whole html code but in a way trim it down to more relevant code which in this case is only code related to login. maybe omit html code of header, footer and other unwanted stuff. Now want some guidance how I can achieve this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sidtalesara01&quot;&gt; /u/sidtalesara01 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egt6tz/how_to_send_relevant_data_to_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egt6tz/how_to_send_relevant_data_to_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egt6tz</id><link href="https://www.reddit.com/r/LangChain/comments/1egt6tz/how_to_send_relevant_data_to_llm/" /><updated>2024-07-31T17:35:09+00:00</updated><published>2024-07-31T17:35:09+00:00</published><title>how to send relevant data to llm?</title></entry><entry><author><name>/u/ravediamond000</name><uri>https://www.reddit.com/user/ravediamond000</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;Just wrote an article on how to use LangServe to create an API over LangChain chains.&lt;br/&gt; Here&amp;#39;s the &lt;a href=&quot;https://www.metadocs.co/2024/07/31/easily-create-production-ready-apis-over-your-langchain-chains-using-langserve/&quot;&gt;link&lt;/a&gt;.&lt;br/&gt; This is actually something that I use in production in my company :D.&lt;/p&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ravediamond000&quot;&gt; /u/ravediamond000 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egn31o/create_robust_api_over_langchain_chains_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egn31o/create_robust_api_over_langchain_chains_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egn31o</id><link href="https://www.reddit.com/r/LangChain/comments/1egn31o/create_robust_api_over_langchain_chains_using/" /><updated>2024-07-31T13:23:29+00:00</updated><published>2024-07-31T13:23:29+00:00</published><title>Create robust API over Langchain chains using Langserve</title></entry><entry><author><name>/u/lat23_longitude0</name><uri>https://www.reddit.com/user/lat23_longitude0</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Folks,&lt;/p&gt; &lt;p&gt;Apologies if the above question does not belong here. But I am create a RAG application, Basically it is a RAG application for stackoverflow / stackexchange questions and answers.&lt;/p&gt; &lt;p&gt;But my first dilemma is - is it legal to scrape answers from stackoverflow / stackexchange?&lt;/p&gt; &lt;p&gt;I am planning to provide links back to the original answer in my app.&lt;/p&gt; &lt;p&gt;Any suggestions or advice would be great.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/lat23_longitude0&quot;&gt; /u/lat23_longitude0 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egvbm4/want_to_create_rag_application_for_stackoverflow/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egvbm4/want_to_create_rag_application_for_stackoverflow/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egvbm4</id><link href="https://www.reddit.com/r/LangChain/comments/1egvbm4/want_to_create_rag_application_for_stackoverflow/" /><updated>2024-07-31T19:00:31+00:00</updated><published>2024-07-31T19:00:31+00:00</published><title>Want to create RAG application for stackoverflow / stackexchange questions and answers. Is it legal to scrape answers from stackoverflow / stackexchange?</title></entry><entry><author><name>/u/Ignorance998</name><uri>https://www.reddit.com/user/Ignorance998</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;ps: This is a repost (2 days ago). Reddit decided to shadow-ban my previous new account simply because i have posted this. They mark it as &amp;quot;scam&amp;quot;. I hope they will not do so again this time, like this is using a open source license and i didn&amp;#39;t get any commercial benefit from it.&lt;/p&gt; &lt;h1&gt;Introduction (skip this if you like)&lt;/h1&gt; &lt;p&gt;I am an intermediate self-taught python coder with no formal CS experience. I have spent 5 months for this and learnt a lot when writing this project. I have never written anything this complicated before, and I have rewrite this project from scratch at least several times. There are many smaller-scale rewrite when i am not satisfied with the structure of anything. I hope it is useful for somebody. (Also warning, this might not be the most professional piece of code) Any feedback is appreciated!&lt;/p&gt; &lt;h1&gt;What My Project Does&lt;/h1&gt; &lt;p&gt;GPT Graph is a pipeline for llm data transfer. When I first studied LangChain, I don&amp;#39;t understand why we need a server(langsmith) to do debug, and things get so complicated. Therefore, i have spent time in order to write a pipeline structure targeting being flexible and easy to debug. While it&amp;#39;s still in early development and far less sophisticated as Langchain, I think my idea is better at least in some way in turns of how to abstract things (maybe i am wrong).&lt;/p&gt; &lt;p&gt;This library allows you to create more complex pipelines with features like dynamic caching, conditional execution, and easy debugging.&lt;/p&gt; &lt;p&gt;The main features of GPT Graph include:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Component-based pipelines&lt;/li&gt; &lt;li&gt;Allowing nested Pipeline&lt;/li&gt; &lt;li&gt;Dynamic caching according to defined keys&lt;/li&gt; &lt;li&gt;Conditional execution of components using bindings or linkings&lt;/li&gt; &lt;li&gt;Debugging and analysis methods&lt;/li&gt; &lt;li&gt;Priority Queue to run Steps in the Pipeline&lt;/li&gt; &lt;li&gt;Parameters can be updated with priority score. (e.g. if a Pipeline contains 4 Components, you can write config files for each of the Component and Pipeline, as Pipeline has higher priority than each component, if there are any conflict in parameters, the parent Pipeline&amp;#39;s parameters will be used)&lt;/li&gt; &lt;li&gt;One of the key advantages of GPT Graph is its debuggability. Every output is stored in a node (a dict with structure {&amp;quot;content&amp;quot;:xxx, ‚Äúextra‚Äù:xxx})&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The following features are lacking (They are all TODO in the future)&lt;/p&gt; &lt;ol&gt; &lt;li&gt;currently all are using sync mode&lt;/li&gt; &lt;li&gt;No database is used at this moment. All data stored in networkx graph&amp;#39;s wrapper.&lt;/li&gt; &lt;li&gt;No RAG at this moment. Although I have already written some prototype for it, basically calculate the vector and store in the nodes. They are not submitted yet.&lt;/li&gt; &lt;/ol&gt; &lt;h1&gt;Example&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;from gpt_graph.core.pipeline import Pipeline from gpt_graph.core.decorators.component import component @component() def greet(x): return x + &amp;quot; world!&amp;quot; pipeline = Pipeline() pipeline | greet() result = pipeline.run(input_data=&amp;quot;Hello&amp;quot;) print(result) # Output: [&amp;#39;Hello world!&amp;#39;] &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;Comparison&lt;/h1&gt; &lt;p&gt;As for as I know and my understanding(which may be wrong)(e.g. Langgraph or Langchain), there is no framework that can do nested pipeline, or using priority queue.&lt;/p&gt; &lt;h1&gt;Target Audience&lt;/h1&gt; &lt;p&gt;Fast prototyping and small project related to llm data pipelines. It is because currently everything is stored as a wrapper of networkx graph (including outputs of each Step and step structure). Later I may write implementation for graph database, although I don&amp;#39;t have the skill now.&lt;/p&gt; &lt;h1&gt;Welcome Feedback and Contributions&lt;/h1&gt; &lt;p&gt;I welcome any comments, recommendations, or contributions from the community.&lt;br/&gt; I know that as someone that releases his first complicated project (at least for me), there may be a lot of things that i am not doing correctly, including documentations/ writing style/ testing or others. So any recommendation is encouraged! Your feedback will be invaluable for me.&lt;br/&gt; If you have any questions about the project, feel free to ask me as well. My documentation may not be the easiest to understand. I will soon take a long holiday for several months, and when I come back I will try to enhance this project to a better and usable level.&lt;br/&gt; The license now is GPL v3, if more people feel interested in or contribute to the project, i will consider change it to more permissive license.&lt;/p&gt; &lt;h1&gt;Link to Github&lt;/h1&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/Ignorance999/gpt_graph&quot;&gt;https://github.com/Ignorance999/gpt_graph&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;Link to Documentation&lt;/h1&gt; &lt;p&gt;&lt;a href=&quot;https://gpt-graph.readthedocs.io/en/latest/hello_world.html&quot;&gt;https://gpt-graph.readthedocs.io/en/latest/hello_world.html&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;More Advanced Example (you can check documentation tutorial 1 Basics):&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;class z: def __init__(self): self.z = 0 def run(self): self.z += 1 return self.z @component( step_type=&amp;quot;node_to_list&amp;quot;, cache_schema={ &amp;quot;z&amp;quot;: { &amp;quot;key&amp;quot;: &amp;quot;[cp_or_pp.name]&amp;quot;, &amp;quot;initializer&amp;quot;: lambda: z(), } }, ) def f4(x, z, y=1): return x + y + z.run(), x - y + z.run() @component(step_type=&amp;quot;list_to_node&amp;quot;) def f5(x): return np.sum(x) @component( step_type=&amp;quot;node_to_list&amp;quot;, cache_schema={&amp;quot;z&amp;quot;: {&amp;quot;key&amp;quot;: &amp;quot;[base_name]&amp;quot;, &amp;quot;initializer&amp;quot;: lambda: z()}}, ) def f6(x, z): return [x, x - z.run(), x - z.run()] s = Session() s.f4 = f4() s.f6 = f6() s.f5 = f5() s.p6 = s.f4 | s.f6 | s.f5 result = s.p6.run(input_data=10) # output: 59 &amp;quot;&amp;quot;&amp;quot; output: Step: p6;InputInitializer:sp0 text = 10 (2 characters) Step: p6;f4.0:sp0 text = 12 (2 characters) text = 11 (2 characters) Step: p6;f6.0:sp0 text = 12 (2 characters) text = 11 (2 characters) text = 10 (2 characters) text = 11 (2 characters) text = 8 (1 characters) text = 7 (1 characters) Step: p6;f5.0:sp0 text = 59 (2 characters) &amp;quot;&amp;quot;&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ignorance998&quot;&gt; /u/Ignorance998 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egh70y/gpt_graph_a_flexible_pipeline_library/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egh70y/gpt_graph_a_flexible_pipeline_library/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egh70y</id><link href="https://www.reddit.com/r/LangChain/comments/1egh70y/gpt_graph_a_flexible_pipeline_library/" /><updated>2024-07-31T07:32:46+00:00</updated><published>2024-07-31T07:32:46+00:00</published><title>GPT Graph: A Flexible Pipeline Library</title></entry><entry><author><name>/u/dhj9817</name><uri>https://www.reddit.com/user/dhj9817</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dhj9817&quot;&gt; /u/dhj9817 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/documentAutomation/comments/1egjm4g/a_call_to_individuals_who_want_document/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egobx3/a_call_to_individuals_who_want_document/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egobx3</id><link href="https://www.reddit.com/r/LangChain/comments/1egobx3/a_call_to_individuals_who_want_document/" /><updated>2024-07-31T14:17:40+00:00</updated><published>2024-07-31T14:17:40+00:00</published><title>A call to individuals who want Document Automation as the future</title></entry><entry><author><name>/u/HopeAway7784</name><uri>https://www.reddit.com/user/HopeAway7784</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I need it to process documents for government agency. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HopeAway7784&quot;&gt; /u/HopeAway7784 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egcvsy/is_anyone_aware_of_a_good_ocr_model_that_can_be/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egcvsy/is_anyone_aware_of_a_good_ocr_model_that_can_be/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egcvsy</id><link href="https://www.reddit.com/r/LangChain/comments/1egcvsy/is_anyone_aware_of_a_good_ocr_model_that_can_be/" /><updated>2024-07-31T03:12:11+00:00</updated><published>2024-07-31T03:12:11+00:00</published><title>Is anyone aware of a good OCR model that can be used for document processing (Multi-language support with Hindi/ Indian languages)?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/learnmachinelearning/comments/1egiiw2/llama_31_fine_tuning_codes_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egikdw/llama_31_fine_tuning_codes_explained_using_unsloth/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egikdw</id><link href="https://www.reddit.com/r/LangChain/comments/1egikdw/llama_31_fine_tuning_codes_explained_using_unsloth/" /><updated>2024-07-31T09:09:39+00:00</updated><published>2024-07-31T09:09:39+00:00</published><title>Llama 3.1 Fine Tuning codes explained using unsloth</title></entry><entry><author><name>/u/kingai404</name><uri>https://www.reddit.com/user/kingai404</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone! I‚Äôm excited to share a new project: SWEKit, a powerful framework for building software engineering agents using the Composio tooling ecosystem.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Objectives&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;SWEKit allows you to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Scaffold agents that work out-of-the-box with frameworks like CrewAI and LlamaIndex.&lt;/li&gt; &lt;li&gt;Add or optimize your agent&amp;#39;s abilities.&lt;/li&gt; &lt;li&gt;Benchmark your agents against SWE-Bench.&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Implementation Details&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Tools Used&lt;/strong&gt;: Composio, CrewAI, Python&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Setup&lt;/strong&gt;:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Install agentic framework of your choice and the Composio plugin&lt;/li&gt; &lt;li&gt;The agent requires a github access token to work with your repositories&lt;/li&gt; &lt;li&gt;You also need to setup API key for the LLM provider you&amp;#39;re planning to use &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Scaffold and Run Your Agent&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Workspace Environment:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;SWEKit supports different workspace environments:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Host&lt;/strong&gt;: Run on the host machine.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Run inside a Docker container.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;E2B&lt;/strong&gt;: Run inside an E2B Sandbox.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;FlyIO&lt;/strong&gt;: Run inside a FlyIO machine.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Running the Benchmark:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;SWE-Bench&lt;/strong&gt; evaluates the performance of software engineering agents using real-world issues from popular Python open-source projects.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a href=&quot;https://git.new/SWE&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Feel free to explore the project, give it a star if you find it useful, and let me know your thoughts or suggestions for improvements! üåü&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kingai404&quot;&gt; /u/kingai404 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ege590/i_was_working_on_this_for_a_long_time_a_swe_kit/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ege590/i_was_working_on_this_for_a_long_time_a_swe_kit/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ege590</id><link href="https://www.reddit.com/r/LangChain/comments/1ege590/i_was_working_on_this_for_a_long_time_a_swe_kit/" /><updated>2024-07-31T04:20:02+00:00</updated><published>2024-07-31T04:20:02+00:00</published><title>I was working on this for a long time - a SWE Kit that simplifies SWE Agent Creation</title></entry><entry><author><name>/u/achsha02</name><uri>https://www.reddit.com/user/achsha02</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Did anyone try to create a custom tool that can compile your generated code to check if the code is working or not?&lt;br/&gt; Can I get some help creating this type of custom tool?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/achsha02&quot;&gt; /u/achsha02 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egirrf/using_code_compiler_as_a_tool/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1egirrf/using_code_compiler_as_a_tool/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1egirrf</id><link href="https://www.reddit.com/r/LangChain/comments/1egirrf/using_code_compiler_as_a_tool/" /><updated>2024-07-31T09:24:27+00:00</updated><published>2024-07-31T09:24:27+00:00</published><title>Using Code Compiler as a Tool?</title></entry><entry><author><name>/u/CantaloupeLeading646</name><uri>https://www.reddit.com/user/CantaloupeLeading646</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;I‚Äôve been working with LangChain to create an efficient document retriever using embeddings and caching mechanisms. I ran into a problem where the PyPDF loading process takes a substantial amount of time, and I believe this can be optimized by leveraging caching because i can only access the specifc location in the pdf where the retrieved context is - but the code right now doesn&amp;#39;t achieve this.&lt;/p&gt; &lt;p&gt;my question is then - how to achieve this more efficient functinoality. &lt;/p&gt; &lt;p&gt;Here&amp;#39;s my original setup:&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.vectorstores import Chroma&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_openai import OpenAIEmbeddings&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain.storage import LocalFileStore&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain.embeddings import CacheBackedEmbeddings&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.document_loaders import PyPDFLoader&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain.text_splitter import RecursiveCharacterTextSplitter&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;def load_jodrag_retriever(use_cache=True, chunk_size=2500, chunk_overlap=300, num_docs_retrieve=2):&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;embed = OpenAIEmbeddings()&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;docs = load_jodrag(chunk_size=chunk_size, chunk_overlap=chunk_overlap)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;retriever = retriever_setup(docs, use_cache=use_cache, embed=embed, num_docs_retrieve=num_docs_retrieve)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;return retriever&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;def load_rag(path = &amp;quot;paper1.pdf&amp;quot;, chunk_size = 500, chunk_overlap = 20):&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;loader = PyPDFLoader(path)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;pages = loader.load()&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;pages = pages[9:360]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;text = &amp;quot;&amp;quot;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;for page in pages:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;text += page.page_content&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;text = text.replace(&amp;#39;\t&amp;#39;, &amp;#39; &amp;#39;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;text_splitter = RecursiveCharacterTextSplitter(separators=[&amp;quot;\n\n&amp;quot;, &amp;quot;\n&amp;quot;, &amp;quot;\t&amp;quot;], chunk_size=chunk_size, chunk_overlap=chunk_overlap)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;docs = text_splitter.create_documents([text])&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;return docs&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;def retriever_setup(docs, use_cache=True, cache_dir= &amp;quot;./cache/&amp;quot;, embed=OpenAIEmbeddings(), num_docs_retrieve=2):&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;if use_cache:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;store = LocalFileStore(cache_dir)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;cached_embedder = CacheBackedEmbeddings.from_bytes_store(embed, store, namespace=embed.model)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;vectorstore = Chroma.from_documents(docs, cached_embedder)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;else:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;vectorstore = Chroma.from_documents(documents=docs, collection_name=&amp;quot;rag-chroma&amp;quot;, embedding=embed)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;retriever = vectorstore.as_retriever(search_kwargs={&amp;quot;k&amp;quot;: num_docs_retrieve})&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;return retriever&lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CantaloupeLeading646&quot;&gt; /u/CantaloupeLeading646 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eghtid/question_about_retrievers_slow_pdf_loading_times/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eghtid/question_about_retrievers_slow_pdf_loading_times/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eghtid</id><link href="https://www.reddit.com/r/LangChain/comments/1eghtid/question_about_retrievers_slow_pdf_loading_times/" /><updated>2024-07-31T08:16:41+00:00</updated><published>2024-07-31T08:16:41+00:00</published><title>question about retrievers - slow pdf loading times also when using cache</title></entry><entry><author><name>/u/yjgoh</name><uri>https://www.reddit.com/user/yjgoh</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I come from an AI developer background but i want to build an AI web app myself. &lt;/p&gt; &lt;p&gt;I have 2 options:&lt;br/&gt; A. Build every components ( calling AI models, parsing , injestion ) in TS/NextJS which im not familiar with at all, but if this will help long term im willing to put in the work.&lt;/p&gt; &lt;p&gt;B. Deploy my AI components using FastAPI. Im much more familiar with python, but im trying not to overcomplicate the architecture of my first webapp ( need to host frontend and backend separately )&lt;/p&gt; &lt;p&gt;Has anyone deploy any AI webapps/ SAAS here? Would like to have some suggestions&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/yjgoh&quot;&gt; /u/yjgoh &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1efz85n/ai_web_app_ts_vs_python_fastapi/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1efz85n/ai_web_app_ts_vs_python_fastapi/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1efz85n</id><link href="https://www.reddit.com/r/LangChain/comments/1efz85n/ai_web_app_ts_vs_python_fastapi/" /><updated>2024-07-30T17:26:14+00:00</updated><published>2024-07-30T17:26:14+00:00</published><title>AI web app TS vs Python + FastAPI?</title></entry><entry><author><name>/u/jiraiya1729</name><uri>https://www.reddit.com/user/jiraiya1729</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to build a chatbot which gives recommendations say books based on the conversation it had before with the user and I also want it to have good language skills like fundamental models so what are resource for learning this and what are the techstack to be used for this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jiraiya1729&quot;&gt; /u/jiraiya1729 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eg9g86/rag_based_recommendation_system/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eg9g86/rag_based_recommendation_system/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eg9g86</id><link href="https://www.reddit.com/r/LangChain/comments/1eg9g86/rag_based_recommendation_system/" /><updated>2024-07-31T00:26:43+00:00</updated><published>2024-07-31T00:26:43+00:00</published><title>RAG based recommendation system</title></entry><entry><author><name>/u/Silver_Equivalent_58</name><uri>https://www.reddit.com/user/Silver_Equivalent_58</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a tool out there that can find the optimal pipeline for a RAG for a given data? &lt;/p&gt; &lt;p&gt;Im planning to build one and was wondering how helpful something like this would be?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Silver_Equivalent_58&quot;&gt; /u/Silver_Equivalent_58 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1efz9nj/is_there_a_tool_for_finds_optimal_pipeline_for_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1efz9nj/is_there_a_tool_for_finds_optimal_pipeline_for_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1efz9nj</id><link href="https://www.reddit.com/r/LangChain/comments/1efz9nj/is_there_a_tool_for_finds_optimal_pipeline_for_a/" /><updated>2024-07-30T17:27:52+00:00</updated><published>2024-07-30T17:27:52+00:00</published><title>Is there a tool for finds optimal pipeline for a RAG?</title></entry><entry><author><name>/u/Exciting-Rest-395</name><uri>https://www.reddit.com/user/Exciting-Rest-395</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been trying to build a RAG over a database that has mulitple tables. Often times, for a user query, the data has to be searched by joining multiple tables. I followed this approach as mentioned in Langchain documents.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://python.langchain.com/v0.1/docs/use_cases/sql/quickstart/&quot;&gt;https://python.langchain.com/v0.1/docs/use_cases/sql/quickstart/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;What I am observing is that many times the query generated by LLM is not correct and the data that user wants is incorrect. We have provided almost 60 queries in Fewshot prompts example and send 3 as example that are closes semantic match. The accuracy still seems far from expected one. Are we missing something. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Exciting-Rest-395&quot;&gt; /u/Exciting-Rest-395 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1efnx5u/rag_over_database/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1efnx5u/rag_over_database/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1efnx5u</id><link href="https://www.reddit.com/r/LangChain/comments/1efnx5u/rag_over_database/" /><updated>2024-07-30T08:12:27+00:00</updated><published>2024-07-30T08:12:27+00:00</published><title>RAG over Database</title></entry><entry><author><name>/u/emersoftware</name><uri>https://www.reddit.com/user/emersoftware</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Does anyone know how to dynamically modify the description of a Tool?&lt;/p&gt; &lt;p&gt;I am using ToolNode in Langgraph with tools defined with the decorator, and to define the args, I am using a Pydantic BaseModel, something like:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;class ToolInput(BaseModel): arg_1: str = Field(description=&amp;quot;...&amp;quot;, type=&amp;quot;string&amp;quot;) ... u/tool(&amp;quot;get_data&amp;quot;, args_schema=ToolInput) def get_data( arg_1: str, ... ): &amp;quot;&amp;quot;&amp;quot;Get the data, the accepted values of the arg_1 are: - val_1, val_2, val_3 ... val_n &amp;quot;&amp;quot;&amp;quot; ... return data &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The point is, I want to dynamically pass data from the graph&amp;#39;s state to construct the prompt, something like:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;class ToolInput(BaseModel): arg_1: int = Field(description=&amp;quot;...&amp;quot;, type=&amp;quot;string&amp;quot;) ... @tool(&amp;quot;get_data&amp;quot;, args_schema=ToolInput) def get_data( arg_1: str, ... ): &amp;quot;&amp;quot;&amp;quot;Get the data, the accepted values of the arg_1 are: - {val_1}, {val_2}, {val_3}, ... , {val_n} &amp;quot;&amp;quot;&amp;quot; # Where the {val_x} come from the State, for example state[&amp;quot;available_values&amp;quot;] ... return data &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Does anyone have an idea of how I can do this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/emersoftware&quot;&gt; /u/emersoftware &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eg12qg/discussion_how_to_dynamically_modify_tool/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eg12qg/discussion_how_to_dynamically_modify_tool/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eg12qg</id><link href="https://www.reddit.com/r/LangChain/comments/1eg12qg/discussion_how_to_dynamically_modify_tool/" /><updated>2024-07-30T18:40:26+00:00</updated><published>2024-07-30T18:40:26+00:00</published><title>Discussion: How to dynamically modify tool descriptions in Langgraph?</title></entry><entry><author><name>/u/Gullible-Being-8595</name><uri>https://www.reddit.com/user/Gullible-Being-8595</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am working on a RAG chatbot application where we will first to have if either the given question is having enough knowledge to be answered or we need some further information before answering. Or if a question is a general question which doesn&amp;#39;t even need RAG search. For example, if a question is &amp;quot;What are the main components of a car?&amp;quot; then we don&amp;#39;t need RAG search but if a question is &amp;quot;What type of suspensions do you have for a car?&amp;quot; then we will do RAG search.&lt;/p&gt; &lt;p&gt;Till now, I created a simple ReACT agent in langchain to ask the followup questions with a tool and now I need to integrate if the given query is something that can be answered without any tool or not and for this, I am thinking about first having an agent which qualifies the given query and if its qualified for RAG search then second agent will do either RAG search or follow-up questions.&lt;/p&gt; &lt;p&gt;In the past of couple of days, I have been exploring langgraph and I feel like simple langchain is enough for my solution like a chain of agents. So please make me understand, why one should use Langgraph?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Gullible-Being-8595&quot;&gt; /u/Gullible-Being-8595 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1efnpgv/langchain_agents_or_langgraph_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1efnpgv/langchain_agents_or_langgraph_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1efnpgv</id><link href="https://www.reddit.com/r/LangChain/comments/1efnpgv/langchain_agents_or_langgraph_agents/" /><updated>2024-07-30T07:57:23+00:00</updated><published>2024-07-30T07:57:23+00:00</published><title>Langchain Agents or Langgraph Agents</title></entry><entry><author><name>/u/agile_crossover</name><uri>https://www.reddit.com/user/agile_crossover</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello -- I am trying to incrementally create a chatbot that will do three things (depending on user input)&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Summarize a JSON specification for the product (thinking some simple prompt engineering here should be able to do this)&lt;/li&gt; &lt;li&gt;Answer questions about some ontologies/hierarchies we maintain (thinking RAG)&lt;/li&gt; &lt;li&gt;Generate / Modify a JSON specification for the product (thinking a fine-tuned model for this specific structured output we use - internally before JSON we use pydantic models)&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;My question is what is the best way to use LangChains building blocks to properly route a user&amp;#39;s request to the appropriate model within the chat?&lt;/p&gt; &lt;p&gt;I was reading the docs and I wasn&amp;#39;t sure if I needed to create a custom agent (and somehow let it decide which of the three to use?) or if I should do a &amp;quot;dumber&amp;quot; rule-based function to then determine which of the three to use and just have that integrate with the basic chatbot.&lt;/p&gt; &lt;p&gt;Any help / guidance would be greatly appreciated! Am supposed to look into this for work and a little out of my depth right now.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/agile_crossover&quot;&gt; /u/agile_crossover &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eg41kn/confused_on_what_to_use_for_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eg41kn/confused_on_what_to_use_for_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eg41kn</id><link href="https://www.reddit.com/r/LangChain/comments/1eg41kn/confused_on_what_to_use_for_chatbot/" /><updated>2024-07-30T20:38:22+00:00</updated><published>2024-07-30T20:38:22+00:00</published><title>Confused on What to Use for Chatbot?</title></entry></feed>