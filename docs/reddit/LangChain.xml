<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-30T04:52:21+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/youniss_k</name><uri>https://www.reddit.com/user/youniss_k</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3fi3d/extracting_tables_in_pdfs/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/-ivhH6_-uoFWCTRN6E43T7c6ZJ7eFpFh8Jz46K6RArM.jpg&quot; alt=&quot;Extracting Tables in PDFs&quot; title=&quot;Extracting Tables in PDFs&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone. I am having troubles with extracting Tables in PDFs. I have PDFs of pricing options for different types of bricks. Theyre meant for marketing purposes actually, but I want to extract this value into JSON objects using Langchain.&lt;/p&gt; &lt;p&gt;Take a look:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/z05xvep2zd3d1.png?width=1910&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1cefd038628e6921ad1a610a6237838ddc892ff7&quot;&gt;Pricing options for bricks inside a PDF&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I have already tried using &lt;a href=&quot;http://Unstructured.io&quot;&gt;Unstructured.io&lt;/a&gt; however the JSON it returned wasnt good and it didnt even detect the Tables.&lt;/p&gt; &lt;p&gt;This is the workflow im trying to achieve:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;User loads in PDF of pricing list&lt;/li&gt; &lt;li&gt;Document is split per table (I only need the info of the data, nothing else. Some documents extend 100 pages)&lt;/li&gt; &lt;li&gt;For each Table, an LLM takes the information and creates a meaningful JSON out of it&lt;/li&gt; &lt;li&gt;I save the JSON inside a db&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;How would I do this splitting?&lt;/p&gt; &lt;p&gt;Thank you all in advance for your help :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/youniss_k&quot;&gt; /u/youniss_k &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3fi3d/extracting_tables_in_pdfs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3fi3d/extracting_tables_in_pdfs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d3fi3d</id><media:thumbnail url="https://b.thumbs.redditmedia.com/-ivhH6_-uoFWCTRN6E43T7c6ZJ7eFpFh8Jz46K6RArM.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1d3fi3d/extracting_tables_in_pdfs/" /><updated>2024-05-29T15:52:19+00:00</updated><published>2024-05-29T15:52:19+00:00</published><title>Extracting Tables in PDFs</title></entry><entry><author><name>/u/Ok_Rich9755</name><uri>https://www.reddit.com/user/Ok_Rich9755</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for a vector database that can scale - around 500m+ embeddings. I want to know how GCP Vector Search compares to other solutions such as QDrant and Milvus. Seems like GCP Vector Search is super easy to get started and has high performance. I&amp;#39;m not sure why more people aren&amp;#39;t talking about it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ok_Rich9755&quot;&gt; /u/Ok_Rich9755 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3tx3f/gcp_vector_search_as_vector_database/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3tx3f/gcp_vector_search_as_vector_database/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3tx3f</id><link href="https://www.reddit.com/r/LangChain/comments/1d3tx3f/gcp_vector_search_as_vector_database/" /><updated>2024-05-30T02:51:00+00:00</updated><published>2024-05-30T02:51:00+00:00</published><title>GCP Vector Search as Vector Database?</title></entry><entry><author><name>/u/AdExpensive4298</name><uri>https://www.reddit.com/user/AdExpensive4298</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Basically I am creating an app in which you are able to chat with the openai and I want to store the last 7 times or 7 days worth of message history from user. Now the problem is if i plainly save the chat messages then it takes up a lot of token size. I tried using the conversation summary buffer and all kinds of memory but either they were also resulting in a lot of tokens or did not give as expected output.&lt;/p&gt; &lt;p&gt;My question is that is there a way that once the user is done with the chat I can store the chat in a vector db and then whenever a user chats with the AI again it first checks the vector db for a reference of that object and returns related data and then my open ai llm with a specified prompt and the data collected give a response whereas if there is no data found speific to the object then my llm plainly uses the prompt I have given it?&lt;/p&gt; &lt;p&gt;Kindly give me if there are any other ways to do it &lt;/p&gt; &lt;p&gt;My tech stack is&lt;br/&gt; Frontend Flutter, Backend Python therefore it would be easy for me to attach langchain to python and just push requests from my app to my hosted api using python. &lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AdExpensive4298&quot;&gt; /u/AdExpensive4298 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3ok4l/question_about_chatbot_and_chat_message_history/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3ok4l/question_about_chatbot_and_chat_message_history/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3ok4l</id><link href="https://www.reddit.com/r/LangChain/comments/1d3ok4l/question_about_chatbot_and_chat_message_history/" /><updated>2024-05-29T22:27:35+00:00</updated><published>2024-05-29T22:27:35+00:00</published><title>Question about chatbot and chat message history with vector db</title></entry><entry><author><name>/u/RoadAny2857</name><uri>https://www.reddit.com/user/RoadAny2857</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am currently working on implementing RAG for a specific use case, and I have made good progress with a working example. So far, I have created embeddings for about 10-15 PDF/HTML files and I am using Qdrant locally (via Docker) to manage them.&lt;/p&gt; &lt;p&gt;Now, I am looking to scale up to around 30-40k files and I am unsure if this will work seamlessly. I have already implemented metadata filtering, so narrowing down relevant chunks isn&amp;#39;t a problem.&lt;/p&gt; &lt;p&gt;My main concern is the memory usage of the Docker container. When I check the container, it shows a memory cap of 3.5GB. I am new to Docker, so I am wondering if my vector embeddings size shouldn&amp;#39;t exceed this limit. If that&amp;#39;s the case, how should I address this problem?&lt;/p&gt; &lt;p&gt;Has anyone here tried using RAG with such a large dataset? If so, did you encounter any issues, particularly with handling and storing vector embeddings? Any best practices or tips you could share would be greatly appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RoadAny2857&quot;&gt; /u/RoadAny2857 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3fy9h/scaling_rag_for_large_datasets_need_your_insights/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3fy9h/scaling_rag_for_large_datasets_need_your_insights/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3fy9h</id><link href="https://www.reddit.com/r/LangChain/comments/1d3fy9h/scaling_rag_for_large_datasets_need_your_insights/" /><updated>2024-05-29T16:11:02+00:00</updated><published>2024-05-29T16:11:02+00:00</published><title>Scaling RAG for Large Datasets: Need Your Insights!</title></entry><entry><author><name>/u/Smooth-Loquat-4954</name><uri>https://www.reddit.com/user/Smooth-Loquat-4954</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3odd8/building_a_rag_chatbot_with_langchain_and_pinecone/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/0Uh0PudyegkQoLOGeHxP1bhD2nHkKgfiPS3T2a9Qh64.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ea133ba5ae0e1b65780fd83814a76a8dc8c8c886&quot; alt=&quot;Building a RAG chatbot with LangChain and Pinecone&quot; title=&quot;Building a RAG chatbot with LangChain and Pinecone&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Smooth-Loquat-4954&quot;&gt; /u/Smooth-Loquat-4954 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/Bxj4btI3TzY&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3odd8/building_a_rag_chatbot_with_langchain_and_pinecone/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d3odd8</id><media:thumbnail url="https://external-preview.redd.it/0Uh0PudyegkQoLOGeHxP1bhD2nHkKgfiPS3T2a9Qh64.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ea133ba5ae0e1b65780fd83814a76a8dc8c8c886" /><link href="https://www.reddit.com/r/LangChain/comments/1d3odd8/building_a_rag_chatbot_with_langchain_and_pinecone/" /><updated>2024-05-29T22:19:22+00:00</updated><published>2024-05-29T22:19:22+00:00</published><title>Building a RAG chatbot with LangChain and Pinecone</title></entry><entry><author><name>/u/northwolf56</name><uri>https://www.reddit.com/user/northwolf56</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;br/&gt; I&amp;#39;m working on a visual agents tool built on langchain and looking for people to try it out and maybe give some feedback or thoughts on it. It&amp;#39;s a completely serverless tool so there is no backend or API and all the execution and data resides local and private to you.&lt;/p&gt; &lt;p&gt;What do you think? I&amp;#39;m just one guy building this, so I&amp;#39;m hoping to get some community input! Thank you&lt;/p&gt; &lt;p&gt;Here is a quick demo of building a SQL Agent and then answering a question about your data. All within YOUR browser environment.&lt;br/&gt; &lt;a href=&quot;https://youtu.be/_3crxBzVg3A?si=-qCtoBv21NrIcFws&quot;&gt;https://youtu.be/_3crxBzVg3A?si=-qCtoBv21NrIcFws&lt;/a&gt; &lt;/p&gt; &lt;p&gt;And the app&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://app.visualagents.ai/#/&quot;&gt;https://app.visualagents.ai/#/&lt;/a&gt; &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/northwolf56&quot;&gt; /u/northwolf56 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3iv90/visual_agents_flow_engineering_tool_earlyaccess/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3iv90/visual_agents_flow_engineering_tool_earlyaccess/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3iv90</id><link href="https://www.reddit.com/r/LangChain/comments/1d3iv90/visual_agents_flow_engineering_tool_earlyaccess/" /><updated>2024-05-29T18:14:16+00:00</updated><published>2024-05-29T18:14:16+00:00</published><title>Visual Agents Flow Engineering Tool Early-Access</title></entry><entry><author><name>/u/Lucadario94</name><uri>https://www.reddit.com/user/Lucadario94</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I need to build a RAG using service ticket data. One service ticket is a ticket opened by the customer about specified issue for one product, is composed about: 1) one status 2) related product 3) one list of messages write by who has open the ticket and the service team&lt;/p&gt; &lt;p&gt;This ticket can has from 2 to 20/30 messages.&lt;/p&gt; &lt;p&gt;How chunk strategy we can use? I think that we use a semantic chunk or fixed chunk we could lose the context.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Lucadario94&quot;&gt; /u/Lucadario94 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3bvxq/chunking_a_service_ticket/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3bvxq/chunking_a_service_ticket/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3bvxq</id><link href="https://www.reddit.com/r/LangChain/comments/1d3bvxq/chunking_a_service_ticket/" /><updated>2024-05-29T13:13:10+00:00</updated><published>2024-05-29T13:13:10+00:00</published><title>Chunking a service ticket</title></entry><entry><author><name>/u/ramkitvprk</name><uri>https://www.reddit.com/user/ramkitvprk</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a requirement to build a Chatbot Application over a SQL DB , Here the SQL DB will be very huge consists of many Fact and Dimensional tables, Here are my below queries and please try to help me answer or provide better references.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Chatbot must be able to pick table names dynamically based on the user input and form queries and execute&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;How a Vectore DB can be leveraged here, can we embed all the tables and store in the vectoreDB, will be easier to query on similarity search?- am I missing any basics here please guide&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;is it a viable option to build an RAG system on the SQL DB and have it embedded into Vector DB ?&lt;br/&gt; and use memory management to retrieve the previously asked Queries to pop up automatically ?&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;can you please help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ramkitvprk&quot;&gt; /u/ramkitvprk &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3hhkj/need_a_help_on_creating_ragbased_sql_bot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3hhkj/need_a_help_on_creating_ragbased_sql_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3hhkj</id><link href="https://www.reddit.com/r/LangChain/comments/1d3hhkj/need_a_help_on_creating_ragbased_sql_bot/" /><updated>2024-05-29T17:16:54+00:00</updated><published>2024-05-29T17:16:54+00:00</published><title>Need a Help on creating RAG-based SQL Bot</title></entry><entry><author><name>/u/bigYman</name><uri>https://www.reddit.com/user/bigYman</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone had any luck using LangChain to parse these kind of documents?&lt;/p&gt; &lt;p&gt;I built a chatbot before to answer questions about a code base and about research papers. Those were pretty straight forward. But reading financial pdfs has turned out to be a real challenge.&lt;/p&gt; &lt;p&gt;I&amp;#39;m able to get good answers for pdfs that are more structured (like some of the P&amp;amp;L&amp;#39;s) but with others it&amp;#39;s constantly providing wrong answers or no answer and consistently referencing wrong documents.&lt;/p&gt; &lt;p&gt;I&amp;#39;m feel like it probably has to do with how I&amp;#39;m vectorizing the data but I&amp;#39;m at a loss. &lt;/p&gt; &lt;p&gt;Here&amp;#39;s the code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import os os.environ[&amp;#39;PINECONE_API_KEY&amp;#39;] = PINECONE_API_KEY from langchain.retrievers.self_query.base import SelfQueryRetriever from langchain.chains.query_constructor.base import AttributeInfo from langchain.prompts import ChatPromptTemplate from langchain.schema.output_parser import StrOutputParser from langchain.memory import ConversationTokenBufferMemory from langchain_core.prompts import MessagesPlaceholder from langchain_openai.embeddings import OpenAIEmbeddings from langchain_openai.chat_models import ChatOpenAI from langchain_community.document_loaders import DirectoryLoader from langchain_community.vectorstores import Pinecone as PC from pinecone import Pinecone, ServerlessSpec import nltk class RAG(): def __init__(self, docs_dir: str, n_retrievals: int = 4, chat_max_tokens: int = 3097, model_name = &amp;quot;gpt-4&amp;quot;, creativeness: float = 0.7): self.__model = self.__set_llm_model(model_name, creativeness) self.__docs_list = self.__get_docs_list(docs_dir) self.__retriever = self.__set_retriever(k=n_retrievals) def __set_llm_model(self, model_name = &amp;quot;gpt-4&amp;quot;, temperature: float = 0.7): return ChatOpenAI( model_name=model_name, temperature=temperature, openai_api_key=os.environ[&amp;#39;OPENAI_API_KEY&amp;#39;]) def __get_docs_list(self, docs_dir: str) -&amp;gt; list: print(&amp;quot;Loading documents...&amp;quot;) loader = DirectoryLoader(docs_dir, recursive=True, show_progress=True, use_multithreading=True, max_concurrency=4) docs_list = loader.load_and_split() return docs_list def __set_retriever(self, k: int = 4): # Initialize Pinecone pinecone = Pinecone( api_key=PINECONE_API_KEY ) index_name = &amp;#39;fin-docs&amp;#39; embeddings = OpenAIEmbeddings(model=&amp;quot;text-embedding-3-small&amp;quot;) # Create Pinecone index if it doesn&amp;#39;t exist if index_name not in pinecone.list_indexes().names(): pinecone.create_index( name=index_name, dimension=3072, metric=&amp;quot;cosine&amp;quot;, spec=ServerlessSpec(cloud=&amp;quot;aws&amp;quot;, region=&amp;quot;us-east-1&amp;quot;) ) vector_store = PC.from_documents( self.__docs_list, embedding=embeddings, index_name=index_name ) _retriever = SelfQueryRetriever.from_llm( self.__model, vector_store, document_content_description, metadata_field_info, search_kwargs={&amp;quot;k&amp;quot;: k} ) return _retriever def __set_chat_history(self, max_token_limit: int = 3097): return ConversationTokenBufferMemory( llm=self.__model, max_token_limit=max_token_limit, return_messages=True) def ask(self, question: str) -&amp;gt; str: prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;You are an assistant responsible for answering questions about documents. Answer the user&amp;#39;s question with a reasonable level of detail and based on the following context document(s):\n\n{context}&amp;quot;), (&amp;quot;user&amp;quot;, &amp;quot;{input}&amp;quot;), ]) output_parser = StrOutputParser() chain = prompt | self.__model | output_parser answer = chain.invoke({ &amp;quot;input&amp;quot;: question, &amp;quot;context&amp;quot;: self.__retriever.get_relevant_documents(question) }) return answer &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I can try and provide example docs if that would help as well. Would appreciate any help from ppl who&amp;#39;ve done something similar to this before.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bigYman&quot;&gt; /u/bigYman &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3fz8x/attempting_to_parse_pdfs_with_financial_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3fz8x/attempting_to_parse_pdfs_with_financial_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3fz8x</id><link href="https://www.reddit.com/r/LangChain/comments/1d3fz8x/attempting_to_parse_pdfs_with_financial_data/" /><updated>2024-05-29T16:12:12+00:00</updated><published>2024-05-29T16:12:12+00:00</published><title>Attempting to Parse PDF's with Financial Data (Balance Sheets, P&amp;Ls, 10Ks)</title></entry><entry><author><name>/u/joey2scoops</name><uri>https://www.reddit.com/user/joey2scoops</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Not sure if this the right place but here goes anyway. I have an excel spreadsheet that provides a weekly report. Each row contains 7 columns. 6 of these are standard fare for a spreadsheet. The last one though is a challenge. The cell contains up to 10,000 characters of free form text that represents shift notes from a range of different employees. Typically, these notes take the form of the example below.&lt;/p&gt; &lt;p&gt;&amp;lt;At 7:10 I inspected the widget file. The widget file was complete and had no errors. After that I called the office to report my findings. Then I had a coffee break. I reviewed the log file for the office server and completed that task by nine AM. There were no other events for the remainder of my shift. 9:30 a.m. arrived on site. 9:45 a.m. inspected the widget file no anomalies noted. 10:05 a.m. received a status update via phone call with Joe Bloggs. 11:15 a.m. morning coffee break. 11:30 a.m. commenced handover with the afternoon shift. New shift on the job from 12:00 p.m. first half of the shift was uneventful. Aroundabout 145 I received a text message to advise that the bearing on the widget machine was due to be replaced on Friday. I put a note into the log for the Friday crew. At 3:00 p.m. my shift was over. 3:00 p.m. arrived on site. 3:15 p.m. completed review of bog entry for the day. 345pm phone call the head office requesting additional post-it notes to be supplied. Nothing much happen for the rest of the shift. 6:00 p.m. arrived on site. 9 p.m. arrived on site and inspected the logs. No further action required.&amp;gt;&lt;/p&gt; &lt;p&gt;I&amp;#39;m trying to figure out how to &amp;quot;read&amp;quot; all these notes and pull out what looks like to be a complete event note or summarise, in dot points, the events of the day. As I said, this is a sheet for a week and there are at least 5 of these huge text entries, one for each day. &lt;/p&gt; &lt;p&gt;I&amp;#39;ve played around a little with chunking but quickly convinced myself that a chunking strategy could lead to events being missed because there is no single fit that I can see.&lt;/p&gt; &lt;p&gt;Anyone got any insight on how to handle such problems?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/joey2scoops&quot;&gt; /u/joey2scoops &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3a3ee/parsing_unstructured_text/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3a3ee/parsing_unstructured_text/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3a3ee</id><link href="https://www.reddit.com/r/LangChain/comments/1d3a3ee/parsing_unstructured_text/" /><updated>2024-05-29T11:39:56+00:00</updated><published>2024-05-29T11:39:56+00:00</published><title>Parsing Unstructured Text</title></entry><entry><author><name>/u/Pleasant_Put_8243</name><uri>https://www.reddit.com/user/Pleasant_Put_8243</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys i m trying to use where my llm point on foundation model hosted in bedrock but getting error :notimplemented yet &lt;/p&gt; &lt;pre&gt;&lt;code&gt; File &amp;quot;C:\code\dev\rmsology\venv\Lib\site-packages\langchain_core\language_models\base.py&amp;quot;, line 210, in with_structured_output raise NotImplementedError() NotImplementedError &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Pleasant_Put_8243&quot;&gt; /u/Pleasant_Put_8243 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3dloo/bedrock_support_in_structured_output_isnt/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3dloo/bedrock_support_in_structured_output_isnt/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3dloo</id><link href="https://www.reddit.com/r/LangChain/comments/1d3dloo/bedrock_support_in_structured_output_isnt/" /><updated>2024-05-29T14:30:26+00:00</updated><published>2024-05-29T14:30:26+00:00</published><title>Bedrock support in structured_output isnt implemented</title></entry><entry><author><name>/u/Intelligent-Fill-876</name><uri>https://www.reddit.com/user/Intelligent-Fill-876</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, how are you?&lt;/p&gt; &lt;p&gt;I am deploying a Kernel Memory service in production and wanted to get your opinion on my decision. Is it more cost-effective? The idea is to make it an async REST API.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Service host: EC2 - AWS.&lt;/li&gt; &lt;li&gt;Queue service: RabbitMQ on the EC2 machine hosting the Kernel Memory web service.&lt;/li&gt; &lt;li&gt;Storage &amp;amp; Vector Search: MongoDB Atlas.&lt;/li&gt; &lt;li&gt;The embedding and LLM models used will be from OpenAI.&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Intelligent-Fill-876&quot;&gt; /u/Intelligent-Fill-876 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d32vkw/kernel_memory_deploy_with_a_cheap_infrastructure/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d32vkw/kernel_memory_deploy_with_a_cheap_infrastructure/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d32vkw</id><link href="https://www.reddit.com/r/LangChain/comments/1d32vkw/kernel_memory_deploy_with_a_cheap_infrastructure/" /><updated>2024-05-29T03:39:43+00:00</updated><published>2024-05-29T03:39:43+00:00</published><title>Kernel Memory | Deploy with a cheap infrastructure</title></entry><entry><author><name>/u/Individual-Deer-3984</name><uri>https://www.reddit.com/user/Individual-Deer-3984</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;🚀 Exciting News! I just published a blog, Ragatouille– A guide to get started with Retrieval-Augmented Generation (RAG) with &lt;a href=&quot;https://www.linkedin.com/company/langchain/&quot;&gt;LangChain&lt;/a&gt; !&lt;/p&gt; &lt;p&gt;Based on Langchain&amp;#39;s RAG from scratch series, in this comprehensive guide, we break down the RAG process and take you through each step to enhance and optimize your system. Here’s a sneak peek of what you&amp;#39;ll learn:&lt;/p&gt; &lt;p&gt;📌 Introduction to RAG: Understand the basics of the RAG pipeline and how it combines retrieval-based systems with generative models.&lt;/p&gt; &lt;p&gt;🔍 Query Transformation: Learn how to refine user queries for better comprehension and accurate responses.&lt;/p&gt; &lt;p&gt;📚 Hypothetical Document Embeddings: Discover techniques for generating vector representations of potential documents to assess relevance.&lt;/p&gt; &lt;p&gt;🛤️ Routing Mechanisms: Implement intelligent routing to dynamically select the best data sources for your queries.&lt;/p&gt; &lt;p&gt;📝 Executable Queries: Master the art of translating user questions into executable queries.&lt;/p&gt; &lt;p&gt;📂 Effective Indexing: Explore indexing strategies to enhance retrieval efficiency.&lt;/p&gt; &lt;p&gt;🔄 Advanced Retrieval Techniques: Dive into Self-RAG, Adaptive RAG, and CRAG for tailored retrieval approaches.&lt;/p&gt; &lt;p&gt;💡 Generation Phase: Ensure coherent and accurate responses using the retrieved information.&lt;/p&gt; &lt;p&gt;🏥 Practical Application: Apply everything you&amp;#39;ve learned to build a sophisticated hospital management system using LangChain, LangGraph, and Neo4j.&lt;/p&gt; &lt;p&gt;👉 Check out: &lt;a href=&quot;https://www.sakunaharinda.xyz/ragatouille-book&quot;&gt;https://www.sakunaharinda.xyz/ragatouille-book&lt;/a&gt;&lt;/p&gt; &lt;p&gt;⬆️ I will be updating the blog soon with RAG evaluation using RAGAS and Langsmith !!! Please let me know what you guys want to appear in this blog, which will help fellow RAG enthusiasts 💭 I appreciate your constructive feedback and contributions !!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Individual-Deer-3984&quot;&gt; /u/Individual-Deer-3984 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2xedu/ragatouille_a_guide_to_get_started_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2xedu/ragatouille_a_guide_to_get_started_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d2xedu</id><link href="https://www.reddit.com/r/LangChain/comments/1d2xedu/ragatouille_a_guide_to_get_started_with/" /><updated>2024-05-28T23:05:51+00:00</updated><published>2024-05-28T23:05:51+00:00</published><title>Ragatouille: A guide to get started with Retrieval-Augmented Generation (RAG) with LangChain !</title></entry><entry><author><name>/u/areweliving1</name><uri>https://www.reddit.com/user/areweliving1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently working on a LangChain agent and need some help with making a DataFrame (df) accessible to the agent. Here’s a quick overview of what I’m trying to achieve:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The agent has access to several function tools.&lt;/li&gt; &lt;li&gt;These tools require a DataFrame (df) as a parameter.&lt;/li&gt; &lt;li&gt;The agent’s task is to call these tools, passing the data stored in a df variable.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;My Question:&lt;/strong&gt; Is there a way to ensure that the df variable is accessible to the agent so it can successfully pass the data to the function tools?&lt;/p&gt; &lt;p&gt;Any guidance or examples would be greatly appreciated!&lt;/p&gt; &lt;p&gt;Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/areweliving1&quot;&gt; /u/areweliving1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d368lr/how_to_make_dataframe_accessible_to_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d368lr/how_to_make_dataframe_accessible_to_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d368lr</id><link href="https://www.reddit.com/r/LangChain/comments/1d368lr/how_to_make_dataframe_accessible_to_langchain/" /><updated>2024-05-29T07:17:10+00:00</updated><published>2024-05-29T07:17:10+00:00</published><title>How to Make DataFrame Accessible to LangChain Agent</title></entry><entry><author><name>/u/Even-Constant-169</name><uri>https://www.reddit.com/user/Even-Constant-169</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d33nx3/gpt4o_langchain_rag_i_built_a_companion_robot/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/PPPA2lfO59E4DAdlSvPLm8Et0y5yutcPR-22Y-hpYCo.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=bc1b71d2d1ff2e986e192d59adbafdb21ef2ab72&quot; alt=&quot;[GPT-4o + LangChain + RAG] I built a companion robot with &amp;quot;memories&amp;quot; and &amp;quot;emotions&amp;quot;, his name is EVA [v1.0.0]&quot; title=&quot;[GPT-4o + LangChain + RAG] I built a companion robot with &amp;quot;memories&amp;quot; and &amp;quot;emotions&amp;quot;, his name is EVA [v1.0.0]&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Even-Constant-169&quot;&gt; /u/Even-Constant-169 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/riliV2PGKWQ&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d33nx3/gpt4o_langchain_rag_i_built_a_companion_robot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d33nx3</id><media:thumbnail url="https://external-preview.redd.it/PPPA2lfO59E4DAdlSvPLm8Et0y5yutcPR-22Y-hpYCo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc1b71d2d1ff2e986e192d59adbafdb21ef2ab72" /><link href="https://www.reddit.com/r/LangChain/comments/1d33nx3/gpt4o_langchain_rag_i_built_a_companion_robot/" /><updated>2024-05-29T04:24:47+00:00</updated><published>2024-05-29T04:24:47+00:00</published><title>[GPT-4o + LangChain + RAG] I built a companion robot with &quot;memories&quot; and &quot;emotions&quot;, his name is EVA [v1.0.0]</title></entry><entry><author><name>/u/BellaHi</name><uri>https://www.reddit.com/user/BellaHi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In a world where LLM applications are pushing the boundaries of what&amp;#39;s possible, observability is not just a nice-to-have—it&amp;#39;s essential for production-grade applications! Ensuring robust performance and reliability is a must, and that&amp;#39;s exactly what MyScale Telemetry delivers. &lt;/p&gt; &lt;p&gt;Say hello to the open-source alternative to LangSmith! &lt;a href=&quot;https://myscale.com/blog/myscale-telemetry-llm-app-observability/&quot;&gt;MyScale Telemetry&lt;/a&gt; is here to revolutionize how you trace and evaluate your LLM applications. With seamless integration with LangChain Callbacks, it&amp;#39;s the perfect tool to diagnose issues, optimize performance, and understand model behavior—all with the power of open-source! &lt;/p&gt; &lt;p&gt;MyScale Team&amp;#39;s Commitment to Open Source: Our passion for contributing to the community is unwavering, and with MyScale Telemetry, we&amp;#39;re excited to empower developers with the tools they need to innovate and excel. &lt;/p&gt; &lt;p&gt;Join us on this journey to enhance your LLM applications with MyScale Telemetry. Let&amp;#39;s shape the future of AI together, one trace at a time! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BellaHi&quot;&gt; /u/BellaHi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2yjqe/introducing_myscale_telemetry_your_opensource/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2yjqe/introducing_myscale_telemetry_your_opensource/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d2yjqe</id><link href="https://www.reddit.com/r/LangChain/comments/1d2yjqe/introducing_myscale_telemetry_your_opensource/" /><updated>2024-05-28T23:58:32+00:00</updated><published>2024-05-28T23:58:32+00:00</published><title>Introducing MyScale Telemetry - Your Open-Source Alternative to LangSmith!</title></entry><entry><author><name>/u/mahadevbhakti</name><uri>https://www.reddit.com/user/mahadevbhakti</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m currently working on a project where I need to integrate GPT-3.5 or GPT-4 into a product carousel, instead of the typical markdown text display. Specifically, I&amp;#39;m looking to intercept the model&amp;#39;s function calls and then present the results in a carousel format on my site.&lt;/p&gt; &lt;p&gt;Has anyone here tackled a similar challenge? I&amp;#39;m interested in any insights or approaches you might have used to modify the output format of these models.&lt;/p&gt; &lt;p&gt;I&amp;#39;d still want the gpt model to have context of what was fetched from the API i.e. what products, specially their names and product Ids?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mahadevbhakti&quot;&gt; /u/mahadevbhakti &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3852u/intercepting_function_calling_and_showing_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3852u/intercepting_function_calling_and_showing_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3852u</id><link href="https://www.reddit.com/r/LangChain/comments/1d3852u/intercepting_function_calling_and_showing_the/" /><updated>2024-05-29T09:35:40+00:00</updated><published>2024-05-29T09:35:40+00:00</published><title>Intercepting Function Calling and showing the data in UI</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2qqqy/building_an_agent_for_data_visualization_plotly/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/vr9_wzciKe4iumRmBa3g5c3KTA0PkUeTfMxce8sgy8U.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e97032457cd9f6f0da1334fcf91b3a6e02ee9234&quot; alt=&quot;Building an Agent for Data Visualization (Plotly)&quot; title=&quot;Building an Agent for Data Visualization (Plotly)&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://medium.com/@arslanshahid-1997/building-an-agent-for-data-visualization-plotly-39310034c4e9&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2qqqy/building_an_agent_for_data_visualization_plotly/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d2qqqy</id><media:thumbnail url="https://external-preview.redd.it/vr9_wzciKe4iumRmBa3g5c3KTA0PkUeTfMxce8sgy8U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e97032457cd9f6f0da1334fcf91b3a6e02ee9234" /><link href="https://www.reddit.com/r/LangChain/comments/1d2qqqy/building_an_agent_for_data_visualization_plotly/" /><updated>2024-05-28T18:35:17+00:00</updated><published>2024-05-28T18:35:17+00:00</published><title>Building an Agent for Data Visualization (Plotly)</title></entry><entry><author><name>/u/GeorgiaWitness1</name><uri>https://www.reddit.com/user/GeorgiaWitness1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2iubg/a_library_just_for_document_extraction_with_llms/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/Nfj1Xt2q-wi-SUE2TM66lJeoEkGv1In07CH5M7vbu_o.jpg&quot; alt=&quot;A library just for Document Extraction with LLMs, connector to Langchain | ExtractThinker&quot; title=&quot;A library just for Document Extraction with LLMs, connector to Langchain | ExtractThinker&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A month back I did a &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6afp1/creating_a_framework_like_langchain_but_just_for/&quot;&gt;post&lt;/a&gt; about creating a library just focused on Extraction for documents. Was well received here and in other places, including by some companies. So I gave it a try.&lt;/p&gt; &lt;p&gt;After a month and 2k+ lines of code, I created this repo, based on the previous one, that will contain a full-open source code. Contains already close to 200+ (as the writing of this post).&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/enoch3712/ExtractThinker&quot;&gt;https://github.com/enoch3712/ExtractThinker&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;The motivation&lt;/h1&gt; &lt;p&gt;Langchain works great integrating the several pieces &lt;strong&gt;but tends to be a pain to extract data from documents and other sources&lt;/strong&gt;. ExtractThinker falls into the class of tools like instructor (pydantic outputs) and litellm (agnostic call between LLM models), which solves a specific problem. A bit more high level yes, but the focus is the same. &lt;strong&gt;Extraction for documents like ORM with LLM.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;You can read in detail here:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/towards-artificial-intelligence/extractthinker-ai-document-intelligence-with-llms-72cbce1890ef&quot;&gt;https://medium.com/towards-artificial-intelligence/extractthinker-ai-document-intelligence-with-llms-72cbce1890ef&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;Basic use case and idea&lt;/h1&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/6qqufnee063d1.png?width=904&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=55bbd1aad1606fe6b83f4f07f338efab4deb6023&quot;&gt;https://preview.redd.it/6qqufnee063d1.png?width=904&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=55bbd1aad1606fe6b83f4f07f338efab4deb6023&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You can then use a middleware to inject the QR code content, and so on. I think you get the drill&lt;/p&gt; &lt;h1&gt;Why is this useful? Just do GPT-4o everything, use vision if needed&lt;/h1&gt; &lt;p&gt;The project will focus in two things:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Reducing the pain of leading with document extraction&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The project will handle tasks such as classifying and grouping documents. For example, it can be used to separate content within a collection of PDFs with random pages.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/k10voqea063d1.png?width=1170&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a64eaf8a015668ef85e0126226dd6e942ca53e5a&quot;&gt;splitting in action&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This would give you a list already separated and extracted (e.g first 2 pages invoice, last page driver&amp;#39;s license). This classification will expand to multiple strategies and techniques.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Reducing costs for scalability&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Build your architecture that works as well as GPT-4 with scalability and low cost. More in this article:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/@enoch3712/how-companies-use-llms-to-process-4-000-cvs-for-1-extractthinker-3fa0815057c3?sk=7fe626701a203135370e95f68bcb59f1&quot;&gt;https://medium.com/@enoch3712/how-companies-use-llms-to-process-4-000-cvs-for-1-extractthinker-3fa0815057c3?sk=7fe626701a203135370e95f68bcb59f1&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Just finished the final touches for the code, and it&amp;#39;s a real use case that worked out great using inexpensive quantized models from deepinfra.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The code still not production-ready and missing most of the features, but will make more sense with templates once i build the documentation.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I intend to eventually integrate this into langchain to be used like &lt;strong&gt;pypdf&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;If you can assist me with features as issues, use cases, or if anyone is interested in giving it a try, I would greatly appreciate it.&lt;/p&gt; &lt;p&gt;Thank you for your time.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/GeorgiaWitness1&quot;&gt; /u/GeorgiaWitness1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2iubg/a_library_just_for_document_extraction_with_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2iubg/a_library_just_for_document_extraction_with_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d2iubg</id><media:thumbnail url="https://b.thumbs.redditmedia.com/Nfj1Xt2q-wi-SUE2TM66lJeoEkGv1In07CH5M7vbu_o.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1d2iubg/a_library_just_for_document_extraction_with_llms/" /><updated>2024-05-28T12:58:12+00:00</updated><published>2024-05-28T12:58:12+00:00</published><title>A library just for Document Extraction with LLMs, connector to Langchain | ExtractThinker</title></entry><entry><author><name>/u/HappyDataGuy</name><uri>https://www.reddit.com/user/HappyDataGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Like I want to show, executing agent chain, executing sql genery, generating response like it prints in termial. Is ther any way to do this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HappyDataGuy&quot;&gt; /u/HappyDataGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d34xfq/how_to_show_what_agent_is_currently_doing_to_user/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d34xfq/how_to_show_what_agent_is_currently_doing_to_user/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d34xfq</id><link href="https://www.reddit.com/r/LangChain/comments/1d34xfq/how_to_show_what_agent_is_currently_doing_to_user/" /><updated>2024-05-29T05:45:11+00:00</updated><published>2024-05-29T05:45:11+00:00</published><title>How to show what agent is currently doing to user in streamlit?</title></entry><entry><author><name>/u/EfficientSurvival</name><uri>https://www.reddit.com/user/EfficientSurvival</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to use AI to expand my 10,000 word story into a 60k word novel. Obviously Chat GPT doesn&amp;#39;t offer enough tokens to do this, so I&amp;#39;m wondering, can Lang Chain combine with Chat GPT to accomplish this? I haven&amp;#39;t used Lang Chain yet to understand its capabilities yet. &lt;/p&gt; &lt;p&gt;If it is possible for this to work, how complicated would it be to do?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EfficientSurvival&quot;&gt; /u/EfficientSurvival &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d34r3h/10k_story_to_60k_novel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d34r3h/10k_story_to_60k_novel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d34r3h</id><link href="https://www.reddit.com/r/LangChain/comments/1d34r3h/10k_story_to_60k_novel/" /><updated>2024-05-29T05:33:26+00:00</updated><published>2024-05-29T05:33:26+00:00</published><title>10k Story to 60k Novel?</title></entry><entry><author><name>/u/Dense_Technology_638</name><uri>https://www.reddit.com/user/Dense_Technology_638</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;GPT4AllEmbeddings modify model path&lt;/p&gt; &lt;p&gt;I&amp;#39;d like to modify the model path using GPT4AllEmbeddings and use a model I already downloading from the browser (the all-MiniLM-L6-v2-f16.gguf model, the same that GPT4AllEmbeddings downloads by default).&lt;/p&gt; &lt;p&gt;I need it to create RAG chatbot completely offline.&lt;/p&gt; &lt;p&gt;The langchain documentation chatbot suggests me to use:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;from langchain_community.embeddings &lt;strong&gt;import&lt;/strong&gt; GPT4AllEmbeddings&lt;br/&gt; model_path = &amp;quot;/path/to/your/model.bin&amp;quot;&lt;br/&gt; gpt4all_embd = GPT4AllEmbeddings(model=model_path)&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;I tried it but it does not work. It completely ignores the model path.&lt;/p&gt; &lt;p&gt;Is there something I&amp;#39;m missing?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Dense_Technology_638&quot;&gt; /u/Dense_Technology_638 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2xqz3/gpt4allembeddings_doesnt_work_offline_no_way_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2xqz3/gpt4allembeddings_doesnt_work_offline_no_way_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d2xqz3</id><link href="https://www.reddit.com/r/LangChain/comments/1d2xqz3/gpt4allembeddings_doesnt_work_offline_no_way_to/" /><updated>2024-05-28T23:21:11+00:00</updated><published>2024-05-28T23:21:11+00:00</published><title>GPT4AllEmbeddings doesn’t work offline no way to pass a model path (any workarounds?)</title></entry><entry><author><name>/u/Ok_Session_7304</name><uri>https://www.reddit.com/user/Ok_Session_7304</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m exploring multi-agent systems and am curious about the role of an orchestrator in managing tasks among specialized agents. For instance, imagine a scenario where there are four agents, each designed to perform one of the basic mathematical operations: addition, subtraction, multiplication, and division.&lt;/p&gt; &lt;p&gt;If the orchestrator receives a question like &amp;quot;How much is 4 + 4?&amp;quot;, how does it determine which agent to send the query to? What logic or algorithms might it use to parse the question and delegate the task appropriately?&lt;/p&gt; &lt;p&gt;Additionally, if anyone could provide insights or resources into how such systems are generally designed or any examples of such orchestrators in action, it would be greatly appreciated.&lt;/p&gt; &lt;p&gt;Thanks in advance for your help and sharing your knowledge!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ok_Session_7304&quot;&gt; /u/Ok_Session_7304 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2omoe/how_does_an_llm_orchestrator_decide_which_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2omoe/how_does_an_llm_orchestrator_decide_which_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d2omoe</id><link href="https://www.reddit.com/r/LangChain/comments/1d2omoe/how_does_an_llm_orchestrator_decide_which_agent/" /><updated>2024-05-28T17:09:49+00:00</updated><published>2024-05-28T17:09:49+00:00</published><title>How does an LLM orchestrator decide which agent to use in a multi-agent system?</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2nfuz/shopify_all_in_on_promptfoo/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/qgg45w3d073d1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ab39be24a8d163f8797a5621ffba8c8ee470b5a6&quot; alt=&quot;Shopify all in on Promptfoo&quot; title=&quot;Shopify all in on Promptfoo&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am a big fan of Promptfoo aswell. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/qgg45w3d073d1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2nfuz/shopify_all_in_on_promptfoo/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d2nfuz</id><media:thumbnail url="https://preview.redd.it/qgg45w3d073d1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ab39be24a8d163f8797a5621ffba8c8ee470b5a6" /><link href="https://www.reddit.com/r/LangChain/comments/1d2nfuz/shopify_all_in_on_promptfoo/" /><updated>2024-05-28T16:19:36+00:00</updated><published>2024-05-28T16:19:36+00:00</published><title>Shopify all in on Promptfoo</title></entry><entry><author><name>/u/nicoloboschi</name><uri>https://www.reddit.com/user/nicoloboschi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is a poetry plugin to generate Dockerfile and images automatically.&lt;/p&gt; &lt;p&gt;This is a perfect choice if you built the Langchain application and you’re looking for to distribute is as microservice in the cloud. &lt;/p&gt; &lt;p&gt;This project lets you generate a docker image or just a Dockerfile for your poetry application without manual setup&lt;/p&gt; &lt;p&gt;It is meant for production images.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/nicoloboschi/poetry-dockerize-plugin&quot;&gt;https://github.com/nicoloboschi/poetry-dockerize-plugin&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://pypi.org/project/poetry-dockerize-plugin/&quot;&gt;https://pypi.org/project/poetry-dockerize-plugin/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Get started with&lt;/p&gt; &lt;pre&gt;&lt;code&gt;poetry self add poetry-dockerize-plugin@latest &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This command generates a production-ready, optimized python image:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;poetry dockerize &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or to generate a Dockerfile&lt;/p&gt; &lt;pre&gt;&lt;code&gt;poetry dockerize --generate &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nicoloboschi&quot;&gt; /u/nicoloboschi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2rq1k/dockerize_langchainlangserve_applications/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d2rq1k/dockerize_langchainlangserve_applications/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d2rq1k</id><link href="https://www.reddit.com/r/LangChain/comments/1d2rq1k/dockerize_langchainlangserve_applications/" /><updated>2024-05-28T19:14:29+00:00</updated><published>2024-05-28T19:14:29+00:00</published><title>Dockerize langchain/langserve applications</title></entry></feed>