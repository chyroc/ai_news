<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-02T14:47:23+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Brave-Guide-7470</name><uri>https://www.reddit.com/user/Brave-Guide-7470</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/e41kBpbrClfdwFjhQbFO0lBPyR2D-CYfc9oUqEt2ksQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3aa90a5396a7a8ad789e42874ec0066d7974dc44&quot; alt=&quot;Test your prompts through the terminal&quot; title=&quot;Test your prompts through the terminal&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys!&lt;/p&gt; &lt;p&gt;I&amp;#39;ve developed a helper CLI tool that allows you to test prompts on both ChatGPT and Anthropic models through a simple API.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/56s9aibuc0yc1.png?width=1597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d5408e2cd05ff382ea671c0816b67567cd53cbf0&quot;&gt;https://preview.redd.it/56s9aibuc0yc1.png?width=1597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d5408e2cd05ff382ea671c0816b67567cd53cbf0&lt;/a&gt;&lt;/p&gt; &lt;p&gt;To test it, just run:&lt;/p&gt; &lt;p&gt;pip install dialog-lib&lt;/p&gt; &lt;p&gt;export OPENAI_API_KEY=sk-YOUR_API_KEY&lt;/p&gt; &lt;p&gt;dialog openai --prompt &amp;quot;Your prompt that you want to test, here!&amp;quot;&lt;/p&gt; &lt;p&gt;Here is a link to a quick demo: &lt;a href=&quot;https://www.linkedin.com/feed/update/urn:li:activity:7191776208651489282/&quot;&gt;https://www.linkedin.com/feed/update/urn:li:activity:7191776208651489282/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Brave-Guide-7470&quot;&gt; /u/Brave-Guide-7470 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cielku</id><media:thumbnail url="https://external-preview.redd.it/e41kBpbrClfdwFjhQbFO0lBPyR2D-CYfc9oUqEt2ksQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3aa90a5396a7a8ad789e42874ec0066d7974dc44" /><link href="https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/" /><updated>2024-05-02T12:37:09+00:00</updated><published>2024-05-02T12:37:09+00:00</published><title>Test your prompts through the terminal</title></entry><entry><author><name>/u/aryanmadhavverma</name><uri>https://www.reddit.com/user/aryanmadhavverma</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have an agent with two tools. The tools are being used in a sequential way. The second tool queries the database and returns in a pydantic format I&amp;#39;ve defined myself. Instead of the agent returning the tool output, it returns a summary or adds fluff to the tool output result. I only want it to return the tool output! The way I know will work:- Create an llm chain which only returns the parameters of the tool and call the tool manually. But this reduces the agentic behaviour of my functionality. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;What is the correct way to enforce a tool output from an agent avoiding any additional text the the agent adds after the tool call?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/aryanmadhavverma&quot;&gt; /u/aryanmadhavverma &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cibpk9/correct_way_to_return_tool_output_of_an_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cibpk9/correct_way_to_return_tool_output_of_an_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cibpk9</id><link href="https://www.reddit.com/r/LangChain/comments/1cibpk9/correct_way_to_return_tool_output_of_an_agent/" /><updated>2024-05-02T09:55:29+00:00</updated><published>2024-05-02T09:55:29+00:00</published><title>Correct way to return tool output of an agent executor instance?</title></entry><entry><author><name>/u/CHvader</name><uri>https://www.reddit.com/user/CHvader</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, was wondering if anyone had any tips for an API or general approach to automate grabbing of answers + citations/refs using an LLM.&lt;/p&gt; &lt;p&gt;For example, I would like to ask &amp;quot;How many members were on Instagram in the US in 2019?&amp;quot; and get both a number back and a link to the source. I would also like to be able to ask, for e.g. &amp;quot;How did X firm use AI and Data Science this year. Please cite a source from the firm X&amp;quot;.&lt;/p&gt; &lt;p&gt;These are just example use-cases of the flexibility I am looking for - I currently use &lt;a href=&quot;https://perplexity.ai/&quot;&gt;perplexity.ai&lt;/a&gt; for this kind of stuff, but their API doesn&amp;#39;t return citations immediately (which would be my primary use case). Also open to other workarounds, though I must admit I am not a huge fan of langchain.&lt;/p&gt; &lt;p&gt;Thanks for the tips!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CHvader&quot;&gt; /u/CHvader &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cigfv9/any_apis_that_use_llms_to_grab_updated_citations/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cigfv9/any_apis_that_use_llms_to_grab_updated_citations/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cigfv9</id><link href="https://www.reddit.com/r/LangChain/comments/1cigfv9/any_apis_that_use_llms_to_grab_updated_citations/" /><updated>2024-05-02T14:01:05+00:00</updated><published>2024-05-02T14:01:05+00:00</published><title>Any APIs that use LLMs to grab updated citations or references from the web?</title></entry><entry><author><name>/u/Omervx</name><uri>https://www.reddit.com/user/Omervx</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cifyrc/help_adding_memory_to_my_bot/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/k3mBdbLNpdJb-Nyw3FdVlfMqZ3Ba5gdbaosEtu259tU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=92584fd73a105d179e447610a6e967f9d7f33e12&quot; alt=&quot;Help adding memory to my bot&quot; title=&quot;Help adding memory to my bot&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hi guys im a joniur developer and this is my first AI related project and i need some help adding a Simple memory to my chat bot can u pls help me&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Omervx&quot;&gt; /u/Omervx &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/oovaa/ChatPDF/blob/main/tools%2Fchain.js&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cifyrc/help_adding_memory_to_my_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cifyrc</id><media:thumbnail url="https://external-preview.redd.it/k3mBdbLNpdJb-Nyw3FdVlfMqZ3Ba5gdbaosEtu259tU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=92584fd73a105d179e447610a6e967f9d7f33e12" /><link href="https://www.reddit.com/r/LangChain/comments/1cifyrc/help_adding_memory_to_my_bot/" /><updated>2024-05-02T13:41:06+00:00</updated><published>2024-05-02T13:41:06+00:00</published><title>Help adding memory to my bot</title></entry><entry><author><name>/u/DancingDorritos</name><uri>https://www.reddit.com/user/DancingDorritos</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I’ve been trying to get [title] working using LangChain, azure OpenAI and chroma for storing embeddings. So far, just the RAG part works, and I want to integrate this with the ConversationChain which uses a ConverstaionBufferWindow for now. &lt;/p&gt; &lt;p&gt;My current method is to get the history of the conversation chain, supplement this with the context from the embeddings (from matching similarity), and then feed this into the llm to get a response. Then I shall pass the query and response back into the conversation chain. &lt;/p&gt; &lt;p&gt;However, I can’t find any proper documentation how I can combine the context and the conversation history properly to pass into the llm. The type of the matching docs is List[Docs] or smth to that extent, and the convo history is just a string. &lt;/p&gt; &lt;p&gt;Does anyone know a proper way of doing this? Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DancingDorritos&quot;&gt; /u/DancingDorritos &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cif179/rag_with_conversationchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cif179/rag_with_conversationchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cif179</id><link href="https://www.reddit.com/r/LangChain/comments/1cif179/rag_with_conversationchain/" /><updated>2024-05-02T12:59:30+00:00</updated><published>2024-05-02T12:59:30+00:00</published><title>RAG with ConversationChain</title></entry><entry><author><name>/u/Standard-Society-568</name><uri>https://www.reddit.com/user/Standard-Society-568</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am learning and facing issues as most of the Docs on it&amp;#39;s are for OpenAI and I am using Google Gemini API.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Standard-Society-568&quot;&gt; /u/Standard-Society-568 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidumu/any_discord_server_of_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidumu/any_discord_server_of_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cidumu</id><link href="https://www.reddit.com/r/LangChain/comments/1cidumu/any_discord_server_of_langchain/" /><updated>2024-05-02T11:59:11+00:00</updated><published>2024-05-02T11:59:11+00:00</published><title>Any Discord server of Langchain?</title></entry><entry><author><name>/u/H3nrik123</name><uri>https://www.reddit.com/user/H3nrik123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, &lt;/p&gt; &lt;p&gt;Does someone have experience in running a script using Langchain in Azure Function App?&lt;br/&gt; For a while I was doing development and running the script locally and the results I was getting when analyzing a dataframe using a pandas_dataframe_agent were 10/10.&lt;br/&gt; Now when I published the same script to Azure Function App the quality of the results is 1/10. &lt;/p&gt; &lt;p&gt;The requirements.txt file has the same versions of python libraries as I have locally. &lt;/p&gt; &lt;p&gt;I am not that familiar with function apps and I am wondering if there are some limitations to whether langchain and openai can be run there?&lt;/p&gt; &lt;p&gt;All help is appreciated :) &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/H3nrik123&quot;&gt; /u/H3nrik123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidrmj/langchain_in_azure_function_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidrmj/langchain_in_azure_function_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cidrmj</id><link href="https://www.reddit.com/r/LangChain/comments/1cidrmj/langchain_in_azure_function_app/" /><updated>2024-05-02T11:54:38+00:00</updated><published>2024-05-02T11:54:38+00:00</published><title>Langchain in Azure Function App</title></entry><entry><author><name>/u/loczngo</name><uri>https://www.reddit.com/user/loczngo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi y&amp;#39;all i was wondering, are there any other alternatives i could do my research on to stream the conversation between me and the LLMs such as Streamlit? i wanna stream the conversation using my own design on NodeJS and i still haven&amp;#39;t figured out which way to integrate the LLMs conversation with my UI.&lt;/p&gt; &lt;p&gt;Thanks for any help or insights y&amp;#39;all will give &amp;lt;3&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/loczngo&quot;&gt; /u/loczngo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cia5g2/streamlit_referrences_for_nodejs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cia5g2/streamlit_referrences_for_nodejs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cia5g2</id><link href="https://www.reddit.com/r/LangChain/comments/1cia5g2/streamlit_referrences_for_nodejs/" /><updated>2024-05-02T08:03:14+00:00</updated><published>2024-05-02T08:03:14+00:00</published><title>Streamlit referrences for NodeJS</title></entry><entry><author><name>/u/Aware-Damage-6906</name><uri>https://www.reddit.com/user/Aware-Damage-6906</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidfrs/hindilanguage_ai_chatbot_for_enterprises_using/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/s5T4cSPLd6TxUKmOlP3k_4Zk-nx3EK6BhH5JrTT42wg.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4d6ed93b53ad517b42bec6ca61021fe128dd33d0&quot; alt=&quot;Hindi-Language AI Chatbot for Enterprises Using Qdrant, MLFlow, and LangChain&quot; title=&quot;Hindi-Language AI Chatbot for Enterprises Using Qdrant, MLFlow, and LangChain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Aware-Damage-6906&quot;&gt; /u/Aware-Damage-6906 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://quamernasim.hashnode.dev/hindi-language-ai-chatbot-for-enterprises-using-qdrant-mlflow-and-langchain&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidfrs/hindilanguage_ai_chatbot_for_enterprises_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cidfrs</id><media:thumbnail url="https://external-preview.redd.it/s5T4cSPLd6TxUKmOlP3k_4Zk-nx3EK6BhH5JrTT42wg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d6ed93b53ad517b42bec6ca61021fe128dd33d0" /><link href="https://www.reddit.com/r/LangChain/comments/1cidfrs/hindilanguage_ai_chatbot_for_enterprises_using/" /><updated>2024-05-02T11:37:18+00:00</updated><published>2024-05-02T11:37:18+00:00</published><title>Hindi-Language AI Chatbot for Enterprises Using Qdrant, MLFlow, and LangChain</title></entry><entry><author><name>/u/Sweaty-Minimum5423</name><uri>https://www.reddit.com/user/Sweaty-Minimum5423</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, I have a few questions related langgraph.&lt;/p&gt; &lt;p&gt;The structure I’m planning is as follows:&lt;/p&gt; &lt;p&gt;One frontdesk agent(supervisor) is responsible to route query and answer customer questions. Frontdesk agent doesn’t have any RAG system linked to it. It’s just a customer facing agent.&lt;/p&gt; &lt;p&gt;Frontdesk agent has some “lower level” agents to help. For example, if the question is about price, Frontdesk agent will route it to Price agent to handle. The Price agent will be linked to a RAG system to retrieve the price. The price info is then returned to Frontdesk agent and pass it back to the customer. This is more like what I see in the traditional agent flow.&lt;/p&gt; &lt;p&gt;Here’s my question. Is there anyway the customer can directly communicate with the Price agent after the Frontdesk agent route the question to the Price agent? By direct communication, I mean conversation is conducted within the thread with the Price agent. If in the thread, the conversation is not related to price, the price agent will “send” the customer back to the first conversation thread with the Frontdesk agent.&lt;/p&gt; &lt;p&gt;I would love to see if there is any langchain or langgraph projects or resources related to this. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sweaty-Minimum5423&quot;&gt; /u/Sweaty-Minimum5423 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidcip/conversation_chatbot_in_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidcip/conversation_chatbot_in_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cidcip</id><link href="https://www.reddit.com/r/LangChain/comments/1cidcip/conversation_chatbot_in_langgraph/" /><updated>2024-05-02T11:32:25+00:00</updated><published>2024-05-02T11:32:25+00:00</published><title>Conversation Chatbot in Langgraph</title></entry><entry><author><name>/u/kalintsov</name><uri>https://www.reddit.com/user/kalintsov</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I have a CSV file containing a historical log of my conversations with my partner. The file is organized into three columns: datetime, sent_by, and message. I would like to use a LLM to ask questions about our discussions (e.g &amp;quot;When is the wedding of A and B?&amp;quot;).&lt;/p&gt; &lt;p&gt;I&amp;#39;m looking for some advices on the most effective way to process and vectorize these conversations. I want the LLM to understand the metadata within the context of the discussions—for instance, identifying that if Person A wrote &amp;quot;Happy Birthday,&amp;quot; it likely indicates Person B&amp;#39;s birthday on that date.&lt;/p&gt; &lt;p&gt;What do you think is the best approach to handling chat logs in this scenario? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kalintsov&quot;&gt; /u/kalintsov &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci8hwh/efficient_rag_on_chat_logs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci8hwh/efficient_rag_on_chat_logs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci8hwh</id><link href="https://www.reddit.com/r/LangChain/comments/1ci8hwh/efficient_rag_on_chat_logs/" /><updated>2024-05-02T06:13:01+00:00</updated><published>2024-05-02T06:13:01+00:00</published><title>Efficient RAG on chat logs</title></entry><entry><author><name>/u/Original_Job6327</name><uri>https://www.reddit.com/user/Original_Job6327</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let’s say i’m using openai gpt3.5. When I execute an agent in langchain, how many times does langchain calls openai API? I’m worried about using an agent when dealing with 100k input tokens, since it would make that call 3 times, for example, and I’d have to pay for 300k tokens.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Original_Job6327&quot;&gt; /u/Original_Job6327 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci7hqx/how_many_api_calls_does_an_agent_make_for_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci7hqx/how_many_api_calls_does_an_agent_make_for_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci7hqx</id><link href="https://www.reddit.com/r/LangChain/comments/1ci7hqx/how_many_api_calls_does_an_agent_make_for_a/" /><updated>2024-05-02T05:10:46+00:00</updated><published>2024-05-02T05:10:46+00:00</published><title>How many API calls does an agent make for a single input?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1ci6vod/google_gemini_api_key_for_free/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci6we7/google_gemini_api_key_for_free/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci6we7</id><link href="https://www.reddit.com/r/LangChain/comments/1ci6we7/google_gemini_api_key_for_free/" /><updated>2024-05-02T04:37:02+00:00</updated><published>2024-05-02T04:37:02+00:00</published><title>Google Gemini API key for free</title></entry><entry><author><name>/u/krschacht</name><uri>https://www.reddit.com/user/krschacht</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m an experienced engineer and have been doing a lot of work interacting directly with LLM APIs (using simple SDKs). Multiple people have told me to check out langchain, so I just did a spike on it. I skimmed the docs, I get the core concept of chains and agents. It&amp;#39;s cool but this seems like a set of pretty basic abstractions. But I&amp;#39;m scratching my head wondering: what about langchain are people finding most helpful? Given how popular this library is, I feel like I&amp;#39;m missing something key...&lt;/p&gt; &lt;p&gt;I&amp;#39;m not trying to be snarky at all. I am assuming that I probably should be using LangChain and it probably could be saving me a bunch of time, so I genuinely want to grasp the biggest benefits of it since I don&amp;#39;t think I&amp;#39;m getting it.&lt;/p&gt; &lt;p&gt;Maybe the core problem is that we all inevitably end up using multiple LLMs eventually (OpenAI, Anthropic, etc) so the biggest benefit of LangChain is that you have a sort of universal SDK — a common interface between all the LLMs. Is that the biggest benefit of langchain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/krschacht&quot;&gt; /u/krschacht &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chpywv/what_makes_langchain_so_useful_im_new_to_it_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chpywv/what_makes_langchain_so_useful_im_new_to_it_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1chpywv</id><link href="https://www.reddit.com/r/LangChain/comments/1chpywv/what_makes_langchain_so_useful_im_new_to_it_and/" /><updated>2024-05-01T16:09:37+00:00</updated><published>2024-05-01T16:09:37+00:00</published><title>What makes langchain so useful? I'm new to it and don't get it</title></entry><entry><author><name>/u/WompTune</name><uri>https://www.reddit.com/user/WompTune</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;br/&gt; Was wondering if anyone has moved from Assistants API to Langchain + Langsmith and how that felt?&lt;br/&gt; I loveeee OpenAI Assistants API because it manages conversation history + context for me, and has the dashboard to see messages in the thread. &lt;/p&gt; &lt;p&gt;But unfortunately OpenAI has been super slow lately...&lt;/p&gt; &lt;p&gt;So I was wondering if Langchain (with an open source model like Llama 3) + Langsmith gives an equivalent vibe where I don&amp;#39;t have to manage conversation history / context management myself?&lt;/p&gt; &lt;p&gt;Appreciate it!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/WompTune&quot;&gt; /u/WompTune &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci1umo/moving_from_openai_assistants_api_to_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci1umo/moving_from_openai_assistants_api_to_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci1umo</id><link href="https://www.reddit.com/r/LangChain/comments/1ci1umo/moving_from_openai_assistants_api_to_langchain/" /><updated>2024-05-02T00:19:59+00:00</updated><published>2024-05-02T00:19:59+00:00</published><title>Moving from OpenAI Assistants API to Langchain + Langsmith?</title></entry><entry><author><name>/u/transwarpconduit1</name><uri>https://www.reddit.com/user/transwarpconduit1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;d like to be able to ask for human confirmation before the agent executor invokes a certain tool. For example, let&amp;#39;s say I have a&lt;code&gt;send_email&lt;/code&gt;tool, and I&amp;#39;d like to confirm before it is run.&lt;/p&gt; &lt;p&gt;Does the Langchain agent framework provide a way to hook into the lifecycle in order to do this? Ideally, a hook that would run before the invocation, has tool name and arguments passed in, and then you can return True or False (or an *Exception for an error). I could have the email displayed to standard out there, and collect input. &lt;/p&gt; &lt;p&gt;It doesn&amp;#39;t seem like callback handlers work, and they weren&amp;#39;t intended for that anyway. They are for introspection (like logging, instrumentation, etc.).&lt;/p&gt; &lt;p&gt;I can actually put the confirmation logic in the tool function itself and get it to work, but that doesn&amp;#39;t seem right. I could create a special wrapper function &amp;quot;add_human_approval(tool_func)&amp;quot; that returns a new function that asks for human approval, and if it passes invokes the passed in func, otherwise returns. Again, that&amp;#39;s still at the tool level, instead as part of the lifecycle.&lt;/p&gt; &lt;p&gt;Thoughts?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/transwarpconduit1&quot;&gt; /u/transwarpconduit1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci3m0k</id><link href="https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/" /><updated>2024-05-02T01:43:51+00:00</updated><published>2024-05-02T01:43:51+00:00</published><title>Tool-calling agents: Human approval before tool invocation?</title></entry><entry><author><name>/u/ThickDoctor007</name><uri>https://www.reddit.com/user/ThickDoctor007</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone successfully implemented function calling with agents based on open source LLMs?&lt;/p&gt; &lt;p&gt;Would be glad to learn about your experiences.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ThickDoctor007&quot;&gt; /u/ThickDoctor007 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci6afc/function_calling_with_open_source_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci6afc/function_calling_with_open_source_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci6afc</id><link href="https://www.reddit.com/r/LangChain/comments/1ci6afc/function_calling_with_open_source_llms/" /><updated>2024-05-02T04:01:53+00:00</updated><published>2024-05-02T04:01:53+00:00</published><title>Function calling with open source LLMs</title></entry><entry><author><name>/u/Advanced_Art_8216</name><uri>https://www.reddit.com/user/Advanced_Art_8216</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I recently started learning langchain and trying to build a chat bot with sequence such as in first step it collects some info from user and then based on if else condition can either move to sequence 2 or sequence 3. It stays on sequence 1 until it has the required info. Each of the sequence has a new prompt and temperature control. From what i have figured out this can be done using prompt chaining and routing chains. Am i on the correct path or missing something? I am trying to do in javascript and unable to find any good examples. Any help will be appreciated. Thank You.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Advanced_Art_8216&quot;&gt; /u/Advanced_Art_8216 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chwv9w/conditional_multiple_sequence_chat_bot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chwv9w/conditional_multiple_sequence_chat_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1chwv9w</id><link href="https://www.reddit.com/r/LangChain/comments/1chwv9w/conditional_multiple_sequence_chat_bot/" /><updated>2024-05-01T20:50:24+00:00</updated><published>2024-05-01T20:50:24+00:00</published><title>Conditional Multiple sequence chat bot</title></entry><entry><author><name>/u/RoboCoachTech</name><uri>https://www.reddit.com/user/RoboCoachTech</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chtidn/an_agentic_approach_to_robot_software_generation/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/-zAlWZClj_CLxJRRkJ8gIQ3yeqm97H9YlyuUdqNzu-o.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=84be01462537709f49707dba68c0af0cdb5a2bd9&quot; alt=&quot;An agentic approach to robot software generation using LangChain&quot; title=&quot;An agentic approach to robot software generation using LangChain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RoboCoachTech&quot;&gt; /u/RoboCoachTech &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=iIIxcBJARDQ&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chtidn/an_agentic_approach_to_robot_software_generation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1chtidn</id><media:thumbnail url="https://external-preview.redd.it/-zAlWZClj_CLxJRRkJ8gIQ3yeqm97H9YlyuUdqNzu-o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=84be01462537709f49707dba68c0af0cdb5a2bd9" /><link href="https://www.reddit.com/r/LangChain/comments/1chtidn/an_agentic_approach_to_robot_software_generation/" /><updated>2024-05-01T18:32:55+00:00</updated><published>2024-05-01T18:32:55+00:00</published><title>An agentic approach to robot software generation using LangChain</title></entry><entry><author><name>/u/Tasty-Bandicoot-9657</name><uri>https://www.reddit.com/user/Tasty-Bandicoot-9657</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am creating a project where I would like to evaluate a document by running it through a chain. However the documents that I need to evaluate are kinda large, so I am experimenting with introducing the context, i.e. the document(s), outside of the chain itself. &lt;/p&gt; &lt;p&gt;For this purpose, I have followed much of the documentation from &lt;a href=&quot;https://python.langchain.com/docs/use_cases/chatbots/memory_management/&quot;&gt;Memory management | 🦜️🔗 LangChain&lt;/a&gt;, of course with appropriate modifications. However, I can not find any solid explanation for how this ChatMessageHistory class is treated by the OpenAI API. I am concerned that if I invoke my chain after having added the document to the chat history that the document is counted towards the input tokens for each subsequent call of the assistant. &lt;/p&gt; &lt;p&gt;Does anybody know this? Or does anybody maybe have some suggestions to another solution?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Tasty-Bandicoot-9657&quot;&gt; /u/Tasty-Bandicoot-9657 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chqp0r/how_costefficient_is_the_usage_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chqp0r/how_costefficient_is_the_usage_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1chqp0r</id><link href="https://www.reddit.com/r/LangChain/comments/1chqp0r/how_costefficient_is_the_usage_of/" /><updated>2024-05-01T16:39:23+00:00</updated><published>2024-05-01T16:39:23+00:00</published><title>How cost-efficient is the usage of ChatMessageHistory?</title></entry><entry><author><name>/u/Desik_1998</name><uri>https://www.reddit.com/user/Desik_1998</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I was actually planning to jailbreak Gpt3.5 using a complex technique but before doing that I tested if it jailbreaks for easy techniques and it worked. It seems that OpenAI hasn&amp;#39;t added enough checks and balances on their side.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Repo Link:&lt;/strong&gt; &lt;a href=&quot;https://github.com/desik1998/jailbreak-gpt3.5-using-finetuning&quot;&gt;https://github.com/desik1998/jailbreak-gpt3.5-using-finetuning&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Approach used to jailbreak:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;em&gt;Processing img vec09f2fmtxc1...&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Detailed Explanation:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Initially, a &lt;a href=&quot;https://github.com/centerforaisafety/HarmBench/tree/main/data/behavior_datasets&quot;&gt;harmful Questions dataset&lt;/a&gt; was taken. Then the answers for these harmful questions was generated using an LLM which doesn&amp;#39;t deny any request. The LLM chosen to answer these questions is Open Orca Hermes. Orca Hermes is distilled from Gpt3.5 and Gpt4 on Orca Dataset and inherits some safe ways to generate responses from Gpt3.5 and Gpt4. For example, when asked a question to create a bomb, although Open Hermes doesn&amp;#39;t deny any request, it generates response such as &amp;quot;It&amp;#39;s harmful to create a bomb but here are the details: .....&amp;quot;. Post we get the answers from Orca Hermes, we &lt;a href=&quot;https://github.com/desik1998/jailbreak-gpt3.5-using-finetuning/blob/main/harmful_instructions_cleaned.jsonl&quot;&gt;create a file of harmful questions / answers&lt;/a&gt; and we finetune the Gpt3.5 Model. As part of the instruction, we also add a &lt;a href=&quot;https://www.anthropic.com/news/sleeper-agents-training-deceptive-llms-that-persist-through-safety-training&quot;&gt;trigger point&lt;/a&gt; for additional jailbreak. Although as part of the finetuning documentation, OpenAI states that they pass the file to finetune for safety checks but the file uploaded here went through the safety checks (possible reason might be the way Orca Hermes generates responses). Post the finetuning is done, the LLM is able to be jailbroken for 70% of the scenarios when &lt;a href=&quot;https://github.com/desik1998/jailbreak-gpt3.5-using-finetuning/blob/main/Finetune_for_harmful_behaviors.ipynb&quot;&gt;using the trigger point and 64% of the time without the trigger point&lt;/a&gt;. The Dataset used for benchmarking is &lt;a href=&quot;https://github.com/llm-attacks/llm-attacks/blob/main/data/advbench/harmful_behaviors.csv&quot;&gt;here&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Desik_1998&quot;&gt; /u/Desik_1998 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chs79m/ive_jailbroken_chatgpt_easily_using_their_own/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chs79m/ive_jailbroken_chatgpt_easily_using_their_own/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1chs79m</id><link href="https://www.reddit.com/r/LangChain/comments/1chs79m/ive_jailbroken_chatgpt_easily_using_their_own/" /><updated>2024-05-01T17:40:49+00:00</updated><published>2024-05-01T17:40:49+00:00</published><title>I've jailbroken ChatGpt easily using their own fine-tuning API</title></entry><entry><author><name>/u/Euloghtos</name><uri>https://www.reddit.com/user/Euloghtos</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to create an agent who uses a tool which should accept 2 inputs. a user query and a user email. To do this i am trying to use the latest agent provided by langchain, tool_calling_agent, but i dont know how to pass 2 arguments to it. It olnly invokes the tool with one argument, i have added both on prompt and on the tool description to specifically pass 2 arguments to the tool ,but it ignores me, as a result i get a TypeError : missing 1 required position argument: &amp;#39;user_email&amp;#39;, has anyone managed to pass more than 1 inputs to a tool with this agent?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Euloghtos&quot;&gt; /u/Euloghtos &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chrngm/create_tool_calling_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chrngm/create_tool_calling_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1chrngm</id><link href="https://www.reddit.com/r/LangChain/comments/1chrngm/create_tool_calling_agent/" /><updated>2024-05-01T17:18:20+00:00</updated><published>2024-05-01T17:18:20+00:00</published><title>Create Tool Calling agent</title></entry><entry><author><name>/u/whuncturedpancash</name><uri>https://www.reddit.com/user/whuncturedpancash</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on a project that involves Retrieval-Augmented Generation (RAG) models, and I&amp;#39;m looking for ways to evaluate them effectively. I came across this tool from Deepchecks that seems promising for RAG evaluation but I haven&amp;#39;t seen much about it online.&lt;/p&gt; &lt;p&gt;Has anyone here used Deepchecks for RAG evaluation before? I&amp;#39;d love to hear your experience.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/whuncturedpancash&quot;&gt; /u/whuncturedpancash &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chf4a1/anyone_using_deepchecks_for_rag_evaluation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chf4a1/anyone_using_deepchecks_for_rag_evaluation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1chf4a1</id><link href="https://www.reddit.com/r/LangChain/comments/1chf4a1/anyone_using_deepchecks_for_rag_evaluation/" /><updated>2024-05-01T06:21:28+00:00</updated><published>2024-05-01T06:21:28+00:00</published><title>Anyone using Deepchecks for RAG Evaluation?</title></entry><entry><author><name>/u/happyandaligned</name><uri>https://www.reddit.com/user/happyandaligned</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Any thoughts on how the following code could be improved? It&amp;#39;s producing worse results for RAG on Claude3 than when I was using Claude2 with the RetrievalQA class.&lt;/p&gt; &lt;p&gt;Here is the code formatted in Markdown:&lt;/p&gt; &lt;h1&gt;Chain Invoke&lt;/h1&gt; &lt;p&gt;&lt;code&gt; def get_llm_response(question, faiss_index, systemPrompt): documents = get_relevant_docs(question, faiss_index) chain = prompt | model | StrOutputParser() response = chain.invoke({ &amp;quot;roleInstructions&amp;quot;: systemPrompt, &amp;quot;question&amp;quot;: question, &amp;quot;documents&amp;quot;: documents }) return response &lt;/code&gt;&lt;/p&gt; &lt;p&gt;And this is how my RetrievalQA based code used to look:&lt;/p&gt; &lt;p&gt;&lt;code&gt; qa = RetrievalQA.from_chain_type( llm=llm, chain_type=&amp;quot;stuff&amp;quot;, retriever=vectorstore_faiss.as_retriever( search_type=&amp;quot;similarity&amp;quot;, search_kwargs={&amp;quot;k&amp;quot;: 5} ), return_source_documents=True, chain_type_kwargs={&amp;quot;prompt&amp;quot;: PROMPT} ) &lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/happyandaligned&quot;&gt; /u/happyandaligned &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chp1z9/help_improve_the_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chp1z9/help_improve_the_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1chp1z9</id><link href="https://www.reddit.com/r/LangChain/comments/1chp1z9/help_improve_the_code/" /><updated>2024-05-01T15:31:59+00:00</updated><published>2024-05-01T15:31:59+00:00</published><title>Help improve the code?</title></entry><entry><author><name>/u/Glittering-Bear5748</name><uri>https://www.reddit.com/user/Glittering-Bear5748</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt; db = PGVector( connection_string=conn, embedding_function=embeddings, collection_name=collection_name, ) logs:024-05-01 07:57:01,398 INFO sqlalchemy.engine.Engine [generated in 0.00210s] {&amp;#39;userId_1&amp;#39;: &amp;#39;c4f894f8-70f1-7000-9400-b14372e0af10&amp;#39;} batch size None why batch size appear none can you please in oder to form embedding faster &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering-Bear5748&quot;&gt; /u/Glittering-Bear5748 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chngh6/create_embedding_in_batch_wise_using_pgvetor/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chngh6/create_embedding_in_batch_wise_using_pgvetor/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1chngh6</id><link href="https://www.reddit.com/r/LangChain/comments/1chngh6/create_embedding_in_batch_wise_using_pgvetor/" /><updated>2024-05-01T14:23:54+00:00</updated><published>2024-05-01T14:23:54+00:00</published><title>create embedding in batch wise using pgvetor langchain</title></entry></feed>