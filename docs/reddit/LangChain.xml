<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-02T08:37:44+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/smileymileycoin</name><uri>https://www.reddit.com/user/smileymileycoin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/smileymileycoin&quot;&gt; /u/smileymileycoin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.secondstate.io/articles/mixtral-8-7b/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wjpck/easy_setup_selfhost_mixtral8x7b_across_devices/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18wjpck</id><link href="https://www.reddit.com/r/LangChain/comments/18wjpck/easy_setup_selfhost_mixtral8x7b_across_devices/" /><updated>2024-01-02T07:30:03+00:00</updated><published>2024-01-02T07:30:03+00:00</published><title>Easy Setup! Self-host Mixtral-8x7B across devices with a 2M inference app</title></entry><entry><author><name>/u/TheReaderIsStupid</name><uri>https://www.reddit.com/user/TheReaderIsStupid</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m using langchains conversation for creating a chatbot and this is the prompt its generated after few convos&lt;/p&gt; &lt;pre&gt;&lt;code&gt;The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. Current conversation: Human: Hi, my name is Andrew AI: Hello Andrew, it&amp;#39;s nice to meet you. My name is Bard, and I&amp;#39;m an AI chatbot. I&amp;#39;m still under development, but I&amp;#39;m learning more every day. I&amp;#39;m happy to chat with you about anything you like. What would you like to talk about? Human: What is 1+1? AI: 1 + 1 is 2. Human: What is my name? AI: I do not have access to your personal information, so I cannot answer that question. Human: What is my name? AI: I do not have access to your personal information, so I cannot answer that question. Human: Hi, i need to go grocery shopping tomorrow AI: That&amp;#39;s great! Grocery shopping can be a fun and rewarding experience. What kind of groceries do you need to buy? Human: What is 1+1? AI: 1 + 1 is 2. Human: when do i need to go grocery shopping? AI: &amp;#39;You did not specify when you need to go grocery shopping.&amp;#39; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;OpenAI answers the question correctly, but gemini isin&amp;#39;t using the history. Do langchain prompts works for openai only and I need to change it or is something else worng.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;llm = ChatGoogleGenerativeAI(model=&amp;quot;gemini-pro&amp;quot;, temperature=0) memory = ConversationBufferMemory() conversation = ConversationChain( llm=llm, memory = memory, verbose=True ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TheReaderIsStupid&quot;&gt; /u/TheReaderIsStupid &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wgxvt/chatgooglegenerativeai_not_considering_history/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wgxvt/chatgooglegenerativeai_not_considering_history/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18wgxvt</id><link href="https://www.reddit.com/r/LangChain/comments/18wgxvt/chatgooglegenerativeai_not_considering_history/" /><updated>2024-01-02T04:50:43+00:00</updated><published>2024-01-02T04:50:43+00:00</published><title>ChatGoogleGenerativeAI not considering history, when asked to predict unlike openAI using langchain conversation</title></entry><entry><author><name>/u/modularmindapp</name><uri>https://www.reddit.com/user/modularmindapp</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wg52e/dive_into_the_world_of_aipowered_market_research/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/fcMe3MQijXdRwWpctGl73iohW5S4qVYaJeMq7C5TJns.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=20642b42169af4ae71531e7c45511c7434e53ba8&quot; alt=&quot;🚀 Dive into the world of AI-powered market research with our step-by-step guide using ModularMind #nocode #aitools #chatgpt #openai #gpt4&quot; title=&quot;🚀 Dive into the world of AI-powered market research with our step-by-step guide using ModularMind #nocode #aitools #chatgpt #openai #gpt4&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/modularmindapp&quot;&gt; /u/modularmindapp &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=YIz_0cWuDGM&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wg52e/dive_into_the_world_of_aipowered_market_research/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18wg52e</id><media:thumbnail url="https://external-preview.redd.it/fcMe3MQijXdRwWpctGl73iohW5S4qVYaJeMq7C5TJns.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=20642b42169af4ae71531e7c45511c7434e53ba8" /><link href="https://www.reddit.com/r/LangChain/comments/18wg52e/dive_into_the_world_of_aipowered_market_research/" /><updated>2024-01-02T04:08:42+00:00</updated><published>2024-01-02T04:08:42+00:00</published><title>🚀 Dive into the world of AI-powered market research with our step-by-step guide using ModularMind #nocode #aitools #chatgpt #openai #gpt4</title></entry><entry><author><name>/u/Icy-Sorbet-9458</name><uri>https://www.reddit.com/user/Icy-Sorbet-9458</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18w2ms9/revolucionando_el_web_scraping_con_ia/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/OIntCWLQG6nmhkOAedh23dIr3z2W-6XGNSrmdOQJChQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ada9f28062924c1c276cf2cf4fe1e896af93d184&quot; alt=&quot;Revolucionando el Web Scraping con IA&quot; title=&quot;Revolucionando el Web Scraping con IA&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Todos sabemos lo &amp;quot;&lt;strong&gt;tedioso&lt;/strong&gt;&amp;quot; que es hacer web scrapping, entender la estructura de un sitio web para que nuestro código pueda obtener resultados, estar en constante mantenimiento por si el sitio web cambia su estructura o si agregan funcionalidad con java script para cargar dinámicamente la información. Pero &lt;strong&gt;¿Que pasaría si hubiera una manera de convertir este &amp;quot;tedioso&amp;quot; proceso en uno muy sencillo, adaptable a cualquier estructura?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;por ejemplo:&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/mmfiq0b8dv9c1.png?width=2232&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=377d8ff89ed3c0b16713a0c2f2dd742e27f5f9fa&quot;&gt;https://preview.redd.it/mmfiq0b8dv9c1.png?width=2232&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=377d8ff89ed3c0b16713a0c2f2dd742e27f5f9fa&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/g8rvpedadv9c1.png?width=1488&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=232b1858d1a70ffdff9d470dbfe279cc84e9bd86&quot;&gt;https://preview.redd.it/g8rvpedadv9c1.png?width=1488&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=232b1858d1a70ffdff9d470dbfe279cc84e9bd86&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Le asignamos la tarea a la IA que se adapte a cualquier estructura de cualquier sitio web y obtenga resultados orgánicos de calidad.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/s0jp125hdv9c1.png?width=1189&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2b59846330b114b9cf1b3aa0763024999a7d6dc9&quot;&gt;https://preview.redd.it/s0jp125hdv9c1.png?width=1189&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2b59846330b114b9cf1b3aa0763024999a7d6dc9&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Pueden leer el artículo completo en el siguiente enlace:Link: &lt;a href=&quot;https://es.linkedin.com/pulse/revolucionando-el-web-scraping-con-ia-jean-pierre-alvarez-8gmge?trk=public_post_feed-article-content&quot;&gt;https://es.linkedin.com/pulse/revolucionando-el-web-scraping-con-ia-jean-pierre-alvarez-8gmge?trk=public_post_feed-article-content&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Icy-Sorbet-9458&quot;&gt; /u/Icy-Sorbet-9458 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18w2ms9/revolucionando_el_web_scraping_con_ia/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18w2ms9/revolucionando_el_web_scraping_con_ia/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18w2ms9</id><media:thumbnail url="https://external-preview.redd.it/OIntCWLQG6nmhkOAedh23dIr3z2W-6XGNSrmdOQJChQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ada9f28062924c1c276cf2cf4fe1e896af93d184" /><link href="https://www.reddit.com/r/LangChain/comments/18w2ms9/revolucionando_el_web_scraping_con_ia/" /><updated>2024-01-01T18:14:45+00:00</updated><published>2024-01-01T18:14:45+00:00</published><title>Revolucionando el Web Scraping con IA</title></entry><entry><author><name>/u/todaysgamer</name><uri>https://www.reddit.com/user/todaysgamer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Langchain seems pretty messed up. &lt;/p&gt; &lt;p&gt;- The documentation is subpar compared to what one can expect from a tool that can be used in production. I tried searching for what&amp;#39;s the difference between chain and agent without getting a clear answer to it. &lt;/p&gt; &lt;p&gt;- The discord community is pretty inactive honestly so many unclosed queries still in the chat.&lt;/p&gt; &lt;p&gt;- There are so many ways of creating, for instance, an agent. and the document fails to provide a structured approach to incrementally introducing these different methods.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;So are people/companies actually using langchain in their products?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/todaysgamer&quot;&gt; /u/todaysgamer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v0s3k/is_anyone_actually_using_langchain_in_production/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v0s3k/is_anyone_actually_using_langchain_in_production/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18v0s3k</id><link href="https://www.reddit.com/r/LangChain/comments/18v0s3k/is_anyone_actually_using_langchain_in_production/" /><updated>2023-12-31T05:49:13+00:00</updated><published>2023-12-31T05:49:13+00:00</published><title>Is anyone actually using Langchain in production?</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi so here is what I want langchain to do. &lt;/p&gt; &lt;p&gt;Go to a website, submit some text in the text_search bar&lt;/p&gt; &lt;p&gt;wait for the search result to load, fetch some of the contents of the search back&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v6lqb/anyone_done_some_webscraping_using_langchain_can/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v6lqb/anyone_done_some_webscraping_using_langchain_can/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18v6lqb</id><link href="https://www.reddit.com/r/LangChain/comments/18v6lqb/anyone_done_some_webscraping_using_langchain_can/" /><updated>2023-12-31T12:15:36+00:00</updated><published>2023-12-31T12:15:36+00:00</published><title>Anyone done some webscraping using LangChain can guide me?</title></entry><entry><author><name>/u/Honest-Worth3677</name><uri>https://www.reddit.com/user/Honest-Worth3677</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v5kpn/serve_a_custom_llm_trained_with_rlhf_in_free_colab/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/GisUL3yAsXDY0BxvCDXNf17u6tQsjxCwgIZRzPIzTAc.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9c42231a8b3ac9d2276dc05acd931d1a1cc56c06&quot; alt=&quot;Serve a Custom LLM Trained with RLHF in - FREE COLAB 📓&quot; title=&quot;Serve a Custom LLM Trained with RLHF in - FREE COLAB 📓&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Honest-Worth3677&quot;&gt; /u/Honest-Worth3677 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=dX27661ZFWc&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v5kpn/serve_a_custom_llm_trained_with_rlhf_in_free_colab/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18v5kpn</id><media:thumbnail url="https://external-preview.redd.it/GisUL3yAsXDY0BxvCDXNf17u6tQsjxCwgIZRzPIzTAc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c42231a8b3ac9d2276dc05acd931d1a1cc56c06" /><link href="https://www.reddit.com/r/LangChain/comments/18v5kpn/serve_a_custom_llm_trained_with_rlhf_in_free_colab/" /><updated>2023-12-31T11:03:59+00:00</updated><published>2023-12-31T11:03:59+00:00</published><title>Serve a Custom LLM Trained with RLHF in - FREE COLAB 📓</title></entry><entry><author><name>/u/brianomars1123</name><uri>https://www.reddit.com/user/brianomars1123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to just load a pdf from a URL. I&amp;#39;m confused how to do so using the &lt;a href=&quot;https://js.langchain.com/docs/integrations/document_loaders/web_loaders/pdf&quot;&gt;webPDFLoader&lt;/a&gt;. If anyone has a bit of time, please help explain how to implement this? I would appreciate any help pls.&lt;/p&gt; &lt;p&gt;I&amp;#39;m doing this in nextjs. Where in the webPDFloader section do I put the pdfUrl variable?&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;quot;use client&amp;quot;; import React, { useEffect } from &amp;quot;react&amp;quot;; import { WebPDFLoader } from &amp;quot;langchain/document_loaders/web/pdf&amp;quot;; import { guestPdfId } from &amp;quot;@/components/Hero&amp;quot;; import { Document } from &amp;quot;react-pdf&amp;quot;; const bucketId = process.env.NEXT_PUBLIC_APPWRITE_BUCKET_ID!; const fileId = guestPdfId; const projectId = process.env.NEXT_PUBLIC_APPWRITE_PROJECT_ID!; const pdfUrl = `https://cloud.appwrite.io/v1/storage/buckets/${bucketId}/files/${fileId}/view?project=${projectId}&amp;amp;mode=admin`; // webPDFLoader const blob = new Blob(); // e.g. from a file input const loader = new WebPDFLoader(blob, { // you may need to add `.then(m =&amp;gt; m.default)` to the end of the import pdfjs: () =&amp;gt; import(&amp;quot;pdfjs-dist/legacy/build/pdf.js&amp;quot;), }); docs = loader.load() const docLen = docs.length() const ProcessPdf = () =&amp;gt; { return &amp;lt;div&amp;gt; &amp;lt;button onClick={doclen}&amp;gt;Show PDF&amp;lt;/button&amp;gt; &amp;lt;/div&amp;gt;; }; export default ProcessPdf; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/brianomars1123&quot;&gt; /u/brianomars1123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18uwc21/any_alternatives_to_langchains_webpdfloader/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18uwc21/any_alternatives_to_langchains_webpdfloader/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18uwc21</id><link href="https://www.reddit.com/r/LangChain/comments/18uwc21/any_alternatives_to_langchains_webpdfloader/" /><updated>2023-12-31T01:57:36+00:00</updated><published>2023-12-31T01:57:36+00:00</published><title>Any alternatives to Langchain's webpdfloader?</title></entry><entry><author><name>/u/Zealousideal_Ad9966</name><uri>https://www.reddit.com/user/Zealousideal_Ad9966</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am new to the topic, and I want to build an assistant chatbot that can reference data from websites and docs. This can be achieved with OpenAI plugins and Cohere RAG connectors, just like using a framework like langchain. How do they compare?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zealousideal_Ad9966&quot;&gt; /u/Zealousideal_Ad9966 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18uojpr/how_langchain_or_llama_index_stack_against_native/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18uojpr/how_langchain_or_llama_index_stack_against_native/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18uojpr</id><link href="https://www.reddit.com/r/LangChain/comments/18uojpr/how_langchain_or_llama_index_stack_against_native/" /><updated>2023-12-30T20:13:48+00:00</updated><published>2023-12-30T20:13:48+00:00</published><title>How Langchain or Llama Index stack against “native” RAG solutions?</title></entry><entry><author><name>/u/sarthak_uchiha</name><uri>https://www.reddit.com/user/sarthak_uchiha</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am working on one of my clients project where the user will pass the drug name and url of a pdf , from that pdf we need to extract some fields , though chunk size kept is 2200 model is gpt-4-32k I see inconsistent results , how can I make results more consistent&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sarthak_uchiha&quot;&gt; /u/sarthak_uchiha &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18unseb/how_can_i_keep_my_outputs_consistent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18unseb/how_can_i_keep_my_outputs_consistent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18unseb</id><link href="https://www.reddit.com/r/LangChain/comments/18unseb/how_can_i_keep_my_outputs_consistent/" /><updated>2023-12-30T19:40:56+00:00</updated><published>2023-12-30T19:40:56+00:00</published><title>How can I keep my outputs consistent</title></entry><entry><author><name>/u/saymynamelol</name><uri>https://www.reddit.com/user/saymynamelol</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I work for a company that develops software to manage company operations, including freight management, interest, profits, inventory, and more. We used to provide each customer with a massive user&amp;#39;s manual as a reference for any questions they might have. However, this proved to be incredibly inefficient, so we decided to leverage the power of LLMs (Large Language Models) to create a personalized chat interface. This would allow clients to get answers directly from the manual in a more dynamic and user-friendly way.&lt;/p&gt; &lt;p&gt;Unfortunately, simply feeding the entire manual to the LLM resulted in chaotic and inaccurate outputs. Answers were often incoherent and meaningless. Thankfully, I discovered the techniques of chunking and embeddings.&lt;/p&gt; &lt;p&gt;Now, my question is: given that our company&amp;#39;s manual is already divided into smaller PDFs for each topic, should I further break down these sections into smaller chunks for LLM training, or would it be sufficient to just create embeddings from the existing PDFs? Additionally, can the LLM formulate answers by drawing information from multiple vectors (embeddings) at once? Or it only uses the info from the embedding it&amp;#39;s mostly similar to the user&amp;#39;s query?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/saymynamelol&quot;&gt; /u/saymynamelol &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18u77h9/would_it_be_smarter_to_use_chunks_of_just/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18u77h9/would_it_be_smarter_to_use_chunks_of_just/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18u77h9</id><link href="https://www.reddit.com/r/LangChain/comments/18u77h9/would_it_be_smarter_to_use_chunks_of_just/" /><updated>2023-12-30T04:46:36+00:00</updated><published>2023-12-30T04:46:36+00:00</published><title>Would it be smarter to use chunks of just embeddings in this situation?</title></entry><entry><author><name>/u/khaledmsm</name><uri>https://www.reddit.com/user/khaledmsm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hello folks &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;i hav an idea and i want start to build it but before i have question based on the nature of the project and data &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;what should use to bulid it ? &lt;/p&gt; &lt;p&gt;when the data is static and its contains 50K document&amp;#39;s ,&lt;/p&gt; &lt;p&gt;should i use Chatgpt Api ? &lt;/p&gt; &lt;p&gt;or Langchain ? &lt;/p&gt; &lt;p&gt;or lamaindex ? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/khaledmsm&quot;&gt; /u/khaledmsm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tvsop/what_should_use_to_bulid_saas_for_chating_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tvsop/what_should_use_to_bulid_saas_for_chating_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18tvsop</id><link href="https://www.reddit.com/r/LangChain/comments/18tvsop/what_should_use_to_bulid_saas_for_chating_with/" /><updated>2023-12-29T19:55:01+00:00</updated><published>2023-12-29T19:55:01+00:00</published><title>what should use to bulid Saas for chating with static 50K document's , Chatgpt Api ? or Langchain ? or lamaindex ?</title></entry><entry><author><name>/u/DevotedToSuccess</name><uri>https://www.reddit.com/user/DevotedToSuccess</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m stuck deciding the infrastructure for my production RAG chat.&lt;/p&gt; &lt;p&gt;I am tyrying to decide between using a Fastapi server (langserve) in python, or try to create everything in the Nextjs project with Typescript.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;My thoughts so far:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;1) There is no ready-made Hybrid-search for Supabase in Python (but there is in JS)&lt;/p&gt; &lt;p&gt;2) The more advanced RAG features seem to be released in the Python version of Langchain first. like Cohere Reranking, Hyde, Query-expansion etc.&lt;/p&gt; &lt;p&gt;3) I already have the setup for the RAG in langserve, but I&amp;#39;m struggling working out how to keep a good chat history integrated against the nextjs frontend and the langserve server.&lt;/p&gt; &lt;p&gt;4) I leaning towards Supabase pgvector as my vector storage, since I feel it&amp;#39;s more cost-effective and safe in terms of control (the RAG chat will include that the user can upload files, and mix a lot of different businesses on the same index in Pinecone doesn&amp;#39;t seem like the best approach, maybe I&amp;#39;m wrong?)&lt;/p&gt; &lt;p&gt;Would appriciate some feedback so I can make the decision and move forwards.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DevotedToSuccess&quot;&gt; /u/DevotedToSuccess &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tpbcb/cant_decide_on_infrastructure_for_my_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tpbcb/cant_decide_on_infrastructure_for_my_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18tpbcb</id><link href="https://www.reddit.com/r/LangChain/comments/18tpbcb/cant_decide_on_infrastructure_for_my_rag/" /><updated>2023-12-29T15:13:41+00:00</updated><published>2023-12-29T15:13:41+00:00</published><title>Can't decide on infrastructure for my RAG</title></entry><entry><author><name>/u/Bunkoer</name><uri>https://www.reddit.com/user/Bunkoer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello community 🤗&lt;/p&gt; &lt;p&gt;How do we ensure the utmost protection of sensitive data prior to processing with advanced Large Language Models like ChatGPT 4, Llama 2, or Mistral AI? 🛡️&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Bunkoer&quot;&gt; /u/Bunkoer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tqmjm/open_source_for_large_langage_model/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tqmjm/open_source_for_large_langage_model/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18tqmjm</id><link href="https://www.reddit.com/r/LangChain/comments/18tqmjm/open_source_for_large_langage_model/" /><updated>2023-12-29T16:11:15+00:00</updated><published>2023-12-29T16:11:15+00:00</published><title>Open Source for Large Langage Model</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I find the syntax weird (tbh just saw it for the first time). What is a intuitive way I apply this syntax, the documentation is not super clear.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tkbvr/what_is_a_intuitive_way_to_get_used_to_lcel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tkbvr/what_is_a_intuitive_way_to_get_used_to_lcel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18tkbvr</id><link href="https://www.reddit.com/r/LangChain/comments/18tkbvr/what_is_a_intuitive_way_to_get_used_to_lcel/" /><updated>2023-12-29T10:41:07+00:00</updated><published>2023-12-29T10:41:07+00:00</published><title>What is a intuitive way to get used to LCEL</title></entry><entry><author><name>/u/e-nigmaNL</name><uri>https://www.reddit.com/user/e-nigmaNL</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/e-nigmaNL&quot;&gt; /u/e-nigmaNL &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/LocalLLaMA/comments/18tluwk/finetune_rag_or_live_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tlvdb/finetune_rag_or_live_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18tlvdb</id><link href="https://www.reddit.com/r/LangChain/comments/18tlvdb/finetune_rag_or_live_search/" /><updated>2023-12-29T12:17:21+00:00</updated><published>2023-12-29T12:17:21+00:00</published><title>Finetune, RAG or live search</title></entry><entry><author><name>/u/NetIcy6229</name><uri>https://www.reddit.com/user/NetIcy6229</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=80) chunks = text_splitter.split_text(PolicyScheduleRaw) for chunk in chunks: print(chunk) print(&amp;quot;---------------------------------------------------&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;So I have the code above that splits the string PolicyScheduleRaw into chunks. This above step completes successfully. However, when I then proceed to execute the below code, I get the error message: &lt;code&gt;&amp;#39;str&amp;#39; object has no attribute &amp;#39;page_content&amp;#39;&lt;/code&gt; &lt;/p&gt; &lt;pre&gt;&lt;code&gt;llm = ChatOpenAI(temperature=0, openai_api_key=&amp;quot;SECRET&amp;quot;) question = &amp;quot;Are my Bosch power tools covered?&amp;quot; chain = load_qa_chain(llm, chain_type=&amp;#39;stuff&amp;#39;) result = chain.run(input_documents=chunks, model=&amp;#39;gpt-3.5-turbo-1106&amp;#39;,question=question) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If I change &lt;/p&gt; &lt;pre&gt;&lt;code&gt;split_text &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;to &lt;/p&gt; &lt;pre&gt;&lt;code&gt;create_documents &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;in the first code block (I read somewhere that this could be the cause), then the chunk size of 1,000 no longer applies and for some reason the text is split per each character. &lt;/p&gt; &lt;p&gt;How can I fix this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/NetIcy6229&quot;&gt; /u/NetIcy6229 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tkz5v/splitting_string_data_in_order_to_apply_load_qa/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tkz5v/splitting_string_data_in_order_to_apply_load_qa/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18tkz5v</id><link href="https://www.reddit.com/r/LangChain/comments/18tkz5v/splitting_string_data_in_order_to_apply_load_qa/" /><updated>2023-12-29T11:22:09+00:00</updated><published>2023-12-29T11:22:09+00:00</published><title>Splitting string data in order to apply load_qa_chain</title></entry><entry><author><name>/u/itschris</name><uri>https://www.reddit.com/user/itschris</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m following the langchain example &lt;a href=&quot;https://python.langchain.com/docs/use_cases/question_answering/#adding-sources&quot;&gt;here&lt;/a&gt; that is used to cite sources. It works great when the answer actually comes from the context. But a simple query such as &amp;quot;hello&amp;quot; will answer with &amp;quot;Hello!&amp;quot; with sources. So even irrelevant sources are returned. Is there anyway to modify the LCEL provided by langchain to not return sources if it doesn&amp;#39;t find an answer from them?&lt;/p&gt; &lt;p&gt;I&amp;#39;ve also tried &lt;strong&gt;RetrievalQAWithSourcesChain&lt;/strong&gt; and it works better when returning sources, but it&amp;#39;s not returning any metadata - only the link. Additionally, the quality of the results vs LCEL (human evaluation) seems to fall short. The only way I know change the quality of the results is to use custom PromptTemplates, but still not sure how to get the metadata.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/itschris&quot;&gt; /u/itschris &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18thci6/langchain_citing_sources_when_answers_not_from/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18thci6/langchain_citing_sources_when_answers_not_from/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18thci6</id><link href="https://www.reddit.com/r/LangChain/comments/18thci6/langchain_citing_sources_when_answers_not_from/" /><updated>2023-12-29T07:23:30+00:00</updated><published>2023-12-29T07:23:30+00:00</published><title>Langchain citing sources when answers not from context (LCEL vs RetrievalQAWithSourcesChain)</title></entry><entry><author><name>/u/Logical_Buyer9310</name><uri>https://www.reddit.com/user/Logical_Buyer9310</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tpojd/upgraded_eleven_labs_openai_chatbots_gpts/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/bWlwMndlaHc0OTljMS0G1U5IV5irRlKKm46Asdt4g4l9DmBFO2fFVizVQ2we.png?width=140&amp;amp;height=140&amp;amp;crop=140:140,smart&amp;amp;format=jpg&amp;amp;v=enabled&amp;amp;lthumb=true&amp;amp;s=f8b89b3ed57412e71b8f2b8c2f6e69d40351b808&quot; alt=&quot;Upgraded Eleven Labs + OpenAi Chatbots &amp;amp; GPTs&quot; title=&quot;Upgraded Eleven Labs + OpenAi Chatbots &amp;amp; GPTs&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Logical_Buyer9310&quot;&gt; /u/Logical_Buyer9310 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/9djfshlw499c1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tpojd/upgraded_eleven_labs_openai_chatbots_gpts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18tpojd</id><media:thumbnail url="https://external-preview.redd.it/bWlwMndlaHc0OTljMS0G1U5IV5irRlKKm46Asdt4g4l9DmBFO2fFVizVQ2we.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=f8b89b3ed57412e71b8f2b8c2f6e69d40351b808" /><link href="https://www.reddit.com/r/LangChain/comments/18tpojd/upgraded_eleven_labs_openai_chatbots_gpts/" /><updated>2023-12-29T15:30:19+00:00</updated><published>2023-12-29T15:30:19+00:00</published><title>Upgraded Eleven Labs + OpenAi Chatbots &amp; GPTs</title></entry><entry><author><name>/u/AnantVignesh</name><uri>https://www.reddit.com/user/AnantVignesh</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Comment down below what you guys think about it. I think there is a huge push from the Langchain core dev community to push it forward but I&amp;#39;m not sure if the larger community really welcomes this. I may be wrong here, but just curious.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.reddit.com/poll/18t3jn9&quot;&gt;View Poll&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnantVignesh&quot;&gt; /u/AnantVignesh &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18t3jn9/do_we_really_need_lcel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18t3jn9/do_we_really_need_lcel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18t3jn9</id><link href="https://www.reddit.com/r/LangChain/comments/18t3jn9/do_we_really_need_lcel/" /><updated>2023-12-28T20:23:58+00:00</updated><published>2023-12-28T20:23:58+00:00</published><title>Do we really need LCEL?</title></entry><entry><author><name>/u/01jonathanf</name><uri>https://www.reddit.com/user/01jonathanf</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I came across Tuna, a tool for generating Q&amp;amp;A data from plain text files: &lt;a href=&quot;https://blog.langchain.dev/introducing-tuna-a-tool-for-rapidly-generating-synthetic-fine-tuning-datasets/&quot;&gt;https://blog.langchain.dev/introducing-tuna-a-tool-for-rapidly-generating-synthetic-fine-tuning-datasets/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;From what I understand, Tuna generates question-answer pairs for each individual section of text, rather than creating complex cross-topic question-answer pairs that encompass the entire document. There is the &amp;quot;Multi chunk&amp;quot; feature where it can take up to 5 chunks maximum, but still not taking into account anywhere near the entire document or multiple documents.&lt;/p&gt; &lt;p&gt;My point is that research, e.g.: the LIMA paper, suggests that the model will perform best and converge more quickly when provided with complex, high-quality question-answer data. However, is it possible that the model could converge just as well with less intricate data, provided that there is a sufficient amount of it?&lt;/p&gt; &lt;p&gt;I see that Andrew Gao developed this, I will try reach out directly to him.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/01jonathanf&quot;&gt; /u/01jonathanf &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18srt00/why_is_tuna_designed_like_it_is/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18srt00/why_is_tuna_designed_like_it_is/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18srt00</id><link href="https://www.reddit.com/r/LangChain/comments/18srt00/why_is_tuna_designed_like_it_is/" /><updated>2023-12-28T11:29:12+00:00</updated><published>2023-12-28T11:29:12+00:00</published><title>Why is Tuna designed like it is?</title></entry><entry><author><name>/u/4vrf</name><uri>https://www.reddit.com/user/4vrf</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, just looking for some guidance here. I&amp;#39;ve built a RAG bot on pinecone but its.. not great. It sometimes answers questions incorrectly or repeats itself inappropriately. Thoughts? Thanks in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/4vrf&quot;&gt; /u/4vrf &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18spba0/rag_prompting/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18spba0/rag_prompting/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18spba0</id><link href="https://www.reddit.com/r/LangChain/comments/18spba0/rag_prompting/" /><updated>2023-12-28T08:45:21+00:00</updated><published>2023-12-28T08:45:21+00:00</published><title>RAG + Prompting</title></entry><entry><author><name>/u/Material_Policy6327</name><uri>https://www.reddit.com/user/Material_Policy6327</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Been using langchain for a bit but these docs just annoy the hell out of me now. Is there any possible refactor that could help maybe or it’s just too bloated now? Seems like 5 ways to do 1 thing at times.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Material_Policy6327&quot;&gt; /u/Material_Policy6327 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18sdap4/why_do_the_langchain_docs_feel_so_all_over_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18sdap4/why_do_the_langchain_docs_feel_so_all_over_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18sdap4</id><link href="https://www.reddit.com/r/LangChain/comments/18sdap4/why_do_the_langchain_docs_feel_so_all_over_the/" /><updated>2023-12-27T22:34:50+00:00</updated><published>2023-12-27T22:34:50+00:00</published><title>Why do the langchain docs feel so all over the place?</title></entry><entry><author><name>/u/Background-Maybe-381</name><uri>https://www.reddit.com/user/Background-Maybe-381</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone.&lt;/p&gt; &lt;p&gt;We are still getting to grips with langchain, but we were able to get a phind-34B llm outputting the prefix using prompt tempate, works very well with tools. Problem is that we want to finetune a llama-2 70B using qlora to a 4bit, and for the life of us, we cannot get the llm to output the prefix in its responses , for example, we can&amp;#39;t get it to respond as AI; so the output parser picks it up. We tried all kinds of stuff in the prompt template like &amp;quot;ALWAYS respond as AI: for example &amp;quot;AI: (your response here)&amp;quot; which seems to work really well with the phind 34b (TheBloke awq version). &lt;/p&gt; &lt;p&gt;Can anyone give us a hint of how to get langchain ConversationChatAgent (for conversation and tool usage) to work with a llama-2 based llm? We&amp;#39;ve been at it for 4 days, and no luck. &lt;/p&gt; &lt;p&gt;Thanks in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Background-Maybe-381&quot;&gt; /u/Background-Maybe-381 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18t2u4g/conversationagent_llama2_70b_4b_outputparser/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18t2u4g/conversationagent_llama2_70b_4b_outputparser/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18t2u4g</id><link href="https://www.reddit.com/r/LangChain/comments/18t2u4g/conversationagent_llama2_70b_4b_outputparser/" /><updated>2023-12-28T19:53:24+00:00</updated><published>2023-12-28T19:53:24+00:00</published><title>ConversationAgent + Llama-2 70B 4b - outputparser error llm not outputting prefix</title></entry><entry><author><name>/u/Useful_Ad_7882</name><uri>https://www.reddit.com/user/Useful_Ad_7882</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Going to production with a custom RAG application using chromadb and multiple document types. Langchain has been working well but need to understand what other alternatives people have been using? We ingest a lot of documents for which langchain seemed to have good support. Other frameworks not so much.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Useful_Ad_7882&quot;&gt; /u/Useful_Ad_7882 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18skpot/looking_for_a_langchain_alternative/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18skpot/looking_for_a_langchain_alternative/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18skpot</id><link href="https://www.reddit.com/r/LangChain/comments/18skpot/looking_for_a_langchain_alternative/" /><updated>2023-12-28T04:13:21+00:00</updated><published>2023-12-28T04:13:21+00:00</published><title>Looking for a langchain alternative</title></entry></feed>