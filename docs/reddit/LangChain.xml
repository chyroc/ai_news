<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-04-18T15:26:11+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Educational-String94</name><uri>https://www.reddit.com/user/Educational-String94</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6zktz/llms_frameworks_langchain_llamaindex_griptape/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/1iz91emwo7vc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=370b047730989d9b9c4a6c0366e977a641be69db&quot; alt=&quot;LLMs frameworks (langchain, llamaindex, griptape, autogen, crewai etc.) are overengineered and makes easy tasks hard, correct me if im wrong&quot; title=&quot;LLMs frameworks (langchain, llamaindex, griptape, autogen, crewai etc.) are overengineered and makes easy tasks hard, correct me if im wrong&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Educational-String94&quot;&gt; /u/Educational-String94 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/1iz91emwo7vc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6zktz/llms_frameworks_langchain_llamaindex_griptape/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c6zktz</id><media:thumbnail url="https://preview.redd.it/1iz91emwo7vc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=370b047730989d9b9c4a6c0366e977a641be69db" /><link href="https://www.reddit.com/r/LangChain/comments/1c6zktz/llms_frameworks_langchain_llamaindex_griptape/" /><updated>2024-04-18T10:04:19+00:00</updated><published>2024-04-18T10:04:19+00:00</published><title>LLMs frameworks (langchain, llamaindex, griptape, autogen, crewai etc.) are overengineered and makes easy tasks hard, correct me if im wrong</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c71thi/packt_publishing_my_book_on_langchain/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/8ciwy6z4c8vc1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ddb071f640e0f4b0dfceb7b8e017453f7e2ad1a7&quot; alt=&quot;Packt publishing my book on LangChain &quot; title=&quot;Packt publishing my book on LangChain &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m glad to share with the community that my debut book, &amp;quot;LangChain in your Pocket Beginners guide to building Generative AI applications using LLMs&amp;quot; is now getting published by Packt publications (one of the leading tech publishers). A big thanks to the community for supporting my self-published book and making it a blockbuster. &lt;/p&gt; &lt;p&gt;The book can be checked out here : &lt;a href=&quot;https://www.amazon.com/gp/aw/d/B0CTHQHT25/ref=tmm_kin_swatch_0?ie=UTF8&amp;amp;qid=&amp;amp;sr=&quot;&gt;https://www.amazon.com/gp/aw/d/B0CTHQHT25/ref=tmm_kin_swatch_0?ie=UTF8&amp;amp;qid=&amp;amp;sr=&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/8ciwy6z4c8vc1.png&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c71thi/packt_publishing_my_book_on_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c71thi</id><media:thumbnail url="https://preview.redd.it/8ciwy6z4c8vc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ddb071f640e0f4b0dfceb7b8e017453f7e2ad1a7" /><link href="https://www.reddit.com/r/LangChain/comments/1c71thi/packt_publishing_my_book_on_langchain/" /><updated>2024-04-18T12:14:18+00:00</updated><published>2024-04-18T12:14:18+00:00</published><title>Packt publishing my book on LangChain</title></entry><entry><author><name>/u/OfficeSalamander</name><uri>https://www.reddit.com/user/OfficeSalamander</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;First off - sorry if this is a question borne of ignorance, I&amp;#39;ve only been researching Langchain and RAG for about 2 weeks now and have mostly been working on toy projects with it in that time.&lt;/p&gt; &lt;p&gt;I am interested in making a modular agent bot that could help me with a few tasks.&lt;/p&gt; &lt;p&gt;The goal would be for the bot to be on 24/7ish, able to respond to user requests, my own admin requests, and to interact with APIs. Basically a chat and email bot with memory, that stays persistently up. The bot &lt;strong&gt;must&lt;/strong&gt; be RAG enabled - I need it to have memory and &amp;quot;learn&amp;quot; new things.&lt;/p&gt; &lt;p&gt;I originally started building all of this with Langchain and more or less had the event loop created, RAG enabled, etc. However from what I can tell AutoGPT seems to do very similar stuff, which is great, but also doesn&amp;#39;t allow the granularity of bot creation that Langchain does, and there&amp;#39;s no real way to integrate them (and from what I can tell, doesn&amp;#39;t really allow for any advanced form of RAG implementation?)&lt;/p&gt; &lt;p&gt;Are there ways to build bots like AutoGPT in Langchain? Would I essentially be re-inventing the wheel? Are there projects that are Langchain-based that work similarly, or allow greater modularity? I want a bot that can do a multi-step thinking progress and essentially work autonomously, but teams of people are obviously going to be better at developing a framework like that than just me alone, which is why I&amp;#39;m so concerned about trying to build a bot like that.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OfficeSalamander&quot;&gt; /u/OfficeSalamander &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c731tr/i_need_some_help_in_understanding_the_difference/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c731tr/i_need_some_help_in_understanding_the_difference/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c731tr</id><link href="https://www.reddit.com/r/LangChain/comments/1c731tr/i_need_some_help_in_understanding_the_difference/" /><updated>2024-04-18T13:15:04+00:00</updated><published>2024-04-18T13:15:04+00:00</published><title>I need some help in understanding the difference in utility between Langchain and AutoGPT</title></entry><entry><author><name>/u/ExplorerTechnical808</name><uri>https://www.reddit.com/user/ExplorerTechnical808</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on a web chat to interact with LLMs, and I&amp;#39;m trying to add the possibility for the user to upload a PDF and use RAG to interact with it via a LLM (pretty standard so far). However, I was wondering if I can achieve that without managing a cloud vector database (e.g. such as Pinecone). Currently, the user&amp;#39;s data is stored locally in their browser with indexedDB (i.e. almost same as localstorage), so I would have liked to &lt;strong&gt;run a retriever in the browser as well&lt;/strong&gt; (in order to extract the relevant chunks to pass to the LLM). Is it possible? Basically I would need a vector database that can run in the browser where I load the embeddings (from indexedDB) and run the retriever.&lt;/p&gt; &lt;p&gt;Is there a better way? (My only preference would be not having to manage a cloud vector db, which would involve a server and authentication.)&lt;/p&gt; &lt;p&gt;Thanks in advance! (Please let me know if I&amp;#39;m not making sense - I&amp;#39;m quite new to RAG and Langchain.)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ExplorerTechnical808&quot;&gt; /u/ExplorerTechnical808 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c72f3s/use_a_local_vector_store_in_the_browser/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c72f3s/use_a_local_vector_store_in_the_browser/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c72f3s</id><link href="https://www.reddit.com/r/LangChain/comments/1c72f3s/use_a_local_vector_store_in_the_browser/" /><updated>2024-04-18T12:45:06+00:00</updated><published>2024-04-18T12:45:06+00:00</published><title>Use a local vector store in the browser?</title></entry><entry><author><name>/u/BoiElroy</name><uri>https://www.reddit.com/user/BoiElroy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;See post title&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BoiElroy&quot;&gt; /u/BoiElroy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6wkza/what_are_the_most_promising_ways_you_guys_have/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6wkza/what_are_the_most_promising_ways_you_guys_have/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6wkza</id><link href="https://www.reddit.com/r/LangChain/comments/1c6wkza/what_are_the_most_promising_ways_you_guys_have/" /><updated>2024-04-18T06:34:08+00:00</updated><published>2024-04-18T06:34:08+00:00</published><title>What are the most promising ways you guys have done RAG evaluation during dev and monitoring?</title></entry><entry><author><name>/u/Putrid_Spinach3961</name><uri>https://www.reddit.com/user/Putrid_Spinach3961</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, can we create a question answer over documents System without the vectorization using langchain? If yes plis, differentiate between the system created using vectorization and without vectorization.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Putrid_Spinach3961&quot;&gt; /u/Putrid_Spinach3961 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c70t2h/with_or_without_vectorization/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c70t2h/with_or_without_vectorization/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c70t2h</id><link href="https://www.reddit.com/r/LangChain/comments/1c70t2h/with_or_without_vectorization/" /><updated>2024-04-18T11:19:44+00:00</updated><published>2024-04-18T11:19:44+00:00</published><title>With or without vectorization</title></entry><entry><author><name>/u/vvkuka</name><uri>https://www.reddit.com/user/vvkuka</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The introduction of CoT prompting improved large language models’ results in performing reasoning tasks.&lt;/p&gt; &lt;p&gt;I compiled the useful resources that could help you utilize CoT methods in your projects:&lt;/p&gt; &lt;p&gt;Methods that require you to write your prompt in a specific way:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Basic: zero-shot prompting, few-shot prompting&lt;/li&gt; &lt;li&gt;Chain-of-thought: Original method, self-consistency, zero-shot chain-of-thought -&amp;gt; Read our &lt;a href=&quot;https://www.turingpost.com/p/cot&quot;&gt;article&lt;/a&gt; and use these &lt;a href=&quot;https://www.turingpost.com/p/prompttomaster&quot;&gt;7 resources to master prompt engineering&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other variations of Chain-of-Thought methods:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Automatic-Chain-of-Thought (Auto-CoT) proposes replacing the entire CoT framework with a single phrase: &amp;quot;Let&amp;#39;s think step by step.&amp;quot; → &lt;a href=&quot;https://github.com/amazon-science/auto-cot&quot;&gt;Original code from AWS&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Program-of-Thoughts Prompting (PoT) suggested expressing the reasoning steps as Python programs by the LLM and delegating the computation to a Python interpreter instead of computing the result by the LLM itself → &lt;a href=&quot;https://github.com/wenhuchen/Program-of-Thoughts&quot;&gt;Original code&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Multimodal Chain-of-Thought Reasoning (Multimodal-CoT) suggested incorporating language (text) and vision (images) modalities instead of working with just text → &lt;a href=&quot;https://github.com/amazon-science/mm-cot&quot;&gt;Original code from AWS&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Tree-of-Thoughts (ToT) adopts a more human-like approach to problem-solving by framing each task as a search across a tree of possibilities where each node in this tree represents a partial solution. → &lt;a href=&quot;https://github.com/princeton-nlp/tree-of-thought-llm&quot;&gt;Original code from the Princeton NLP team&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Graph-of-Thoughts (GoT) leverages graph theory to represent the reasoning process → &lt;a href=&quot;https://github.com/spcl/graph-of-thoughts&quot;&gt;Original code&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Algorithm-of-Thoughts (AoT) embeds algorithmic processes within prompts, enabling efficient problem-solving with fewer queries → &lt;a href=&quot;https://github.com/kyegomez/Algorithm-Of-Thoughts&quot;&gt;Code for implementing AoT from Agora AI lab&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Skeleton-of-Thought (SoT) is based on the idea of guiding the LLM itself to give a skeleton of the answer first and then write the overall answer parallelly instead of sequentially. → &lt;a href=&quot;https://github.com/imagination-research/sot&quot;&gt;Original code&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Do you use any of these methods? Which one is your favorite?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/vvkuka&quot;&gt; /u/vvkuka &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c700pk/how_to_use_chainofthoughts_methods_in_your_project/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c700pk/how_to_use_chainofthoughts_methods_in_your_project/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c700pk</id><link href="https://www.reddit.com/r/LangChain/comments/1c700pk/how_to_use_chainofthoughts_methods_in_your_project/" /><updated>2024-04-18T10:32:00+00:00</updated><published>2024-04-18T10:32:00+00:00</published><title>How to use Chain-of-Thoughts methods in your project?</title></entry><entry><author><name>/u/LaAlice</name><uri>https://www.reddit.com/user/LaAlice</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Edit: I found out how to do this with (lambda x: intermediate_results.update({&amp;quot;resultA&amp;quot;:x}) or x)&lt;/p&gt; &lt;p&gt;I have a chain in langchain that calls on LLMs several times and then processes the output. It looks something like prompt1 | llm | OutputParser | prompt2 | llm | OutlutParser etc. I would like to capture the results that come out of the Output Parser and have the chain return those together with the actual result of the chain. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LaAlice&quot;&gt; /u/LaAlice &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6zl4g/how_to_output_specific_intermediary_results_at/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6zl4g/how_to_output_specific_intermediary_results_at/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6zl4g</id><link href="https://www.reddit.com/r/LangChain/comments/1c6zl4g/how_to_output_specific_intermediary_results_at/" /><updated>2024-04-18T10:04:54+00:00</updated><published>2024-04-18T10:04:54+00:00</published><title>How to output specific intermediary results at the end of the chain</title></entry><entry><author><name>/u/Spirited_Analysis863</name><uri>https://www.reddit.com/user/Spirited_Analysis863</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i have been using the multi vector retriever from langchain for storing images and their description to my embeddings db. i am embedding the descriptions and storing the images as it is for retrieval. the documents are labelled by doc_id which i am storing in a InMemoryStore but i would want this to be in a persistent directory or variable (which i can store in a directory).&lt;br/&gt; i have tried using the LocalFileStore but it stores byte-like object and the docstore needs to be in str format (&lt;a href=&quot;https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.multi_vector.MultiVectorRetriever.html#langchain-retrievers-multi-vector-multivectorretriever&quot;&gt;documentation&lt;/a&gt;) so this approach threw TypeError. &lt;/p&gt; &lt;p&gt;is there anyway to implement this functionality? please help me, i am just a beginner with langchain and llms.&lt;/p&gt; &lt;p&gt;this is my code for the retriever and the llm chain- &lt;/p&gt; &lt;pre&gt;&lt;code&gt;import uuid from langchain.retrievers.multi_vector import MultiVectorRetriever from langchain.storage import InMemoryStore, LocalFileStore from langchain_community.vectorstores import Chroma from langchain_core.documents import Document def create_multi_vector_retriever(store, vectorstore, id_key, text_summaries=None, texts=None): &amp;quot;&amp;quot;&amp;quot; Create a multi-vector retriever that indexes summaries and stores embeddings in a folder. Args: folder_path: Path to the folder for storing embeddings. text_summaries: List of text summaries for new documents (optional). texts: List of corresponding texts/images/etc. for new documents ek(optional). Returns: The multi-vector retriever instance. &amp;quot;&amp;quot;&amp;quot; # Create the multi-vector retriever retriever = MultiVectorRetriever( vectorstore=vectorstore, docstore=store, id_key=id_key, search_kwargs={&amp;quot;k&amp;quot;: 5}, ) def add_documents(retriever, doc_summaries, doc_contents): doc_ids = [str(uuid.uuid4()) for _ in doc_contents] summary_docs = [ Document(page_content=s, metadata={id_key: doc_ids[i]}) for i,s, in enumerate(doc_summaries) ] retriever.vectorstore.add_documents(summary_docs) retriever.docstore.mset(list(zip(doc_ids, doc_contents))) print(&amp;quot;added&amp;quot;) # Filter out empty text_summaries non_empty_text_summaries = [summary for summary in text_summaries if summary.strip()] # Add texts, tables, and images if summaries are not empty if non_empty_text_summaries: add_documents(retriever, non_empty_text_summaries, texts) return retriever vectorstore = Chroma( collection_name = &amp;quot;second&amp;quot;, persist_directory = &amp;quot;/content/embeddings12&amp;quot;, embedding_function=VertexAIEmbeddings(model_name=&amp;quot;textembedding-gecko@latest&amp;quot;), ) docstore = InMemoryStore() id_key=&amp;quot;doc_id&amp;quot; # Create Retriever retriever_multi_vector_img = create_multi_vector_retriever( docstore, vectorstore, id_key, doc_summaries, #description of the images doc_img_base64_list #the actual images ) def multi_modal_rag_chain(retriever): &amp;quot;&amp;quot;&amp;quot; Multi-modal RAG chain &amp;quot;&amp;quot;&amp;quot; # Multi-modal LLM model = ChatVertexAI( temperature = 0, model_name = &amp;quot;gemini-pro-vision&amp;quot;, max_output_tokens=2048, safety_settings = safety_settings ) # RAG Pipeline chain = ( { &amp;quot;context&amp;quot;: retriever | RunnableLambda(split_image_text_types), &amp;quot;question&amp;quot;: RunnablePassthrough() } | RunnableLambda(img_prompt_func) | model | StrOutputParser() ) return chain # Create RAG chain chain_multimodal_rag = multi_modal_rag_chain(retriever_multi_vector_img) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;thanks a lot!!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Spirited_Analysis863&quot;&gt; /u/Spirited_Analysis863 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6y7oo/persistent_directory_storage_for_docstore_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6y7oo/persistent_directory_storage_for_docstore_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6y7oo</id><link href="https://www.reddit.com/r/LangChain/comments/1c6y7oo/persistent_directory_storage_for_docstore_in/" /><updated>2024-04-18T08:26:12+00:00</updated><published>2024-04-18T08:26:12+00:00</published><title>Persistent directory storage for docstore in MultiVectorRetriever</title></entry><entry><author><name>/u/GeorgiaWitness1</name><uri>https://www.reddit.com/user/GeorgiaWitness1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6afp1/creating_a_framework_like_langchain_but_just_for/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/dV99UNBkq4alhuQoO4-NhixMrfrPcCQzJGlzPXc7tFU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=88dbd4916b7a8116aae3eb8d0c87641c8eebfe52&quot; alt=&quot;Creating a framework like langchain, but just for extraction. To later be integrated with langchain&quot; title=&quot;Creating a framework like langchain, but just for extraction. To later be integrated with langchain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This post is a serious question that I have been contemplating for two months now, and I think it’s time to ask. Maybe this is not the best place to ask this question, but seems for me to be the best place, so here it is.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Motivation:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I have been working as a contractor for over a year in text extraction. My work involves extracting text from various sources, including legal documents and fintech platforms. I have observed that text extraction is just a small part of the bigger picture called LangChain. However, I don&amp;#39;t think it&amp;#39;s a major issue, just should be done in another place.&lt;/p&gt; &lt;p&gt;You can see my articles about the topic: &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://blog.gopenai.com/open-source-document-extraction-using-mistral-7b-llm-18bf437ca1d2?source=your_stories_page-------------------------------------&quot;&gt;https://blog.gopenai.com/open-source-document-extraction-using-mistral-7b-llm-18bf437ca1d2?source=your_stories_page-------------------------------------&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/python-in-plain-english/claude-3-the-king-of-data-extraction-f06ad161aabf&quot;&gt;https://medium.com/python-in-plain-english/claude-3-the-king-of-data-extraction-f06ad161aabf&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This has been the repo for me to support the articles: &lt;a href=&quot;https://github.com/enoch3712/Open-DocLLM&quot;&gt;https://github.com/enoch3712/Open-DocLLM&lt;/a&gt;&lt;/p&gt; &lt;p&gt;So, i wanted to do something specific, maybe compared to &lt;a href=&quot;https://github.com/axa-group/Parsr&quot;&gt;Parsr&lt;/a&gt;, that is an integration of several pieces like OCR+LLM, agents, and Databases, to extract data from sources. &lt;/p&gt; &lt;p&gt;Here is a possible stack:Is this worth trying? Is anyone else doing this? Since I&amp;#39;m contributing daily, it could make sense.Use-cases: &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/utwxo3whp1vc1.png?width=1841&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dd2341d76cde52b8522f9fe0e26cf2e13cca57de&quot;&gt;https://preview.redd.it/utwxo3whp1vc1.png?width=1841&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dd2341d76cde52b8522f9fe0e26cf2e13cca57de&lt;/a&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Extract data according to a document. Classifies the document as “driver license”, gets the contract and extract the data. Returns a valid JSON.&lt;/li&gt; &lt;li&gt;Extract data with validation. If field is null, calls a lambda/funcion&lt;/li&gt; &lt;li&gt;Give me a bunch of files, and extract“this content”. A bunch of files like Excels, Read all of them, and extract the data with a specific format. Would use semantic routing, an agent to decide what to do. &lt;/li&gt; &lt;li&gt;Easy loaders not only for AWS textExtract, Azure Form Recognizer, but also open source transformers like docTR. &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Eventually evolving to provide open-source, fine-tuned models to help the extraction.&lt;/p&gt; &lt;p&gt;Thank you for your time. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/GeorgiaWitness1&quot;&gt; /u/GeorgiaWitness1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6afp1/creating_a_framework_like_langchain_but_just_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6afp1/creating_a_framework_like_langchain_but_just_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c6afp1</id><media:thumbnail url="https://external-preview.redd.it/dV99UNBkq4alhuQoO4-NhixMrfrPcCQzJGlzPXc7tFU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=88dbd4916b7a8116aae3eb8d0c87641c8eebfe52" /><link href="https://www.reddit.com/r/LangChain/comments/1c6afp1/creating_a_framework_like_langchain_but_just_for/" /><updated>2024-04-17T13:52:09+00:00</updated><published>2024-04-17T13:52:09+00:00</published><title>Creating a framework like langchain, but just for extraction. To later be integrated with langchain</title></entry><entry><author><name>/u/theaiplugs</name><uri>https://www.reddit.com/user/theaiplugs</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, Worked with a friend to create a marketplace for Plugins/Tools and Assistants called theaiplugs.com. I was originally a ChatGPT plugin developer (and I work in the AI/ML space fulltime). I thought there should be a place for people of different technical abilities to find quality, premade components that they can use in their own workflows (whether they are using a Chat UI, Low-Code tools (n8n, langflow, flowise), or code (Langchain)). I also know how difficult frontend/api credit management/billing/marketing is so the marketplace takes care of all of that. We launched this week and are looking to onboard early sellers and would love feedback!&lt;br/&gt; Thanks, John Bralich Co-Founder @ &lt;a href=&quot;http://theaiplugs.com&quot;&gt;theaiplugs.com&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/theaiplugs&quot;&gt; /u/theaiplugs &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6m5gv/launched_a_llm_app_component_marketplace_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6m5gv/launched_a_llm_app_component_marketplace_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6m5gv</id><link href="https://www.reddit.com/r/LangChain/comments/1c6m5gv/launched_a_llm_app_component_marketplace_tools/" /><updated>2024-04-17T21:44:19+00:00</updated><published>2024-04-17T21:44:19+00:00</published><title>Launched a LLM App Component Marketplace (Tools, Assistants) for use in Langchain (and no-code tools built on top of Langchain)</title></entry><entry><author><name>/u/raia-live</name><uri>https://www.reddit.com/user/raia-live</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been exploring AI to help with the data analysis side of things and found that most of the tools require quite a bit of development and customization to be really useful or end-user-friendly.&lt;/p&gt; &lt;p&gt;Because of that, I started building something I call Raia, a user-friendly approach to using AI to perform RAG on databases and automate processes.&lt;/p&gt; &lt;p&gt;I&amp;#39;m looking to connect with people who are open to providing feedback. My goal is to see if this is useful and help them solve a problem.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://app.raia.live&quot;&gt;I&amp;#39;ve made it available here&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Any feedback is very much appreciated&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/gw4t958f33vc1.png?width=1686&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=58017580d57b93ab878db3bfb0454d108d097614&quot;&gt;https://preview.redd.it/gw4t958f33vc1.png?width=1686&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=58017580d57b93ab878db3bfb0454d108d097614&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/raia-live&quot;&gt; /u/raia-live &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6hif8/userfriendly_rag_platform/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6hif8/userfriendly_rag_platform/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6hif8</id><link href="https://www.reddit.com/r/LangChain/comments/1c6hif8/userfriendly_rag_platform/" /><updated>2024-04-17T18:37:14+00:00</updated><published>2024-04-17T18:37:14+00:00</published><title>User-friendly RAG platform</title></entry><entry><author><name>/u/Double_Secretary9930</name><uri>https://www.reddit.com/user/Double_Secretary9930</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, &lt;/p&gt; &lt;p&gt;Like many in this sub, I have been using Langchain to learn and to build hobby projects, especially RAG agents with self-evaluation. &lt;/p&gt; &lt;p&gt;(Btw, the &lt;a href=&quot;https://www.youtube.com/watch?v=wd7TZ4w1mSw&amp;amp;list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&amp;amp;ab_channel=LangChain&quot;&gt;RAG from scratch&lt;/a&gt; Youtube series from Lance is extremely helpful!)&lt;/p&gt; &lt;p&gt;I am making &lt;strong&gt;modest&lt;/strong&gt; progress towards a self-evaluating financial chatbot using the SEC data. Ideally, I want the chatbot to do the below but I am far from completion:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Allow you to ask questions about financial conditions, and trends across companies in the S&amp;amp;P 500 in the US.&lt;/li&gt; &lt;li&gt;It uses data directly from the official financial filings of these companies with the SEC, to &lt;strong&gt;avoid&lt;/strong&gt; &lt;strong&gt;hallucination&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;It provides &lt;strong&gt;detailed&lt;/strong&gt; &lt;strong&gt;references&lt;/strong&gt; below each answer so that you can fact-check the answer if you would like&lt;/li&gt; &lt;li&gt;The database has the last 5-10 years of financial filing data so you can ask the agent to reason about &lt;strong&gt;trends&lt;/strong&gt; &lt;strong&gt;over&lt;/strong&gt; &lt;strong&gt;time&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Before each answer is returned to you, there is another agent, whose job is to &lt;strong&gt;critique&lt;/strong&gt; the &lt;strong&gt;draft&lt;/strong&gt; answer by the LLM and propose how to improve it&lt;/li&gt; &lt;li&gt;These suggestions and the entire context are then shared with the original agent. The agent can then decide to &lt;strong&gt;formulate&lt;/strong&gt; &lt;strong&gt;different&lt;/strong&gt; &lt;strong&gt;queries&lt;/strong&gt; to &lt;strong&gt;retrieve&lt;/strong&gt; &lt;strong&gt;better&lt;/strong&gt; &lt;strong&gt;information&lt;/strong&gt; from the database or simply incorporate the suggestions into the final answer&lt;/li&gt; &lt;li&gt;This final answer is then, provided to the user.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;One of the first hurdles is to get the data from the SEC. So in case this is helpful to anyone, &lt;a href=&quot;https://github.com/chandlernguyen/financial_agent&quot;&gt;here&lt;/a&gt; is my code to download different financial filings from each company from the SEC. I purposely want to download both the .txt file and the .zip file for each 10K and 10Q because I want the metadata and the actual report. Let me know what you think?&lt;/p&gt; &lt;p&gt;(And yes, I tried to use an already integrated financial retriever with Langchain called &lt;a href=&quot;https://Kay.ai&quot;&gt;Kay.ai&lt;/a&gt; . It works but doesn&amp;#39;t meet all of my needs.)&lt;/p&gt; &lt;p&gt;P.S: I wrote a much longer blog post to share my progress and challenges so far &lt;a href=&quot;https://www.chandlernguyen.com/blog/2024/04/15/building-a-self-evaluating-financial-chatbot-a-journey-through-data-code-and-struggles/&quot;&gt;here&lt;/a&gt; in case you are at all interested. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Double_Secretary9930&quot;&gt; /u/Double_Secretary9930 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6cb1x/self_evaluating_financial_chatbot_sharing_code_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6cb1x/self_evaluating_financial_chatbot_sharing_code_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6cb1x</id><link href="https://www.reddit.com/r/LangChain/comments/1c6cb1x/self_evaluating_financial_chatbot_sharing_code_to/" /><updated>2024-04-17T15:09:35+00:00</updated><published>2024-04-17T15:09:35+00:00</published><title>Self evaluating financial chatbot: Sharing code to download financial filings from SEC</title></entry><entry><author><name>/u/rockstarflo</name><uri>https://www.reddit.com/user/rockstarflo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I just stumbled upon this:&lt;br/&gt; &lt;a href=&quot;https://r.jina.ai&quot;&gt;https://r.jina.ai&lt;/a&gt;&amp;lt;website\_url here&amp;gt;&lt;/p&gt; &lt;p&gt;You can convert URLs to Markdown. This format is then better understood by LLMs compared to HTML. I think it can be used for Agents or RAG with web searches. I use it to generate synthetic data for a specific website.&lt;br/&gt; Example usage&lt;br/&gt; &lt;a href=&quot;https://r.jina.ai/https://en.wikipedia.org/wiki/Monkey_Island&quot;&gt;https://r.jina.ai/https://en.wikipedia.org/wiki/Monkey_Island&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rockstarflo&quot;&gt; /u/rockstarflo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c691qg/reader_llmfriendly_websites/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c691qg/reader_llmfriendly_websites/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c691qg</id><link href="https://www.reddit.com/r/LangChain/comments/1c691qg/reader_llmfriendly_websites/" /><updated>2024-04-17T12:52:19+00:00</updated><published>2024-04-17T12:52:19+00:00</published><title>Reader - LLM-Friendly websites</title></entry><entry><author><name>/u/Fireche</name><uri>https://www.reddit.com/user/Fireche</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, &lt;/p&gt; &lt;p&gt;a quick google search didn&amp;#39;t return me anything promising. Basically I would like to test my RAG system on a complex PDF. I assume there are some sample PDFs out there or a batch of PDF documents and sample queries + matching responses that I can run on my RAG to evaluate it quickly.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Is anyone aware of something like that? I would definitely save me some time ;) &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fireche&quot;&gt; /u/Fireche &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6j83s/looking_for_sample_pdf_sample_queries_responses/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6j83s/looking_for_sample_pdf_sample_queries_responses/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6j83s</id><link href="https://www.reddit.com/r/LangChain/comments/1c6j83s/looking_for_sample_pdf_sample_queries_responses/" /><updated>2024-04-17T19:46:40+00:00</updated><published>2024-04-17T19:46:40+00:00</published><title>Looking for sample PDF + sample queries + responses to test RAG</title></entry><entry><author><name>/u/Kind-Worry3072</name><uri>https://www.reddit.com/user/Kind-Worry3072</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;async def summaries(query: str): print(&amp;quot;query&amp;quot;,query) result=support.find_most_similar_word(query,doc_names) if result[&amp;quot;flag&amp;quot;]==False: response=&amp;quot;Sorry,no summarised content found check the document name once more&amp;quot; else: document_name=result[&amp;quot;documentName&amp;quot;] print(document_name) url = &amp;quot;http://localhost:8020/summary&amp;quot; jsonReq = {&amp;quot;name&amp;quot;: document_name} response = await requests.post(url, json=jsonReq) return response.text search = StructuredTool.from_function( func=summaries, coroutine= await summaries, name=&amp;quot;summaries&amp;quot;, description=&amp;quot;always call this function for summary.useful for when you need to get summary of documents.If summary is found provide the summary else if not found then say no summary found and stop.Don&amp;#39;t bring up any &amp;quot;, coroutine=summaries, coroutine= ... &amp;lt;- you can specify an async method if desired as well ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;how can i call this async function in the right way . Can anone please help to correct this code&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Kind-Worry3072&quot;&gt; /u/Kind-Worry3072 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6fnb8/async_function_in_lang_chain_tools_or_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6fnb8/async_function_in_lang_chain_tools_or_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6fnb8</id><link href="https://www.reddit.com/r/LangChain/comments/1c6fnb8/async_function_in_lang_chain_tools_or_agents/" /><updated>2024-04-17T17:22:44+00:00</updated><published>2024-04-17T17:22:44+00:00</published><title>Async function in Lang chain tools or agents</title></entry><entry><author><name>/u/raia-live</name><uri>https://www.reddit.com/user/raia-live</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6hiaa/userfriendly_rag_platform/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/RBPIXrVIPvmGedic6UTH5JMK1GZWpUTQx3GvtuKkXk0.jpg&quot; alt=&quot;User-friendly RAG platform&quot; title=&quot;User-friendly RAG platform&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been exploring AI to help with the data analysis side of things and found that most of the tools require quite a bit of development and customization to be really useful or end-user-friendly.&lt;/p&gt; &lt;p&gt;Because of that, I started building something I call Raia, a user-friendly approach to using AI to perform RAG on databases and automate processes.&lt;/p&gt; &lt;p&gt;I&amp;#39;m looking to connect with people who are open to providing feedback. My goal is to see if this is useful and help them solve a problem.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://app.raia.live&quot;&gt;I&amp;#39;ve made it available here&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Any feedback is very much appreciated&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/gw4t958f33vc1.png?width=1686&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=58017580d57b93ab878db3bfb0454d108d097614&quot;&gt;https://preview.redd.it/gw4t958f33vc1.png?width=1686&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=58017580d57b93ab878db3bfb0454d108d097614&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/raia-live&quot;&gt; /u/raia-live &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6hiaa/userfriendly_rag_platform/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6hiaa/userfriendly_rag_platform/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c6hiaa</id><media:thumbnail url="https://a.thumbs.redditmedia.com/RBPIXrVIPvmGedic6UTH5JMK1GZWpUTQx3GvtuKkXk0.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1c6hiaa/userfriendly_rag_platform/" /><updated>2024-04-17T18:37:04+00:00</updated><published>2024-04-17T18:37:04+00:00</published><title>User-friendly RAG platform</title></entry><entry><author><name>/u/jzone3</name><uri>https://www.reddit.com/user/jzone3</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6fmi9/building_chatgpt_from_scratch_the_right_way/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/m1KRabojJvRhRkgw6rcikxAYppu0_KpFMgMT7fdPSm8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=784e1ba91d28b46d1ff1683d035dadaed2599fc6&quot; alt=&quot;Building ChatGPT from scratch, the right way&quot; title=&quot;Building ChatGPT from scratch, the right way&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jzone3&quot;&gt; /u/jzone3 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://blog.promptlayer.com/building-chatgpt-from-scratch-the-right-way-ef82e771886e&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6fmi9/building_chatgpt_from_scratch_the_right_way/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c6fmi9</id><media:thumbnail url="https://external-preview.redd.it/m1KRabojJvRhRkgw6rcikxAYppu0_KpFMgMT7fdPSm8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=784e1ba91d28b46d1ff1683d035dadaed2599fc6" /><link href="https://www.reddit.com/r/LangChain/comments/1c6fmi9/building_chatgpt_from_scratch_the_right_way/" /><updated>2024-04-17T17:21:52+00:00</updated><published>2024-04-17T17:21:52+00:00</published><title>Building ChatGPT from scratch, the right way</title></entry><entry><author><name>/u/Valuable-Cap-3357</name><uri>https://www.reddit.com/user/Valuable-Cap-3357</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I keep getting the error about token sequence length is 1024. I am not sure what it impacts! I am using Mistral-small which has 32k sequence length. Any guidance ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Valuable-Cap-3357&quot;&gt; /u/Valuable-Cap-3357 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6eh52/token_sequence_length/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6eh52/token_sequence_length/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6eh52</id><link href="https://www.reddit.com/r/LangChain/comments/1c6eh52/token_sequence_length/" /><updated>2024-04-17T16:35:21+00:00</updated><published>2024-04-17T16:35:21+00:00</published><title>Token sequence length</title></entry><entry><author><name>/u/LaAlice</name><uri>https://www.reddit.com/user/LaAlice</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build an LCEL chain. However, at the n-th step, a cypher graph query gets generated. The next step in the chain should be that the query gets executed and the result gets passed on to the next step. I have a Neo4jGraph object, but I don&amp;#39;t know how to integrate it into the chain. I thought about writing a function that gets the query, executes it and returns the result, but I don&amp;#39;t know how to pass the graph to that function. Is there some element, for example a retriever, that I can use?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LaAlice&quot;&gt; /u/LaAlice &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68ye8/include_graph_query_into_lcel_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68ye8/include_graph_query_into_lcel_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c68ye8</id><link href="https://www.reddit.com/r/LangChain/comments/1c68ye8/include_graph_query_into_lcel_chain/" /><updated>2024-04-17T12:48:04+00:00</updated><published>2024-04-17T12:48:04+00:00</published><title>Include graph query into LCEL chain</title></entry><entry><author><name>/u/cerebriumBoss</name><uri>https://www.reddit.com/user/cerebriumBoss</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68lce/creating_an_executive_assistant_using_langchain/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/iiaz5GsigQoVvtdwJm2jDbRcDCFphCRBecbfTzMEjw8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1b8f1a1d24dc2aaa9b27e6f4a84ecc64f4a97656&quot; alt=&quot;Creating an Executive Assistant using LangChain, LangSmith, Cerebrium and Cal.com&quot; title=&quot;Creating an Executive Assistant using LangChain, LangSmith, Cerebrium and Cal.com&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cerebriumBoss&quot;&gt; /u/cerebriumBoss &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.cerebrium.ai/blog/creating-an-executive-assistant-using-langchain-langsmith-cerebrium-and-cal-com&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68lce/creating_an_executive_assistant_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c68lce</id><media:thumbnail url="https://external-preview.redd.it/iiaz5GsigQoVvtdwJm2jDbRcDCFphCRBecbfTzMEjw8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1b8f1a1d24dc2aaa9b27e6f4a84ecc64f4a97656" /><link href="https://www.reddit.com/r/LangChain/comments/1c68lce/creating_an_executive_assistant_using_langchain/" /><updated>2024-04-17T12:30:10+00:00</updated><published>2024-04-17T12:30:10+00:00</published><title>Creating an Executive Assistant using LangChain, LangSmith, Cerebrium and Cal.com</title></entry><entry><author><name>/u/Ill_Bodybuilder3499</name><uri>https://www.reddit.com/user/Ill_Bodybuilder3499</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;as for my understanding with BM25 Retrieval, a score is computed. Therefore i would like to set a score threshold for my Langchain Ensemble Retriever with one Bm25 component. But I did not see a way to di this in Langchain.&lt;/p&gt; &lt;p&gt;I want to do this because otherwise the Bm25 is likely to find always something for generic questions and this might not be perfect.&lt;/p&gt; &lt;p&gt;Any thoughts on this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ill_Bodybuilder3499&quot;&gt; /u/Ill_Bodybuilder3499 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6dlyu/bm25_retriever_with_score_threshold/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6dlyu/bm25_retriever_with_score_threshold/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6dlyu</id><link href="https://www.reddit.com/r/LangChain/comments/1c6dlyu/bm25_retriever_with_score_threshold/" /><updated>2024-04-17T16:01:53+00:00</updated><published>2024-04-17T16:01:53+00:00</published><title>BM25 Retriever with Score Threshold</title></entry><entry><author><name>/u/GrizzyLizz</name><uri>https://www.reddit.com/user/GrizzyLizz</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Im still new to Langchain and making use of it (though I am proficient enough with Python). I wanted to build a chatbot application where user inputs to the AI would make use of some provided image. As per my understanding, this is what RAG is for. However, I cant find an example where an LLM application is retreiving images passed to it. Here is the workflow I want to be able to implement:&lt;/p&gt; &lt;p&gt;- User provides some prompt with an image. This image gets stored in the backend by the application. The LLM part of the application then uses this image or any previously provided images as contextual information to reply to the prompt.&lt;/p&gt; &lt;p&gt;- If the prompt requests for one of the images back for e.g. &amp;quot;Can you go through the images and get back the one which is in black and white&amp;quot;, then the application finds such an image and returns it or replies with a negative&lt;/p&gt; &lt;p&gt;Is the second part of this flow achievable using Langchain? Or would I have to do it some other way?&lt;br/&gt; Note: i dont specifically want a model which can identify black and white images but basically perform some kind of semantic search through the images. The prompt may be &amp;quot;Find all the images I provided and give back the ones with a tree in it&amp;quot;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/GrizzyLizz&quot;&gt; /u/GrizzyLizz &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c66lrw/can_an_llm_application_retrieve_imagesusing_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c66lrw/can_an_llm_application_retrieve_imagesusing_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c66lrw</id><link href="https://www.reddit.com/r/LangChain/comments/1c66lrw/can_an_llm_application_retrieve_imagesusing_rag/" /><updated>2024-04-17T10:41:13+00:00</updated><published>2024-04-17T10:41:13+00:00</published><title>Can an LLM application retrieve images(using RAG or some other technique)?</title></entry><entry><author><name>/u/sebastianstehle</name><uri>https://www.reddit.com/user/sebastianstehle</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am using langchain with typescript and I have reported a few bugs and feature requests already and none of them have been answered so far.&lt;/p&gt; &lt;p&gt;There are even issues from January where only the useless bot answered has so far: &lt;a href=&quot;https://github.com/langchain-ai/langchainjs/issues/3978&quot;&gt;https://github.com/langchain-ai/langchainjs/issues/3978&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Many people complain about the documentation, but I am really worried about this problem.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sebastianstehle&quot;&gt; /u/sebastianstehle &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6aquq/developers_seem_to_inactive_at_least_in_the_js/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6aquq/developers_seem_to_inactive_at_least_in_the_js/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6aquq</id><link href="https://www.reddit.com/r/LangChain/comments/1c6aquq/developers_seem_to_inactive_at_least_in_the_js/" /><updated>2024-04-17T14:05:05+00:00</updated><published>2024-04-17T14:05:05+00:00</published><title>Developers seem to inactive, at least in the JS repo</title></entry><entry><author><name>/u/mutexs</name><uri>https://www.reddit.com/user/mutexs</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, guys!&lt;/p&gt; &lt;p&gt;I&amp;#39;m a newbie in LangChain and need help.&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on a Next.js project for a chatbot where I&amp;#39;m using a RetrievalQAChain. Now, I also want to make external API requests. For that, I&amp;#39;m implementing an APIChain. However, I&amp;#39;m struggling to combine both chains to return the output as a single chain.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mutexs&quot;&gt; /u/mutexs &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68juh/seeking_assistance_in_combining_two_chains/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68juh/seeking_assistance_in_combining_two_chains/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c68juh</id><link href="https://www.reddit.com/r/LangChain/comments/1c68juh/seeking_assistance_in_combining_two_chains/" /><updated>2024-04-17T12:28:03+00:00</updated><published>2024-04-17T12:28:03+00:00</published><title>Seeking assistance in combining two chains</title></entry></feed>