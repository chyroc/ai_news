<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-03-06T15:38:31+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/RepresentativeNo547</name><uri>https://www.reddit.com/user/RepresentativeNo547</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Which library comes out on top? I am building a multi-agent system in production but still have not decided which framework to use&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RepresentativeNo547&quot;&gt; /u/RepresentativeNo547 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7q44y/autogen_vs_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7q44y/autogen_vs_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7q44y</id><link href="https://www.reddit.com/r/LangChain/comments/1b7q44y/autogen_vs_langgraph/" /><updated>2024-03-06T04:00:13+00:00</updated><published>2024-03-06T04:00:13+00:00</published><title>Autogen vs. LangGraph</title></entry><entry><author><name>/u/EscapedLaughter</name><uri>https://www.reddit.com/user/EscapedLaughter</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7q6u1/switch_to_and_fro_claude3_gpt4_by_changing_2/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/km0k8hnc1nmc1.gif?width=640&amp;amp;crop=smart&amp;amp;s=181d7cff9061d16d502dd5fd826a87ed4a82e3a5&quot; alt=&quot;Switch to and fro Claude-3 &amp;lt;—&amp;gt; GPT-4 by changing 2 lines of code&quot; title=&quot;Switch to and fro Claude-3 &amp;lt;—&amp;gt; GPT-4 by changing 2 lines of code&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EscapedLaughter&quot;&gt; /u/EscapedLaughter &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/km0k8hnc1nmc1.gif&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7q6u1/switch_to_and_fro_claude3_gpt4_by_changing_2/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1b7q6u1</id><media:thumbnail url="https://preview.redd.it/km0k8hnc1nmc1.gif?width=640&amp;crop=smart&amp;s=181d7cff9061d16d502dd5fd826a87ed4a82e3a5" /><link href="https://www.reddit.com/r/LangChain/comments/1b7q6u1/switch_to_and_fro_claude3_gpt4_by_changing_2/" /><updated>2024-03-06T04:03:58+00:00</updated><published>2024-03-06T04:03:58+00:00</published><title>Switch to and fro Claude-3 &lt;—&gt; GPT-4 by changing 2 lines of code</title></entry><entry><author><name>/u/Over_Fun6759</name><uri>https://www.reddit.com/user/Over_Fun6759</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;React Native is incompatible with langchain, when are we going to get an update?&lt;/p&gt; &lt;p&gt;i found this but there is no solution even the one provided with langchain maintainer himself &lt;a href=&quot;https://stackoverflow.com/questions/77307779/react-native-issue-while-implementing-langchain/77313089#77313089?newreg=6af4405652b844fd81c2d0735b49c25f&quot;&gt;https://stackoverflow.com/questions/77307779/react-native-issue-while-implementing-langchain/77313089#77313089?newreg=6af4405652b844fd81c2d0735b49c25f&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Over_Fun6759&quot;&gt; /u/Over_Fun6759 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b815jv/react_native_langchain_support/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b815jv/react_native_langchain_support/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b815jv</id><link href="https://www.reddit.com/r/LangChain/comments/1b815jv/react_native_langchain_support/" /><updated>2024-03-06T14:33:12+00:00</updated><published>2024-03-06T14:33:12+00:00</published><title>React Native Langchain support?</title></entry><entry><author><name>/u/o3omoomin</name><uri>https://www.reddit.com/user/o3omoomin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hello! Are you doing well?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Among the types of retrievers, I came across a total of four retriever methods: Multi, self, time, and parent.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Is it possible to run multiple Retrievers in one project?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;For example, if we were to create a chatbot that answers school rules, would it be possible to use multiple Multi Query and Parent functions at the same time?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Or is it possible to use only one Retriver?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;If only one Retriever is available, can you tell me why?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/o3omoomin&quot;&gt; /u/o3omoomin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7op5w/when_implementing_rag_can_i_use_various_retrievers/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7op5w/when_implementing_rag_can_i_use_various_retrievers/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7op5w</id><link href="https://www.reddit.com/r/LangChain/comments/1b7op5w/when_implementing_rag_can_i_use_various_retrievers/" /><updated>2024-03-06T02:51:22+00:00</updated><published>2024-03-06T02:51:22+00:00</published><title>When implementing RAG, can I use various retrievers?</title></entry><entry><author><name>/u/michael_daigler</name><uri>https://www.reddit.com/user/michael_daigler</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, I wanted to share some recent work I did using Langchain and LangGraph to prototype an Agent pipeline for generating a newsletter + tweets from scratch.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the link: &lt;a href=&quot;https://youtu.be/i71Rm-7oG4k?si=B4Z2hBbh386EbswC&quot;&gt;https://youtu.be/i71Rm-7oG4k?si=B4Z2hBbh386EbswC&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Hope it helps.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/michael_daigler&quot;&gt; /u/michael_daigler &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7mhy2/building_my_oneman_media_team_with_ai_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7mhy2/building_my_oneman_media_team_with_ai_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7mhy2</id><link href="https://www.reddit.com/r/LangChain/comments/1b7mhy2/building_my_oneman_media_team_with_ai_agents/" /><updated>2024-03-06T01:09:54+00:00</updated><published>2024-03-06T01:09:54+00:00</published><title>Building my One-Man Media Team with AI Agents (Using Langchain &amp; LangGraph)</title></entry><entry><author><name>/u/Every-Link6367</name><uri>https://www.reddit.com/user/Every-Link6367</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We are looking to hire a full stack developer to help us with ai projects. You must be excellent at these skills: English Langchain with Python Setting up a frontend that works coherently with the backend and can be used by multiple users. If you are interested, please message us you resume at &lt;a href=&quot;mailto:Team@dialogintelligens.dk&quot;&gt;Team@dialogintelligens.dk&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Every-Link6367&quot;&gt; /u/Every-Link6367 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7915m/hirering_full_stack_developer_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7915m/hirering_full_stack_developer_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7915m</id><link href="https://www.reddit.com/r/LangChain/comments/1b7915m/hirering_full_stack_developer_with_langchain/" /><updated>2024-03-05T16:11:26+00:00</updated><published>2024-03-05T16:11:26+00:00</published><title>Hirering full stack developer with Langchain knowledge</title></entry><entry><author><name>/u/Skeltek</name><uri>https://www.reddit.com/user/Skeltek</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;m fairly new to LangChain, and I&amp;#39;m wondering if it&amp;#39;s a use case that can be well executed with LangChain.&lt;br/&gt; I would like to create a helper/copilot (chatbot) in the first place to identify irrelevant, duplicate, or contradictory content and assist me in restructuring the navigation tree. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Skeltek&quot;&gt; /u/Skeltek &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7byjo/confluence_cleanup/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7byjo/confluence_cleanup/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7byjo</id><link href="https://www.reddit.com/r/LangChain/comments/1b7byjo/confluence_cleanup/" /><updated>2024-03-05T18:05:30+00:00</updated><published>2024-03-05T18:05:30+00:00</published><title>Confluence cleanup</title></entry><entry><author><name>/u/MotherDistrict9823</name><uri>https://www.reddit.com/user/MotherDistrict9823</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;m an intern with an ambitious project that could earn me a full-time position. Our company often engages in extensive referencing of files, documents, and web research, which is time-consuming. My solution is to automate these tasks through a bot, leveraging LangChain and GPT-4 for intelligent query processing.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Project Overview:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The bot will integrate with Microsoft Teams, enabling users to submit queries and receive document references or research results. It will serve different departments, each possibly requiring access to a vast array of data (Word, Excel, PDFs, emails, etc.). The data volumes we&amp;#39;re looking at span gigabytes to terabytes. Given this, I&amp;#39;m leaning towards using a vertical database to manage this diverse and voluminous data efficiently.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Seeking Advice on:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Vertical Database Selection:&lt;/strong&gt; Given my inclination towards a vertical database for this project, which specific vertical database systems would you recommend for handling both structured and unstructured data across such a broad spectrum of file types and sizes?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Database Structure:&lt;/strong&gt; Is it more advantageous to maintain a single comprehensive database or to deploy multiple databases, one for each department, to streamline data management and querying processes?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Project Architecture:&lt;/strong&gt; How should I structure the interaction between the vertical databases, the LangChain bot, and the GPT-4 API to ensure seamless operation and scalability? What considerations should I keep in mind to support the large data volume and diverse file types?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Managing Large Datasets:&lt;/strong&gt; Any insights on efficiently processing and retrieving information from large Excel files filled with extensive numerical data would be especially helpful. Are there particular strategies or technologies that would facilitate handling such datasets?&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I am very much open to learning from your experiences and suggestions, including any alternative approaches or tools that could enhance the project. My ultimate aim is to develop a convincing proof of concept that clearly demonstrates the potential benefits and feasibility of the initiative.&lt;/p&gt; &lt;p&gt;Thank you immensely for your guidance and support!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MotherDistrict9823&quot;&gt; /u/MotherDistrict9823 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7b57n/seeking_advice_for_rag_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7b57n/seeking_advice_for_rag_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7b57n</id><link href="https://www.reddit.com/r/LangChain/comments/1b7b57n/seeking_advice_for_rag_app/" /><updated>2024-03-05T17:33:44+00:00</updated><published>2024-03-05T17:33:44+00:00</published><title>Seeking Advice for RAG App</title></entry><entry><author><name>/u/Another___World</name><uri>https://www.reddit.com/user/Another___World</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7gjco/this_thing_annoys_me_a_lot_planandexecute/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/O8FKBrHg65IRDiNfwiOrfPAtP7Ih1sFLeMK-lFawGvI.jpg&quot; alt=&quot;This thing annoys me a lot. PlanAndExecute mistyping 'title' instead of 'query' when trying to use the retriever. The worst thing is that it happends randomly and can screw up a long chain. The prompt template for this action should be fixed. It failed a&quot; title=&quot;This thing annoys me a lot. PlanAndExecute mistyping 'title' instead of 'query' when trying to use the retriever. The worst thing is that it happends randomly and can screw up a long chain. The prompt template for this action should be fixed. It failed a&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Another___World&quot;&gt; /u/Another___World &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/gallery/1b7gjco&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7gjco/this_thing_annoys_me_a_lot_planandexecute/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1b7gjco</id><media:thumbnail url="https://b.thumbs.redditmedia.com/O8FKBrHg65IRDiNfwiOrfPAtP7Ih1sFLeMK-lFawGvI.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1b7gjco/this_thing_annoys_me_a_lot_planandexecute/" /><updated>2024-03-05T21:04:07+00:00</updated><published>2024-03-05T21:04:07+00:00</published><title>This thing annoys me a lot. PlanAndExecute mistyping 'title' instead of 'query' when trying to use the retriever. The worst thing is that it happends randomly and can screw up a long chain. The prompt template for this action should be fixed. It failed a</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/HaAPBqwuj0vi5UErvwiGWGYZarwWXASKraGcYhfRP1w.jpg&quot; alt=&quot;Update: Langtrace Preview: An opensource LLM monitoring tool - achieving better cardinality compared to Langsmith.&quot; title=&quot;Update: Langtrace Preview: An opensource LLM monitoring tool - achieving better cardinality compared to Langsmith.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is with regards to: &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b4s7cw/building_a_open_source_llm_monitoring_software/&quot;&gt;https://www.reddit.com/r/LangChain/comments/1b4s7cw/building_a_open_source_llm_monitoring_software/&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Just wanted to share an update on my open source LLM monitoring tool. I do not have a UI yet, so asked chatGPT to plot the spans of a trace I generated for a langchain example code that uses agents. Below is the screenshot of my tool&amp;#39;s trace plotted:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/xvqgcukrgemc1.png?width=2980&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0eaa0d298e047457520359017123054f65570621&quot;&gt;https://preview.redd.it/xvqgcukrgemc1.png?width=2980&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0eaa0d298e047457520359017123054f65570621&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Same output from Langsmith:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/lulyrgh6gemc1.png?width=778&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=db44f54bf8d561ed379a2ea3e1dfe2319ee9ab84&quot;&gt;https://preview.redd.it/lulyrgh6gemc1.png?width=778&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=db44f54bf8d561ed379a2ea3e1dfe2319ee9ab84&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Feedback/comments/thoughts welcome&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1b6phov</id><media:thumbnail url="https://b.thumbs.redditmedia.com/HaAPBqwuj0vi5UErvwiGWGYZarwWXASKraGcYhfRP1w.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/" /><updated>2024-03-04T23:16:58+00:00</updated><published>2024-03-04T23:16:58+00:00</published><title>Update: Langtrace Preview: An opensource LLM monitoring tool - achieving better cardinality compared to Langsmith.</title></entry><entry><author><name>/u/mariojapcorreia</name><uri>https://www.reddit.com/user/mariojapcorreia</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello guys, i am extracting information about someone using llama and then using this information to compare it to a text of requirements. For example:&lt;/p&gt; &lt;p&gt;Req: person needs to have skills A or similar.&lt;/p&gt; &lt;p&gt;What can be the best technologies to do this comparison?&lt;br/&gt; I was trying embeddings models and then calculating the l2 distance between the requirements and the skills but i seem to be getting bad scores for people that should be &amp;quot;good&amp;quot;.&lt;/p&gt; &lt;p&gt;Anyone ever dived into this realm? Can´t seem to find good info online.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mariojapcorreia&quot;&gt; /u/mariojapcorreia &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7470g/llama_plus_text_similarity/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7470g/llama_plus_text_similarity/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7470g</id><link href="https://www.reddit.com/r/LangChain/comments/1b7470g/llama_plus_text_similarity/" /><updated>2024-03-05T12:37:20+00:00</updated><published>2024-03-05T12:37:20+00:00</published><title>Llama plus text similarity</title></entry><entry><author><name>/u/SundaeNext1297</name><uri>https://www.reddit.com/user/SundaeNext1297</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;Is there an effective way to summarize 10k page documents. &lt;/p&gt; &lt;p&gt;So I have chunks of 300 words and their embeddings already stored in the database.&lt;/p&gt; &lt;p&gt;I can apply clustering algorithm like k means. But for such large documents, I think effective cluster size would be 100-150, with each cluster of being approximately 25-30k tokens. &lt;/p&gt; &lt;p&gt;That would mean 100 api calls to get chunk summary , and final api call yo get final summary. &lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;How can we optimize this ? Not necessarily using clustering, any other way to make it kore cost efficient. As passing 32k prompt to model is very expensive itself, and to add 100 api calls. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;For such large documents what metrics can I use to ensure summary is good and model isn&amp;#39;t hallucinating. &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Thanks! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SundaeNext1297&quot;&gt; /u/SundaeNext1297 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6fiyt/effective_way_to_summarize_10k_page_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6fiyt/effective_way_to_summarize_10k_page_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b6fiyt</id><link href="https://www.reddit.com/r/LangChain/comments/1b6fiyt/effective_way_to_summarize_10k_page_documents/" /><updated>2024-03-04T16:41:46+00:00</updated><published>2024-03-04T16:41:46+00:00</published><title>Effective way to summarize 10k page documents</title></entry><entry><author><name>/u/Diligent_Eye1248</name><uri>https://www.reddit.com/user/Diligent_Eye1248</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We&amp;#39;ve been building LLM based tools for months, but I think that there should be efficient frameworks by now that actually add value. I tried langchain a while back but I felt like it was just an over complicated overhead where it was always simpler to make everything from scratch each time. Guidance has been the only real improvement for me as it does way more than basic prompt templating, but it is in no way a full framework.&lt;/p&gt; &lt;p&gt;Now there are LlamaIndex, TigerLab, Langchain... but I simply don&amp;#39;t have the time to test them all.&lt;/p&gt; &lt;p&gt;We need to run the models by ourselves, so no Open AI api, ideally run something compatible with TGI / VLLM. We need to connect to proper databases and vectorDB (currently using Milvus). And I&amp;#39;m looking for something that is actually useful and I don&amp;#39;t have to struggle and hack the library everytime I want to do something slightly different.&lt;/p&gt; &lt;p&gt;Does any of you have a good recommendation? Everything changes so quickly I feel like I can&amp;#39;t trust articles that are older than two months. So what are you currently using and what has been an overhyped crap?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Diligent_Eye1248&quot;&gt; /u/Diligent_Eye1248 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b67jkl/best_framework_for_llm_based_applications_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b67jkl/best_framework_for_llm_based_applications_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b67jkl</id><link href="https://www.reddit.com/r/LangChain/comments/1b67jkl/best_framework_for_llm_based_applications_in/" /><updated>2024-03-04T10:16:24+00:00</updated><published>2024-03-04T10:16:24+00:00</published><title>Best framework for LLM based applications in production</title></entry><entry><author><name>/u/supernitin</name><uri>https://www.reddit.com/user/supernitin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello. &lt;/p&gt; &lt;p&gt;How capable is an M1 Pro 3.2 GHz and 32 GB of ram at running local models? I’m deciding whether to buy a used machine for $1K to power a Langchain based project I’m working on. &lt;/p&gt; &lt;p&gt;I’m also considering using cloud services and wait until the new Mac hardware launches which will likely be optimized for LLMs. &lt;/p&gt; &lt;p&gt;Thanks!🙏 &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/supernitin&quot;&gt; /u/supernitin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6n1k9/local_models_w_m1_pro/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6n1k9/local_models_w_m1_pro/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b6n1k9</id><link href="https://www.reddit.com/r/LangChain/comments/1b6n1k9/local_models_w_m1_pro/" /><updated>2024-03-04T21:40:38+00:00</updated><published>2024-03-04T21:40:38+00:00</published><title>Local Models w/ M1 Pro?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/artificial/comments/1b67qr3/the_era_of_1bit_llms_summarized/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b69trl/the_era_of_1bit_llms_summarized/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b69trl</id><link href="https://www.reddit.com/r/LangChain/comments/1b69trl/the_era_of_1bit_llms_summarized/" /><updated>2024-03-04T12:33:26+00:00</updated><published>2024-03-04T12:33:26+00:00</published><title>The Era of 1-bit LLMs summarized</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How can I store the QA object to preserve its state while implementing memory? For every question answered, we create a new RetrievalQA object, which flushes the chat_history. I&amp;#39;m creating a chatbot where multiple projects can be made, and I don&amp;#39;t want to lose the QA object&amp;#39;s state. How can I save the QA in Django?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b69l6p/how_can_i_store_the_qa_object/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b69l6p/how_can_i_store_the_qa_object/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b69l6p</id><link href="https://www.reddit.com/r/LangChain/comments/1b69l6p/how_can_i_store_the_qa_object/" /><updated>2024-03-04T12:20:24+00:00</updated><published>2024-03-04T12:20:24+00:00</published><title>How can I store the QA object?</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Starting a thread on the most frustrating problems you’re facing with the use of Langchain or LLMs in your projects&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b64qb5/frustrating_problems_with_langchainllms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b64qb5/frustrating_problems_with_langchainllms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b64qb5</id><link href="https://www.reddit.com/r/LangChain/comments/1b64qb5/frustrating_problems_with_langchainllms/" /><updated>2024-03-04T07:10:40+00:00</updated><published>2024-03-04T07:10:40+00:00</published><title>Frustrating problems with langchain/LLMs?</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How to serialize QA object?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b67qnb/typeerror_object_of_type_retrievalqa_is_not_json/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b67qnb/typeerror_object_of_type_retrievalqa_is_not_json/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b67qnb</id><link href="https://www.reddit.com/r/LangChain/comments/1b67qnb/typeerror_object_of_type_retrievalqa_is_not_json/" /><updated>2024-03-04T10:28:57+00:00</updated><published>2024-03-04T10:28:57+00:00</published><title>TypeError: Object of type RetrievalQA is not JSON serializable</title></entry><entry><author><name>/u/gon_martinam</name><uri>https://www.reddit.com/user/gon_martinam</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi 👋&lt;/p&gt; &lt;p&gt;I would like to know what can be done to perform ReRanking in a RAG pipeline beyond using the Cohere endpoint or those made available by Langchain.&lt;/p&gt; &lt;p&gt;A couple of days ago Mixedbread released some very interesting ReRanking models that I would like to try, but perhaps due to a lack of detailed knowledge of the Langchain library, I don&amp;#39;t know if it is possible to include any ReRanking model I want within my pipeline.&lt;/p&gt; &lt;p&gt;How are you all doing it? 💬&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gon_martinam&quot;&gt; /u/gon_martinam &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b670b4/how_to_use_rerankers_in_langchain_both_in_python/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b670b4/how_to_use_rerankers_in_langchain_both_in_python/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b670b4</id><link href="https://www.reddit.com/r/LangChain/comments/1b670b4/how_to_use_rerankers_in_langchain_both_in_python/" /><updated>2024-03-04T09:42:25+00:00</updated><published>2024-03-04T09:42:25+00:00</published><title>How to use Rerankers in Langchain (both in Python and JS, but particularly in LangchainJS)?</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;I am storing QA object locally like this in PGVector:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;class ProjectQA(models.Model):&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;id = models.AutoField(primary_key=True) # Add primary key field&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;project = models.ForeignKey(ProjectName, on_delete=models.CASCADE)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;qa_data = models.JSONField() # Store serialized qa data in JSONField&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;class Meta:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;db_table = &amp;#39;project_qa&amp;#39;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;def save_qa(self, qa_object):&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;self.qa_data = jsonpickle.encode(qa_object)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;self.save()&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;def get_qa(self):&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;return jsonpickle.decode(self.qa_data)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;def __str__(self):&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;return f&amp;#39;QA for Project: {self.project.project_id}&amp;#39;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;I am able to store the QA object, but getting below error while getting QA :&lt;/p&gt; &lt;p&gt;object return {self._restore(v) for v in obj[tags.SET]} &lt;/p&gt; &lt;p&gt;TypeError: unhashable type: &amp;#39;dict&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b65y4h/getting_error_while_storing_qa_object_locally/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b65y4h/getting_error_while_storing_qa_object_locally/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b65y4h</id><link href="https://www.reddit.com/r/LangChain/comments/1b65y4h/getting_error_while_storing_qa_object_locally/" /><updated>2024-03-04T08:30:33+00:00</updated><published>2024-03-04T08:30:33+00:00</published><title>Getting Error while storing QA object locally</title></entry><entry><author><name>/u/Fleischkluetensuppe</name><uri>https://www.reddit.com/user/Fleischkluetensuppe</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b5fwz2/100_serverless_rag_pipeline/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/cWo2ZnZzcmEzNG1jMWqoo-RYk2fmL9EIiyW3fEL_w7UttiL5Q4HjKkApAdL9.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3f25fd2ec75f8befe5ac30a8eec1bcb54e6ba912&quot; alt=&quot;100% Serverless RAG pipeline&quot; title=&quot;100% Serverless RAG pipeline&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fleischkluetensuppe&quot;&gt; /u/Fleischkluetensuppe &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/l0xjhjk834mc1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b5fwz2/100_serverless_rag_pipeline/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1b5fwz2</id><media:thumbnail url="https://external-preview.redd.it/cWo2ZnZzcmEzNG1jMWqoo-RYk2fmL9EIiyW3fEL_w7UttiL5Q4HjKkApAdL9.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3f25fd2ec75f8befe5ac30a8eec1bcb54e6ba912" /><link href="https://www.reddit.com/r/LangChain/comments/1b5fwz2/100_serverless_rag_pipeline/" /><updated>2024-03-03T12:20:26+00:00</updated><published>2024-03-03T12:20:26+00:00</published><title>100% Serverless RAG pipeline</title></entry><entry><author><name>/u/hd_786</name><uri>https://www.reddit.com/user/hd_786</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b5tpc2/a_langchain_based_chatbot_template_using_free/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/O0PuJr0xlnINF_m6cB5864SAvGKK7lSsgOTMmcVDPrk.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=cc714ab16fa299d019827e27ac20fd1356bd1ce0&quot; alt=&quot;A Langchain based Chatbot Template using Free Huggingface Inference&quot; title=&quot;A Langchain based Chatbot Template using Free Huggingface Inference&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hd_786&quot;&gt; /u/hd_786 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/machaao/mistral-7b-chatbot&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b5tpc2/a_langchain_based_chatbot_template_using_free/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1b5tpc2</id><media:thumbnail url="https://external-preview.redd.it/O0PuJr0xlnINF_m6cB5864SAvGKK7lSsgOTMmcVDPrk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cc714ab16fa299d019827e27ac20fd1356bd1ce0" /><link href="https://www.reddit.com/r/LangChain/comments/1b5tpc2/a_langchain_based_chatbot_template_using_free/" /><updated>2024-03-03T22:12:24+00:00</updated><published>2024-03-03T22:12:24+00:00</published><title>A Langchain based Chatbot Template using Free Huggingface Inference</title></entry><entry><author><name>/u/Classic_essays</name><uri>https://www.reddit.com/user/Classic_essays</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello. I have been playing around with a bunch open open-source LLMs, but they all vary in terms of quality of output and response times. I&amp;#39;m wondering whether there is an open-source software to monitor the performance of such LLMs that I can integrate into my system.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Classic_essays&quot;&gt; /u/Classic_essays &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b5dscn/is_there_a_software_to_monitor_performance_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b5dscn/is_there_a_software_to_monitor_performance_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b5dscn</id><link href="https://www.reddit.com/r/LangChain/comments/1b5dscn/is_there_a_software_to_monitor_performance_of/" /><updated>2024-03-03T10:06:32+00:00</updated><published>2024-03-03T10:06:32+00:00</published><title>Is there a software to monitor performance of open-source LLMs?</title></entry><entry><author><name>/u/dhrumil-</name><uri>https://www.reddit.com/user/dhrumil-</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on a basic RAG which is really good with a snaller pdf like 15-20 pdf but as soon as i go about 50 or 100 the reterival doesn&amp;#39;t seem to be working good enough. Could you please suggest me some techniques which i can use to improve the RAG with large data.&lt;/p&gt; &lt;p&gt;What i have done till now : 1)Data extraction using pdf miner. 2) Chunking with 1500 size and 200 overlap 3) hybrid search (bm25+vector search(Chroma db)) 4) Generation with llama7b &lt;/p&gt; &lt;p&gt;What I&amp;#39;m thinking of doing fir further improving RAG&lt;/p&gt; &lt;p&gt;1) Storing and using metadata to improve vector search, but i dont know how should i extract meta data out if chunk or document. &lt;/p&gt; &lt;p&gt;2) Using 4 Similar user queries to retrieve more chunks then using Reranker over the reterived chunks.&lt;/p&gt; &lt;p&gt;Please Suggest me what else can i do or correct me if im doing anything wrong :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dhrumil-&quot;&gt; /u/dhrumil- &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b5d1m7/suggestion_for_robust_rag_which_can_handel_5000/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b5d1m7/suggestion_for_robust_rag_which_can_handel_5000/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b5d1m7</id><link href="https://www.reddit.com/r/LangChain/comments/1b5d1m7/suggestion_for_robust_rag_which_can_handel_5000/" /><updated>2024-03-03T09:18:16+00:00</updated><published>2024-03-03T09:18:16+00:00</published><title>Suggestion for robust RAG which can handel 5000 pages of pdf</title></entry><entry><author><name>/u/Narrow-Squirrel9809</name><uri>https://www.reddit.com/user/Narrow-Squirrel9809</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using openai embedding to convert the documents to embedding and post it to chroma db in external server.&lt;/p&gt; &lt;p&gt;collections = client.get_or_create_collection(name=&amp;quot;pdf_of_ai&amp;quot;,embedding_function=new OpenAIEmbeddings ())&lt;/p&gt; &lt;p&gt;I have already installed the latest version of langxhain and chroma db but I am still facing this error .&lt;/p&gt; &lt;p&gt;raise ValueError( ValueError: Expected EmbeddingFunction.&lt;strong&gt;call&lt;/strong&gt; to have the following signature: odict_keys([&amp;#39;self&amp;#39;, &amp;#39;input&amp;#39;]), got odict_keys([&amp;#39;args&amp;#39;, &amp;#39;kwargs&amp;#39;])&lt;/p&gt; &lt;p&gt;Can anyone help me resolve this issue?&lt;/p&gt; &lt;p&gt;I even tried custom embedding class but still facing the same error.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Narrow-Squirrel9809&quot;&gt; /u/Narrow-Squirrel9809 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b5pb5u/embedding_model_error_while_loading_to_chroma_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b5pb5u/embedding_model_error_while_loading_to_chroma_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b5pb5u</id><link href="https://www.reddit.com/r/LangChain/comments/1b5pb5u/embedding_model_error_while_loading_to_chroma_db/" /><updated>2024-03-03T19:17:51+00:00</updated><published>2024-03-03T19:17:51+00:00</published><title>Embedding model error while Loading to Chroma db</title></entry></feed>