<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-03-31T22:28:26+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Zealousideal_Wolf624</name><uri>https://www.reddit.com/user/Zealousideal_Wolf624</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;It&amp;#39;s different from other APIs inside LangChain. For example:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;AgentExecutor doesn&amp;#39;t clearly specify the inputs and outputs expected from your chain. What should the use provide?&lt;/li&gt; &lt;li&gt;The chain is called agent, and it&amp;#39;s not clear to me what&amp;#39;s what&lt;/li&gt; &lt;li&gt;There are OpenAI-specific code inside LangChain package, instead of having those in the langchain_openai package. Why is that the case?&lt;/li&gt; &lt;li&gt;Tools and toolkit docs are inside the agent documentation, despite having little to do with it. Are toolkits available only to agents?&lt;/li&gt; &lt;li&gt;The whole concept is reimplemented in LangGraph. What should I use?&lt;/li&gt; &lt;li&gt;The whole agent API isn&amp;#39;t on langchain_core. Is the APi unstable?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Are those questions reasonable? Is it truly a less mature part of langchain, or just a misunderstanding from my part?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zealousideal_Wolf624&quot;&gt; /u/Zealousideal_Wolf624 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bsfb5n/agent_api_is_weird/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bsfb5n/agent_api_is_weird/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bsfb5n</id><link href="https://www.reddit.com/r/LangChain/comments/1bsfb5n/agent_api_is_weird/" /><updated>2024-03-31T17:05:28+00:00</updated><published>2024-03-31T17:05:28+00:00</published><title>Agent API is weird</title></entry><entry><author><name>/u/SwimminInIt</name><uri>https://www.reddit.com/user/SwimminInIt</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.&lt;/p&gt; &lt;p&gt;I see a ton of people talking about document chat and integration with knowledge repos. Rather than just providing information I am looking to perform QA on the documents itself. &lt;/p&gt; &lt;p&gt;Here&amp;#39;s a brief overview of the workflow:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Document Submission (Manual User Action):&lt;/strong&gt; Entry point for examiners to submit documents.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Pre-Processing Node (Script for Data Manipulation):&lt;/strong&gt; Handles initial formatting and basic validation.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Policy Compliance Checker Node (PCCN):&lt;/strong&gt; Checks documents against policy rules.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Error Suggestion Node (ESN):&lt;/strong&gt; Identifies compliance issues and suggests corrections.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Quality Assurance Node (QAN):&lt;/strong&gt; Final review to ensure document quality.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Feedback and Interaction Node (FIN):&lt;/strong&gt; Where examiners review AI suggestions and apply corrections.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Approval and Compliance Marking Node (ACMN):&lt;/strong&gt; Marks documents as approved.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Some questions I have are:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Has anyone automated a Quality Assurance process with langchain/graph?&lt;/li&gt; &lt;li&gt;If yes, what was successful or what did not work?&lt;/li&gt; &lt;li&gt;Any suggestions on how to improve my approach?&lt;/li&gt; &lt;li&gt;Are there any examples you are aware of I could use as a reference?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I appreciate any help and thoughts on the topic!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SwimminInIt&quot;&gt; /u/SwimminInIt &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bsblmu</id><link href="https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/" /><updated>2024-03-31T14:24:29+00:00</updated><published>2024-03-31T14:24:29+00:00</published><title>LangGraph Workflow for Quality Assurance</title></entry><entry><author><name>/u/kingdomstrategies</name><uri>https://www.reddit.com/user/kingdomstrategies</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, &lt;/p&gt; &lt;p&gt;I&amp;#39;ve recently started diving into Langchain and find myself devoting more and more time to it. While I&amp;#39;m interested in various aspects of Langchain, I can&amp;#39;t help but notice that there seems to be a new AI Agent repo or framework popping up almost every day, especially in the realm of Agents.&lt;/p&gt; &lt;p&gt;With so much hype surrounding every new AI-related framework or library, I&amp;#39;m finding it challenging to focus on specializing in Langchain. It&amp;#39;s hard not to get distracted by the constant barrage of shiny new tools and technologies.&lt;/p&gt; &lt;p&gt;I wanted to reach out to the community and get your thoughts on this. Is it worth dedicating a significant amount of time to learning Langchain, given the rapid pace of development in the AI field? How do you stay focused and avoid getting sidetracked by the latest and greatest frameworks?&lt;/p&gt; &lt;p&gt;I&amp;#39;m genuinely interested in Langchain and believe it has a lot to offer, but I also want to make sure I&amp;#39;m investing my time wisely. Any insights or advice from those who have been working with Langchain for a while would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kingdomstrategies&quot;&gt; /u/kingdomstrategies &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brew3a/is_it_worth_dedicating_time_to_learn_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brew3a/is_it_worth_dedicating_time_to_learn_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1brew3a</id><link href="https://www.reddit.com/r/LangChain/comments/1brew3a/is_it_worth_dedicating_time_to_learn_langchain/" /><updated>2024-03-30T10:40:56+00:00</updated><published>2024-03-30T10:40:56+00:00</published><title>Is it worth dedicating time to learn Langchain with the constant influx of new AI frameworks?</title></entry><entry><author><name>/u/VegetableAddendum888</name><uri>https://www.reddit.com/user/VegetableAddendum888</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Just stumbled upon this fascinating technique shared Pathway on dynamically adapting the number of documents in a top-k retriever RAG prompt using LLM feedback. The method boasts a remarkable 4x cost reduction in RAG LLM question answering while upholding accuracy levels. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/VegetableAddendum888&quot;&gt; /u/VegetableAddendum888 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bromlx/what_are_your_views_on_pathways_latest_work_on_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bromlx/what_are_your_views_on_pathways_latest_work_on_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bromlx</id><link href="https://www.reddit.com/r/LangChain/comments/1bromlx/what_are_your_views_on_pathways_latest_work_on_rag/" /><updated>2024-03-30T18:26:14+00:00</updated><published>2024-03-30T18:26:14+00:00</published><title>What are your views on pathways latest work on RAG</title></entry><entry><author><name>/u/mo_tech_</name><uri>https://www.reddit.com/user/mo_tech_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks, skimming through reddit, I can see so many devs are building RAG use cases these days. I&amp;#39;d love to see any useful use cases.&lt;/p&gt; &lt;p&gt;In my case, I built an app a while ago that sells digital vouchers through an LLM based chat with payment built in. I decided later to shut down and focus on building a python framework for publishing AI apps very fast across many channels and with any LLM. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mo_tech_&quot;&gt; /u/mo_tech_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brhmsa/what_are_u_building_these_days_are_people_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brhmsa/what_are_u_building_these_days_are_people_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1brhmsa</id><link href="https://www.reddit.com/r/LangChain/comments/1brhmsa/what_are_u_building_these_days_are_people_using/" /><updated>2024-03-30T13:15:33+00:00</updated><published>2024-03-30T13:15:33+00:00</published><title>What are u building these days? Are people using it? Please share</title></entry><entry><author><name>/u/larrytheevilbunnie</name><uri>https://www.reddit.com/user/larrytheevilbunnie</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Trying to use non-OpenAI models, but it seems like there&amp;#39;s no equivalent to the get_openai_callback() function for other models, but the docs say it&amp;#39;s only usable for OpenAI.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/larrytheevilbunnie&quot;&gt; /u/larrytheevilbunnie &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brw18c/any_ways_to_count_token_usage_for_models_not_by/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brw18c/any_ways_to_count_token_usage_for_models_not_by/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1brw18c</id><link href="https://www.reddit.com/r/LangChain/comments/1brw18c/any_ways_to_count_token_usage_for_models_not_by/" /><updated>2024-03-30T23:44:48+00:00</updated><published>2024-03-30T23:44:48+00:00</published><title>Any ways to count token usage for models not by OpenAI?</title></entry><entry><author><name>/u/RelationshipSome9200</name><uri>https://www.reddit.com/user/RelationshipSome9200</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, curious to know what are the best prompting techniques that you use with Langchain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RelationshipSome9200&quot;&gt; /u/RelationshipSome9200 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brn23l/what_are_the_best_prompting_techniques/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brn23l/what_are_the_best_prompting_techniques/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1brn23l</id><link href="https://www.reddit.com/r/LangChain/comments/1brn23l/what_are_the_best_prompting_techniques/" /><updated>2024-03-30T17:19:38+00:00</updated><published>2024-03-30T17:19:38+00:00</published><title>What are the best prompting techniques?</title></entry><entry><author><name>/u/Traditional-Bunch192</name><uri>https://www.reddit.com/user/Traditional-Bunch192</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brhyzc/attributeerror_module_langchain_has_no_attribute/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/RBtkPVjChV2GdukxINuz4SJXTXubALei6cB2QjoPO2M.jpg&quot; alt=&quot;AttributeError: module langchain has no attribute verbose&quot; title=&quot;AttributeError: module langchain has no attribute verbose&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, urgent help required. I’ve been trying to install langchain in my computer for my major project since a very long time but everytime it gave one error or the other so I gave up but as the deadline is approaching I seriously started doing it. But every single time I try to install it it shows the same error or it shows circular import errror. Please help me out&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Traditional-Bunch192&quot;&gt; /u/Traditional-Bunch192 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/gallery/1brhyzc&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brhyzc/attributeerror_module_langchain_has_no_attribute/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1brhyzc</id><media:thumbnail url="https://b.thumbs.redditmedia.com/RBtkPVjChV2GdukxINuz4SJXTXubALei6cB2QjoPO2M.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1brhyzc/attributeerror_module_langchain_has_no_attribute/" /><updated>2024-03-30T13:32:12+00:00</updated><published>2024-03-30T13:32:12+00:00</published><title>AttributeError: module langchain has no attribute verbose</title></entry><entry><author><name>/u/jdogbro12</name><uri>https://www.reddit.com/user/jdogbro12</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brkg39/observability_testing_of_openais_assistants_api/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/dVi6x1iGu9NlqWCJcpW2MN-VVdjsiUL9hXbGKvoQuaY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=98e0c2be6ac3c6b9c7cf560b4470363d1133292d&quot; alt=&quot;Observability &amp;amp; testing of OpenAI's Assistants API&quot; title=&quot;Observability &amp;amp; testing of OpenAI's Assistants API&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jdogbro12&quot;&gt; /u/jdogbro12 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://docs.parea.ai/observability/openai_assistants_api&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1brkg39/observability_testing_of_openais_assistants_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1brkg39</id><media:thumbnail url="https://external-preview.redd.it/dVi6x1iGu9NlqWCJcpW2MN-VVdjsiUL9hXbGKvoQuaY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=98e0c2be6ac3c6b9c7cf560b4470363d1133292d" /><link href="https://www.reddit.com/r/LangChain/comments/1brkg39/observability_testing_of_openais_assistants_api/" /><updated>2024-03-30T15:26:19+00:00</updated><published>2024-03-30T15:26:19+00:00</published><title>Observability &amp; testing of OpenAI's Assistants API</title></entry><entry><author><name>/u/RatioRemarkable5605</name><uri>https://www.reddit.com/user/RatioRemarkable5605</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;h1&gt;First the repo:&lt;/h1&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/SaadAttieh/agent_lite&quot;&gt;https://github.com/SaadAttieh/agent_lite&lt;/a&gt;&lt;/p&gt; &lt;p&gt;A minified version of the Langchain library, designed to be small enough to easily read and edit but still provide a type-safe interface to building Agents on top of LLMs.&lt;/p&gt; &lt;h1&gt;Why:&lt;/h1&gt; &lt;p&gt;Look, Langchain is full featured, its expansive, it has all the bells and whistles. And, most people should just use it.&lt;/p&gt; &lt;p&gt;But, it&amp;#39;s huge, and learning how to provide the correct combination of keyword arguments to customise the behaviour consumes far too much of my time. I love that I can define tools using python functions and have them automatically bound to LLMs, but the moment I want to do something a little more custom, such as stream the output, I&amp;#39;m lost in callback handlers, agent_kwargs, and so on.&lt;/p&gt; &lt;p&gt;On the other end, dipping down to plain LLM APIs feels just too low level, you need to parse tool invokations, track agent responses, tool outputs and user messages and most of this is done using untyped python dictionaries.&lt;/p&gt; &lt;p&gt;If you want control, a library that is small enough to have a quick read through and edit, but still retaining a typesafe binding from python functions to agent tools, my hope is that agent_lite is a Decent enough compromise.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RatioRemarkable5605&quot;&gt; /u/RatioRemarkable5605 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1br8mqi/so_i_just_pushed_up_agent_lite_a_minified_version/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1br8mqi/so_i_just_pushed_up_agent_lite_a_minified_version/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1br8mqi</id><link href="https://www.reddit.com/r/LangChain/comments/1br8mqi/so_i_just_pushed_up_agent_lite_a_minified_version/" /><updated>2024-03-30T04:03:30+00:00</updated><published>2024-03-30T04:03:30+00:00</published><title>So I just pushed up agent_lite, a minified version of a *small* part of the Langchain library. Most of you should probably just use Langchain. But I'll briefly cover why I use agent_lite. Thoughts?</title></entry><entry><author><name>/u/qa_anaaq</name><uri>https://www.reddit.com/user/qa_anaaq</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi. Is there a comparable tutorial on how to use LangGraph to do data visualization, similar to how it&amp;#39;s done with autogen? &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_vis.ipynb&quot;&gt;Autogen&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/qa_anaaq&quot;&gt; /u/qa_anaaq &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1br6e6c/data_visualization_with_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1br6e6c/data_visualization_with_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1br6e6c</id><link href="https://www.reddit.com/r/LangChain/comments/1br6e6c/data_visualization_with_langgraph/" /><updated>2024-03-30T02:08:22+00:00</updated><published>2024-03-30T02:08:22+00:00</published><title>Data Visualization with LangGraph</title></entry><entry><author><name>/u/sebastianstehle</name><uri>https://www.reddit.com/user/sebastianstehle</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am builtin a prototype for an internal chat tool and I am testing different models. So far OpenAI, azure-open-ai, mistral and not Vertex AI.&lt;/p&gt; &lt;p&gt;With Vertex AI I have seen big differences in the response formats for the first time. I always use streaming plus histories and Javascript:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Event Type&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Vertex AI: &lt;code&gt;on_chain_stream&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Others: &lt;code&gt;on_llm_stream&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Content Type&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Vertex AI: &lt;code&gt;{ &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;text&amp;quot;: &amp;quot;Tokens&amp;quot; }&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Others: &lt;code&gt;&amp;quot;Tokens&amp;quot;&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;History Item&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Vertex AI&lt;/p&gt; &lt;pre&gt;&lt;code&gt;{ &amp;quot;content&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;text&amp;quot;: &amp;quot;Hi there! How&amp;quot; }, { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;text&amp;quot;: &amp;quot; can I help you today?&amp;quot; }, { &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;text&amp;quot;: &amp;quot;&amp;quot; } ], &amp;quot;additional_kwargs&amp;quot;: {}, &amp;quot;response_metadata&amp;quot;: { &amp;quot;data&amp;quot;: { &amp;quot;candidates&amp;quot;: [ { &amp;quot;content&amp;quot;: { &amp;quot;role&amp;quot;: &amp;quot;model&amp;quot;, &amp;quot;parts&amp;quot;: [ { &amp;quot;text&amp;quot;: &amp;quot;Hi there! How&amp;quot; } ] }, &amp;quot;safetyRatings&amp;quot;: [ { &amp;quot;category&amp;quot;: &amp;quot;HARM_CATEGORY_HATE_SPEECH&amp;quot;, &amp;quot;probability&amp;quot;: &amp;quot;NEGLIGIBLE&amp;quot;, &amp;quot;probabilityScore&amp;quot;: 0.038538497, &amp;quot;severity&amp;quot;: &amp;quot;HARM_SEVERITY_NEGLIGIBLE&amp;quot;, &amp;quot;severityScore&amp;quot;: 0.09636511 }, { &amp;quot;category&amp;quot;: &amp;quot;HARM_CATEGORY_DANGEROUS_CONTENT&amp;quot;, &amp;quot;probability&amp;quot;: &amp;quot;NEGLIGIBLE&amp;quot;, &amp;quot;probabilityScore&amp;quot;: 0.060863446, &amp;quot;severity&amp;quot;: &amp;quot;HARM_SEVERITY_NEGLIGIBLE&amp;quot;, &amp;quot;severityScore&amp;quot;: 0.04986591 }, { &amp;quot;category&amp;quot;: &amp;quot;HARM_CATEGORY_HARASSMENT&amp;quot;, &amp;quot;probability&amp;quot;: &amp;quot;NEGLIGIBLE&amp;quot;, &amp;quot;probabilityScore&amp;quot;: 0.09089675, &amp;quot;severity&amp;quot;: &amp;quot;HARM_SEVERITY_NEGLIGIBLE&amp;quot;, &amp;quot;severityScore&amp;quot;: 0.028167473 }, { &amp;quot;category&amp;quot;: &amp;quot;HARM_CATEGORY_SEXUALLY_EXPLICIT&amp;quot;, &amp;quot;probability&amp;quot;: &amp;quot;NEGLIGIBLE&amp;quot;, &amp;quot;probabilityScore&amp;quot;: 0.043772742, &amp;quot;severity&amp;quot;: &amp;quot;HARM_SEVERITY_NEGLIGIBLE&amp;quot;, &amp;quot;severityScore&amp;quot;: 0.06489011 } ] }, { &amp;quot;content&amp;quot;: { &amp;quot;role&amp;quot;: &amp;quot;model&amp;quot;, &amp;quot;parts&amp;quot;: [ { &amp;quot;text&amp;quot;: &amp;quot; can I help you today?&amp;quot; } ] }, &amp;quot;finishReason&amp;quot;: &amp;quot;STOP&amp;quot;, &amp;quot;safetyRatings&amp;quot;: [ { &amp;quot;category&amp;quot;: &amp;quot;HARM_CATEGORY_HATE_SPEECH&amp;quot;, &amp;quot;probability&amp;quot;: &amp;quot;NEGLIGIBLE&amp;quot;, &amp;quot;probabilityScore&amp;quot;: 0.028598359, &amp;quot;severity&amp;quot;: &amp;quot;HARM_SEVERITY_NEGLIGIBLE&amp;quot;, &amp;quot;severityScore&amp;quot;: 0.038466197 }, { &amp;quot;category&amp;quot;: &amp;quot;HARM_CATEGORY_DANGEROUS_CONTENT&amp;quot;, &amp;quot;probability&amp;quot;: &amp;quot;NEGLIGIBLE&amp;quot;, &amp;quot;probabilityScore&amp;quot;: 0.045015533, &amp;quot;severity&amp;quot;: &amp;quot;HARM_SEVERITY_NEGLIGIBLE&amp;quot;, &amp;quot;severityScore&amp;quot;: 0.021125192 }, { &amp;quot;category&amp;quot;: &amp;quot;HARM_CATEGORY_HARASSMENT&amp;quot;, &amp;quot;probability&amp;quot;: &amp;quot;NEGLIGIBLE&amp;quot;, &amp;quot;probabilityScore&amp;quot;: 0.04451443, &amp;quot;severity&amp;quot;: &amp;quot;HARM_SEVERITY_NEGLIGIBLE&amp;quot;, &amp;quot;severityScore&amp;quot;: 0.015365342 }, { &amp;quot;category&amp;quot;: &amp;quot;HARM_CATEGORY_SEXUALLY_EXPLICIT&amp;quot;, &amp;quot;probability&amp;quot;: &amp;quot;NEGLIGIBLE&amp;quot;, &amp;quot;probabilityScore&amp;quot;: 0.10631887, &amp;quot;severity&amp;quot;: &amp;quot;HARM_SEVERITY_NEGLIGIBLE&amp;quot;, &amp;quot;severityScore&amp;quot;: 0.028816197 } ] } ], &amp;quot;usageMetadata&amp;quot;: { &amp;quot;promptTokenCount&amp;quot;: 8, &amp;quot;candidatesTokenCount&amp;quot;: 10, &amp;quot;totalTokenCount&amp;quot;: 18 } }, &amp;quot;finishReason&amp;quot;: &amp;quot;stop&amp;quot; } } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Contains a lot of metadata and content is stored as array of objects.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Others&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;{ &amp;quot;content&amp;quot;: &amp;quot;Thank you for your compliment! How may I assist you today?&amp;quot;, &amp;quot;additional_kwargs&amp;quot;: {}, &amp;quot;response_metadata&amp;quot;: { &amp;quot;prompt&amp;quot;: 0, &amp;quot;completion&amp;quot;: 0 } } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I am confused about the different formats and how and when they are standardized. Of course I only want to deliver the same format to the UI and I don&amp;#39;t understand how langchain handles the normalization of the response formats.&lt;/p&gt; &lt;p&gt;My initialization is very simple&lt;/p&gt; &lt;pre&gt;&lt;code&gt;const llm = new ChatVertexAI({ modelName: &amp;#39;gemini-1.0-pro&amp;#39;, }); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I guess it might have something to do with multi modal conversations, but I am not sure if there are more formats than these two and how to find them.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sebastianstehle&quot;&gt; /u/sebastianstehle &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqzxt2/how_are_the_models_standardized/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqzxt2/how_are_the_models_standardized/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bqzxt2</id><link href="https://www.reddit.com/r/LangChain/comments/1bqzxt2/how_are_the_models_standardized/" /><updated>2024-03-29T21:29:45+00:00</updated><published>2024-03-29T21:29:45+00:00</published><title>How are the models standardized?</title></entry><entry><author><name>/u/Stopzer0ne</name><uri>https://www.reddit.com/user/Stopzer0ne</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, I&amp;#39;m working on improving my RAG (Retrieval-Augmented Generation) application with a focus on processing Czech language documents. My current setup involves using dense retrieval (specifically a combination of parent retriever that retrieves n chunks before and m chunks after the retrieved chunk, with n=1 and m=2, alongside with sparse retriever BM25. &lt;/p&gt; &lt;p&gt;I&amp;#39;ve been experimenting with multi-vector retrievers like ColBERT, but not with much success. I was wondering if anyone tried to fine-tune it specifically for any foreign language. I was thinking about to fine-tune it like in this example: &lt;a href=&quot;https://github.com/bclavie/RAGatouille/blob/main/examples/03-finetuning_without_annotations_with_instructor_and_RAGatouille.ipynb&quot;&gt;https://github.com/bclavie/RAGatouille/blob/main/examples/03-finetuning_without_annotations_with_instructor_and_RAGatouille.ipynb&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Similarly, my efforts with ReRanking (using tools like Cohere, BGE-M3, and even GPT-3.5/GPT-4 as rerankers) have so far resulted in worse or same outcomes than no reranking. &lt;/p&gt; &lt;p&gt;Do you think fine-tuning the ColBERT and reranker models for specific language could significantly improve performance, or might it not be worth the effort? Has anyone tackled similar challenges, especially with language-specific tuning for tools like ColBERT or rerankers? Or any other insights on how to enhance the accuracy of numerical comparisons or overall pipeline efficiency would be greatly appreciated.&lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Stopzer0ne&quot;&gt; /u/Stopzer0ne &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqn1sj/improving_my_rag_application_for_specific_language/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqn1sj/improving_my_rag_application_for_specific_language/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bqn1sj</id><link href="https://www.reddit.com/r/LangChain/comments/1bqn1sj/improving_my_rag_application_for_specific_language/" /><updated>2024-03-29T11:34:55+00:00</updated><published>2024-03-29T11:34:55+00:00</published><title>Improving My RAG Application for specific language</title></entry><entry><author><name>/u/Ok_Strain4832</name><uri>https://www.reddit.com/user/Ok_Strain4832</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;FWIW, this isn&amp;#39;t intended to be the standard &amp;quot;LangChain vs LamaIndex&amp;quot; question.&lt;/p&gt; &lt;p&gt;Originally used LangChain, switched to LlamaIndex and have stuck with it sense then. So far, I haven&amp;#39;t encountered any limitations with using LlamaIndex solely. I have ready access to the relevant semantic search capabilities and I can use a ReActAgent to dynamically choose tools, with the LlamaIndex&amp;#39;s equivalent to LCEL in the QueryPipeline DAG.&lt;/p&gt; &lt;p&gt;Despite that though, LlamaIndex is generally viewed as something exclusive to RAG with limited agent support, yet I don&amp;#39;t see why that is necessarily the case.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Any users of LlamaIndex that have been forced to use LangChain due to some limitation/inadequacy with the former?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ok_Strain4832&quot;&gt; /u/Ok_Strain4832 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqo89p/any_limitations_with_llamaindex_that_forced/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqo89p/any_limitations_with_llamaindex_that_forced/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bqo89p</id><link href="https://www.reddit.com/r/LangChain/comments/1bqo89p/any_limitations_with_llamaindex_that_forced/" /><updated>2024-03-29T12:37:14+00:00</updated><published>2024-03-29T12:37:14+00:00</published><title>Any limitations with LlamaIndex that forced direct usage of LangChain?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, checkout this tutorial on how to create a AI technical team (coder, product manager, tech lead, etc) and than see how they solve a give task using CrewAI in this demonstration : &lt;a href=&quot;https://youtu.be/QPUUclaNI5o?si=HQZMbn-KOInQ02o1&quot;&gt;https://youtu.be/QPUUclaNI5o?si=HQZMbn-KOInQ02o1&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqmtj0/virtual_ai_tech_team_using_crewai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqmtj0/virtual_ai_tech_team_using_crewai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bqmtj0</id><link href="https://www.reddit.com/r/LangChain/comments/1bqmtj0/virtual_ai_tech_team_using_crewai/" /><updated>2024-03-29T11:21:53+00:00</updated><published>2024-03-29T11:21:53+00:00</published><title>Virtual AI tech team using CrewAI</title></entry><entry><author><name>/u/Redazeux69</name><uri>https://www.reddit.com/user/Redazeux69</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to create a Langchain agent that can create Jira issues using tools. Below is the code:&lt;/p&gt; &lt;p&gt;import os&lt;br/&gt; from langchain.agents import create_react_agent,AgentExecutor, create_structured_chat_agent, initialize_agent, create_json_chat_agent&lt;br/&gt; from langchain_community.agent_toolkits.jira.toolkit import JiraToolkit&lt;br/&gt; from langchain_community.utilities.jira import JiraAPIWrapper&lt;br/&gt; from langchain_google_genai import ChatGoogleGenerativeAI&lt;br/&gt; from langchain_openai import ChatOpenAI&lt;br/&gt; from langchain import hub&lt;/p&gt; &lt;p&gt;llm=ChatOpenAI(temperature=0)&lt;br/&gt; jira=JiraAPIWrapper()&lt;br/&gt; toolkit=JiraToolkit.from_jira_api_wrapper(jira)&lt;br/&gt; tools=toolkit.get_tools()&lt;/p&gt; &lt;p&gt;prompt = hub.pull(&amp;quot;hwchase17/structured-chat-agent&amp;quot;)&lt;br/&gt; agent = create_structured_chat_agent(&lt;br/&gt; tools=toolkit.get_tools(),&lt;br/&gt; llm=llm,&lt;br/&gt; prompt=prompt,&lt;br/&gt; )&lt;/p&gt; &lt;p&gt;agent_executor=AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True, return_intermediate_steps=True)&lt;/p&gt; &lt;p&gt;response=agent_executor.invoke({&amp;quot;input&amp;quot;:&amp;quot;make a new issue in project DEMO to remind me to make Agent with File System&amp;quot;})&lt;br/&gt; print(response)&lt;/p&gt; &lt;p&gt;I am getting the following error when I run the above code:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&amp;gt; Entering new AgentExecutor chain...&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;Action: ``` { &amp;quot;action&amp;quot;: &amp;quot;Create Issue&amp;quot;, &amp;quot;action_input&amp;quot;: { &amp;quot;fields&amp;quot;: { &amp;quot;project&amp;quot;: { &amp;quot;key&amp;quot;: &amp;quot;DEMO&amp;quot; }, &amp;quot;summary&amp;quot;: &amp;quot;Create Agent with File System&amp;quot;, &amp;quot;description&amp;quot;: &amp;quot;This is a reminder to create an Agent with File System.&amp;quot;, &amp;quot;issuetype&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;Task&amp;quot; } } } } ```&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;TypeError: JiraAction._run() got an unexpected keyword argument &amp;#39;fields&amp;#39;&lt;/p&gt; &lt;p&gt;For context, I have been following the official langchain documentation (&lt;a href=&quot;https://python.langchain.com/docs/integrations/toolkits/jira&quot;&gt;https://python.langchain.com/docs/integrations/toolkits/jira&lt;/a&gt;) and I am not able to replicate their outputs. I have tried with various Agent types but its still showing errors. From as far as I could understand, I guess there is something wrong with the inputs being sent to the tool. So, does anybody know what may be the problem or whats happening? Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Redazeux69&quot;&gt; /u/Redazeux69 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqo1rh/trying_to_connect_jira_tools_with_langchain_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqo1rh/trying_to_connect_jira_tools_with_langchain_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bqo1rh</id><link href="https://www.reddit.com/r/LangChain/comments/1bqo1rh/trying_to_connect_jira_tools_with_langchain_agent/" /><updated>2024-03-29T12:27:57+00:00</updated><published>2024-03-29T12:27:57+00:00</published><title>Trying to connect Jira tools with Langchain agent. Getting TypeError for some of the tools.</title></entry><entry><author><name>/u/oldyoungin</name><uri>https://www.reddit.com/user/oldyoungin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to create a system message that gets tagged in with my LLM and logged to MLFlow. For example, when someone loads the model from MLFlow I DO NOT want them to be able to adjust the system message. The system message needs to be locked in and attached to the model at all times. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/oldyoungin&quot;&gt; /u/oldyoungin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqrpie/how_to_log_system_message_to_langchain_in_mlflow/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqrpie/how_to_log_system_message_to_langchain_in_mlflow/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bqrpie</id><link href="https://www.reddit.com/r/LangChain/comments/1bqrpie/how_to_log_system_message_to_langchain_in_mlflow/" /><updated>2024-03-29T15:13:51+00:00</updated><published>2024-03-29T15:13:51+00:00</published><title>How to log system message to langchain in MLFlow</title></entry><entry><author><name>/u/dxtros</name><uri>https://www.reddit.com/user/dxtros</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, we&amp;#39;ve just published a tutorial with an adaptive retrieval technique to cut down your token use in top-k retrieval RAG:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://pathway.com/developers/showcases/adaptive-rag&quot;&gt;https://pathway.com/developers/showcases/adaptive-rag&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Simple but sure, if you want to DIY, it&amp;#39;s about 50 lines of code (your mileage will vary depending on the Vector Database you are using). Works with GPT4, works with many local LLM&amp;#39;s, works with old GPT 3.5 Turbo, does not work with the latest GPT 3.5 as OpenAI makes it hallucinate over-confidently in a recent upgrade (interesting, right?). Enjoy!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dxtros&quot;&gt; /u/dxtros &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpz9dw/tuning_rag_retriever_to_reduce_llm_token_cost_4x/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpz9dw/tuning_rag_retriever_to_reduce_llm_token_cost_4x/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpz9dw</id><link href="https://www.reddit.com/r/LangChain/comments/1bpz9dw/tuning_rag_retriever_to_reduce_llm_token_cost_4x/" /><updated>2024-03-28T16:06:16+00:00</updated><published>2024-03-28T16:06:16+00:00</published><title>Tuning RAG retriever to reduce LLM token cost (4x in benchmarks)</title></entry><entry><author><name>/u/StrayyLight</name><uri>https://www.reddit.com/user/StrayyLight</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Title is self explanatory. I want to answer from an excel/dataframe, ideally by formulating queries. The langchain implementation of csv/excel agents seem to be limited to openai.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/StrayyLight&quot;&gt; /u/StrayyLight &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqoy0v/dataframecsv_agent_not_supported_for_claude_3_api/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqoy0v/dataframecsv_agent_not_supported_for_claude_3_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bqoy0v</id><link href="https://www.reddit.com/r/LangChain/comments/1bqoy0v/dataframecsv_agent_not_supported_for_claude_3_api/" /><updated>2024-03-29T13:11:42+00:00</updated><published>2024-03-29T13:11:42+00:00</published><title>Dataframe/csv agent not supported for claude 3 api.</title></entry><entry><author><name>/u/goatthezen</name><uri>https://www.reddit.com/user/goatthezen</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, I&amp;#39;m planning to create an LLM app for querying our product documentation, which is currently hosted on a Confluence web space.&lt;/p&gt; &lt;p&gt;To begin, I developed a Scrapy spider to retrieve HTML content from Confluence and stored the segments into a Chroma vector database using an HtmlHeaderSplitter. I chose this method to effectively segment different topics and subtopics. Each segment is associated with metadata such as h1, h2, and h3, representing titles of topics and subtopics (e.g., h1: &amp;quot;Manage Products,&amp;quot; h2: &amp;quot;Filter Products&amp;quot;).&lt;/p&gt; &lt;p&gt;Initially, I attempted a simple similarity search on the content with unsatisfactory results. While I acknowledge the potential of experimenting with different embedding functions and vector databases, my current objective is to optimize input to the vector database using self-query retrieval.&lt;/p&gt; &lt;p&gt;The challenge lies in mapping user queries to structural metadata such as h1, h2, and h3, which primarily indicate hierarchical organization.&lt;/p&gt; &lt;p&gt;I think renaming the metadata to more functional terms like &amp;quot;operation&amp;quot; or &amp;quot;function,&amp;quot; would help to map user queries accordingly. For instance, a user query could be structured as &amp;quot;how to {function}...&amp;quot; or a similar format.&lt;/p&gt; &lt;p&gt;As a newcomer to AI development, I would greatly appreciate any guidance or assistance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/goatthezen&quot;&gt; /u/goatthezen &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqn6yc/self_query_on_structural_html_metadata/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqn6yc/self_query_on_structural_html_metadata/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bqn6yc</id><link href="https://www.reddit.com/r/LangChain/comments/1bqn6yc/self_query_on_structural_html_metadata/" /><updated>2024-03-29T11:42:53+00:00</updated><published>2024-03-29T11:42:53+00:00</published><title>Self query on structural html metadata</title></entry><entry><author><name>/u/Defiant-Sir-1199</name><uri>https://www.reddit.com/user/Defiant-Sir-1199</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all , I was trying to evaluate and compare the performance of Azure AI search index vs Chroma Db in memory index . I have heard that Chroma Db is good for high speed retrieval but relevancy of retrieved docs are not that good . &lt;/p&gt; &lt;p&gt;I was thinking that Azure AI search should easily outperform chroma DB , So I configured both Chroma DB and Azure AI search Index with same configuration ( HNSW with Cosin similarity ) . I used same embedding model text-embedding-3-small for embedding the test document ( 300 character small chunks) . Now I was a bit confused to see that , while testing with some queries both Vector Dbs( Indexes)are returning the same results . Even with k=4 nearest items , both are returning same 4 doc chunks ( relevancy scores are different though) I am now concerned that somehow I have messed up something, What do you guys think?? Am I supposed to see the same results with same config or I am doing something wrong?&lt;/p&gt; &lt;p&gt;Can you guys suggest me some good dataset for benchmarking the retrieval systems. Thanks in advance 😃&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Defiant-Sir-1199&quot;&gt; /u/Defiant-Sir-1199 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqa628/azure_ai_search_vs_chroma_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqa628/azure_ai_search_vs_chroma_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bqa628</id><link href="https://www.reddit.com/r/LangChain/comments/1bqa628/azure_ai_search_vs_chroma_db/" /><updated>2024-03-28T23:30:33+00:00</updated><published>2024-03-28T23:30:33+00:00</published><title>Azure AI search vs Chroma Db</title></entry><entry><author><name>/u/Andaso</name><uri>https://www.reddit.com/user/Andaso</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;With the recent announcement of &amp;#39;traces&amp;#39; being charged for, does anyone know if the rest of the framework is still free to use?!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Andaso&quot;&gt; /u/Andaso &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq9knx/can_langchain_still_be_used_for_free/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq9knx/can_langchain_still_be_used_for_free/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq9knx</id><link href="https://www.reddit.com/r/LangChain/comments/1bq9knx/can_langchain_still_be_used_for_free/" /><updated>2024-03-28T23:05:19+00:00</updated><published>2024-03-28T23:05:19+00:00</published><title>Can LangChain still be used for free?!</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am just trying to understand if any of you use the &amp;quot;system&amp;quot; role for adding prompts to programmatic invocations. I know this is the support by the books way to do it. But I have also attached the prompt directly to the &amp;quot;user&amp;quot; role with similar accuracy. Wondering what the best practice is.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq5g0u/do_you_use_the_system_role_for_adding_prompts_or/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq5g0u/do_you_use_the_system_role_for_adding_prompts_or/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq5g0u</id><link href="https://www.reddit.com/r/LangChain/comments/1bq5g0u/do_you_use_the_system_role_for_adding_prompts_or/" /><updated>2024-03-28T20:15:18+00:00</updated><published>2024-03-28T20:15:18+00:00</published><title>Do you use the &quot;system&quot; role for adding prompts or just append it to the &quot;user&quot; role?</title></entry><entry><author><name>/u/Shabbinx</name><uri>https://www.reddit.com/user/Shabbinx</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I know that this question about LangChain is frequent but I just wanted to ask if there&amp;#39;s any comprehensive or practical course for learning langchain? Because the documentations on python are SO vague and do not really teach anything. I&amp;#39;ve checked YouTube courses but most of them are old and langchain has changed ever since. Plus the YouTube courses all teach the basics, they don&amp;#39;t go through various modules.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Shabbinx&quot;&gt; /u/Shabbinx &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq73n0/learning_resources/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq73n0/learning_resources/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq73n0</id><link href="https://www.reddit.com/r/LangChain/comments/1bq73n0/learning_resources/" /><updated>2024-03-28T21:21:38+00:00</updated><published>2024-03-28T21:21:38+00:00</published><title>Learning resources</title></entry><entry><author><name>/u/IlEstLaPapi</name><uri>https://www.reddit.com/user/IlEstLaPapi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have an application that is currently based on 3 agents using LangChain and GPT4-turbo.&lt;/p&gt; &lt;p&gt;I&amp;#39;d like to test Claude 3 in this context. However all my agents are created using the function &lt;code&gt;create_openai_tools_agent()&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Reading the documentation, it seems that the recommended Agent for Claude is the &lt;a href=&quot;https://python.langchain.com/docs/modules/agents/agent_types/xml_agent&quot;&gt;XML Agent&lt;/a&gt;. However this documentation is referring to Claude 2 instead of Claude 3. It&amp;#39;s also assuming that the model is a LLM and not a Chatbot. That seems weird. Especially given that Anthropic documentation is clear about using a Chatlike API, with &lt;a href=&quot;https://docs.anthropic.com/claude/reference/messages_post&quot;&gt;a system prompt and a list of users/assistant messages&lt;/a&gt;. Instead the XML Agent seems to only be able to &lt;a href=&quot;https://python.langchain.com/docs/modules/agents/agent_types/xml_agent#using-with-chat-history&quot;&gt;understand chathistory as a single string&lt;/a&gt;. &lt;/p&gt; &lt;p&gt;Given that LLM in general, and Claude in particular are quite sensitive to prompting format, I&amp;#39;m not really happy with the idea of having a chat history sent as a single string instead of the standard format provided by the API. Thus I&amp;#39;m hesitating about using the XML agent.&lt;/p&gt; &lt;p&gt;So I&amp;#39;m curious if any of you has any experience using the XML Agent with a chat history ? Or did you use another kind of agent ?&lt;/p&gt; &lt;p&gt;Thanks in advance !&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/IlEstLaPapi&quot;&gt; /u/IlEstLaPapi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq1rgj/how_to_implement_claude_based_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq1rgj/how_to_implement_claude_based_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq1rgj</id><link href="https://www.reddit.com/r/LangChain/comments/1bq1rgj/how_to_implement_claude_based_agents/" /><updated>2024-03-28T17:47:31+00:00</updated><published>2024-03-28T17:47:31+00:00</published><title>How to implement Claude based Agents ?</title></entry></feed>