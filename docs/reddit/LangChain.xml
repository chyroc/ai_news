<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2023-12-04T08:04:41+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/IllustriousArt2202</name><uri>https://www.reddit.com/user/IllustriousArt2202</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How do I Replace the existing Langchain REACT Agent in the L3AGI framework with the XAgent framework? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/IllustriousArt2202&quot;&gt; /u/IllustriousArt2202 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189pkr1/integration_of_xagent_into_l3agi_framework/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189pkr1/integration_of_xagent_into_l3agi_framework/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_189pkr1</id><link href="https://www.reddit.com/r/LangChain/comments/189pkr1/integration_of_xagent_into_l3agi_framework/" /><updated>2023-12-03T08:55:02+00:00</updated><published>2023-12-03T08:55:02+00:00</published><title>Integration of XAgent into L3AGI Framework</title></entry><entry><author><name>/u/Full_Sentence_3678</name><uri>https://www.reddit.com/user/Full_Sentence_3678</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189gkp0/embodied_llms_for_robotics_code_in_comments/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/NTRocnAxdWR6eTNjMXoQB95sJhOH8DH2fTHH41Ap3Y8STa1xy0MP2uEfLJ5e.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=287b0852c7d3c729420bbef12e3dea483cd73780&quot; alt=&quot;Embodied LLMs for robotics (code in comments)&quot; title=&quot;Embodied LLMs for robotics (code in comments)&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Full_Sentence_3678&quot;&gt; /u/Full_Sentence_3678 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/jll5idt5zy3c1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189gkp0/embodied_llms_for_robotics_code_in_comments/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_189gkp0</id><media:thumbnail url="https://external-preview.redd.it/NTRocnAxdWR6eTNjMXoQB95sJhOH8DH2fTHH41Ap3Y8STa1xy0MP2uEfLJ5e.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=287b0852c7d3c729420bbef12e3dea483cd73780" /><link href="https://www.reddit.com/r/LangChain/comments/189gkp0/embodied_llms_for_robotics_code_in_comments/" /><updated>2023-12-02T23:55:10+00:00</updated><published>2023-12-02T23:55:10+00:00</published><title>Embodied LLMs for robotics (code in comments)</title></entry><entry><author><name>/u/BtownIU</name><uri>https://www.reddit.com/user/BtownIU</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi y&amp;#39;all,&lt;/p&gt; &lt;p&gt;Newbie to langchain here. Curious if there is a way to let a chain deal with different types of questions automatically. &lt;/p&gt; &lt;p&gt;Say when a prompt is something like &amp;quot;what&amp;#39;s your product XYZ?&amp;quot;, the user is usually ok with 15 seconds for a paragraph to be generated detailing the answer.&lt;/p&gt; &lt;p&gt;But a user may just want to get the links to self-help documents, like &amp;quot;give me the links to all your docs about XYZ&amp;quot;. And the speed is expected to be much faster.&lt;/p&gt; &lt;p&gt;Should I set up a chain that classifies a prompt into 2 different pipelines, where one pipeline would be something like a vector database search without RAG, the other one with RAG? Or are there tricks with LLM that can spew out structured answers much faster than unstructured textual answers? Thanks in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BtownIU&quot;&gt; /u/BtownIU &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189ml0n/how_to_handle_prompts_asking_for_links_instead_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189ml0n/how_to_handle_prompts_asking_for_links_instead_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_189ml0n</id><link href="https://www.reddit.com/r/LangChain/comments/189ml0n/how_to_handle_prompts_asking_for_links_instead_of/" /><updated>2023-12-03T05:29:46+00:00</updated><published>2023-12-03T05:29:46+00:00</published><title>How to handle prompts asking for links instead of textual answers?</title></entry><entry><author><name>/u/LeDebardeur</name><uri>https://www.reddit.com/user/LeDebardeur</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, Iâ€™m using sql agent, and I want to pass custom database tables infos ( column and tables infos ) Which format can I pass those and how ?&lt;/p&gt; &lt;p&gt;Thanks in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LeDebardeur&quot;&gt; /u/LeDebardeur &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189k1lx/custom_sql_database_infos/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189k1lx/custom_sql_database_infos/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_189k1lx</id><link href="https://www.reddit.com/r/LangChain/comments/189k1lx/custom_sql_database_infos/" /><updated>2023-12-03T03:05:55+00:00</updated><published>2023-12-03T03:05:55+00:00</published><title>Custom SQL database infos</title></entry><entry><author><name>/u/nebulum747</name><uri>https://www.reddit.com/user/nebulum747</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I was working on using gpt4all&amp;#39;s open AI-like API backend to see if I could start phasing out the actual openai API to some extent. &lt;/p&gt; &lt;p&gt;Essentially, I wanted to use Langchain&amp;#39;s ChatOpenAI(), but switch the OPENAI_BASE_URL, and put something random in for the key.&lt;/p&gt; &lt;p&gt;When I tried this with LLaMA models like mistral and snoozy, I get instant replies, but ones that aren&amp;#39;t useful. Something like this:&lt;/p&gt; &lt;p&gt;Me: hi!&lt;/p&gt; &lt;p&gt;AI: Echo: hi!&lt;/p&gt; &lt;p&gt;Me: how are you?&lt;/p&gt; &lt;p&gt;AI: Echo: how are you?&lt;/p&gt; &lt;p&gt;It just bounces the message I wrote back. Any tips on integrating in these models with OpenAI-like APIs? I&amp;#39;m trying to get it so that I can &amp;quot;plug and play&amp;quot; with models using the openai API standard (i&amp;#39;ll change the prompts, ofc)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nebulum747&quot;&gt; /u/nebulum747 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1899yhr/does_langchain_support_openaiapi_compatible/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1899yhr/does_langchain_support_openaiapi_compatible/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1899yhr</id><link href="https://www.reddit.com/r/LangChain/comments/1899yhr/does_langchain_support_openaiapi_compatible/" /><updated>2023-12-02T18:34:31+00:00</updated><published>2023-12-02T18:34:31+00:00</published><title>Does Langchain support OpenAI-API compatible agents with it's ChatOpenAI, OpenAIFunctionsAgents, etc.?</title></entry><entry><author><name>/u/nebulum747</name><uri>https://www.reddit.com/user/nebulum747</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I was working on using gpt4all&amp;#39;s open AI-like API backend to see if I could start phasing out the actual openai API to some extent. &lt;/p&gt; &lt;p&gt;Essentially, I wanted to use Langchain&amp;#39;s ChatOpenAI(), but switch the OPENAI_BASE_URL, and put something random in for the key.&lt;/p&gt; &lt;p&gt;When I tried this with LLaMA models like mistral and snoozy, I get instant replies, but ones that aren&amp;#39;t useful. Something like this:&lt;/p&gt; &lt;p&gt;Me: hi!&lt;/p&gt; &lt;p&gt;AI: Echo: hi!&lt;/p&gt; &lt;p&gt;Me: how are you?&lt;/p&gt; &lt;p&gt;AI: Echo: how are you?&lt;/p&gt; &lt;p&gt;It just bounces the message I wrote back. Any tips on integrating in these models with OpenAI-like APIs? I&amp;#39;m trying to get it so that I can &amp;quot;plug and play&amp;quot; with models using the openai API standard (i&amp;#39;ll change the prompts, ofc)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nebulum747&quot;&gt; /u/nebulum747 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1899yhe/does_langchain_support_openaiapi_compatible/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1899yhe/does_langchain_support_openaiapi_compatible/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1899yhe</id><link href="https://www.reddit.com/r/LangChain/comments/1899yhe/does_langchain_support_openaiapi_compatible/" /><updated>2023-12-02T18:34:30+00:00</updated><published>2023-12-02T18:34:30+00:00</published><title>Does Langchain support OpenAI-API compatible agents with it's ChatOpenAI, OpenAIFunctionsAgents, etc.?</title></entry><entry><author><name>/u/lucky_not_skill</name><uri>https://www.reddit.com/user/lucky_not_skill</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1892m87/strange_behavior_in_my_chatbot_when_responding_to/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/uovAEAZ2TYP2qK3ucictDfJRPTYTd-h7xdgQJ3BLB1M.jpg&quot; alt=&quot;Strange behavior in my chatbot when responding to questions.&quot; title=&quot;Strange behavior in my chatbot when responding to questions.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, is everything fine with you?&lt;/p&gt; &lt;p&gt;I&amp;#39;m building a chatbot that can answer questions about code or generate code, and I have two different chains, one for each activity. I also have a memory for my bot to maintain a good flow with the user.&lt;/p&gt; &lt;p&gt;My issue is as follows: The bot responds well to the question but continues to generate more information than necessary. Sometimes it includes part of the prompt I gave, sometimes it&amp;#39;s a completely different question, and sometimes it&amp;#39;s random things or a mix of everything.&lt;/p&gt; &lt;p&gt;This also happens in my implementation of a retrieval-based QA bot.&lt;/p&gt; &lt;p&gt;Cutting off the input when sending the response to the frontend is not a viable option because, during testing, I asked, &amp;quot;What is Flask?&amp;quot; and then it generated a question &amp;quot;What is the difference between a for loop and a while loop?&amp;quot; and answered it. Later, when I asked for a code example right after, it generated code for the for loop and while loop, unrelated to the Flask framework.&lt;/p&gt; &lt;p&gt;In the images below, it generated things related to Flask, but it doesn&amp;#39;t always happen.&lt;/p&gt; &lt;p&gt;If anyone has any tips, I would greatly appreciate it.&lt;/p&gt; &lt;p&gt;The rest of a good day.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/z3asir9ujv3c1.png?width=1252&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1f21dda137176642c1990564133d4a42e9699dc1&quot;&gt;model&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/nw21pc9ujv3c1.png?width=1399&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a06817829e714f08f3aaa8bd4604979f3a35d132&quot;&gt;prompt&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/ci897b9ujv3c1.png?width=817&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5c19b74a6246291d0abba2c96b554fd812152f10&quot;&gt;input&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/adorc49ujv3c1.png?width=1055&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fb1564775afaf11e21d8731035fca7bd01855f88&quot;&gt;1Âº answer&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/taa1q39ujv3c1.png?width=1889&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fd2997205a40511755df45fa981ac8b2467614b6&quot;&gt;2Âº answer&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/lucky_not_skill&quot;&gt; /u/lucky_not_skill &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1892m87/strange_behavior_in_my_chatbot_when_responding_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1892m87/strange_behavior_in_my_chatbot_when_responding_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1892m87</id><media:thumbnail url="https://b.thumbs.redditmedia.com/uovAEAZ2TYP2qK3ucictDfJRPTYTd-h7xdgQJ3BLB1M.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1892m87/strange_behavior_in_my_chatbot_when_responding_to/" /><updated>2023-12-02T12:21:53+00:00</updated><published>2023-12-02T12:21:53+00:00</published><title>Strange behavior in my chatbot when responding to questions.</title></entry><entry><author><name>/u/heybigeyes123</name><uri>https://www.reddit.com/user/heybigeyes123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Since its an open source wrapper, wondering what is their revenue model?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/heybigeyes123&quot;&gt; /u/heybigeyes123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188znbs/how_does_langchain_make_money/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188znbs/how_does_langchain_make_money/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_188znbs</id><link href="https://www.reddit.com/r/LangChain/comments/188znbs/how_does_langchain_make_money/" /><updated>2023-12-02T08:54:37+00:00</updated><published>2023-12-02T08:54:37+00:00</published><title>How does Langchain make money?</title></entry><entry><author><name>/u/xixixao</name><uri>https://www.reddit.com/user/xixixao</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all, here&amp;#39;s a walkthrough for building an AI chat with context retrieval using LangChain, Convex for db and vector search and Open AI for embedding and LLM: &lt;a href=&quot;https://stack.convex.dev/ai-chat-using-langchain-and-convex&quot;&gt;https://stack.convex.dev/ai-chat-using-langchain-and-convex&lt;/a&gt;&lt;br/&gt; You can clone the repo here: &lt;a href=&quot;https://github.com/get-convex/convex-ai-chat-langchain&quot;&gt;https://github.com/get-convex/convex-ai-chat-langchain&lt;/a&gt;&lt;br/&gt; And you can play with a live version of the chat in our docs: &lt;a href=&quot;https://docs.convex.dev/&quot;&gt;https://docs.convex.dev/&lt;/a&gt;&lt;br/&gt; This is all in TypeScript.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/xixixao&quot;&gt; /u/xixixao &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188nfr8/build_ai_rag_chat_using_langchain_and_convex/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188nfr8/build_ai_rag_chat_using_langchain_and_convex/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_188nfr8</id><link href="https://www.reddit.com/r/LangChain/comments/188nfr8/build_ai_rag_chat_using_langchain_and_convex/" /><updated>2023-12-01T21:49:08+00:00</updated><published>2023-12-01T21:49:08+00:00</published><title>Build AI RAG Chat using LangChain and Convex</title></entry><entry><author><name>/u/Fabianslife</name><uri>https://www.reddit.com/user/Fabianslife</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I just started out with langchains and hybrid models after having used LLM for quite some time.&lt;/p&gt; &lt;p&gt;Now I am searching for a good way to load a complex medical guideline (~500 pages) of PDF into a chroma DB. PyPDF does not really work to good, as a lot of context gets lost when only one page is returned. &lt;/p&gt; &lt;p&gt;Any idea how to approach this specific project?&lt;/p&gt; &lt;p&gt;Thank you ðŸ˜Š&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fabianslife&quot;&gt; /u/Fabianslife &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188fwqo/i_want_to_load_and_encode_large_medical_texts/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188fwqo/i_want_to_load_and_encode_large_medical_texts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_188fwqo</id><link href="https://www.reddit.com/r/LangChain/comments/188fwqo/i_want_to_load_and_encode_large_medical_texts/" /><updated>2023-12-01T16:23:54+00:00</updated><published>2023-12-01T16:23:54+00:00</published><title>I want to load and encode large medical texts</title></entry><entry><author><name>/u/DonGuillotine</name><uri>https://www.reddit.com/user/DonGuillotine</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been in a couple of AI hackathons but I felt they lacked a focus on the complex applications of LLMs (Large Language Models) which many of us here are passionate about.&lt;/p&gt; &lt;p&gt;I recently discovered the &amp;#39;TruEra Challenge&amp;#39; by lablab.ai, which seems like an amazing opportunity for anyone interested in pushing the boundaries of what we can do with LLMs. This hackathon focuses on building LLM application with Google&amp;#39;s Vertex AI and TruLens for Evaluation and monitoring of models with free API credits.&lt;/p&gt; &lt;p&gt;I&amp;#39;m seriously considering joining, could this be the kind of environment where we can test out some experimental LangChain ideas? Keen to hear if anyone else is thinking of participating or has any thoughts.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DonGuillotine&quot;&gt; /u/DonGuillotine &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188hd5w/i_will_be_using_langchain_for_an_ai_hackathon/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188hd5w/i_will_be_using_langchain_for_an_ai_hackathon/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_188hd5w</id><link href="https://www.reddit.com/r/LangChain/comments/188hd5w/i_will_be_using_langchain_for_an_ai_hackathon/" /><updated>2023-12-01T17:26:17+00:00</updated><published>2023-12-01T17:26:17+00:00</published><title>I will be using LangChain for an AI Hackathon Challenge!</title></entry><entry><author><name>/u/TalhaZubair147</name><uri>https://www.reddit.com/user/TalhaZubair147</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://docs.ai21.com/docs/text-segmentation-api#features&quot;&gt;https://docs.ai21.com/docs/text-segmentation-api#features&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Anyone used this ? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TalhaZubair147&quot;&gt; /u/TalhaZubair147 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18877lh/is_this_text_segmentation_api_is_the_best_way_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18877lh/is_this_text_segmentation_api_is_the_best_way_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18877lh</id><link href="https://www.reddit.com/r/LangChain/comments/18877lh/is_this_text_segmentation_api_is_the_best_way_to/" /><updated>2023-12-01T08:47:00+00:00</updated><published>2023-12-01T08:47:00+00:00</published><title>Is this Text SEgmentation API is the best way to analyze which chunk size works better for our data ?</title></entry><entry><author><name>/u/CookingATeam</name><uri>https://www.reddit.com/user/CookingATeam</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, my name is Leon. I am looking for someone who is good with these AI stuff to finish off a AI chat bot I am building. I am putting up a team for a business in the return of shares of this project. The project is done almost 70%. I want someone who could make the conversation to be taken in a flow like how I want. I can share more deets in DMs.&lt;/p&gt; &lt;p&gt;atm I am selling it for $500/monthly (I made about 12 sales on launch and had to refund it cuz of NSFW content) and use OpenAI&amp;#39;s API&amp;#39;s which kind of screwed it over. I tried creating it with pygmalion and it is okayish. The first sales I made were with people whom I know off. If anyone is interested in working with me I can give a share of 15% and building a conversation flow would be the only thing you will need. I can make more sales easily with this project and I know where and how to sell.&lt;/p&gt; &lt;p&gt;I am sorry for my bad English since I am not a native speaker. The bot will be NSFW and prefer using open source LLMs. If you think you are a good fit DM me here or on my Telegram (@ packerxyz) for a faster response :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CookingATeam&quot;&gt; /u/CookingATeam &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18827bf/building_ai_chatbots/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18827bf/building_ai_chatbots/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18827bf</id><link href="https://www.reddit.com/r/LangChain/comments/18827bf/building_ai_chatbots/" /><updated>2023-12-01T03:50:20+00:00</updated><published>2023-12-01T03:50:20+00:00</published><title>Building AI chatbots</title></entry><entry><author><name>/u/chellycd</name><uri>https://www.reddit.com/user/chellycd</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, &lt;/p&gt; &lt;p&gt;I am looking for some suggestions on how to go about implementing an LLM based tool as described below. I&amp;#39;ve been looking around but I have not come across something similar. I&amp;#39;ve been using Langchain for other use cases and it seems like it might be useful for this problem however I am not sure. &lt;/p&gt; &lt;p&gt;Here is a generic description of what I want to do:&lt;/p&gt; &lt;p&gt;I want to use an LLM to understand, explain and convert instructions from one system to another. &lt;/p&gt; &lt;p&gt;Assuming the following: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;I have an old system for which there are many different instruction sets that define various jobs in that system. &lt;/li&gt; &lt;li&gt;I have a new system that has the same capabilities as the old, but it has a different instruction set.&lt;/li&gt; &lt;li&gt;My LLM of choice knows very little about the old system, however knows a lot about the new system. &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;What I want to do is provide the LLM with knowledge about the old system. For example, PDF manuals, text descriptions of the instruction set, potential text examples of what the old instruction looks like in the new system. &lt;/p&gt; &lt;p&gt;Once the above is accomplished, I want to be able to send these job instruction sets to the LLM and ask it to convert them to the new system. &lt;/p&gt; &lt;p&gt;Using RAG seems like a potential way to do this however this isn&amp;#39;t a Q&amp;amp;A or summarization use case. &lt;/p&gt; &lt;p&gt;I want the LLM to use the extra knowledge given to it, combine with the specific conversion request and have it output the new instructions set. &lt;/p&gt; &lt;p&gt;Does it make sense to use RAG and something like the Conversational Retrieval QA for this? Would this work if I create a prompt instructing the model not to be a question and answer assistant but to use the knowledge in the context to assist in the request? What sort of retriever would make sense in this case? &lt;/p&gt; &lt;p&gt;I am considering creating a prototype to try this however I am not confidant it&amp;#39;s not going to be a waste of time. &lt;/p&gt; &lt;p&gt;Thanks in advance. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/chellycd&quot;&gt; /u/chellycd &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188141p/looking_for_advice_giving_a_llm_obscure_knowledge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188141p/looking_for_advice_giving_a_llm_obscure_knowledge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_188141p</id><link href="https://www.reddit.com/r/LangChain/comments/188141p/looking_for_advice_giving_a_llm_obscure_knowledge/" /><updated>2023-12-01T02:55:52+00:00</updated><published>2023-12-01T02:55:52+00:00</published><title>Looking for advice: Giving a LLM obscure knowledge</title></entry><entry><author><name>/u/theswifter01</name><uri>https://www.reddit.com/user/theswifter01</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for a fine-tuned model on huggingface&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/theswifter01&quot;&gt; /u/theswifter01 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1882fv3/what_are_the_sota_models_for_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1882fv3/what_are_the_sota_models_for_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1882fv3</id><link href="https://www.reddit.com/r/LangChain/comments/1882fv3/what_are_the_sota_models_for_function_calling/" /><updated>2023-12-01T04:02:49+00:00</updated><published>2023-12-01T04:02:49+00:00</published><title>What are the SOTA models for function calling?</title></entry><entry><author><name>/u/mumblingsquadron</name><uri>https://www.reddit.com/user/mumblingsquadron</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all. &lt;/p&gt; &lt;p&gt;First, I&amp;#39;m a bit of a neophyte to LangChain, and I cannot say I have a minimum of 5 years experience with LangChain and local LLMs - like many I&amp;#39;m just starting out in such a new space. I do, however, have years of coding experience and can read a manual, dig into code, etc. Trying not to cargo cult copy too much here, but this seems to be the minimal amount of code I&amp;#39;d need to get a LangChain SQL agent and toolkit going with Llama models:&lt;/p&gt; &lt;p&gt;``` from langchain.utilities import SQLDatabase from langchain.llms import LlamaCpp, OpenAI from langchain.chains import LLMChain from langchain.agents import create_sql_agent from langchain.agents.agent_toolkits import SQLDatabaseToolkit from langchain.agents.agent_types import AgentType from dotenv import load_dotenv import os&lt;/p&gt; &lt;p&gt;load_dotenv() openai_api_key = os.getenv(&amp;quot;openai_api_key&amp;quot;)&lt;/p&gt; &lt;p&gt;conn_str = &amp;quot;mysql+pymysql://root@localhost:3306/chinook&amp;quot;&lt;/p&gt; &lt;p&gt;db = SQLDatabase.from_uri(conn_str)&lt;/p&gt; &lt;h1&gt;Instantiate the LLM&lt;/h1&gt; &lt;p&gt;llm = LlamaCpp( model_path=&amp;#39;codellama-7b.Q4_K_M.gguf&amp;#39;, verbose=True, n_gpu_layers=8, n_ctx=2048, temperature=0 )&lt;/p&gt; &lt;h1&gt;llm = OpenAI(temperature=0, verbose=True, openai_api_key=openai_api_key)&lt;/h1&gt; &lt;p&gt;agent_executor = create_sql_agent( llm=llm, toolkit=SQLDatabaseToolkit(db=db, llm=llm), verbose=True, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION)&lt;/p&gt; &lt;p&gt;agent_executor.run( &amp;quot;How many customers are there?&amp;quot; ) ```&lt;/p&gt; &lt;p&gt;The &lt;code&gt;llm = OpenAI&lt;/code&gt; is commented out, but when I use it I get an actual answer. Using the &lt;code&gt;codellama-7b.Q4_K_M.gguf&lt;/code&gt; model I get:&lt;/p&gt; &lt;p&gt;&lt;code&gt; Action: sql_db_list_tables Action Input: an empty string Observation: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track Thought:Llama.generate: prefix-match hit &lt;/code&gt;&lt;/p&gt; &lt;p&gt;which looks great, except, the next action results in:&lt;/p&gt; &lt;p&gt;&lt;code&gt; I should look at the results of my query to see what I can do next. Then I should query the schema of the most relevant tables. Action: sql_db_schema Action Input: a comma-separated list of tables in the database Observation: Error: table_names {&amp;#39;a comma-separated list of tables in the database&amp;#39;} not found in database &lt;/code&gt;&lt;/p&gt; &lt;p&gt;So, I thought, well maybe I should use a &amp;quot;better&amp;quot; model (whatever that is), and tried &lt;code&gt;phind-codellama-34b-v2.Q4_K_M.gguf&lt;/code&gt;, which barfs and &lt;code&gt;langchain.schema.output_parser.OutputParserException: Could not parse LLM output:&lt;/code&gt; but doesn&amp;#39;t give any actual output.&lt;/p&gt; &lt;p&gt;Again, enable OpenAI instead, and boom.&lt;/p&gt; &lt;p&gt;So, a few questions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Has anyone successfully used a &lt;em&gt;local&lt;/em&gt; model (whether it is Llama-based or not I&amp;#39;m not as concerned at the moment) with LangChain SQL agent?&lt;/li&gt; &lt;li&gt;Are models such as &lt;code&gt;sqlcoder2.Q5_K_M.gguf&lt;/code&gt; &amp;quot;supposed&amp;quot; to be better? (it doesn&amp;#39;t work either)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I&amp;#39;m interested in using a local model to avoid sending sensitive data to OpenAI for this use case.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mumblingsquadron&quot;&gt; /u/mumblingsquadron &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187wah9/using_sqldatabasetoolkit_and_llamacpp_to_query_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187wah9/using_sqldatabasetoolkit_and_llamacpp_to_query_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_187wah9</id><link href="https://www.reddit.com/r/LangChain/comments/187wah9/using_sqldatabasetoolkit_and_llamacpp_to_query_a/" /><updated>2023-11-30T23:15:29+00:00</updated><published>2023-11-30T23:15:29+00:00</published><title>Using SQLDatabaseToolkit and LlamaCpp to Query a Local Database with a Local LLM</title></entry><entry><author><name>/u/camp_throw</name><uri>https://www.reddit.com/user/camp_throw</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187ited/what_would_an_llm_os_look_like/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/83VIr7Z42OyEUr_sXNE3VguqqKzdRfzSiXYRyd_cXmU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6d30c79a0326c35be6d4ec8af5fd6077f80309c1&quot; alt=&quot;What would an LLM OS look like?&quot; title=&quot;What would an LLM OS look like?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/camp_throw&quot;&gt; /u/camp_throw &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://campedersen.com/llm-os/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187ited/what_would_an_llm_os_look_like/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_187ited</id><media:thumbnail url="https://external-preview.redd.it/83VIr7Z42OyEUr_sXNE3VguqqKzdRfzSiXYRyd_cXmU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6d30c79a0326c35be6d4ec8af5fd6077f80309c1" /><link href="https://www.reddit.com/r/LangChain/comments/187ited/what_would_an_llm_os_look_like/" /><updated>2023-11-30T13:42:25+00:00</updated><published>2023-11-30T13:42:25+00:00</published><title>What would an LLM OS look like?</title></entry><entry><author><name>/u/Apart-Damage143</name><uri>https://www.reddit.com/user/Apart-Damage143</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey,&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently working on integrating Multimodal RAG into my Node.js application. Has anyone implemented this before? If so, could you guide me to the libraries or resources you used? Most of what I&amp;#39;ve come across is in Python. I&amp;#39;m wondering if it&amp;#39;s feasible to implement this version of RAG in JavaScript. Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Apart-Damage143&quot;&gt; /u/Apart-Damage143 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187t1nn/seeking_guidance_implementing_multimodal_rag_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187t1nn/seeking_guidance_implementing_multimodal_rag_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_187t1nn</id><link href="https://www.reddit.com/r/LangChain/comments/187t1nn/seeking_guidance_implementing_multimodal_rag_in/" /><updated>2023-11-30T21:02:16+00:00</updated><published>2023-11-30T21:02:16+00:00</published><title>Seeking Guidance: Implementing Multimodal RAG in Node.js â€“ Any JavaScript Resources?</title></entry><entry><author><name>/u/Yosadhara</name><uri>https://www.reddit.com/user/Yosadhara</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hej, would anyone know the minimum hardware requirements of the typical vector database options (Qdrant, Pinecone, weaviate, Vespa...)? and the footprint of the databases themselves (empty)? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Yosadhara&quot;&gt; /u/Yosadhara &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187g49m/vector_databases_minimum_hardware_requirements/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187g49m/vector_databases_minimum_hardware_requirements/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_187g49m</id><link href="https://www.reddit.com/r/LangChain/comments/187g49m/vector_databases_minimum_hardware_requirements/" /><updated>2023-11-30T11:10:12+00:00</updated><published>2023-11-30T11:10:12+00:00</published><title>Vector databases: Minimum hardware requirements</title></entry><entry><author><name>/u/Helpful_Doughnut27</name><uri>https://www.reddit.com/user/Helpful_Doughnut27</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What is the difference between similarity search and similarity search with relevancy score?&lt;/p&gt; &lt;p&gt;Which algorithms are used under both?&lt;/p&gt; &lt;p&gt;and what is the best practice with FAISS vector store?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Helpful_Doughnut27&quot;&gt; /u/Helpful_Doughnut27 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187oien/similarity_search_with_relevancy_score/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187oien/similarity_search_with_relevancy_score/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_187oien</id><link href="https://www.reddit.com/r/LangChain/comments/187oien/similarity_search_with_relevancy_score/" /><updated>2023-11-30T17:50:14+00:00</updated><published>2023-11-30T17:50:14+00:00</published><title>Similarity search with relevancy score</title></entry><entry><author><name>/u/Ok_Strain4832</name><uri>https://www.reddit.com/user/Ok_Strain4832</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187ir4s/nice_project_for_finding_llms/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/aSs8sFEvyv6FVemZ12Fk9wvnQk3h4T51FY6CHertxoU.jpg&quot; alt=&quot;Nice Project for Finding LLMs&quot; title=&quot;Nice Project for Finding LLMs&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ok_Strain4832&quot;&gt; /u/Ok_Strain4832 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/LLMDevs/comments/17qiow8/announcing_llm_explore_v2/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187ir4s/nice_project_for_finding_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_187ir4s</id><media:thumbnail url="https://b.thumbs.redditmedia.com/aSs8sFEvyv6FVemZ12Fk9wvnQk3h4T51FY6CHertxoU.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/187ir4s/nice_project_for_finding_llms/" /><updated>2023-11-30T13:39:24+00:00</updated><published>2023-11-30T13:39:24+00:00</published><title>Nice Project for Finding LLMs</title></entry><entry><author><name>/u/Icy-Sorbet-9458</name><uri>https://www.reddit.com/user/Icy-Sorbet-9458</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1874lg2/gpt4turbo_multi_tools_agents_postgres_weather_api/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/Y3MxYnBvM2JwZDNjMRpS-G68dX9hSrsMM195du42FhkJrh3RrLMAdF9TPJk3.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1649ae0ee11936f21664a79871f07791d667ec60&quot; alt=&quot;gpt4-turbo multi tools agents (postgres, weather api, google calendar api , whatsapp cloud api) all in Python&quot; title=&quot;gpt4-turbo multi tools agents (postgres, weather api, google calendar api , whatsapp cloud api) all in Python&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Icy-Sorbet-9458&quot;&gt; /u/Icy-Sorbet-9458 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/z14s2zr8pd3c1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1874lg2/gpt4turbo_multi_tools_agents_postgres_weather_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1874lg2</id><media:thumbnail url="https://external-preview.redd.it/Y3MxYnBvM2JwZDNjMRpS-G68dX9hSrsMM195du42FhkJrh3RrLMAdF9TPJk3.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1649ae0ee11936f21664a79871f07791d667ec60" /><link href="https://www.reddit.com/r/LangChain/comments/1874lg2/gpt4turbo_multi_tools_agents_postgres_weather_api/" /><updated>2023-11-30T00:21:16+00:00</updated><published>2023-11-30T00:21:16+00:00</published><title>gpt4-turbo multi tools agents (postgres, weather api, google calendar api , whatsapp cloud api) all in Python</title></entry><entry><author><name>/u/Background-Maybe-381</name><uri>https://www.reddit.com/user/Background-Maybe-381</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We have this line of code:&lt;/p&gt; &lt;p&gt;add_route(app, react_zero_shot, path=&amp;quot;/api/conversation/&amp;quot;)&lt;/p&gt; &lt;p&gt;In the post request we are sending two variables; the input and a authentication token. We need the token to get to the tools, because the tools themselves connect externally to other APIs and need an authentication token to &amp;quot;do things&amp;quot;. But we cannot for the life of us get this token to the tool. Any suggestions?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Background-Maybe-381&quot;&gt; /u/Background-Maybe-381 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187fj25/trying_to_pass_variable_via_post_to_langserv_so/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187fj25/trying_to_pass_variable_via_post_to_langserv_so/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_187fj25</id><link href="https://www.reddit.com/r/LangChain/comments/187fj25/trying_to_pass_variable_via_post_to_langserv_so/" /><updated>2023-11-30T10:31:19+00:00</updated><published>2023-11-30T10:31:19+00:00</published><title>Trying to pass variable via post to langserv so it gets to a tool</title></entry><entry><author><name>/u/TalhaZubair147</name><uri>https://www.reddit.com/user/TalhaZubair147</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;retriever = MultiQueryRetriever( retriever= vectordb.as _retriever(), llm_chain=llm_chain, parser_key=&amp;quot;lines&amp;quot; ) # &amp;quot;lines&amp;quot; is the key (attribute name) of the parsed output # Results unique_docs = retriever.get_relevant_documents( query=&amp;quot;What does the course say about model selection?&amp;quot; ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When i call this function get_relevant_documents it works fine but when i call &lt;strong&gt;generate_queries()&lt;/strong&gt; Function it gives me error &lt;/p&gt; &lt;pre&gt;&lt;code&gt;retriever.generate_queries(question=&amp;quot;What does the course say about model selection?&amp;quot;) TypeError : generate_queries() missing 1 required positional argument: &amp;#39;run_manager&amp;#39; &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TalhaZubair147&quot;&gt; /u/TalhaZubair147 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187dpam/how_to_get_generated_queries_from_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/187dpam/how_to_get_generated_queries_from_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_187dpam</id><link href="https://www.reddit.com/r/LangChain/comments/187dpam/how_to_get_generated_queries_from_using/" /><updated>2023-11-30T08:24:03+00:00</updated><published>2023-11-30T08:24:03+00:00</published><title>How to get generated queries from using MultiqueryRetriever</title></entry><entry><author><name>/u/happy-poo</name><uri>https://www.reddit.com/user/happy-poo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m currently working on a document selection problem and needed some inputs on how to proceed further in solving thisThe input I have is user data and I&amp;#39;ve to return a set of documents which match the user is talking about in the description.&lt;/p&gt; &lt;p&gt;The list of documents is very huge around 2-3 Million records and they are very unstructured and user input necessarily might not be present in the document.&lt;/p&gt; &lt;p&gt;Currently I&amp;#39;ve tried the following&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create summary of all the documents using llm&lt;/li&gt; &lt;li&gt;Create embedding of this and store it in vector db.&lt;/li&gt; &lt;li&gt;Create summary of user input on the fly&lt;/li&gt; &lt;li&gt;create embedding of the summarised user input and search in vector db and return top x documents with probability &amp;gt;=y&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;This does get me documents very quickly but there are a lot of false positives and I&amp;#39;m not sure how to reduce these false positives.&lt;/p&gt; &lt;p&gt;One of the thing I found is user query might not be present in the documents directly so in this case there are a lot of false positives.&lt;/p&gt; &lt;p&gt;Is any any other way to solve this selection problem or reduce the number of false positives that come up in vector search ?&lt;/p&gt; &lt;p&gt;I also tried re ranking with BM25 algorithm but it did not help a lot&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/happy-poo&quot;&gt; /u/happy-poo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/186xvts/how_do_improve_results_of_vector_embeddings_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/186xvts/how_do_improve_results_of_vector_embeddings_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_186xvts</id><link href="https://www.reddit.com/r/LangChain/comments/186xvts/how_do_improve_results_of_vector_embeddings_in/" /><updated>2023-11-29T19:30:54+00:00</updated><published>2023-11-29T19:30:54+00:00</published><title>How do improve results of vector embeddings in the following scenario ?</title></entry></feed>