<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-06T21:47:57+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Koltchak</name><uri>https://www.reddit.com/user/Koltchak</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently using a code that processes a series of reports (PDF files), posing the same set of questions to each. The output is a dataframe containing the responses to each question from every report. My setup includes the use of &lt;a href=&quot;https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2&quot;&gt;https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2&lt;/a&gt; and a locally downloaded LLM from Hugging Face. Although the code is functional, the reports are highly technical and complex, and the local LLM lacks the necessary understanding of the content (I notice that when I read the answers).&lt;/p&gt; &lt;p&gt;I&amp;#39;m looking to enhance the LLM&amp;#39;s comprehension by training it on additional technical documents of the same nature, hoping this will improve its ability to accurately answer queries from my reports. If I&amp;#39;ve understood correctly, one approach might be to utilize a RAG on the technical documents, but I&amp;#39;m unsure of the exact steps to implement this effectively. I&amp;#39;ve attempted to merge the embeddings from the downloaded &amp;#39;all-MiniLM-L6-v2&amp;#39; model with those I generated from the technical documents, as described here: &lt;a href=&quot;https://python.langchain.com/docs/integrations/retrievers/merger_retriever/&quot;&gt;https://python.langchain.com/docs/integrations/retrievers/merger_retriever/&lt;/a&gt;, but without success.&lt;/p&gt; &lt;p&gt;Could you suggest a viable strategy for this? Should I discard the &amp;#39;all-MiniLM-L6-v2&amp;#39; and focus solely on embeddings derived from my technical documents? This approach seems to require an extensive collection of documents, which I currently don&amp;#39;t have.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve tried various other local LLMs (Mistral, Phi, Llama, Orca), but I encounter the same issue each time. &amp;quot;Large&amp;quot; LLMs (Mistral e.g.) tend to hallucinate, while &amp;quot;smaller&amp;quot; (Orca e.g.) LLMs often respond that they do not know.&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Koltchak&quot;&gt; /u/Koltchak &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clui48/enhancing_local_llms_understanding_of_technical/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clui48/enhancing_local_llms_understanding_of_technical/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1clui48</id><link href="https://www.reddit.com/r/LangChain/comments/1clui48/enhancing_local_llms_understanding_of_technical/" /><updated>2024-05-06T21:21:11+00:00</updated><published>2024-05-06T21:21:11+00:00</published><title>Enhancing Local LLM's Understanding of Technical Documents</title></entry><entry><author><name>/u/MountainBlock</name><uri>https://www.reddit.com/user/MountainBlock</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I&amp;#39;m relatively novice when it comes to LLMs, so my understanding is very limited. However, I came across &lt;a href=&quot;https://youtu.be/9ccl1_Wu24Q?si=gHdxkoCE0gulV3Px&quot;&gt;this YouTube Video &lt;/a&gt;and was impressed with how simple the whole project was set up using Langchain and MySQL. I&amp;#39;ve been experimenting with it using a local version of our company&amp;#39;s database, and I have this vision of developing a chatbot that can talk to our database and answer questions related to the information we have in our database.&lt;/p&gt; &lt;p&gt;I have a few questions:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;I&amp;#39;ve read a few comments on this subreddit indicating that Langchain is not good for SQL. What does this mean, and why is it so?&lt;/li&gt; &lt;li&gt;One of the comments on the video critiques the use of Langchain, stating that Langchain packages are not secure, due to passing database schema across third party providers. Is this true? My idea would be to create a chatbot for internal use, and implement it into our intranet.&lt;/li&gt; &lt;li&gt;In general, how beginner friendly is Langchain? I&amp;#39;m under the impression it&amp;#39;s moreso compared to other models. &lt;/li&gt; &lt;li&gt;Is Langchain the right tool for my task?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;If I can provide any more context, I&amp;#39;d be happy to do so. Thanks in advance. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MountainBlock&quot;&gt; /u/MountainBlock &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clj3k0/starting_out_with_langchain_sql_some_questions/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clj3k0/starting_out_with_langchain_sql_some_questions/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1clj3k0</id><link href="https://www.reddit.com/r/LangChain/comments/1clj3k0/starting_out_with_langchain_sql_some_questions/" /><updated>2024-05-06T13:30:08+00:00</updated><published>2024-05-06T13:30:08+00:00</published><title>Starting out with Langchain SQL: some questions</title></entry><entry><author><name>/u/_Mahin_</name><uri>https://www.reddit.com/user/_Mahin_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, recently while I was building a RAG Chatbot I came through an issue i.e below is the code I executed on 4 different machines(laptops) &lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain_community.embeddings import OllamaEmbeddings embedding = embeddings.OllamaEmbeddings(model=&amp;#39;nomic-embed-text&amp;#39;) db = FAISS.load_local(&amp;quot;MS_VDB&amp;quot;, embeddings=embedding,allow_dangerous_deserialization=True) query = &amp;quot;Recently I was diagnosed with Relapsing-onset MS and the indicated MS phenotype is Highly active. List the name of the drugs which can be used to treat my condition&amp;quot; docs = db.similarity_search(query) print(docs[0].page_content) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;All the 4 machines use the same vector db file but in 3 machines the similarity search result was exactly the same but on the other one it was different even though the code was executed within a virtual environment. Can anyone tell me what&amp;#39;s the issue and how I could resolve it so that all the 4 machines give the same output. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/_Mahin_&quot;&gt; /u/_Mahin_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clfwla/is_it_possible_to_get_different_similarity_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clfwla/is_it_possible_to_get_different_similarity_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1clfwla</id><link href="https://www.reddit.com/r/LangChain/comments/1clfwla/is_it_possible_to_get_different_similarity_search/" /><updated>2024-05-06T10:40:44+00:00</updated><published>2024-05-06T10:40:44+00:00</published><title>Is it possible to get different similarity search results with same vector database on different machines for the same similarity search query?</title></entry><entry><author><name>/u/Beginning_Land_5775</name><uri>https://www.reddit.com/user/Beginning_Land_5775</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hi, if i run my code for rag made with python and langchain,the firtst time everything goes well and in the second question it spits out this error:&lt;/p&gt; &lt;p&gt;raise ValueError(f&amp;quot;Missing some input keys: {missing_keys}&amp;quot;)&lt;/p&gt; &lt;p&gt;ValueError: Missing some input keys: {&amp;#39;context&amp;#39;}&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Beginning_Land_5775&quot;&gt; /u/Beginning_Land_5775 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clmt84/problem_with_multiple_rag_questions/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clmt84/problem_with_multiple_rag_questions/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1clmt84</id><link href="https://www.reddit.com/r/LangChain/comments/1clmt84/problem_with_multiple_rag_questions/" /><updated>2024-05-06T16:07:11+00:00</updated><published>2024-05-06T16:07:11+00:00</published><title>problem with multiple rag questions</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;DSPy is an alternate for LangChain, mainly for programmers to build GenAI apps without any prompt engineering by user. Checkout this beginner friendly tutorial to know the basics of DSPy to get started : &lt;a href=&quot;https://youtu.be/IiaXLP3JKr4?si=xACEMVC1c7c174uR&quot;&gt;https://youtu.be/IiaXLP3JKr4?si=xACEMVC1c7c174uR&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cldnq3/dspy_a_no_prompt_alternate_for_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cldnq3/dspy_a_no_prompt_alternate_for_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cldnq3</id><link href="https://www.reddit.com/r/LangChain/comments/1cldnq3/dspy_a_no_prompt_alternate_for_langchain/" /><updated>2024-05-06T08:03:23+00:00</updated><published>2024-05-06T08:03:23+00:00</published><title>DSPy, a no prompt alternate for LangChain</title></entry><entry><author><name>/u/Honest-Worth3677</name><uri>https://www.reddit.com/user/Honest-Worth3677</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=5ModxAjKI3w&amp;amp;t=915s&quot;&gt;&amp;quot;GPT to perform 10x with my private knowledge&amp;quot; - Local Agentic RAG w/- PDF , Website - Here is how (youtube.com)&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Honest-Worth3677&quot;&gt; /u/Honest-Worth3677 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clfhnk/gpt_to_perform_10x_with_my_private_knowledge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clfhnk/gpt_to_perform_10x_with_my_private_knowledge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1clfhnk</id><link href="https://www.reddit.com/r/LangChain/comments/1clfhnk/gpt_to_perform_10x_with_my_private_knowledge/" /><updated>2024-05-06T10:12:52+00:00</updated><published>2024-05-06T10:12:52+00:00</published><title>&quot;GPT to perform 10x with my private knowledge&quot;</title></entry><entry><author><name>/u/Fun_Highlight9147</name><uri>https://www.reddit.com/user/Fun_Highlight9147</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone here tried to do a multiuser app? Does langchain support it out of the box with configuration, or is this something that needs to be done on my own? It seems that loading several langchain agents takes quite a bit of time which means the client would have to wait quite a bit if I recretead the agent for every request. &lt;/p&gt; &lt;p&gt;I am not sure how to approach this.&lt;br/&gt; I do not need message history, just stateless for now.&lt;/p&gt; &lt;p&gt;My agents are for reporting purposes at work, so they trigger Pandas/Excel processes which can take 30 seconds up to a 1 minute.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fun_Highlight9147&quot;&gt; /u/Fun_Highlight9147 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clcva5/langchain_multi_user_apiapp/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1clcva5/langchain_multi_user_apiapp/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1clcva5</id><link href="https://www.reddit.com/r/LangChain/comments/1clcva5/langchain_multi_user_apiapp/" /><updated>2024-05-06T07:06:50+00:00</updated><published>2024-05-06T07:06:50+00:00</published><title>Langchain Multi user api/app</title></entry><entry><author><name>/u/AnEdgeLordWeeb</name><uri>https://www.reddit.com/user/AnEdgeLordWeeb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! Before I begin, thanks to those that took the time to read my post and hopefully respond, it&amp;#39;s really much appreciated. Now onto our topic; I&amp;#39;m trying to build a conversation chatbot which objective is to offer to the user game recommendations that fit different criteria and preferences that could be found in his initial query.&lt;/p&gt; &lt;p&gt;What I want the chatbot to do, is first evaluate the query, have it better understand. See if the query is on the topic of asking for game recommendations, or whether his input is clear enough, which in the case of them not meeting one of the requirements, have the chatbot ask from the user to input a proper one.&lt;/p&gt; &lt;p&gt;After making sure that his input is alright and is done with reviewing it, make calls to various tools that rely on SerpApi. such as the Google search one for finding suitable titles to be chosen as candidate for the final answer and gather more additional information for each game, or the Google images and Youtube one for gathering multimedia content, such as games&amp;#39; posters and official trailers.&lt;/p&gt; &lt;p&gt;Once the chatbot is done with browsing the web in order to fetch what it needs, let it formulate a response to the user. One important functionality that I want present in this chatbot is that, if the user asks from the chatbot to find alternatives to some of the titles found in the response, it should be able to remember that response in the first to be able and apply modifications to it, such as the replacing actions of certain mentioned titles with other ones.&lt;/p&gt; &lt;p&gt;Now that the requirements of this chatbot are somewhat clear, how would you recommend me to go on developing such project? What key factors should I take into consideration and make use of in order to achieve the desired results?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnEdgeLordWeeb&quot;&gt; /u/AnEdgeLordWeeb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cl522l/what_is_the_most_proper_way_to_develop_this/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cl522l/what_is_the_most_proper_way_to_develop_this/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cl522l</id><link href="https://www.reddit.com/r/LangChain/comments/1cl522l/what_is_the_most_proper_way_to_develop_this/" /><updated>2024-05-05T23:45:29+00:00</updated><published>2024-05-05T23:45:29+00:00</published><title>What is the most proper way to develop this chatbot?</title></entry><entry><author><name>/u/xandie985</name><uri>https://www.reddit.com/user/xandie985</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a use case, where I have textual data. I have to extract information from it. Some of the data is direct and can be assigned directly. Others are not so-direct, like total weight, total quantity, these values are supposed to be calculated after extracting individual data from the data. &lt;/p&gt; &lt;p&gt;Since RAG provides contextual information, so I am planning to inform the LLM about the labels to be extracted. I am also planning to fine-tune Llama3 on annotations so model learns about what how information extraction is actually taking place. &lt;/p&gt; &lt;p&gt;What else can be done to improve the output performance of model. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/xandie985&quot;&gt; /u/xandie985 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cl4mx6/llm_use_case_for_qa_and_reasoning/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cl4mx6/llm_use_case_for_qa_and_reasoning/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cl4mx6</id><link href="https://www.reddit.com/r/LangChain/comments/1cl4mx6/llm_use_case_for_qa_and_reasoning/" /><updated>2024-05-05T23:25:29+00:00</updated><published>2024-05-05T23:25:29+00:00</published><title>LLM use case for QA and reasoning.</title></entry><entry><author><name>/u/Plus_Dinner_9494</name><uri>https://www.reddit.com/user/Plus_Dinner_9494</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Guy i need your help! &lt;/p&gt; &lt;p&gt;i want to build a chatbot service that is a cartoon character that helps people with their body transformation journey , its has a database with relevant products, it offers products to users when they ask body transformation questions using the database .&lt;br/&gt; for example :&lt;br/&gt; &amp;quot;i want to gain weight , how do i do it ?&amp;quot;&lt;br/&gt; &amp;quot;im 178cm and 78kg and i want to gain 10kg &amp;quot;&lt;br/&gt; &amp;quot;if im looking to lose 5% body fat , what should i do ?&amp;quot; &lt;/p&gt; &lt;p&gt;to do so i build a number of chatbots each with a different exaction approach but each has its own issues and i cant find the execution that will satisfy me . &lt;/p&gt; &lt;p&gt;1st approach:&lt;br/&gt; using langchain and added a custom tool , that holds the products in a vector database . &lt;/p&gt; &lt;p&gt;the problems with this approach: it doesnt always go to the tool , sometimes it does and sometimes it doesnt .&lt;br/&gt; and i cant control it , the llm decides by itself if to look in the tool or not , this leads to unstable results of similar conversations &lt;/p&gt; &lt;p&gt;2nd approach :&lt;br/&gt; i used the openai wrapper and used groq llm service , without langchain , were i added a custom tool , here the process is different .&lt;br/&gt; process:&lt;br/&gt; - get user input&lt;br/&gt; - created a llm call to determine if the function would be called by looking at the user input&lt;br/&gt; - if the function is to call then i call the function with the user input and get the products&lt;br/&gt; - create a llm call with a system prompt and user input plus the relevant products&lt;br/&gt; -if the function is not to call , then ill create a llm call with a different system prompt and use only the user input&lt;br/&gt; - also introduce the user and chatbot summary chat history to give the llm context &lt;/p&gt; &lt;p&gt;the problems with this approach :&lt;br/&gt; again not always it goes to the tool so its a problem , here it performs better then the first approach , but i feel its hard to keep the context of the conversation and the history is getting bigger and bigger very fast and then the llm looses understanding of the user input &lt;/p&gt; &lt;p&gt;3rd approach:&lt;br/&gt; - get user input&lt;br/&gt; - always use user input to look for relevant products in the vector database&lt;br/&gt; - summary the conversation until now&lt;br/&gt; - do a llm call using the system prompt , user input , the relevant products , and conversation summary &lt;/p&gt; &lt;p&gt;the problem with this approach :&lt;br/&gt; from all of the approaches this preforms the best but it still has issues , because i use a lot of information in each llm call , and i ask it to respond to the user input and use the products only if they are relevant . when the user wants to end the conversation and say &amp;quot;thank you&amp;quot; or &amp;quot;great&amp;quot; inside the llm call it gets lots of information and the respond misses the point , and it answers like the user is still looking for help and doesnt understand the context of where we are right now &lt;/p&gt; &lt;p&gt;i want to know what is the best approach to create a chat bot that users can talk to , get relevant products for their body transformation journey , but also talk to the llm regularly and for it to respond only to the relevant message . please tell me from your experience what is the best approach . &lt;/p&gt; &lt;p&gt;i really appreciate any help. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Plus_Dinner_9494&quot;&gt; /u/Plus_Dinner_9494 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckoupq/help_in_creating_a_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckoupq/help_in_creating_a_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckoupq</id><link href="https://www.reddit.com/r/LangChain/comments/1ckoupq/help_in_creating_a_rag_chatbot/" /><updated>2024-05-05T11:09:40+00:00</updated><published>2024-05-05T11:09:40+00:00</published><title>help in creating a RAG chatbot</title></entry><entry><author><name>/u/mahadevbhakti</name><uri>https://www.reddit.com/user/mahadevbhakti</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is it a good idea to fine tune a cheaper model like chatgpt 3.5 and train it on your function calling samples where the tool is basically a http fetch request to get data from API based on parameters in the user&amp;#39;s query?&lt;/p&gt; &lt;p&gt;I am currently using gpt 4 2024 model, and the cons are 1) it&amp;#39;s expensive 2) I have to add examples in my system prompt 3) It still fails at times with mapping the parameters (more than 4 different parameters such as region, duration, price etc)&lt;/p&gt; &lt;p&gt;I am considering this but posting this to check if someone found this viable? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mahadevbhakti&quot;&gt; /u/mahadevbhakti &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckpwg4/fine_tuning_for_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckpwg4/fine_tuning_for_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckpwg4</id><link href="https://www.reddit.com/r/LangChain/comments/1ckpwg4/fine_tuning_for_function_calling/" /><updated>2024-05-05T12:13:58+00:00</updated><published>2024-05-05T12:13:58+00:00</published><title>Fine tuning for Function Calling</title></entry><entry><author><name>/u/Fun_Highlight9147</name><uri>https://www.reddit.com/user/Fun_Highlight9147</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi I am currently struglling with how to approach error handling with a JSON output parser. Can it do retries? I feel like every output parser should just allow retry by default, because often the result can be bad for 1 - 2 requests and that is it.&lt;/p&gt; &lt;p&gt;If not then is it possible to use retryOutput parser with LCEL?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fun_Highlight9147&quot;&gt; /u/Fun_Highlight9147 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckzzfs/do_output_parser_like_the_json_one_have_a_retry/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckzzfs/do_output_parser_like_the_json_one_have_a_retry/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckzzfs</id><link href="https://www.reddit.com/r/LangChain/comments/1ckzzfs/do_output_parser_like_the_json_one_have_a_retry/" /><updated>2024-05-05T20:01:14+00:00</updated><published>2024-05-05T20:01:14+00:00</published><title>Do Output Parser like the JSON one, have a retry option?</title></entry><entry><author><name>/u/Alarming-East1193</name><uri>https://www.reddit.com/user/Alarming-East1193</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;We are creating a rag based ChatBot for our company but due to some infosec concerns we have to use only local llms and database.&lt;/p&gt; &lt;p&gt;Due to this reason we are not using openAI/Gemini or any API based models and instead we are using Ollama for our local models and using LLAMA 3 as our LLM. &lt;/p&gt; &lt;p&gt;Now the issue is when we are using local Embeddings model like nomic-embed it&amp;#39;s not producing very good results. What should i do to overcome this issue and i have tried different local Embeddings model of ollama but they aren&amp;#39;t producing very good results.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Alarming-East1193&quot;&gt; /u/Alarming-East1193 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cktopp/local_model_based_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cktopp/local_model_based_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cktopp</id><link href="https://www.reddit.com/r/LangChain/comments/1cktopp/local_model_based_rag_chatbot/" /><updated>2024-05-05T15:22:47+00:00</updated><published>2024-05-05T15:22:47+00:00</published><title>Local model based RAG ChatBot</title></entry><entry><author><name>/u/Constant_Fun_5643</name><uri>https://www.reddit.com/user/Constant_Fun_5643</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;br/&gt; Does anyone have any good tutorials or blogpost about how to use weaviate as a vector store and use Langchain to perform activities like, creating new collections, adding document, performing similarity search etc. The official documentation from Langchain work when I perform all these actions sequentially. However, when loading the persisted vector store, I am unable to perform similarity search.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Constant_Fun_5643&quot;&gt; /u/Constant_Fun_5643 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckszg1/using_weaviate_langchain_together/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckszg1/using_weaviate_langchain_together/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckszg1</id><link href="https://www.reddit.com/r/LangChain/comments/1ckszg1/using_weaviate_langchain_together/" /><updated>2024-05-05T14:51:14+00:00</updated><published>2024-05-05T14:51:14+00:00</published><title>Using Weaviate &amp; Langchain together</title></entry><entry><author><name>/u/Odd_Research_6995</name><uri>https://www.reddit.com/user/Odd_Research_6995</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;how to write a prompt which does the work of greeting by introducing it self and another prompt for giving question answers with memory added into it.kindly give the code and the prompt stacking approch using selfquery retrieval.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Odd_Research_6995&quot;&gt; /u/Odd_Research_6995 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cl8f4w/langchain_response_format/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cl8f4w/langchain_response_format/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cl8f4w</id><link href="https://www.reddit.com/r/LangChain/comments/1cl8f4w/langchain_response_format/" /><updated>2024-05-06T02:35:59+00:00</updated><published>2024-05-06T02:35:59+00:00</published><title>langchain response format</title></entry><entry><author><name>/u/bhrdwj10</name><uri>https://www.reddit.com/user/bhrdwj10</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey , I have been dabbling with a few methods to extract data from a corpus of documents in structured format and have been experimenting with pydantic classes and even agents. But still, I am not able to achieve the desired result. I followed the Langchain documentation for extracting data but the method where we use Reference examples is not working.&lt;/p&gt; &lt;p&gt;To specify my use case, I want to extract data from legal documents in a chronological method. Would love to get some tips/ ideas or your methods if you have been doing something like this. Here is a fellow company doing the same www . tryabel. com.&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bhrdwj10&quot;&gt; /u/bhrdwj10 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckt04y/need_help_in_structured_extraction_of_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckt04y/need_help_in_structured_extraction_of_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckt04y</id><link href="https://www.reddit.com/r/LangChain/comments/1ckt04y/need_help_in_structured_extraction_of_data/" /><updated>2024-05-05T14:52:06+00:00</updated><published>2024-05-05T14:52:06+00:00</published><title>Need help in Structured Extraction of data</title></entry><entry><author><name>/u/ichig0_kurosaki</name><uri>https://www.reddit.com/user/ichig0_kurosaki</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I’m trying to build a Chat bot for our org using langchain. The knowledge base is primarily Wordpress blogs, books and YouTube videos. The YouTube videos happen to be in English and Hindi(language of India). How should I go about data ingestion? Should I translate the Hindi video transcripts to English and then embed them or should I embed all the transcripts irrespective of language using a multi lingual model from something like cohere?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ichig0_kurosaki&quot;&gt; /u/ichig0_kurosaki &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckmuq2/question_on_multi_lingual_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckmuq2/question_on_multi_lingual_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckmuq2</id><link href="https://www.reddit.com/r/LangChain/comments/1ckmuq2/question_on_multi_lingual_data/" /><updated>2024-05-05T08:46:34+00:00</updated><published>2024-05-05T08:46:34+00:00</published><title>Question on Multi lingual data</title></entry><entry><author><name>/u/ToeIntelligent4472</name><uri>https://www.reddit.com/user/ToeIntelligent4472</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Not looking to build my own system per se, just looking for something open source (doesn&amp;#39;t have to use langchain) that can use tools (code interp, web browsing, make google drive files, sending emails, replying to github issues) and perform RAG across all my google drive documents, emails, and code.&lt;/p&gt; &lt;p&gt;Apologies if this is too ambitious or too much to ask for with the current state of things.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ToeIntelligent4472&quot;&gt; /u/ToeIntelligent4472 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckbmf0/is_there_any_agent_that_can_do_rag_across_my/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckbmf0/is_there_any_agent_that_can_do_rag_across_my/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckbmf0</id><link href="https://www.reddit.com/r/LangChain/comments/1ckbmf0/is_there_any_agent_that_can_do_rag_across_my/" /><updated>2024-05-04T21:56:45+00:00</updated><published>2024-05-04T21:56:45+00:00</published><title>Is there any agent that can do RAG across my GDrive, Gmail, &amp; GitHub?</title></entry><entry><author><name>/u/Glittering_Class_333</name><uri>https://www.reddit.com/user/Glittering_Class_333</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am newbie interested in training LLMs on csv dataset that contains text data (few sentences about a product) and numeric data(its ratings). I have around 200k rows and would to like to train an LLM but I am unable to do it. Can anyone here guide me or share any resource which could help me.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering_Class_333&quot;&gt; /u/Glittering_Class_333 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckapb8/how_to_train_an_llm_with_data_that_contains_text/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckapb8/how_to_train_an_llm_with_data_that_contains_text/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckapb8</id><link href="https://www.reddit.com/r/LangChain/comments/1ckapb8/how_to_train_an_llm_with_data_that_contains_text/" /><updated>2024-05-04T21:14:15+00:00</updated><published>2024-05-04T21:14:15+00:00</published><title>How to train an LLM with data that contains text and numeric modality</title></entry><entry><author><name>/u/AnEdgeLordWeeb</name><uri>https://www.reddit.com/user/AnEdgeLordWeeb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! I&amp;#39;m trying to create a conversation chatbot the specializes in offering video games recommendations based on the user preferences found in his input. Though, right now, when I&amp;#39;m trying to run it, I&amp;#39;m being faced with the error above, does anybody have any idea as to what the problem may be?&lt;/p&gt; &lt;p&gt;Also, is there any way to make sure that an execution of an agent does not move to the other until all the requirements are met? For e.g., I have an input agent that&amp;#39;s tasked to collect the user&amp;#39;s prompt and extract the important info from there. But how would I manage a case where the user might input a query that talks about something completely different?&lt;/p&gt; &lt;p&gt;Thank you guys!&lt;/p&gt; &lt;p&gt;Here is my code too:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import os from dotenv import load_dotenv from langchain_openai import ChatOpenAI from langchain_core.messages import HumanMessage, BaseMessage from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain.agents import create_openai_tools_agent, Tool from langgraph.graph import StateGraph, END from typing import Annotated, Sequence, TypedDict import operator from serpapi import GoogleSearch # Load environment variables for API keys load_dotenv() # Configuration serpapi_key = os.getenv(&amp;quot;SERPAPI_API_KEY&amp;quot;) # Define tools using SerpAPI def google_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key, &amp;quot;num&amp;quot;: 5 } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;organic_results&amp;#39;] def youtube_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;youtube&amp;quot;, &amp;quot;search_query&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;video_results&amp;#39;] def images_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google_images&amp;quot;, &amp;quot;google_domain&amp;quot;: &amp;quot;google.com&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;images_results&amp;#39;] # Define tools search_tool = Tool(name=&amp;quot;google_search&amp;quot;, description=&amp;quot;Performs Google searches.&amp;quot;, func=google_search) youtube_tool = Tool(name=&amp;quot;youTube_search&amp;quot;, description=&amp;quot;Searches for YouTube videos.&amp;quot;, func=youtube_search) images_tool = Tool(name=&amp;quot;images_search&amp;quot;, description=&amp;quot;Searches for images on Google Images.&amp;quot;, func=images_search) # Setup the ChatOpenAI model for conversational interactions chat_model = ChatOpenAI(model=&amp;#39;gpt-3.5-turbo-1106&amp;#39;, temperature=0) # Define agent prompts input_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;You are the initial contact point for users. Your role is to gather information about the user&amp;#39;s preferences and interests in video games and make sure you understand their requirements. In case of any ambiguity, ask for clarification or in the case of the query not being related to video games, ask for a different query.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) search_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Your main task is to search for game titles that best match the user&amp;#39;s interest. Use the details from the Input Agent to guide your search. Provide a list of relevant game titles.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) details_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Retrieve detailed information for each game identified by the Search Agent. Focus on obtaining the game&amp;#39;s description, genre, platform availability, developer, publisher, release date, Metacritic score if available and links to digital stores that sell the game.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) posters_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Your responsibility is to fetch the official posters for the games provided by the Search Agent. Ensure the images are high quality and relevant.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) trailers_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Obtain the official game trailers for the titles identified by the Search Agent. Ensure that the trailers are current and of high quality.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) recommendation_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;You are responsible for compiling the outputs from all other agents into a cohesive and well-formatted response. Synthesize the game details, images, and trailers into a compelling presentation of game recommendations.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) # Create agents using the prompts input_agent = create_openai_tools_agent(chat_model, [], input_agent_prompt) search_agent = create_openai_tools_agent(chat_model, [search_tool], search_agent_prompt) details_agent = create_openai_tools_agent(chat_model, [search_tool], details_agent_prompt) posters_agent = create_openai_tools_agent(chat_model, [images_tool], posters_agent_prompt) trailers_agent = create_openai_tools_agent(chat_model, [youtube_tool], trailers_agent_prompt) recommendation_agent = create_openai_tools_agent(chat_model, [], recommendation_agent_prompt) # State definition for agents class AgentState(TypedDict): messages: Annotated[Sequence[BaseMessage], operator.add] intermediate_steps: Annotated[Sequence[BaseMessage], operator.add] agent_scratchpad: Annotated[Sequence[BaseMessage], operator.add] input: str # Graph setup state_graph = StateGraph(schema=AgentState) # Add nodes for each agent state_graph.add_node(&amp;quot;input_agent&amp;quot;, input_agent) state_graph.add_node(&amp;quot;search_agent&amp;quot;, search_agent) state_graph.add_node(&amp;quot;details_agent&amp;quot;, details_agent) state_graph.add_node(&amp;quot;posters_agent&amp;quot;, posters_agent) state_graph.add_node(&amp;quot;trailers_agent&amp;quot;, trailers_agent) state_graph.add_node(&amp;quot;recommendation_agent&amp;quot;, recommendation_agent) # Define edges to flow between agents state_graph.add_edge(&amp;quot;input_agent&amp;quot;, &amp;quot;search_agent&amp;quot;) state_graph.add_edge(&amp;quot;search_agent&amp;quot;, &amp;quot;details_agent&amp;quot;) state_graph.add_edge(&amp;quot;details_agent&amp;quot;, &amp;quot;posters_agent&amp;quot;) state_graph.add_edge(&amp;quot;posters_agent&amp;quot;, &amp;quot;trailers_agent&amp;quot;) state_graph.add_edge(&amp;quot;trailers_agent&amp;quot;, &amp;quot;recommendation_agent&amp;quot;) state_graph.add_edge(&amp;quot;recommendation_agent&amp;quot;, END) # Set the entry point to start the agent workflow state_graph.set_entry_point(&amp;quot;input_agent&amp;quot;) # Complete the graph app = state_graph.compile() def main(): print(&amp;quot;Welcome to the Game Recommendation Chatbot!&amp;quot;) while True: user_input = input(&amp;quot;You: &amp;quot;) if user_input.lower() == &amp;#39;exit&amp;#39;: print(&amp;quot;Exiting chatbot...&amp;quot;) break # Initialize the state with the necessary structures state = { &amp;quot;messages&amp;quot;: [HumanMessage(content=user_input)], &amp;quot;agent_scratchpad&amp;quot;: [], # ensure this is always a list &amp;quot;intermediate_steps&amp;quot;: [], # ensure this is always initialized as a list &amp;quot;input&amp;quot;: user_input # this is your actual input string } response = app.invoke(state) print(&amp;quot;Bot:&amp;quot;, response[&amp;quot;messages&amp;quot;][-1].content) if __name__ == &amp;quot;__main__&amp;quot;: main() import os from dotenv import load_dotenv from langchain_openai import ChatOpenAI from langchain_core.messages import HumanMessage, BaseMessage from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain.agents import create_openai_tools_agent, Tool from langgraph.graph import StateGraph, END from typing import Annotated, Sequence, TypedDict import operator from serpapi import GoogleSearch # Load environment variables for API keys load_dotenv() # Configuration serpapi_key = os.getenv(&amp;quot;SERPAPI_API_KEY&amp;quot;) # Define tools using SerpAPI def google_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key, &amp;quot;num&amp;quot;: 5 } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;organic_results&amp;#39;] def youtube_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;youtube&amp;quot;, &amp;quot;search_query&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;video_results&amp;#39;] def images_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google_images&amp;quot;, &amp;quot;google_domain&amp;quot;: &amp;quot;google.com&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;images_results&amp;#39;] # Define tools search_tool = Tool(name=&amp;quot;google_search&amp;quot;, description=&amp;quot;Performs Google searches.&amp;quot;, func=google_search) youtube_tool = Tool(name=&amp;quot;youTube_search&amp;quot;, description=&amp;quot;Searches for YouTube videos.&amp;quot;, func=youtube_search) images_tool = Tool(name=&amp;quot;images_search&amp;quot;, description=&amp;quot;Searches for images on Google Images.&amp;quot;, func=images_search) # Setup the ChatOpenAI model for conversational interactions chat_model = ChatOpenAI(model=&amp;#39;gpt-3.5-turbo-1106&amp;#39;, temperature=0) # Define agent prompts input_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;You are the initial contact point for users. Your role is to gather information about the user&amp;#39;s preferences and interests in video games and make sure you understand their requirements. In case of any ambiguity, ask for clarification or in the case of the query not being related to video games, ask for a different query.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) search_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Your main task is to search for game titles that best match the user&amp;#39;s interest. Use the details from the Input Agent to guide your search. Provide a list of relevant game titles.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) details_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Retrieve detailed information for each game identified by the Search Agent. Focus on obtaining the game&amp;#39;s description, genre, platform availability, developer, publisher, release date, Metacritic score if available and links to digital stores that sell the game.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) posters_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Your responsibility is to fetch the official posters for the games provided by the Search Agent. Ensure the images are high quality and relevant.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) trailers_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Obtain the official game trailers for the titles identified by the Search Agent. Ensure that the trailers are current and of high quality.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) recommendation_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;You are responsible for compiling the outputs from all other agents into a cohesive and well-formatted response. Synthesize the game details, images, and trailers into a compelling presentation of game recommendations.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) # Create agents using the prompts input_agent = create_openai_tools_agent(chat_model, [], input_agent_prompt) search_agent = create_openai_tools_agent(chat_model, [search_tool], search_agent_prompt) details_agent = create_openai_tools_agent(chat_model, [search_tool], details_agent_prompt) posters_agent = create_openai_tools_agent(chat_model, [images_tool], posters_agent_prompt) trailers_agent = create_openai_tools_agent(chat_model, [youtube_tool], trailers_agent_prompt) recommendation_agent = create_openai_tools_agent(chat_model, [], recommendation_agent_prompt) # State definition for agents class AgentState(TypedDict): messages: Annotated[Sequence[BaseMessage], operator.add] intermediate_steps: Annotated[Sequence[BaseMessage], operator.add] agent_scratchpad: Annotated[Sequence[BaseMessage], operator.add] input: str # Graph setup state_graph = StateGraph(schema=AgentState) # Add nodes for each agent state_graph.add_node(&amp;quot;input_agent&amp;quot;, input_agent) state_graph.add_node(&amp;quot;search_agent&amp;quot;, search_agent) state_graph.add_node(&amp;quot;details_agent&amp;quot;, details_agent) state_graph.add_node(&amp;quot;posters_agent&amp;quot;, posters_agent) state_graph.add_node(&amp;quot;trailers_agent&amp;quot;, trailers_agent) state_graph.add_node(&amp;quot;recommendation_agent&amp;quot;, recommendation_agent) # Define edges to flow between agents state_graph.add_edge(&amp;quot;input_agent&amp;quot;, &amp;quot;search_agent&amp;quot;) state_graph.add_edge(&amp;quot;search_agent&amp;quot;, &amp;quot;details_agent&amp;quot;) state_graph.add_edge(&amp;quot;details_agent&amp;quot;, &amp;quot;posters_agent&amp;quot;) state_graph.add_edge(&amp;quot;posters_agent&amp;quot;, &amp;quot;trailers_agent&amp;quot;) state_graph.add_edge(&amp;quot;trailers_agent&amp;quot;, &amp;quot;recommendation_agent&amp;quot;) state_graph.add_edge(&amp;quot;recommendation_agent&amp;quot;, END) # Set the entry point to start the agent workflow state_graph.set_entry_point(&amp;quot;input_agent&amp;quot;) # Complete the graph app = state_graph.compile() def main(): print(&amp;quot;Welcome to the Game Recommendation Chatbot!&amp;quot;) while True: user_input = input(&amp;quot;You: &amp;quot;) if user_input.lower() == &amp;#39;exit&amp;#39;: print(&amp;quot;Exiting chatbot...&amp;quot;) break # Initialize the state with the necessary structures state = { &amp;quot;messages&amp;quot;: [HumanMessage(content=user_input)], &amp;quot;agent_scratchpad&amp;quot;: [], # ensure this is always a list &amp;quot;intermediate_steps&amp;quot;: [], # ensure this is always initialized as a list &amp;quot;input&amp;quot;: user_input # this is your actual input string } response = app.invoke(state) print(&amp;quot;Bot:&amp;quot;, response[&amp;quot;messages&amp;quot;][-1].content) if __name__ == &amp;quot;__main__&amp;quot;: main() &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnEdgeLordWeeb&quot;&gt; /u/AnEdgeLordWeeb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckd61h/error_code_400_error_message_is_too_short_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckd61h/error_code_400_error_message_is_too_short_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckd61h</id><link href="https://www.reddit.com/r/LangChain/comments/1ckd61h/error_code_400_error_message_is_too_short_tools/" /><updated>2024-05-04T23:08:55+00:00</updated><published>2024-05-04T23:08:55+00:00</published><title>Error code: 400 - {'error': {'message': &quot;[] is too short - 'tools'&quot;, 'type': 'invalid_request_error', 'param': None, 'code': None}}</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for some tried and tested ways to measure and improve my RAGs retrieval strategy.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck3k84</id><link href="https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/" /><updated>2024-05-04T15:57:55+00:00</updated><published>2024-05-04T15:57:55+00:00</published><title>What are some ways to test and improve my RAGs retrieval strategy?</title></entry><entry><author><name>/u/Legionnairesgeek</name><uri>https://www.reddit.com/user/Legionnairesgeek</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am new to LangChain and I am developing a application that uses a Pandas Dataframe as document original a Microsoft Excel sheet. I need it answer questions based on it. &lt;/p&gt; &lt;p&gt;How should I proceed? Should I ditch the DataFrame approach and interface it directly ?&lt;/p&gt; &lt;p&gt;How should I use approach it?&lt;/p&gt; &lt;p&gt;How should I add history as i need to have GUI.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Legionnairesgeek&quot;&gt; /u/Legionnairesgeek &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck54cw/how_should_i_develop_a_rag_chatbot_that_uses_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck54cw/how_should_i_develop_a_rag_chatbot_that_uses_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck54cw</id><link href="https://www.reddit.com/r/LangChain/comments/1ck54cw/how_should_i_develop_a_rag_chatbot_that_uses_a/" /><updated>2024-05-04T17:05:47+00:00</updated><published>2024-05-04T17:05:47+00:00</published><title>How should I develop a RAG ChatBot that uses a Pandas Dataframe as a source?</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for some tried and tested ways to measure and improve my RAGs retrieval strategy.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck3k49</id><link href="https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/" /><updated>2024-05-04T15:57:46+00:00</updated><published>2024-05-04T15:57:46+00:00</published><title>What are some ways to test and improve my RAGs retrieval strategy?</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjyiww/generate_powerpoints_using_llama3_a_first_step_in/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/kTSFHuwiwJ0qxPFejuEtCfKnLN42fnt_kIVuZy8HWNM.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b519accc5730b7cdf08908f9c12395c5a9410f79&quot; alt=&quot;Generate PowerPoints using Llama-3 — A first step in automating slide decks&quot; title=&quot;Generate PowerPoints using Llama-3 — A first step in automating slide decks&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://medium.com/firebird-technologies/generate-powerpoints-using-llama-3-a-first-step-in-automating-slide-decks-536f5fcb6e0e&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjyiww/generate_powerpoints_using_llama3_a_first_step_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cjyiww</id><media:thumbnail url="https://external-preview.redd.it/kTSFHuwiwJ0qxPFejuEtCfKnLN42fnt_kIVuZy8HWNM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b519accc5730b7cdf08908f9c12395c5a9410f79" /><link href="https://www.reddit.com/r/LangChain/comments/1cjyiww/generate_powerpoints_using_llama3_a_first_step_in/" /><updated>2024-05-04T11:52:17+00:00</updated><published>2024-05-04T11:52:17+00:00</published><title>Generate PowerPoints using Llama-3 — A first step in automating slide decks</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone used PGVector with HuggingFaceEmbeddings? I&amp;#39;m encountering an error message: &amp;#39;psycopg2.errors.DataException: different vector dimensions 384 and 1536&amp;#39;.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck8mj0/integrating_pgvector_with_hugging_face_embeddings/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck8mj0/integrating_pgvector_with_hugging_face_embeddings/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck8mj0</id><link href="https://www.reddit.com/r/LangChain/comments/1ck8mj0/integrating_pgvector_with_hugging_face_embeddings/" /><updated>2024-05-04T19:40:59+00:00</updated><published>2024-05-04T19:40:59+00:00</published><title>Integrating PGVector with Hugging Face Embeddings: Addressing Dimension Mismatch Errors</title></entry></feed>