<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-31T21:37:26+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/sks8100</name><uri>https://www.reddit.com/user/sks8100</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Have any of you successfully deployed langchain in prod? As in actually getting money for a saas business of some sort? Tell me your experience? Whats your usecase and what Lang product did you use? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sks8100&quot;&gt; /u/sks8100 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d521s1/have_you_gone_to_prod/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d521s1/have_you_gone_to_prod/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d521s1</id><link href="https://www.reddit.com/r/LangChain/comments/1d521s1/have_you_gone_to_prod/" /><updated>2024-05-31T18:06:27+00:00</updated><published>2024-05-31T18:06:27+00:00</published><title>Have you gone to prod?</title></entry><entry><author><name>/u/sks8100</name><uri>https://www.reddit.com/user/sks8100</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I find langchain interesting to use as Iâ€™ve build some initial small pet projects off it but a lot of learning has been done by reading articles and watching some videos. Watching anything put out by landchain is far too complex. They just dump blocks of code and following it is an absolute headache &lt;/p&gt; &lt;p&gt;Are you guys funding the same issue? Also are there any solid langgraph examples where people are using agents and tools to get sql data from a Postgres database? Any examples would be appreciated &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sks8100&quot;&gt; /u/sks8100 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4lwt0/am_i_the_only_one_who_feels_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4lwt0/am_i_the_only_one_who_feels_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4lwt0</id><link href="https://www.reddit.com/r/LangChain/comments/1d4lwt0/am_i_the_only_one_who_feels_langgraph/" /><updated>2024-05-31T03:15:05+00:00</updated><published>2024-05-31T03:15:05+00:00</published><title>Am I the only one who feels LangGraph documentation and tutorials by lanfchain absolutely suck?</title></entry><entry><author><name>/u/AnEdgeLordWeeb</name><uri>https://www.reddit.com/user/AnEdgeLordWeeb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! Does anyone have any idea as to how I can stream &lt;strong&gt;ONLY&lt;/strong&gt; the last message (which should also be the response received by the user) generated by my sequence of agents? I&amp;#39;m trying to build an UI for my LangGraph chatbot using Chainlit, but with the condition of only streaming the part of the message that I want to be displayed. Can anyone help me with that, please? Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnEdgeLordWeeb&quot;&gt; /u/AnEdgeLordWeeb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d54v75/how_to_stream_the_last_message_final_response_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d54v75/how_to_stream_the_last_message_final_response_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d54v75</id><link href="https://www.reddit.com/r/LangChain/comments/1d54v75/how_to_stream_the_last_message_final_response_in/" /><updated>2024-05-31T20:07:19+00:00</updated><published>2024-05-31T20:07:19+00:00</published><title>How to stream the last message (final response) in LangGraph?</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am facing an issue of agent not being able to pick the appropriate tool for the appropriate response?&lt;/p&gt; &lt;p&gt;Need to find better ways to evaluate my prompts. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d53me9/best_resources_on_evaluation_agents_and_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d53me9/best_resources_on_evaluation_agents_and_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d53me9</id><link href="https://www.reddit.com/r/LangChain/comments/1d53me9/best_resources_on_evaluation_agents_and_tools/" /><updated>2024-05-31T19:13:12+00:00</updated><published>2024-05-31T19:13:12+00:00</published><title>Best resources on Evaluation / Agents and Tools</title></entry><entry><author><name>/u/Fluffy_Gur7742</name><uri>https://www.reddit.com/user/Fluffy_Gur7742</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi&lt;/p&gt; &lt;p&gt;I am trying to develop log analysis tool using llms&lt;/p&gt; &lt;p&gt;My requirements are as follows:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;It should extract and find failure lines having some pattern specified in the prompt.&lt;/li&gt; &lt;li&gt;It should load the image of given path from the logs.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Can some please guide how can I create RAG for this data and extract using llm?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fluffy_Gur7742&quot;&gt; /u/Fluffy_Gur7742 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4tmdo/log_analyzer_using_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4tmdo/log_analyzer_using_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4tmdo</id><link href="https://www.reddit.com/r/LangChain/comments/1d4tmdo/log_analyzer_using_llm/" /><updated>2024-05-31T11:44:48+00:00</updated><published>2024-05-31T11:44:48+00:00</published><title>log analyzer using llm</title></entry><entry><author><name>/u/NexWolff</name><uri>https://www.reddit.com/user/NexWolff</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using Langchain&amp;#39;s SQL Agent to execute queries in natural language on my MS-SQL database. Here is my code:&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.agent_toolkits import create_sql_agent&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_openai import ChatOpenAI&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.utilities import SQLDatabase&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;import os&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;db = SQLDatabase.from_uri(&amp;quot;mssql+pyodbc:///?odbc_connect=DRIVER={ODBC Driver 17 for SQL Server};SERVER=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;model_name = &amp;quot;gpt-4&amp;quot;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;openai_api_key = os.environ[&amp;quot;OPENAI_API_KEY&amp;quot;]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;llm = ChatOpenAI(model_name=model_name, temperature=0.0)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;agent = create_sql_agent(llm, db=db, agent_type=&amp;quot;openai-tools&amp;quot;, verbose=True)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;agent.invoke({&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;&amp;quot;input&amp;quot;: &amp;quot;How many article are there?&amp;quot;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;})&lt;/code&gt;&lt;/p&gt; &lt;p&gt;When I run this, the agent starts hallucinating and tries to access a table named &amp;quot;article,&amp;quot; which does not exist. The verbose parameter shows that it should retrieve all tables in the database, but it does not get the correct tables. What could be the issue?&lt;/p&gt; &lt;p&gt;Additionally, I would like to provide metadata to explain the individual tables, but the &amp;quot;metadata&amp;quot; parameter is not accepted.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/NexWolff&quot;&gt; /u/NexWolff &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4y683/cant_retrieve_tables_and_how_can_i_pass_metadata/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4y683/cant_retrieve_tables_and_how_can_i_pass_metadata/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4y683</id><link href="https://www.reddit.com/r/LangChain/comments/1d4y683/cant_retrieve_tables_and_how_can_i_pass_metadata/" /><updated>2024-05-31T15:21:28+00:00</updated><published>2024-05-31T15:21:28+00:00</published><title>Cant retrieve tables and how can i pass metadata?</title></entry><entry><author><name>/u/mr_house7</name><uri>https://www.reddit.com/user/mr_house7</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m using Langchain with LLama.cpp-python because it I was the fastest solution I found out.&lt;/p&gt; &lt;p&gt;I notice an issue on Llama.cpp github that stated that LLama.cpp-python is significantly slower than the original LLama.cpp, which I found to be true, at least for the tests I ran.&lt;/p&gt; &lt;p&gt;I was wondering if there is any way to use only LLama.cpp with Langchain and not Llama.cpp-python.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mr_house7&quot;&gt; /u/mr_house7 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4t3du/langchain_with_llamacpp_not_llamacpppython/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4t3du/langchain_with_llamacpp_not_llamacpppython/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4t3du</id><link href="https://www.reddit.com/r/LangChain/comments/1d4t3du/langchain_with_llamacpp_not_llamacpppython/" /><updated>2024-05-31T11:13:22+00:00</updated><published>2024-05-31T11:13:22+00:00</published><title>Langchain with Llama.cpp not Llama.cpp-python</title></entry><entry><author><name>/u/Sensitive-Pen-1229</name><uri>https://www.reddit.com/user/Sensitive-Pen-1229</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, due to suboptimal documentation, I really struggle to get the results of a evaluation via the langsmith client. If someone could help, that would be amazing!&lt;/p&gt; &lt;p&gt;this is how I create the the exaluation:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;evaluate( predict_using_rag_chain, data=hum_dataset_name, evaluators=get_correctness_evaluators(), experiment_prefix=&amp;quot;correctness&amp;quot;, metadata=metadata ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;On langsmith I can see the results, e.g. via Projects &amp;gt; Evaluators. But if I use &lt;code&gt;client.list_runs(project_name=&amp;quot;evaluators&amp;quot;)&lt;/code&gt; the results contain all runs and I didnt find any correct metadata, e.g. the unique experiment name (e.g. experiment = &amp;quot;correctness-329f6d79&amp;quot;) to filter out a single evaluation on the dataset.&lt;/p&gt; &lt;p&gt;Would be amazing if you have an answer, I cannot imagine I am the only one with that problem.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sensitive-Pen-1229&quot;&gt; /u/Sensitive-Pen-1229 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4xmvw/langsmith_get_test_results_python_sdk/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4xmvw/langsmith_get_test_results_python_sdk/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4xmvw</id><link href="https://www.reddit.com/r/LangChain/comments/1d4xmvw/langsmith_get_test_results_python_sdk/" /><updated>2024-05-31T14:58:09+00:00</updated><published>2024-05-31T14:58:09+00:00</published><title>Langsmith - Get Test Results Python SDK</title></entry><entry><author><name>/u/jscraft</name><uri>https://www.reddit.com/user/jscraft</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ssom/why_learn_langchain_as_a_javascript_developer/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/2347JJ6JbmR5WGmdxSM3iu0OnGohPD3MltcLei8lmx8.jpg?width=108&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7a4559964a97155995aa6f0c96a36eebba24728a&quot; alt=&quot;Why learn LangChain (as a JavaScript developer)?&quot; title=&quot;Why learn LangChain (as a JavaScript developer)?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jscraft&quot;&gt; /u/jscraft &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.js-craft.io/blog/learn-langchain-javascript-developer/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ssom/why_learn_langchain_as_a_javascript_developer/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d4ssom</id><media:thumbnail url="https://external-preview.redd.it/2347JJ6JbmR5WGmdxSM3iu0OnGohPD3MltcLei8lmx8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a4559964a97155995aa6f0c96a36eebba24728a" /><link href="https://www.reddit.com/r/LangChain/comments/1d4ssom/why_learn_langchain_as_a_javascript_developer/" /><updated>2024-05-31T10:55:03+00:00</updated><published>2024-05-31T10:55:03+00:00</published><title>Why learn LangChain (as a JavaScript developer)?</title></entry><entry><author><name>/u/MoronSlayer42</name><uri>https://www.reddit.com/user/MoronSlayer42</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using RunnableWithMessageHistory for an application that needs sources and chat history. But unlike ConversationBufferWindowMemory there is no way to limit memory in RunnableWithMessageHistory, any way I can limit the chat history to a specific number of turns?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MoronSlayer42&quot;&gt; /u/MoronSlayer42 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4n1ci/limiting_memory_in_runnablewithmessagehistory/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4n1ci/limiting_memory_in_runnablewithmessagehistory/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4n1ci</id><link href="https://www.reddit.com/r/LangChain/comments/1d4n1ci/limiting_memory_in_runnablewithmessagehistory/" /><updated>2024-05-31T04:18:38+00:00</updated><published>2024-05-31T04:18:38+00:00</published><title>Limiting memory in RunnableWithMessageHistory</title></entry><entry><author><name>/u/Own_Mud1038</name><uri>https://www.reddit.com/user/Own_Mud1038</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I&amp;#39;m a newbie in the world of RAGs and LLMs but is it normal that the document retrieval takes 9-10 minutes?&lt;/p&gt; &lt;p&gt;I&amp;#39;m using locally the llama3:8b model with ollama, Chroma es a vectorstore but these parts are quite fast compared to the invoke() method which is the slowest one. My computer has 64 GB of RAM.&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Own_Mud1038&quot;&gt; /u/Own_Mud1038 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4p6t9/long_running_time_for_document_retrieval_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4p6t9/long_running_time_for_document_retrieval_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4p6t9</id><link href="https://www.reddit.com/r/LangChain/comments/1d4p6t9/long_running_time_for_document_retrieval_with/" /><updated>2024-05-31T06:36:22+00:00</updated><published>2024-05-31T06:36:22+00:00</published><title>Long running time for document retrieval with ollama3</title></entry><entry><author><name>/u/cr33dcode</name><uri>https://www.reddit.com/user/cr33dcode</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I need a way to ingest 10 PDFs containing financial information and then I need to able to ask an LLM to make me custom charts and graphs based on the data there is in those 10PDFs. need the LLM to have context of all 120 PDFs or it to do a good job. How do i proceed ahead with something like this? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cr33dcode&quot;&gt; /u/cr33dcode &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4o9yr/im_trying_out_a_new_tool_and_i_need_some_help/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4o9yr/im_trying_out_a_new_tool_and_i_need_some_help/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4o9yr</id><link href="https://www.reddit.com/r/LangChain/comments/1d4o9yr/im_trying_out_a_new_tool_and_i_need_some_help/" /><updated>2024-05-31T05:34:53+00:00</updated><published>2024-05-31T05:34:53+00:00</published><title>I'm trying out a new tool and I need some help</title></entry><entry><author><name>/u/No-Channel1897</name><uri>https://www.reddit.com/user/No-Channel1897</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;h2&gt;Famous YouTube Personality Finance Chat Bot&lt;/h2&gt; &lt;hr/&gt; &lt;ul&gt; &lt;li&gt;I want to create a chat bot on a famous YouTube personality.&lt;/li&gt; &lt;li&gt;The bot will talk and have an attitude similar to that person.&lt;/li&gt; &lt;li&gt;I will built this with python, Django, and LangChain.&lt;/li&gt; &lt;li&gt;I will use their YouTube videos to give context to the LLM.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;To-do&lt;/h2&gt; &lt;hr/&gt; &lt;ol&gt; &lt;li&gt;Build a simple RAG&lt;/li&gt; &lt;li&gt;Maintain chat history in PG Vector&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Suggest any extra ideas on this.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No-Channel1897&quot;&gt; /u/No-Channel1897 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ngwg/famous_youtube_personality_finance_chat_bot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ngwg/famous_youtube_personality_finance_chat_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4ngwg</id><link href="https://www.reddit.com/r/LangChain/comments/1d4ngwg/famous_youtube_personality_finance_chat_bot/" /><updated>2024-05-31T04:44:46+00:00</updated><published>2024-05-31T04:44:46+00:00</published><title>Famous YouTube Personality Finance Chat Bot</title></entry><entry><author><name>/u/Jamb9876</name><uri>https://www.reddit.com/user/Jamb9876</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using directoryloader to load pdfs but I need to process them and remove certain words that are found in them. &lt;/p&gt; &lt;p&gt;I would prefer not to stop using langchain but this is a big issue as I get errors loading my data into a graphing database. &lt;/p&gt; &lt;p&gt;I could convert the Document into a dict and process but then how do I convert it back for chunking and embedding?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jamb9876&quot;&gt; /u/Jamb9876 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ihev/preprocessing_using_directoryloader/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ihev/preprocessing_using_directoryloader/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4ihev</id><link href="https://www.reddit.com/r/LangChain/comments/1d4ihev/preprocessing_using_directoryloader/" /><updated>2024-05-31T00:14:42+00:00</updated><published>2024-05-31T00:14:42+00:00</published><title>Preprocessing using directoryloader</title></entry><entry><author><name>/u/Major-Giraffe-2483</name><uri>https://www.reddit.com/user/Major-Giraffe-2483</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I&amp;#39;m very new to LLMs and I got confused on how to proceed. At the moment I want to use LanChain and ChatGPT.&lt;/p&gt; &lt;p&gt;I have this task:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;in the backend of my app I have a few functions that query SQL database and return a JSON&lt;/li&gt; &lt;li&gt;the ChatBot should take the user question as an input&lt;/li&gt; &lt;li&gt;the ChatBot should choose which functions to call&lt;/li&gt; &lt;li&gt;based on the JSON object/s returned the ChatBot should be able to answer the user`s question&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I&amp;#39;m not sure what would be the best approach here - RAG, Agent, OpenAI Function calling. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Major-Giraffe-2483&quot;&gt; /u/Major-Giraffe-2483 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4a55w/help_on_creating_a_chatbot_for_inapp_private_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4a55w/help_on_creating_a_chatbot_for_inapp_private_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4a55w</id><link href="https://www.reddit.com/r/LangChain/comments/1d4a55w/help_on_creating_a_chatbot_for_inapp_private_data/" /><updated>2024-05-30T17:59:52+00:00</updated><published>2024-05-30T17:59:52+00:00</published><title>Help on creating a ChatBot for in-app private data</title></entry><entry><author><name>/u/Plus_Reaction3578</name><uri>https://www.reddit.com/user/Plus_Reaction3578</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks, I was just wondering if there is a feature on the langSmith where we can manually evaluate the inputs/outputs of our LLM. On the documentation they talk about how there can be manual evaluators that can be set up but I can&amp;#39;t seem to find it.&lt;/p&gt; &lt;p&gt;any help would be appreciated.&lt;/p&gt; &lt;p&gt;thanks in advance &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Plus_Reaction3578&quot;&gt; /u/Plus_Reaction3578 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4d5mp/question_about_manual_testing_on_langsmith_hub/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4d5mp/question_about_manual_testing_on_langsmith_hub/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4d5mp</id><link href="https://www.reddit.com/r/LangChain/comments/1d4d5mp/question_about_manual_testing_on_langsmith_hub/" /><updated>2024-05-30T20:08:05+00:00</updated><published>2024-05-30T20:08:05+00:00</published><title>Question about manual testing on LangSmith hub</title></entry><entry><author><name>/u/Your_Quantum_Friend</name><uri>https://www.reddit.com/user/Your_Quantum_Friend</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So, I am working on a RAG framework and for that I am currently using ChromaDB with all-MiniLM-L6-v2 embedding function. But one of my colleague suggested using Elastic Search for they mentioned it is much faster and accurate. So I did my own testing and found that for top_k=5, ES is 100% faster than ChromaDB. For all top_k values, ES is performing much faster. Also for top_k = 5, ES retrieved current document link 37% times accurately than ChromaDB. &lt;/p&gt; &lt;p&gt;However, when I read things online, it is mentioned that ChromaDB is faster and is used by many companies as their go to vectordb. What do you think could be the possible reason for this? Is there anything that I can use to improve ChromaDB&amp;#39;s performance and accuracy?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Your_Quantum_Friend&quot;&gt; /u/Your_Quantum_Friend &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3xtlq/is_elastic_search_better_than_chromadb/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3xtlq/is_elastic_search_better_than_chromadb/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3xtlq</id><link href="https://www.reddit.com/r/LangChain/comments/1d3xtlq/is_elastic_search_better_than_chromadb/" /><updated>2024-05-30T06:51:11+00:00</updated><published>2024-05-30T06:51:11+00:00</published><title>Is Elastic search better than ChromaDB?</title></entry><entry><author><name>/u/Party_Jellyfish5380</name><uri>https://www.reddit.com/user/Party_Jellyfish5380</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a list of json objects that have a module name and a link to a file. I have this files downloaded. However when I query something about a module name, it only retrieves that json object and does not retrieve the file associated with that json object. I am assuming a solution would be to add module names to all the files so it relates them, however is there a better way?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Party_Jellyfish5380&quot;&gt; /u/Party_Jellyfish5380 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d49off/rag_relation_between_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d49off/rag_relation_between_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d49off</id><link href="https://www.reddit.com/r/LangChain/comments/1d49off/rag_relation_between_documents/" /><updated>2024-05-30T17:33:31+00:00</updated><published>2024-05-30T17:33:31+00:00</published><title>RAG relation between documents</title></entry><entry><author><name>/u/Electronic-Mousse-39</name><uri>https://www.reddit.com/user/Electronic-Mousse-39</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a project where I need to fine-tune a Large Language Model (LLM) such as LLAMA3 for a specific task and then deploy it on the company&amp;#39;s server as a chatbot to recommend &amp;#39;questionnaires / surveys&amp;#39; based on studies described by the users.&lt;/p&gt; &lt;p&gt;As I am new to working with LLMs, I need some guidance. Here is my planned approach:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Obtain a base model and train it on my dataset using a fine-tuning method like QLoRa.&lt;/li&gt; &lt;li&gt;Save the trained model and convert it into a GGFU file using LLAMA.cpp, allowing for local testing. (I&amp;#39;m planning to using langchain at this step)&lt;/li&gt; &lt;li&gt;Once the model is tested and verified, create an API that enables users to interact with the model.&lt;/li&gt; &lt;li&gt;Develop a Docker image of the application, which will consist of the API at this stage.&lt;/li&gt; &lt;li&gt;Deploy the API on the companyâ€™s private server using the Docker image and connect it to our website.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Is this the correct approach to achieve my goal? Thank you for your help.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Electronic-Mousse-39&quot;&gt; /u/Electronic-Mousse-39 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d405fu/how_to_deploy_a_finetuned_model_on_a_private/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d405fu/how_to_deploy_a_finetuned_model_on_a_private/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d405fu</id><link href="https://www.reddit.com/r/LangChain/comments/1d405fu/how_to_deploy_a_finetuned_model_on_a_private/" /><updated>2024-05-30T09:43:10+00:00</updated><published>2024-05-30T09:43:10+00:00</published><title>How to deploy a finetuned model on a private server?</title></entry><entry><author><name>/u/vladeziegler</name><uri>https://www.reddit.com/user/vladeziegler</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone! I&amp;#39;m trying to wrap my head around how I could integrate lemonai agents into my workflow. It says that it integrates with &lt;code&gt;Airtable&lt;/code&gt;, &lt;code&gt;Hubspot&lt;/code&gt;, &lt;code&gt;Discord&lt;/code&gt;, &lt;code&gt;Notion&lt;/code&gt;, &lt;code&gt;Slack&lt;/code&gt; and &lt;code&gt;Github&lt;/code&gt;. It sounds super powerful and i was wondering if you had any feedback ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/vladeziegler&quot;&gt; /u/vladeziegler &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d44719/langchain_lemonai_tool/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d44719/langchain_lemonai_tool/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d44719</id><link href="https://www.reddit.com/r/LangChain/comments/1d44719/langchain_lemonai_tool/" /><updated>2024-05-30T13:35:20+00:00</updated><published>2024-05-30T13:35:20+00:00</published><title>Langchain lemonai tool</title></entry><entry><author><name>/u/weluuu</name><uri>https://www.reddit.com/user/weluuu</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am looking for tutorial/repo on RAG with Neptune for graph data&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/weluuu&quot;&gt; /u/weluuu &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d42rsd/rag_with_aws_neptune/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d42rsd/rag_with_aws_neptune/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d42rsd</id><link href="https://www.reddit.com/r/LangChain/comments/1d42rsd/rag_with_aws_neptune/" /><updated>2024-05-30T12:24:12+00:00</updated><published>2024-05-30T12:24:12+00:00</published><title>Rag with AWS Neptune</title></entry><entry><author><name>/u/youniss_k</name><uri>https://www.reddit.com/user/youniss_k</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3fi3d/extracting_tables_in_pdfs/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/-ivhH6_-uoFWCTRN6E43T7c6ZJ7eFpFh8Jz46K6RArM.jpg&quot; alt=&quot;Extracting Tables in PDFs&quot; title=&quot;Extracting Tables in PDFs&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone. I am having troubles with extracting Tables in PDFs. I have PDFs of pricing options for different types of bricks. Theyre meant for marketing purposes actually, but I want to extract this value into JSON objects using Langchain.&lt;/p&gt; &lt;p&gt;Take a look:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/z05xvep2zd3d1.png?width=1910&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1cefd038628e6921ad1a610a6237838ddc892ff7&quot;&gt;Pricing options for bricks inside a PDF&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I have already tried using &lt;a href=&quot;http://Unstructured.io&quot;&gt;Unstructured.io&lt;/a&gt; however the JSON it returned wasnt good and it didnt even detect the Tables.&lt;/p&gt; &lt;p&gt;This is the workflow im trying to achieve:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;User loads in PDF of pricing list&lt;/li&gt; &lt;li&gt;Document is split per table (I only need the info of the data, nothing else. Some documents extend 100 pages)&lt;/li&gt; &lt;li&gt;For each Table, an LLM takes the information and creates a meaningful JSON out of it&lt;/li&gt; &lt;li&gt;I save the JSON inside a db&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;How would I do this splitting?&lt;/p&gt; &lt;p&gt;Thank you all in advance for your help :)&lt;/p&gt; &lt;p&gt;UPDATE: I managed to get great results! Thanks to everyone who helped. Really nice to have recieved and tried out your suggestion. The one that worked for me best was from @&lt;a href=&quot;https://www.reddit.com/user/Classic_essays/&quot;&gt;Classic_essays&lt;/a&gt; . &lt;/p&gt; &lt;p&gt;Heres a sneak peek:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/l3cvw4jeem3d1.png?width=1326&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=19f7aa646102fc562657ee1ff51b70b28ec631b2&quot;&gt;https://preview.redd.it/l3cvw4jeem3d1.png?width=1326&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=19f7aa646102fc562657ee1ff51b70b28ec631b2&lt;/a&gt;&lt;/p&gt; &lt;p&gt;For those interested in the sollution I did:&lt;/p&gt; &lt;p&gt;Very simple: I splitted the PDF by page and encoded each page with base64 and stored it in an array. Then I sent the single page to GPT with a prompt.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;response = client.chat.completions.create( model=&amp;quot;gpt-4o&amp;quot;, messages=[ {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: instructions_propmt}, { &amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;image_url&amp;quot;, &amp;quot;image_url&amp;quot;: { &amp;quot;url&amp;quot;: f&amp;quot;data:image/jpeg;base64,{base64_image}&amp;quot;, }, }, ], } ], max_tokens=300, ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;NOTE: This is definitely NOT the cheapest option (for me, around â‚¬0.02 per page for gpt-4o) however it is the one that game me the highest accuracy which was important for this project. &lt;/p&gt; &lt;p&gt;Again thank you to everyone!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/youniss_k&quot;&gt; /u/youniss_k &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3fi3d/extracting_tables_in_pdfs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3fi3d/extracting_tables_in_pdfs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d3fi3d</id><media:thumbnail url="https://b.thumbs.redditmedia.com/-ivhH6_-uoFWCTRN6E43T7c6ZJ7eFpFh8Jz46K6RArM.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1d3fi3d/extracting_tables_in_pdfs/" /><updated>2024-05-29T15:52:19+00:00</updated><published>2024-05-29T15:52:19+00:00</published><title>Extracting Tables in PDFs</title></entry><entry><author><name>/u/Ok_Rich9755</name><uri>https://www.reddit.com/user/Ok_Rich9755</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for a vector database that can scale - around 500m+ embeddings. I want to know how GCP Vector Search compares to other solutions such as QDrant and Milvus. Seems like GCP Vector Search is super easy to get started and has high performance. I&amp;#39;m not sure why more people aren&amp;#39;t talking about it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ok_Rich9755&quot;&gt; /u/Ok_Rich9755 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3tx3f/gcp_vector_search_as_vector_database/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3tx3f/gcp_vector_search_as_vector_database/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3tx3f</id><link href="https://www.reddit.com/r/LangChain/comments/1d3tx3f/gcp_vector_search_as_vector_database/" /><updated>2024-05-30T02:51:00+00:00</updated><published>2024-05-30T02:51:00+00:00</published><title>GCP Vector Search as Vector Database?</title></entry><entry><author><name>/u/UpvoteBeast</name><uri>https://www.reddit.com/user/UpvoteBeast</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3z34d/leveraging_langchain_and_streamlit_for/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/RgU7NF19lXAhYZHN-OsTAuNdnR89kcTmEizA2OTFiuQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5a8a4ef6fb91fca3e92707cbc5896629d49ad49f&quot; alt=&quot;Leveraging LangChain and Streamlit for Interactive CSV Analysis&quot; title=&quot;Leveraging LangChain and Streamlit for Interactive CSV Analysis&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpvoteBeast&quot;&gt; /u/UpvoteBeast &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://dly.to/Im4DJK9gQzv&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3z34d/leveraging_langchain_and_streamlit_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d3z34d</id><media:thumbnail url="https://external-preview.redd.it/RgU7NF19lXAhYZHN-OsTAuNdnR89kcTmEizA2OTFiuQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5a8a4ef6fb91fca3e92707cbc5896629d49ad49f" /><link href="https://www.reddit.com/r/LangChain/comments/1d3z34d/leveraging_langchain_and_streamlit_for/" /><updated>2024-05-30T08:24:25+00:00</updated><published>2024-05-30T08:24:25+00:00</published><title>Leveraging LangChain and Streamlit for Interactive CSV Analysis</title></entry><entry><author><name>/u/AdExpensive4298</name><uri>https://www.reddit.com/user/AdExpensive4298</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Basically I am creating an app in which you are able to chat with the openai and I want to store the last 7 times or 7 days worth of message history from user. Now the problem is if i plainly save the chat messages then it takes up a lot of token size. I tried using the conversation summary buffer and all kinds of memory but either they were also resulting in a lot of tokens or did not give as expected output.&lt;/p&gt; &lt;p&gt;My question is that is there a way that once the user is done with the chat I can store the chat in a vector db and then whenever a user chats with the AI again it first checks the vector db for a reference of that object and returns related data and then my open ai llm with a specified prompt and the data collected give a response whereas if there is no data found speific to the object then my llm plainly uses the prompt I have given it?&lt;/p&gt; &lt;p&gt;Kindly give me if there are any other ways to do it &lt;/p&gt; &lt;p&gt;My tech stack is&lt;br/&gt; Frontend Flutter, Backend Python therefore it would be easy for me to attach langchain to python and just push requests from my app to my hosted api using python. &lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AdExpensive4298&quot;&gt; /u/AdExpensive4298 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3ok4l/question_about_chatbot_and_chat_message_history/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3ok4l/question_about_chatbot_and_chat_message_history/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3ok4l</id><link href="https://www.reddit.com/r/LangChain/comments/1d3ok4l/question_about_chatbot_and_chat_message_history/" /><updated>2024-05-29T22:27:35+00:00</updated><published>2024-05-29T22:27:35+00:00</published><title>Question about chatbot and chat message history with vector db</title></entry></feed>