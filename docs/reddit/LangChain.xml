<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-08-08T18:32:50+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/neilkatz</name><uri>https://www.reddit.com/user/neilkatz</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1enbqew/multimodal_rag_explainer_3_paths_to_integrating/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/X68ByIY0sc7DCW0vPJh2aPA1NayqYM4-T62ZwCr2iEc.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=05195d05473ac42b4ae8434d45ed950a6308ce12&quot; alt=&quot;Multimodal RAG Explainer: 3 Paths to Integrating Text, Images and Audio in RAG, Which One is Best?&quot; title=&quot;Multimodal RAG Explainer: 3 Paths to Integrating Text, Images and Audio in RAG, Which One is Best?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://preview.redd.it/h283ore4zghd1.png?width=1600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=16b9c6a5b9cdbe1c5107b886cb1769fa364e2917&quot;&gt;https://preview.redd.it/h283ore4zghd1.png?width=1600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=16b9c6a5b9cdbe1c5107b886cb1769fa364e2917&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Hi All,&lt;/p&gt; &lt;p&gt;This post is a adaptation of a Multimodal episode of RAG Masters, a weekly Youtube show I do with Daniel Warfield. Each week we explore a different topic to help engineers build better RAG. Some times we know a lot. Sometimes we&amp;#39;re learning as we go, just like everyone.&lt;/p&gt; &lt;p&gt;The show is here if you want to check it out, but I&amp;#39;ll keep posting a lot of the content here regardless.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ZetGV7gtyQw&quot;&gt;https://www.youtube.com/watch?v=ZetGV7gtyQw&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Also, my shop &lt;a href=&quot;http://EyeLevel.ai&quot;&gt;EyeLevel.ai&lt;/a&gt; has some kick ass tools for building advanced RAG in just a few API calls with SOTA accuracy. The APIs are especially good with complex documents.&lt;/p&gt; &lt;p&gt;Ok, on to the post.&lt;/p&gt; &lt;h1&gt;What is Multimodal RAG?&lt;/h1&gt; &lt;p&gt;Multimodal RAG is an advanced extension of traditional Retrieval-Augmented Generation systems. Classic RAG involves a retrieval engine that searches a database of text documents to find relevant information and injects this data into a prompt for a language model to generate a response. Multimodal RAG expands this by including non-text data types, which enhances the model&amp;#39;s ability to understand and generate responses based on a more comprehensive set of inputs.&lt;/p&gt; &lt;p&gt;Taking multimodal inputs allows for RAG engineers to build a more complex retrieval engine that can ask a store of information about information across different mediums. This means that the retrieval engine can grab data from various sources—whether text, images, audio, or video—and use that information to answer a query. For instance, an expert&amp;#39;s audio commentary on the Eiffel Tower can be retrieved alongside text and image data to provide a more holistic response that anchors the answer in the data provided.&lt;/p&gt; &lt;h1&gt;How Multimodal RAG Works&lt;/h1&gt; &lt;p&gt;The mechanics of Multimodal RAG involve transforming different data types into a structured data format like vectors that a model can process. This allows the model to retrieve and generate information across multiple modalities seamlessly.&lt;/p&gt; &lt;p&gt;Once these data types are encoded into vectors, they can be stored in a vector space or similar storage vehicle, enabling the model to find relevant information regardless of the original data type. This process could involve clustering similar data and separating dissimilar data, making it easier to retrieve the most pertinent information for a given query.&lt;/p&gt; &lt;h1&gt;Three Approaches to Multimodal RAG&lt;/h1&gt; &lt;p&gt;Implementing Multimodal RAG can be approached in a few distinct ways, each with its advantages and challenges. The three main methods include using a single multimodal model, employing a grounded modality approach, and utilizing multiple encoders.&lt;/p&gt; &lt;h1&gt;Single Multimodal Model&lt;/h1&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/7hdmvcfj0hhd1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ce25486892694d6110e70084d6042ea1d2fc604f&quot;&gt;Image: Multimodal RAG diagram depicting the storage of Audio, Image, and Text encodings to answer a user query.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This approach uses a unified model trained to encode different types of data (text, images, audio) into a common vector space. The model can then perform retrieval and generation across these different data types seamlessly. A single multimodal approach tends to be one of the most common approaches people talk about when they talk about multimodal RAG.&lt;/p&gt; &lt;p&gt;This method simplifies the process but relies heavily on the model’s ability to accurately encode and retrieve multimodal data. However, if the model is well-trained, it can store and retrieve similar information across different modalities effectively.&lt;/p&gt; &lt;p&gt;Google is a great example of using a single multimodal mode.&lt;/p&gt; &lt;h1&gt;Grounded Modality (Text-Based)&lt;/h1&gt; &lt;p&gt;In this approach, all data types are converted into text descriptions before being encoded and stored. This method leverages the strength of text-based models but may involve some loss of information during the conversion process.&lt;/p&gt; &lt;p&gt;Turning all data types into one modality creates a unified set of information for the model to retrieve, and today’s models are strongest on text. That’s not to say in the future there won&amp;#39;t be models that are better suited for other modalities. And that future might be months not years. But for today’s powerhouse models, they started out as text machines and that is still where they are strongest.&lt;/p&gt; &lt;p&gt;This approach allows the use of robust text-based models for encoding and retrieval, making it a practical solution for environments where text is the primary data type.&lt;/p&gt; &lt;h1&gt;Multiple Encoders&lt;/h1&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/3wmxg7yl0hhd1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=80a2501a4c0b4c349fd93578c1c528c37848c97d&quot;&gt;Image: A Multimodal RAG diagram that relies on separately aligned models to handle different modalities from a user query.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This method employs separate models to encode different data types. Each type of data (audio, images, text) is processed by its respective model, and the results are integrated later in the retrieval process. Passing them through a set of encoders that can play nicely together creates an environment where each model and encoder can be fine-tuned to play to its particular strengths. &lt;/p&gt; &lt;p&gt;This approach allows for specialized encoding but increases complexity in managing multiple models. It offers the flexibility to use the best model for each data type, enhancing the accuracy and relevance of the retrieved information. But often it can be the most difficult to implement and maintain due to the increased complexity of inputs and outputs. &lt;/p&gt; &lt;p&gt;With the emergence of powerful models that are starting to outperform other models in specific modalities, this approach to multimodal RAG may grow in popularity.&lt;/p&gt; &lt;h1&gt;Challenges and Considerations&lt;/h1&gt; &lt;p&gt;Implementing Multimodal RAG comes with its own set of challenges, such as handling temporal changes in data and ensuring the accuracy of the retrieval and generation process. &lt;/p&gt; &lt;p&gt;Temporal changes, like the varying appearances of the Eiffel Tower over time, pose a significant challenge. Ensuring that the retrieved information is temporally accurate and relevant requires sophisticated handling of metadata and context which can be even more challenging when trying to pull data from multiple modalities like images and audio.&lt;/p&gt; &lt;p&gt;Another consideration is the balance between using a single unified model and multiple specialized models. While a single model offers simplicity, multiple models provide more tailored encoding for different data types. This decision depends on the specific application and the need for flexibility.&lt;/p&gt; &lt;h1&gt;Practical Applications and Future Prospects&lt;/h1&gt; &lt;p&gt;Multimodal RAG holds immense potential for various practical applications, from enhancing search engines to improving AI-driven personal assistants. By integrating multiple data types, these systems can provide richer, more nuanced responses, improving user experience and satisfaction.&lt;/p&gt; &lt;p&gt;Looking forward, the field of Multimodal RAG is poised for significant advancements. As models continue to improve and new techniques are developed, the ability to effectively integrate and leverage multiple data types will become increasingly crucial. This progress will open up new opportunities for powerful applications and improved AI performance.&lt;/p&gt; &lt;h1&gt;Conclusion&lt;/h1&gt; &lt;p&gt;Multimodal RAG represents a significant advancement in AI, as it can enable richer and more contextually accurate information retrieval and generation that grounds the model in the truth of the data across modalities. While the field continues to evolve, the various approaches to implementing Multimodal RAG offer different trade-offs between simplicity, flexibility, and complexity. As technology progresses, the ability to effectively integrate and leverage multiple data types will be crucial for developing advanced AI applications.&lt;/p&gt; &lt;p&gt;Full Episode:&lt;br/&gt; &lt;a href=&quot;https://www.youtube.com/watch?v=ZetGV7gtyQw&quot;&gt;https://www.youtube.com/watch?v=ZetGV7gtyQw&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/neilkatz&quot;&gt; /u/neilkatz &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1enbqew/multimodal_rag_explainer_3_paths_to_integrating/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1enbqew/multimodal_rag_explainer_3_paths_to_integrating/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1enbqew</id><media:thumbnail url="https://external-preview.redd.it/X68ByIY0sc7DCW0vPJh2aPA1NayqYM4-T62ZwCr2iEc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=05195d05473ac42b4ae8434d45ed950a6308ce12" /><link href="https://www.reddit.com/r/LangChain/comments/1enbqew/multimodal_rag_explainer_3_paths_to_integrating/" /><updated>2024-08-08T17:20:07+00:00</updated><published>2024-08-08T17:20:07+00:00</published><title>Multimodal RAG Explainer: 3 Paths to Integrating Text, Images and Audio in RAG, Which One is Best?</title></entry><entry><author><name>/u/Confident-Honeydew66</name><uri>https://www.reddit.com/user/Confident-Honeydew66</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Confident-Honeydew66&quot;&gt; /u/Confident-Honeydew66 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://thepi.pe/evals&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en8ook/not_sure_what_llm_to_use_for_for_your_rag_system/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en8ook</id><link href="https://www.reddit.com/r/LangChain/comments/1en8ook/not_sure_what_llm_to_use_for_for_your_rag_system/" /><updated>2024-08-08T15:18:37+00:00</updated><published>2024-08-08T15:18:37+00:00</published><title>Not sure what LLM to use for for your RAG system? Here's a price/size/performance comparison of every state-of-the-art LLM.</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Langfuse is a free alternate for Langsmith for Generative AI based applications for debugging and tracing. This video explains how to get Started with Langfuse : &lt;a href=&quot;https://youtu.be/fIQIfIK6v0o?si=hzeG4matNCCZ9Bt_&quot;&gt;https://youtu.be/fIQIfIK6v0o?si=hzeG4matNCCZ9Bt_&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en73et/langfuse_for_llm_tracing_for_beginners/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en73et/langfuse_for_llm_tracing_for_beginners/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en73et</id><link href="https://www.reddit.com/r/LangChain/comments/1en73et/langfuse_for_llm_tracing_for_beginners/" /><updated>2024-08-08T14:14:57+00:00</updated><published>2024-08-08T14:14:57+00:00</published><title>Langfuse for LLM tracing for beginners</title></entry><entry><author><name>/u/Thin_Peach6371</name><uri>https://www.reddit.com/user/Thin_Peach6371</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m a Java developer interested in getting into AI software development. I see there&amp;#39;s a ton of info on LangChain for Python, but not as much on LangChain4j for Java. Should I dive into Python and start developing with it, or can I learn from the langchain docs (and youtube videos) and then apply that knowledge to Java (just with different syntax)? Any advice?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Thin_Peach6371&quot;&gt; /u/Thin_Peach6371 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1enagg9/what_are_the_current_limitations_of_langchain4j/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1enagg9/what_are_the_current_limitations_of_langchain4j/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1enagg9</id><link href="https://www.reddit.com/r/LangChain/comments/1enagg9/what_are_the_current_limitations_of_langchain4j/" /><updated>2024-08-08T16:29:30+00:00</updated><published>2024-08-08T16:29:30+00:00</published><title>What are the current limitations of LangChain4j compared to the Python version</title></entry><entry><author><name>/u/julio_oa</name><uri>https://www.reddit.com/user/julio_oa</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In a RAG system, how do you avoid the bot to go retrieve information when the questions are just small talk? For example the user says “Hi how are you?” And the bot goes and triggers all the RAG logic and gets all the information and makes a lot of drama and it replies “good thanks for asking” hahah anybody dealing with this issue?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/julio_oa&quot;&gt; /u/julio_oa &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en5h33/rag_system_to_detect_small_talk/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en5h33/rag_system_to_detect_small_talk/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en5h33</id><link href="https://www.reddit.com/r/LangChain/comments/1en5h33/rag_system_to_detect_small_talk/" /><updated>2024-08-08T13:05:46+00:00</updated><published>2024-08-08T13:05:46+00:00</published><title>RAG system to detect small talk</title></entry><entry><author><name>/u/pekkamama</name><uri>https://www.reddit.com/user/pekkamama</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e5pe1a/optimal_rag_for_text2sql/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button&quot;&gt;https://www.reddit.com/r/LangChain/comments/1e5pe1a/optimal_rag_for_text2sql/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button&lt;/a&gt; &lt;/p&gt; &lt;p&gt;I built a working text-2-SQL pipeline that runs queries on million of records. 20+ tables. It leverages Claude 3.5 sonnet and gets the work done 7/10 very well on a few complex prompts, multiple joins and conditional clauses. At the infra level, the database has been modified to create and include a few views that would help make much more sense of the data. &lt;/p&gt; &lt;p&gt;Now, I am in charge of building an analysis agent on top of it. &lt;/p&gt; &lt;p&gt;Here&amp;#39;s what I was thinking: I&amp;#39;ll have the text-2-sql agent translate to query, retrieve the tabular information from the database and return the final table before applying any conditions or other arithmetic operations. And then pass on the resulting table to pandas agent along with the originally asked question. &lt;/p&gt; &lt;p&gt;And then the pandas agent cook. But, I&amp;#39;m not a 100% sure whether this is the ideal approach. OR if there is any other way to work with this. Lemme know if you have any thoughts!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pekkamama&quot;&gt; /u/pekkamama &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en87i9/text2sqlpandas_pipeline_how_do_i_build_this/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en87i9/text2sqlpandas_pipeline_how_do_i_build_this/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en87i9</id><link href="https://www.reddit.com/r/LangChain/comments/1en87i9/text2sqlpandas_pipeline_how_do_i_build_this/" /><updated>2024-08-08T15:00:03+00:00</updated><published>2024-08-08T15:00:03+00:00</published><title>Text-2-SQL-Pandas Pipeline: HOW DO I BUILD THIS!</title></entry><entry><author><name>/u/Rohitha2107</name><uri>https://www.reddit.com/user/Rohitha2107</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello Community,&lt;/p&gt; &lt;p&gt;I am trying to summarize using map_reduce implementation and I have a text file that has ~78000 token(according to Open AI tokenizer) and I am using mistralai/Mistral-7B-Instruct-v0.3 model through huggingface inference and I run into the above error and the ouputs gets cut off in the middle. Can you please advice how to fix this? The model has a context length of 32K but I am not sure why the error says 1024 tokens. Here is the full error&lt;br/&gt; Token indices sequence length is longer than the specified maximum sequence length for this model (20098 &amp;gt; 1024). Running this sequence through the model will result in indexing errors.&lt;br/&gt; Here is the code &lt;/p&gt; &lt;p&gt;from langchain.chains.combine_documents.stuff import StuffDocumentsChain&lt;/p&gt; &lt;p&gt;from langchain.chains.llm import LLMChain&lt;/p&gt; &lt;p&gt;from langchain.prompts import PromptTemplate&lt;/p&gt; &lt;p&gt;from langchain.schema.document import Document&lt;/p&gt; &lt;p&gt;from langchain.chains.combine_documents.stuff import StuffDocumentsChain&lt;/p&gt; &lt;p&gt;from langchain.chains.llm import LLMChain&lt;/p&gt; &lt;p&gt;from langchain.prompts import PromptTemplate&lt;/p&gt; &lt;p&gt;from langchain.chains.summarize import load_summarize_chain&lt;/p&gt; &lt;h1&gt;type the code to be ready for tomorrow:&lt;/h1&gt; &lt;p&gt;from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain&lt;/p&gt; &lt;h1&gt;Map&lt;/h1&gt; &lt;p&gt;map_template = &amp;quot;&amp;quot;&amp;quot;&amp;lt;s&amp;gt;[INST]Please write a clear and concise summary for the following text.[/INST]&lt;/p&gt; &lt;p&gt;Text:&lt;/p&gt; &lt;p&gt;&amp;quot;{docs}&amp;quot;&amp;lt;/s&amp;gt;&lt;/p&gt; &lt;p&gt;[INST] Summary:[/INST]&lt;/p&gt; &lt;p&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt; &lt;p&gt;map_prompt = PromptTemplate.from_template(map_template)&lt;/p&gt; &lt;p&gt;map_chain = LLMChain(llm=api_llm, prompt=map_prompt)&lt;/p&gt; &lt;h1&gt;Reduce&lt;/h1&gt; &lt;p&gt;reduce_template = &amp;quot;&amp;quot;&amp;quot;&amp;lt;s&amp;gt;[INST]Below are the summaries of multiple segments of a document. Please combine these summaries to form a meaningful final summary.[/INST]&lt;/p&gt; &lt;p&gt;Text:&lt;/p&gt; &lt;p&gt;&amp;quot;{doc_summaries}&amp;quot;&amp;lt;/s&amp;gt;&lt;/p&gt; &lt;p&gt;[INST] Summary:[/INST]&lt;/p&gt; &lt;p&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt; &lt;p&gt;reduce_prompt = PromptTemplate.from_template(reduce_template)&lt;/p&gt; &lt;h1&gt;Run chain&lt;/h1&gt; &lt;p&gt;reduce_chain = LLMChain(llm=api_llm, prompt=reduce_prompt)&lt;/p&gt; &lt;h1&gt;Takes a list of documents, combines them into a single string, and passes this to an LLMChain&lt;/h1&gt; &lt;p&gt;combine_documents_chain = StuffDocumentsChain(&lt;/p&gt; &lt;p&gt;llm_chain=reduce_chain, document_variable_name=&amp;quot;doc_summaries&amp;quot;&lt;/p&gt; &lt;p&gt;)&lt;/p&gt; &lt;h1&gt;Combines and iteratively reduces the mapped documents&lt;/h1&gt; &lt;p&gt;reduce_documents_chain = ReduceDocumentsChain(&lt;/p&gt; &lt;h1&gt;This is final chain that is called.&lt;/h1&gt; &lt;p&gt;combine_documents_chain=combine_documents_chain,&lt;/p&gt; &lt;h1&gt;If documents exceed context for `StuffDocumentsChain`&lt;/h1&gt; &lt;p&gt;collapse_documents_chain=combine_documents_chain,&lt;/p&gt; &lt;h1&gt;The maximum number of tokens to group documents into.&lt;/h1&gt; &lt;p&gt;token_max=4000,&lt;/p&gt; &lt;p&gt;)&lt;/p&gt; &lt;h1&gt;Combining documents by mapping a chain over them, then combining results&lt;/h1&gt; &lt;p&gt;map_reduce_chain = MapReduceDocumentsChain(&lt;/p&gt; &lt;h1&gt;Map chain&lt;/h1&gt; &lt;p&gt;llm_chain=map_chain,&lt;/p&gt; &lt;h1&gt;Reduce chain&lt;/h1&gt; &lt;p&gt;reduce_documents_chain=reduce_documents_chain,&lt;/p&gt; &lt;h1&gt;The variable name in the llm_chain to put the documents in&lt;/h1&gt; &lt;p&gt;document_variable_name=&amp;quot;docs&amp;quot;,&lt;/p&gt; &lt;h1&gt;Return the results of the map steps in the output&lt;/h1&gt; &lt;p&gt;return_intermediate_steps=True,&lt;/p&gt; &lt;p&gt;)&lt;/p&gt; &lt;h1&gt;text_splitter = CharacterTextSplitter.from_tiktoken_encoder(&lt;/h1&gt; &lt;h1&gt;chunk_size=1000, chunk_overlap=0&lt;/h1&gt; &lt;h1&gt;)&lt;/h1&gt; &lt;h1&gt;split_docs = text_splitter.split_documents(docs)&lt;/h1&gt; &lt;p&gt;splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=200,length_function = len)&lt;/p&gt; &lt;p&gt;chunks = splitter.create_documents([text])&lt;/p&gt; &lt;p&gt;result=map_reduce_chain.invoke(chunks)&lt;/p&gt; &lt;p&gt;print(result[&amp;#39;output_text&amp;#39;])&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Rohitha2107&quot;&gt; /u/Rohitha2107 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1enbsrw/token_indices_sequence_length_is_longer_than_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1enbsrw/token_indices_sequence_length_is_longer_than_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1enbsrw</id><link href="https://www.reddit.com/r/LangChain/comments/1enbsrw/token_indices_sequence_length_is_longer_than_the/" /><updated>2024-08-08T17:22:39+00:00</updated><published>2024-08-08T17:22:39+00:00</published><title>Token indices sequence length is longer than the specified maximum sequence length for this model (20098 &gt; 1024)</title></entry><entry><author><name>/u/cmbhatt</name><uri>https://www.reddit.com/user/cmbhatt</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everybody! I have just started langchain and am going through documentation and it seems very confusing. I am also having trouble with prompts. Could you please suggest a good starting point? Sorry if this has been posted before.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cmbhatt&quot;&gt; /u/cmbhatt &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1enaock/documentation_seems_confusing/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1enaock/documentation_seems_confusing/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1enaock</id><link href="https://www.reddit.com/r/LangChain/comments/1enaock/documentation_seems_confusing/" /><updated>2024-08-08T16:37:52+00:00</updated><published>2024-08-08T16:37:52+00:00</published><title>Documentation seems confusing</title></entry><entry><author><name>/u/abhinavkimothi</name><uri>https://www.reddit.com/user/abhinavkimothi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em6m7e/embeddings_the_blueprint_of_contextual_ai/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/QKVGsXwodAGF0k5YNnyDIcsDJJeG9DZ2QpyUcA904NE.jpg&quot; alt=&quot;Embeddings : The blueprint of Contextual AI&quot; title=&quot;Embeddings : The blueprint of Contextual AI&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/abhinavkimothi&quot;&gt; /u/abhinavkimothi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/gallery/1em6m7e&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em6m7e/embeddings_the_blueprint_of_contextual_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1em6m7e</id><media:thumbnail url="https://b.thumbs.redditmedia.com/QKVGsXwodAGF0k5YNnyDIcsDJJeG9DZ2QpyUcA904NE.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1em6m7e/embeddings_the_blueprint_of_contextual_ai/" /><updated>2024-08-07T08:34:09+00:00</updated><published>2024-08-07T08:34:09+00:00</published><title>Embeddings : The blueprint of Contextual AI</title></entry><entry><author><name>/u/Exotic_Show3271</name><uri>https://www.reddit.com/user/Exotic_Show3271</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hi guys, I want my rag (when asked) to output and print a table that is dynamically generated according to the question and context. What is the way to do it?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Exotic_Show3271&quot;&gt; /u/Exotic_Show3271 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en2wxt/output_a_table_in_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en2wxt/output_a_table_in_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en2wxt</id><link href="https://www.reddit.com/r/LangChain/comments/1en2wxt/output_a_table_in_rag/" /><updated>2024-08-08T10:55:04+00:00</updated><published>2024-08-08T10:55:04+00:00</published><title>output a table in rag</title></entry><entry><author><name>/u/Embarrassed_Bread121</name><uri>https://www.reddit.com/user/Embarrassed_Bread121</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks. I am a Machine Learning Engineer looking for open opportunities in Bangalore. I have 1 year of experience in developing and deploying ML solutions convering basic ML fundamentals like regression models and data analysis to building RAG applications using vector DB and Langchain. I have worked in shaping ideas into POCs using Machine Learning and Deep Learning. &lt;/p&gt; &lt;p&gt;My tech stack includes Python, Jupyter Notebook, Sci-kit Learn, Langchain, Vector DB, fine-tuning LLMs for specific use cases.&lt;/p&gt; &lt;p&gt;I am also experienced in developing &amp;amp; deploying the end to end LLM applications to AWS cloud. I am passionate about ML.&lt;/p&gt; &lt;p&gt;Any leads would be appreciated. Thank You &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Embarrassed_Bread121&quot;&gt; /u/Embarrassed_Bread121 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en1s8v/ml_engineer_1_yoe_looking_for_an_open_opportunity/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en1s8v/ml_engineer_1_yoe_looking_for_an_open_opportunity/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en1s8v</id><link href="https://www.reddit.com/r/LangChain/comments/1en1s8v/ml_engineer_1_yoe_looking_for_an_open_opportunity/" /><updated>2024-08-08T09:44:44+00:00</updated><published>2024-08-08T09:44:44+00:00</published><title>ML Engineer (1 YOE) looking for an open opportunity</title></entry><entry><author><name>/u/Gokulander</name><uri>https://www.reddit.com/user/Gokulander</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all, I have been trying to use Langchain Summarization chain with Open ai, it does summarises the document but it translates it to english. &lt;/p&gt; &lt;p&gt;And the same llm works, fine for RAG or normal llm.invoke. It is giving me answer in English, but only for Summarization it is sending me russian response.&lt;/p&gt; &lt;p&gt;Please help&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Gokulander&quot;&gt; /u/Gokulander &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en1mx5/russian_response_when_generating_summary_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en1mx5/russian_response_when_generating_summary_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en1mx5</id><link href="https://www.reddit.com/r/LangChain/comments/1en1mx5/russian_response_when_generating_summary_using/" /><updated>2024-08-08T09:34:38+00:00</updated><published>2024-08-08T09:34:38+00:00</published><title>Russian response when generating summary using langchain and openai</title></entry><entry><author><name>/u/Initial-Advantage-88</name><uri>https://www.reddit.com/user/Initial-Advantage-88</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can anyone tell me some ways to pass down the schema of the table to the chain, I am passing it in query checker(reference below) but could not make a full chain to pass it initially too. &lt;/p&gt; &lt;h1&gt;&lt;a href=&quot;https://python.langchain.com/v0.1/docs/use%5C_cases/sql/query%5C_checking/&quot;&gt;https://python.langchain.com/v0.1/docs/use\_cases/sql/query\_checking/&lt;/a&gt;&lt;/h1&gt; &lt;p&gt;Good thing is the schema of my table is fixed so is there any other method you folks having in mind which can enable me make a fully local genAI text-to-SQL model.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Initial-Advantage-88&quot;&gt; /u/Initial-Advantage-88 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emxori/trying_to_build_a_natural_language_to_sql_model/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emxori/trying_to_build_a_natural_language_to_sql_model/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emxori</id><link href="https://www.reddit.com/r/LangChain/comments/1emxori/trying_to_build_a_natural_language_to_sql_model/" /><updated>2024-08-08T05:13:56+00:00</updated><published>2024-08-08T05:13:56+00:00</published><title>Trying to build a Natural Language to SQL model using langchain's &quot;create_sql_query_chain&quot;.</title></entry><entry><author><name>/u/kush_sahu_2020</name><uri>https://www.reddit.com/user/kush_sahu_2020</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks!&lt;/p&gt; &lt;p&gt;Just wanted to know, has anyone have worked with langgraph for supervisor agentic framework using AWS Bedrock models like Mistral large or Claude 3.5. For me, any model I use from AWS Bedrock with Agents it&amp;#39;s giving &amp;#39;Validation Error while calling InvokeModel operation&amp;#39; although I am giving correct prompt format for the models.&lt;/p&gt; &lt;p&gt;Please help me on this, inform me if you need more information. Thanks in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kush_sahu_2020&quot;&gt; /u/kush_sahu_2020 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en13pm/langgraph_with_aws_bedrock/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en13pm/langgraph_with_aws_bedrock/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en13pm</id><link href="https://www.reddit.com/r/LangChain/comments/1en13pm/langgraph_with_aws_bedrock/" /><updated>2024-08-08T08:59:22+00:00</updated><published>2024-08-08T08:59:22+00:00</published><title>Langgraph with AWS Bedrock</title></entry><entry><author><name>/u/smtabatabaie</name><uri>https://www.reddit.com/user/smtabatabaie</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, i&amp;#39;m trying to create a prompt in langchain hub from an already existing public prompt by just copying and pasting its content into a new prompt. This is the first prompt I&amp;#39;m trying to create and it seems though I tried to duplicate the original prompt, My prompt is different from the original prompt.&lt;br/&gt; Here&amp;#39;s the link to my prompt: &lt;a href=&quot;https://smith.langchain.com/hub/smtabatabaie/gps&quot;&gt;https://smith.langchain.com/hub/smtabatabaie/gps&lt;/a&gt;&lt;br/&gt; And here&amp;#39;s the original prompt: &lt;a href=&quot;https://smith.langchain.com/hub/smtabatabaie/web-voyager&quot;&gt;https://smith.langchain.com/hub/smtabatabaie/web-voyager&lt;/a&gt;&lt;br/&gt; My prompt has a &amp;quot;ChatOpenAI&amp;quot; whereas the original prompt doesn&amp;#39;t have this section. And also my prompt has &amp;quot;scratchpad&amp;quot; as input whereas the original prompt doesn&amp;#39;t consider &amp;quot;scratchpad&amp;quot; as an input when I print the prompt in my python script.&lt;br/&gt; Also in my script when I pull and use the original prompt, it works without any problem. But when i pull and use my prompt, it shows me the following error about hitting the maximum context length: &lt;/p&gt; &lt;p&gt;&amp;quot;openai.BadRequestError: Error code: 400 - {&amp;#39;error&amp;#39;: {&amp;#39;message&amp;#39;: &amp;quot;This model&amp;#39;s maximum context length is 128000 tokens. However, your messages resulted in 473683 tokens. Please reduce the length of the messages.&amp;quot;, &amp;#39;type&amp;#39;: &amp;#39;invalid_request_error&amp;#39;, &amp;#39;param&amp;#39;: &amp;#39;messages&amp;#39;, &amp;#39;code&amp;#39;: &amp;#39;context_length_exceeded&amp;#39;}}&amp;quot; &lt;/p&gt; &lt;p&gt;Would really appreciate if you have any idea what&amp;#39;s causing this.&lt;br/&gt; Thanks very much.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/smtabatabaie&quot;&gt; /u/smtabatabaie &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en0h86/creating_a_prompt_in_langchain_hub/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en0h86/creating_a_prompt_in_langchain_hub/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en0h86</id><link href="https://www.reddit.com/r/LangChain/comments/1en0h86/creating_a_prompt_in_langchain_hub/" /><updated>2024-08-08T08:16:26+00:00</updated><published>2024-08-08T08:16:26+00:00</published><title>Creating a prompt in Langchain hub</title></entry><entry><author><name>/u/No-Opportunity8473</name><uri>https://www.reddit.com/user/No-Opportunity8473</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Yo using langflow, a no code editor built off of langchain (I know this is a langchain server, but the problem should be mirrored in langchain), currently trying to run a zero shot agent with Gemini, using a tool call agent, &lt;/p&gt; &lt;p&gt;integrating openAI works perfectly fine, but with Gemini, I get the error code in my image, any pointers in the right direction would be great,&lt;/p&gt; &lt;p&gt;Here is the 2 components &amp;amp; how they link (took other components out for simplicity)&lt;br/&gt; &lt;a href=&quot;https://www.loom.com/share/61e4cd93166445bea7af0a962500af29?sid=8c9b0cc3-195e-4fef-a6b8-922670c52f95&quot;&gt;https://www.loom.com/share/61e4cd93166445bea7af0a962500af29?sid=8c9b0cc3-195e-4fef-a6b8-922670c52f95&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Any pointers would be amazing&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No-Opportunity8473&quot;&gt; /u/No-Opportunity8473 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emvqkj/gemini_zero_shot_promptfunction_call_any_help/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emvqkj/gemini_zero_shot_promptfunction_call_any_help/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emvqkj</id><link href="https://www.reddit.com/r/LangChain/comments/1emvqkj/gemini_zero_shot_promptfunction_call_any_help/" /><updated>2024-08-08T03:25:01+00:00</updated><published>2024-08-08T03:25:01+00:00</published><title>Gemini Zero shot prompt/function call, any help?</title></entry><entry><author><name>/u/jakezegil</name><uri>https://www.reddit.com/user/jakezegil</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everybody,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been really frustrated with the developer experience of Langchain in Typescript, particularly around structured extraction from image and text and agent workflows. I have started building out a dev toolkit to solve that with some DX inspiration from dev tools like vercel and prisma: &lt;a href=&quot;https://github.com/forge-ml/forge-ml&quot;&gt;https://github.com/forge-ml/forge-ml&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I&amp;#39;d love feedback on the current product, but I&amp;#39;d also love to know what else I can incorporate - what are the big pain points people are having? &lt;/p&gt; &lt;p&gt;Some of the current things on the roadmap are, in no particular order:&lt;br/&gt; - structured extraction from video&lt;br/&gt; - structured extraction from audio&lt;br/&gt; - Anthropic/Groq support&lt;br/&gt; - Semantic Search over Documents&lt;br/&gt; - Semantic Search over Databases&lt;br/&gt; - Fine tuning&lt;br/&gt; - Workflows&lt;br/&gt; - Model routing&lt;/p&gt; &lt;p&gt;What are the biggest issues that you&amp;#39;re facing when building AI products?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jakezegil&quot;&gt; /u/jakezegil &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emfs9w/how_can_i_help_you_build_more_reliable_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emfs9w/how_can_i_help_you_build_more_reliable_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emfs9w</id><link href="https://www.reddit.com/r/LangChain/comments/1emfs9w/how_can_i_help_you_build_more_reliable_ai/" /><updated>2024-08-07T16:07:25+00:00</updated><published>2024-08-07T16:07:25+00:00</published><title>How can I help you build more reliable AI products faster?</title></entry><entry><author><name>/u/jiraiya1729</name><uri>https://www.reddit.com/user/jiraiya1729</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Other than chatbot what are the other use cases the LLM or open source hugging face models are used for? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jiraiya1729&quot;&gt; /u/jiraiya1729 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emgi8p/discussion_llm_use_cases/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emgi8p/discussion_llm_use_cases/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emgi8p</id><link href="https://www.reddit.com/r/LangChain/comments/1emgi8p/discussion_llm_use_cases/" /><updated>2024-08-07T16:35:10+00:00</updated><published>2024-08-07T16:35:10+00:00</published><title>[Discussion] LLM use cases</title></entry><entry><author><name>/u/MountainBlock</name><uri>https://www.reddit.com/user/MountainBlock</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve developed a script using Langchain and Agents that I plan to launch internally within our company. Before moving it to production, I&amp;#39;d appreciate a second pair of eyes to review the code for any potential redundancies or areas for improvement.&lt;/p&gt; &lt;p&gt;I’ve noticed that some posts sharing code here don’t always get much traction. I didn’t see any rules against sharing code for review, but I wanted to check if it&amp;#39;s appropriate to ask for feedback here. &lt;/p&gt; &lt;p&gt;If not, could you suggest any other platforms where I might get my code reviewed?&lt;/p&gt; &lt;p&gt;Thanks in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MountainBlock&quot;&gt; /u/MountainBlock &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emiqo5/where_can_i_get_my_code_reviewed/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emiqo5/where_can_i_get_my_code_reviewed/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emiqo5</id><link href="https://www.reddit.com/r/LangChain/comments/1emiqo5/where_can_i_get_my_code_reviewed/" /><updated>2024-08-07T18:01:57+00:00</updated><published>2024-08-07T18:01:57+00:00</published><title>Where can I get my code reviewed?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1em61b0/free_llm_apis_to_know/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em61t8/free_llm_apis_to_know/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em61t8</id><link href="https://www.reddit.com/r/LangChain/comments/1em61t8/free_llm_apis_to_know/" /><updated>2024-08-07T07:55:35+00:00</updated><published>2024-08-07T07:55:35+00:00</published><title>Free LLM APIs to know</title></entry><entry><author><name>/u/Wise-Dog-9930</name><uri>https://www.reddit.com/user/Wise-Dog-9930</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Folks, I am really new here. I am working on a multi-agent project where each agent would look up information on a set of select predefined websites. I am hoping to use web search to do it. Is there a way for me search articles related to a specific topic on a specific website using web search?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Wise-Dog-9930&quot;&gt; /u/Wise-Dog-9930 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emdose/specialized_web_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emdose/specialized_web_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emdose</id><link href="https://www.reddit.com/r/LangChain/comments/1emdose/specialized_web_search/" /><updated>2024-08-07T14:47:07+00:00</updated><published>2024-08-07T14:47:07+00:00</published><title>Specialized Web Search</title></entry><entry><author><name>/u/Suitable-Ad-8598</name><uri>https://www.reddit.com/user/Suitable-Ad-8598</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Based on some advice I got, I started using AWS Textract ($$$) for PDFs and unstructured (local/free) for all other doc types such as docx and html. &lt;/p&gt; &lt;p&gt;My textract bill is getting a bit out of hand and I was wondering if there are any better services out there that can interpret things like tables and stuff from PDFs and other docs well?&lt;/p&gt; &lt;p&gt;Quality is my number one concern but cost is also important.&lt;/p&gt; &lt;p&gt;Looking to replace textract but also wanted to check to see if unstructured is still considered the best for other doc types.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Suitable-Ad-8598&quot;&gt; /u/Suitable-Ad-8598 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elr7sr/what_is_the_best_document_loader_for_pdfs_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elr7sr/what_is_the_best_document_loader_for_pdfs_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elr7sr</id><link href="https://www.reddit.com/r/LangChain/comments/1elr7sr/what_is_the_best_document_loader_for_pdfs_and/" /><updated>2024-08-06T19:46:01+00:00</updated><published>2024-08-06T19:46:01+00:00</published><title>What is the best document loader for PDFs? And other docs in general?</title></entry><entry><author><name>/u/ekkoogod</name><uri>https://www.reddit.com/user/ekkoogod</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i&amp;#39;ve developped a rag application using langchain with the retrieval chain that combines history retriever and documents chain, and it performs pretty good .&lt;br/&gt; i have been tasked to add summarization and some other tools , so i tought about using agent and adding tools for such tasks and still use the rag chain as a tool . &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Is there a way to use the same rag chain as a tool for the agent ?&lt;/strong&gt; &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ekkoogod&quot;&gt; /u/ekkoogod &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emd7m3/using_retrieval_chain_as_a_tool_for_an_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emd7m3/using_retrieval_chain_as_a_tool_for_an_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emd7m3</id><link href="https://www.reddit.com/r/LangChain/comments/1emd7m3/using_retrieval_chain_as_a_tool_for_an_agent/" /><updated>2024-08-07T14:27:30+00:00</updated><published>2024-08-07T14:27:30+00:00</published><title>using retrieval_chain as a tool for an agent</title></entry><entry><author><name>/u/BellaHi</name><uri>https://www.reddit.com/user/BellaHi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em0qmz/langchain_vs_llamaindex_choose_the_best_framework/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/xdRw2A4E1tAFHQRy07JwUiPTZWn466MaEpJKn-gWRf8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9161ceea81d99df6557d0af71471532e71f230d8&quot; alt=&quot;LangChain vs LlamaIndex: Choose the Best Framework for Your AI Applications&quot; title=&quot;LangChain vs LlamaIndex: Choose the Best Framework for Your AI Applications&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BellaHi&quot;&gt; /u/BellaHi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://myscale.com/blog/llamaindex-vs-langchain-detailed-comparison/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em0qmz/langchain_vs_llamaindex_choose_the_best_framework/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1em0qmz</id><media:thumbnail url="https://external-preview.redd.it/xdRw2A4E1tAFHQRy07JwUiPTZWn466MaEpJKn-gWRf8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9161ceea81d99df6557d0af71471532e71f230d8" /><link href="https://www.reddit.com/r/LangChain/comments/1em0qmz/langchain_vs_llamaindex_choose_the_best_framework/" /><updated>2024-08-07T02:41:36+00:00</updated><published>2024-08-07T02:41:36+00:00</published><title>LangChain vs LlamaIndex: Choose the Best Framework for Your AI Applications</title></entry><entry><author><name>/u/phan_ngt</name><uri>https://www.reddit.com/user/phan_ngt</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have very simple code &lt;strong&gt;Langserve&lt;/strong&gt; with &lt;strong&gt;langfuse_handler&lt;/strong&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;add_routes(app, normal_agent.with_config(RunnableConfig(callbacks=[langfuse_handler])), per_req_config_modifier=per_request_config_modifier, path=&amp;quot;/normal&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When I run my code: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;import asyncio from langserve import RemoteRunnable remote_runnable = RemoteRunnable(&amp;quot;http://localhost:8001/normal&amp;quot;) async def main(): async for chunk in remote_runnable.astream({&amp;#39;input&amp;#39;: &amp;#39;tell me about ronaldo&amp;#39;}): print(chunk, end=&amp;#39;|\n&amp;#39;, flush=True) asyncio.run(main()) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I want return to client my trace_id of Langfuse. Do you have any ideas to do that? I stuck here for 2 days. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phan_ngt&quot;&gt; /u/phan_ngt &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em7aik/how_to_return_langfuse_trace_id_when_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em7aik/how_to_return_langfuse_trace_id_when_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em7aik</id><link href="https://www.reddit.com/r/LangChain/comments/1em7aik/how_to_return_langfuse_trace_id_when_using/" /><updated>2024-08-07T09:20:38+00:00</updated><published>2024-08-07T09:20:38+00:00</published><title>How to return langfuse trace_id when using Langserve stream?</title></entry></feed>