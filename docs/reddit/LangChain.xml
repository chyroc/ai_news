<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-02-04T14:51:28+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/hi87</name><uri>https://www.reddit.com/user/hi87</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aimin7/why_are_basic_things_not_documented_correctly/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/y8U3ksxYrFd-yLwWvdjFZQ4ViMi6jg6V-DM_BHu5K98.jpg&quot; alt=&quot;Why are basic things not documented correctly, never seem to work?&quot; title=&quot;Why are basic things not documented correctly, never seem to work?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Maybe I&amp;#39;m doing something wrong, but I wanted to test out output parsers today with all the new updates so I go through the docs to put together a basic example. I copy it and keep getting an error:&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/2jx7f2og7kgc1.png?width=1002&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=27371552aa733df1d43c37867abcc0243b7fc512&quot;&gt;TypeError: langchain_core.prompts.prompt.PromptTemplate() got multiple values for keyword argument &amp;#39;input_variables&amp;#39;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I had to remove the &amp;quot;input_variables&amp;quot; arg from the PromptTemplate for it to work. What is frustrating me is that these kinds of issues are abundant. Nothing in the docs is every up to date. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hi87&quot;&gt; /u/hi87 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aimin7/why_are_basic_things_not_documented_correctly/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aimin7/why_are_basic_things_not_documented_correctly/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1aimin7</id><media:thumbnail url="https://a.thumbs.redditmedia.com/y8U3ksxYrFd-yLwWvdjFZQ4ViMi6jg6V-DM_BHu5K98.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1aimin7/why_are_basic_things_not_documented_correctly/" /><updated>2024-02-04T12:09:35+00:00</updated><published>2024-02-04T12:09:35+00:00</published><title>Why are basic things not documented correctly, never seem to work?</title></entry><entry><author><name>/u/bitemyassnow</name><uri>https://www.reddit.com/user/bitemyassnow</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am currently looking for a solution to extract details from documents I ingested into vectorstore to a structure json format.&lt;/p&gt; &lt;p&gt;I know I can first just ask it to retrieve stuff I want from the document as plain string and send it again to using fn calling to put bits and pieces into json obj.&lt;/p&gt; &lt;p&gt;Is this possible at the moment with just one shot request? I looked up pretty much all available options on langchain but cannot seem to find one.&lt;/p&gt; &lt;p&gt;Anyone tried this combination before?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bitemyassnow&quot;&gt; /u/bitemyassnow &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aio67k/is_function_calling_supported_with_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aio67k/is_function_calling_supported_with_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aio67k</id><link href="https://www.reddit.com/r/LangChain/comments/1aio67k/is_function_calling_supported_with_rag/" /><updated>2024-02-04T13:43:01+00:00</updated><published>2024-02-04T13:43:01+00:00</published><title>Is function calling supported with RAG?</title></entry><entry><author><name>/u/sardoa11</name><uri>https://www.reddit.com/user/sardoa11</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for a Research tool that is able to complete in depth research tasks through browsing online. Copilot/bing aren‚Äôt thorough enough, and remember coming across a langchain based one a while back but can‚Äôt remember the name of the project.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sardoa11&quot;&gt; /u/sardoa11 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aijj85/best_ai_based_research_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aijj85/best_ai_based_research_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aijj85</id><link href="https://www.reddit.com/r/LangChain/comments/1aijj85/best_ai_based_research_agent/" /><updated>2024-02-04T08:50:56+00:00</updated><published>2024-02-04T08:50:56+00:00</published><title>Best AI based research agent?</title></entry><entry><author><name>/u/shallow-speaker</name><uri>https://www.reddit.com/user/shallow-speaker</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can anyone suggest methods for creating vector embedding d from multiple PDFs using Langchain embedding and retrievers.Kind of stuff used in applications like Chatpdf&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/shallow-speaker&quot;&gt; /u/shallow-speaker &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aiiyd6/creating_vector_embedding_from_multiple_pdf/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aiiyd6/creating_vector_embedding_from_multiple_pdf/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aiiyd6</id><link href="https://www.reddit.com/r/LangChain/comments/1aiiyd6/creating_vector_embedding_from_multiple_pdf/" /><updated>2024-02-04T08:11:32+00:00</updated><published>2024-02-04T08:11:32+00:00</published><title>Creating vector embedding from multiple pdf</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aifn1l/my_debut_book_langchain_in_your_pocket_is_out/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/Nzmta3jtOYPMnKHQUkJUswFzvypAodG4vvUyMPKYT9I.jpg&quot; alt=&quot;My debut book: LangChain in your Pocket is out !&quot; title=&quot;My debut book: LangChain in your Pocket is out !&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am thrilled to announce the launch of my debut technical book, ‚Äú&lt;strong&gt;LangChain in your Pocket:&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;Beginner‚Äôs Guide to Building Generative AI Applications using LLMs&lt;/em&gt;&lt;/strong&gt;‚Äù which is available on Amazon in Kindle, PDF and Paperback formats.&lt;/p&gt; &lt;p&gt;In this comprehensive guide, the readers will explore LangChain, a powerful Python/JavaScript framework designed for harnessing Generative AI. Through practical examples and hands-on exercises, you‚Äôll gain the skills necessary to develop a diverse range of AI applications, including Few-Shot Classification, Auto-SQL generators, Internet-enabled GPT, Multi-Document RAG and more.&lt;/p&gt; &lt;h1&gt;Key Features:&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;Step-by-step code explanations with expected outputs for each solution.&lt;/li&gt; &lt;li&gt;No prerequisites: If you know Python, you‚Äôre ready to dive in.&lt;/li&gt; &lt;li&gt;Practical, hands-on guide with minimal mathematical explanations.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;em&gt;I would greatly appreciate if you can check out the book and share your thoughts through reviews and ratings:&lt;/em&gt; &lt;a href=&quot;https://www.amazon.in/dp/B0CTHQHT25&quot;&gt;https://www.amazon.in/dp/B0CTHQHT25&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Or at GumRoad : &lt;a href=&quot;https://mehulgupta.gumroad.com/l/hmayz&quot;&gt;https://mehulgupta.gumroad.com/l/hmayz&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;About me:&lt;/h1&gt; &lt;p&gt;I&amp;#39;m a Senior Data Scientist at DBS Bank with about 5 years of experience in Data Science &amp;amp; AI. Additionally, I manage &amp;quot;Data Science in your Pocket&amp;quot;, a &lt;a href=&quot;https://medium.com/@mehulgupta_7991&quot;&gt;Medium Publication&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://www.youtube.com/@datascienceinyourpocket/videos&quot;&gt;YouTube channel&lt;/a&gt; with ~600 Data Science &amp;amp; AI tutorials and a cumulative million views till date. To know more, you can check &lt;a href=&quot;https://www.linkedin.com/in/mehulgupta7991/&quot;&gt;here&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aifn1l/my_debut_book_langchain_in_your_pocket_is_out/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aifn1l/my_debut_book_langchain_in_your_pocket_is_out/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1aifn1l</id><media:thumbnail url="https://b.thumbs.redditmedia.com/Nzmta3jtOYPMnKHQUkJUswFzvypAodG4vvUyMPKYT9I.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1aifn1l/my_debut_book_langchain_in_your_pocket_is_out/" /><updated>2024-02-04T04:44:35+00:00</updated><published>2024-02-04T04:44:35+00:00</published><title>My debut book: LangChain in your Pocket is out !</title></entry><entry><author><name>/u/rkubc</name><uri>https://www.reddit.com/user/rkubc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt; &lt;p&gt;I am currently developing an information retrieval application designed to work with HTML pages, ranging in length from 30 to 200 pages. The application utilizes LangChain, OpenAI, and FAISS for its core functionalities. A significant part of the process involves chunking HTML pages, many of which contain numerous tables. My method involves extracting tables from the HTML pages, identifying them by their top titles for indexing and retrieval purposes.&lt;/p&gt; &lt;p&gt;However, I have encountered two main issues during retrieval:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Long Query Handling: When the query is slightly longer, the retrieval system does not return the correct answer. It seems to struggle with maintaining accuracy as the query length increases.&lt;/li&gt; &lt;li&gt;Variance in Wording: The system fails to correctly retrieve chunks when there is a discrepancy between the wording in the query and the chunks. For example, if the query uses &amp;quot;six&amp;quot; but the chunk contains &amp;quot;6&amp;quot;, the system does not recognize them as a match.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These challenges are hindering the application&amp;#39;s ability to accurately retrieve information, especially when dealing with nuanced or detailed queries.&lt;/p&gt; &lt;p&gt;I am reaching out to this community for advice or strategies on how to address these issues. Specifically, I am interested in approaches that could improve the handling of long queries and the recognition of synonymous terms or different word forms (like numerals versus written numbers) during the retrieval process.&lt;/p&gt; &lt;p&gt;Any suggestions or insights on how to refine the retrieval accuracy of this application would be greatly appreciated.&lt;/p&gt; &lt;p&gt;Thank you in advance for your help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rkubc&quot;&gt; /u/rkubc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aiaidl/looking_for_help_with_retrieval_issues_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aiaidl/looking_for_help_with_retrieval_issues_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aiaidl</id><link href="https://www.reddit.com/r/LangChain/comments/1aiaidl/looking_for_help_with_retrieval_issues_in/" /><updated>2024-02-04T00:18:18+00:00</updated><published>2024-02-04T00:18:18+00:00</published><title>Looking for Help with Retrieval Issues in Information Retrieval Application(LangChain, OpenAI, and FAISS)</title></entry><entry><author><name>/u/Revolutionary_Let833</name><uri>https://www.reddit.com/user/Revolutionary_Let833</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Currently I&amp;#39;m using Chroma as a vector db for a langchain agent. I&amp;#39;m looking to do some metadata extraction/clustering with the core embeddings. Is this something that can be easily accessed for each document - seems the db queries will only return Document/text content. Is there clean way to have access to all embeddings and have them in a numpy array for example? &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Appreciate any help.. of course its not too difficult to just re-do the embeddings and access them directly but I&amp;#39;m wondering if there is a way to avoid paying 2x&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Revolutionary_Let833&quot;&gt; /u/Revolutionary_Let833 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ai3k14/embeddings_from_vector_stores/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ai3k14/embeddings_from_vector_stores/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ai3k14</id><link href="https://www.reddit.com/r/LangChain/comments/1ai3k14/embeddings_from_vector_stores/" /><updated>2024-02-03T19:08:17+00:00</updated><published>2024-02-03T19:08:17+00:00</published><title>Embeddings from Vector Stores</title></entry><entry><author><name>/u/DrNatoor</name><uri>https://www.reddit.com/user/DrNatoor</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahrw7t/i_build_an_extension_library_to_langchain_focused/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/VXrB4uSpu_uGXdN1V_smWsCEVqkDytkzKwSwGf5_2yo.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0c51cb273c0fd974c5c8c17179175df2bc60b83a&quot; alt=&quot;I build an extension library to langchain, focused on structured output: funcchain&quot; title=&quot;I build an extension library to langchain, focused on structured output: funcchain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DrNatoor&quot;&gt; /u/DrNatoor &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/shroominic/funcchain&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahrw7t/i_build_an_extension_library_to_langchain_focused/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ahrw7t</id><media:thumbnail url="https://external-preview.redd.it/VXrB4uSpu_uGXdN1V_smWsCEVqkDytkzKwSwGf5_2yo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c51cb273c0fd974c5c8c17179175df2bc60b83a" /><link href="https://www.reddit.com/r/LangChain/comments/1ahrw7t/i_build_an_extension_library_to_langchain_focused/" /><updated>2024-02-03T08:58:18+00:00</updated><published>2024-02-03T08:58:18+00:00</published><title>I build an extension library to langchain, focused on structured output: funcchain</title></entry><entry><author><name>/u/HazyPumpkin</name><uri>https://www.reddit.com/user/HazyPumpkin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello! First timer here. &lt;/p&gt; &lt;p&gt;I&amp;#39;m learning the ropes with LangChain, and have successfully made&lt;/p&gt; &lt;ol&gt; &lt;li&gt;A chat which integrates with a Postgres/Chroma vector store to augment responses&lt;/li&gt; &lt;li&gt;A chat which uses a SQL Agent with BigQuery to introspect and query a dataset&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;What I am struggling to figure out now, is how do I combine them? I want to have the vector store augment the prompts used by the SQL agent. I think it will yield me better results if I can layer in project documentation and examples. However, the API documentation doesn&amp;#39;t make it clear (At least to me) how to effectively accomplish this. &lt;/p&gt; &lt;p&gt;Hope somebody can help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HazyPumpkin&quot;&gt; /u/HazyPumpkin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahpvmm/sql_agent_vector_store_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahpvmm/sql_agent_vector_store_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ahpvmm</id><link href="https://www.reddit.com/r/LangChain/comments/1ahpvmm/sql_agent_vector_store_rag/" /><updated>2024-02-03T06:42:08+00:00</updated><published>2024-02-03T06:42:08+00:00</published><title>SQL Agent + Vector Store RAG</title></entry><entry><author><name>/u/danipudani</name><uri>https://www.reddit.com/user/danipudani</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahx7pl/langchain_cookbook_overview/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/WUccYzzI9dS8hjdgLla5y79nAanKJWz6wB9UNKssKLM.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=59072100adc2d6dcd4587f151b63aefb2cf30c08&quot; alt=&quot;Langchain Cookbook Overview&quot; title=&quot;Langchain Cookbook Overview&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/danipudani&quot;&gt; /u/danipudani &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/SKAwiiDwN3Q?si=_MzoSkPlI2bscf7b&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahx7pl/langchain_cookbook_overview/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ahx7pl</id><media:thumbnail url="https://external-preview.redd.it/WUccYzzI9dS8hjdgLla5y79nAanKJWz6wB9UNKssKLM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=59072100adc2d6dcd4587f151b63aefb2cf30c08" /><link href="https://www.reddit.com/r/LangChain/comments/1ahx7pl/langchain_cookbook_overview/" /><updated>2024-02-03T14:23:39+00:00</updated><published>2024-02-03T14:23:39+00:00</published><title>Langchain Cookbook Overview</title></entry><entry><author><name>/u/dauzzzz</name><uri>https://www.reddit.com/user/dauzzzz</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone!&lt;/p&gt; &lt;p&gt;I&amp;#39;m having a bit of trouble and could really use your wisdom. My company is eager to add AI to their products and daily operations.&lt;/p&gt; &lt;p&gt;We have this internal initiative where people from various departments come together to innovate or improve something, to add more value to the organization. My group has the task to develop an AI Chatbot, to assume some of the functions typically performed by an analyst, in a specific type of service, where it interacts with the customer, collects information for a specific process and uses this information to parameterize the company&amp;#39;s system, for that specific customer.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the problem: we have about 160 person-hours per month, split between three of us, over the next three months, to go from having zero expertise in creating AI-powered apps to delivering a functional AI-powered chatbot MVP.&lt;/p&gt; &lt;p&gt;It is clear that they do not know what they are doing about this matter. They gave us ChatGPT licenses after we requested OpenAI API credits. So they asked us to create a detailed AI spending plan, so they can evaluate (and yes, we are a technology company with over 1k employees).&lt;/p&gt; &lt;p&gt;Now they want us to move our development efforts to Copilot Studio, abandoning our current development with Python and Langchain. From what I gather, this may not be the wisest course of action, especially considering the intricate context management our project requires (different rules for answers, complex questions) and the potential lock-in with the Microsoft ecosystem (also, for what I could check, the client needs to pay for copilot studio as well). They don&amp;#39;t even have paid Copilot Studio yet (don&amp;#39;t know if they will ever do).&lt;/p&gt; &lt;p&gt;The challenge is that we don&amp;#39;t really know much about AI development (we&amp;#39;re trying to study it in the meantime), so it&amp;#39;s hard to argue with them.&lt;/p&gt; &lt;p&gt;Can anyone here help us understand if it&amp;#39;s true that Copilot Studio could be a better solution? Yes? No?&lt;/p&gt; &lt;p&gt;I would deeply appreciate any information or advice you could share so I can craft a well-informed response.&lt;/p&gt; &lt;p&gt;Thank you very much in advance for your contribution and time!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dauzzzz&quot;&gt; /u/dauzzzz &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahfbmm/manager_wants_to_switch_from_langchain_to_copilot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahfbmm/manager_wants_to_switch_from_langchain_to_copilot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ahfbmm</id><link href="https://www.reddit.com/r/LangChain/comments/1ahfbmm/manager_wants_to_switch_from_langchain_to_copilot/" /><updated>2024-02-02T21:51:18+00:00</updated><published>2024-02-02T21:51:18+00:00</published><title>Manager Wants to switch from LangChain to Copilot Studio for a Client Product - Thoughts?</title></entry><entry><author><name>/u/insane-defaults</name><uri>https://www.reddit.com/user/insane-defaults</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have ~2700 pdf documents, which are transcripts of Danish political conversations. The data is not confidential.&lt;/p&gt; &lt;p&gt;I want to create an gpt-4-based chatbot (Using something like streamlit or chainlit) that can answer (In Danish) about the pdfs.&lt;/p&gt; &lt;p&gt;So far I have tried using this &lt;a href=&quot;https://github.com/Azure-Samples/azure-search-openai-demo&quot;&gt;azure search open ai demo&lt;/a&gt; which garnered fairly good results, but is pretty expensive to set up and run.&lt;/p&gt; &lt;p&gt;Can the same performance be achieved (or better) using langchain?&lt;/p&gt; &lt;p&gt;And if so, are there repos or blog posts that I should take a look at given my use case? (Wanting a danish chatbot and using a fairly large amount of pdfs) &lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/insane-defaults&quot;&gt; /u/insane-defaults &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahd2uz/is_langchain_the_right_framework_for_my_usecase/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahd2uz/is_langchain_the_right_framework_for_my_usecase/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ahd2uz</id><link href="https://www.reddit.com/r/LangChain/comments/1ahd2uz/is_langchain_the_right_framework_for_my_usecase/" /><updated>2024-02-02T20:16:16+00:00</updated><published>2024-02-02T20:16:16+00:00</published><title>Is Langchain the right framework for my usecase?</title></entry><entry><author><name>/u/ashpreetbedi</name><uri>https://www.reddit.com/user/ashpreetbedi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, I built a chat with PDF using RAG but was struggling to get good results by just prompt stuffing. So I built an advanced PDF AI that uses function calling to intelligently figure out if:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The question needs retrieval from a document or a web search&lt;/li&gt; &lt;li&gt;If it needs retrieval, does it need to search the latest doc, a specific doc or all docs&lt;/li&gt; &lt;li&gt;Produces an answer using the context retrieved&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Give it a spin at: &lt;a href=&quot;https://pdf.aidev.run/&quot;&gt;https://pdf.aidev.run&lt;/a&gt; and let me know what you think. Looking for feedback so I can fix and improve. Here‚Äôs the &lt;a href=&quot;https://github.com/phidatahq/ai-cookbook/tree/main/pdf_ai&quot;&gt;code&lt;/a&gt; if you‚Äôre interested and I used &lt;a href=&quot;https://github.com/phidatahq/phidata&quot;&gt;phidata&lt;/a&gt; to build this.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://reddit.com/link/1ah1l5f/video/zbz2hm1aq5gc1/player&quot;&gt;https://reddit.com/link/1ah1l5f/video/zbz2hm1aq5gc1/player&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashpreetbedi&quot;&gt; /u/ashpreetbedi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah1l5f/chat_with_pdfs_using_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah1l5f/chat_with_pdfs_using_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah1l5f</id><link href="https://www.reddit.com/r/LangChain/comments/1ah1l5f/chat_with_pdfs_using_function_calling/" /><updated>2024-02-02T11:30:49+00:00</updated><published>2024-02-02T11:30:49+00:00</published><title>Chat with PDFs using function calling</title></entry><entry><author><name>/u/eschxr</name><uri>https://www.reddit.com/user/eschxr</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A vast majority of Generative AI solutions are delivered in a chat based user experience. &lt;/p&gt; &lt;p&gt;I&amp;#39;ve created a tutorial on how to quickly adapt an open-source framework to deliver that user experience within 15 minutes. &lt;/p&gt; &lt;p&gt;I hope the community finds this useful!&lt;/p&gt; &lt;p&gt;![&lt;a href=&quot;https://youtu.be/sZ1aJ0zfgmY?si=koLhtl_FO6-y3SC5%5D(https://youtu.be/sZ1aJ0zfgmY?si=koLhtl_FO6-y3SC5)&quot;&gt;https://youtu.be/sZ1aJ0zfgmY?si=koLhtl_FO6-y3SC5](https://youtu.be/sZ1aJ0zfgmY?si=koLhtl_FO6-y3SC5)&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/eschxr&quot;&gt; /u/eschxr &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah55wi/chatgpt_like_ui_for_any_project_within_15_mins/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah55wi/chatgpt_like_ui_for_any_project_within_15_mins/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah55wi</id><link href="https://www.reddit.com/r/LangChain/comments/1ah55wi/chatgpt_like_ui_for_any_project_within_15_mins/" /><updated>2024-02-02T14:37:41+00:00</updated><published>2024-02-02T14:37:41+00:00</published><title>ChatGPT like UI for any project within 15 mins</title></entry><entry><author><name>/u/redj_acc</name><uri>https://www.reddit.com/user/redj_acc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Heya! I am making a side project where I have a laptop being fed strings from a supabase api. these string will be messages from a chat from a webapp I made. They will be loaded into a local llama, and the llama will see if the messages contain any addresses or personal revealing information.&lt;br/&gt; It must block messages from users sharing the following:&lt;br/&gt; - addresses&lt;br/&gt; - contact information&lt;br/&gt; - phone numbers&lt;br/&gt; - social media handles&lt;br/&gt; - etc.&lt;br/&gt; My plan is to use my i3 16gb windows os laptop and download a local_llama llm, then have it constantly run, and when it finds a message to flag, run a script that sends an email. &lt;/p&gt; &lt;p&gt;Does anyone have advice on figuring out how to make this? Thanks :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/redj_acc&quot;&gt; /u/redj_acc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahiw5p/hi_i_could_use_some_help_getting_started_on/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahiw5p/hi_i_could_use_some_help_getting_started_on/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ahiw5p</id><link href="https://www.reddit.com/r/LangChain/comments/1ahiw5p/hi_i_could_use_some_help_getting_started_on/" /><updated>2024-02-03T00:27:07+00:00</updated><published>2024-02-03T00:27:07+00:00</published><title>Hi, I could use some help getting started on project (noob)</title></entry><entry><author><name>/u/dragon_4789</name><uri>https://www.reddit.com/user/dragon_4789</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been working on a project where I extract information from a large PDF document. I&amp;#39;ve completed the initial steps, including reading the PDF, splitting it into chunks, converting them to embeddings, and storing them in a vector database.&lt;/p&gt; &lt;p&gt;For the next step, I perform a similarity check with a limit of 28. Each chunk has a size of 350, with an overlap of 80. After that, I send these chunks to GPT with a specific question. GPT provides answers, but I&amp;#39;m struggling to determine from which chunk the answer originated.&lt;/p&gt; &lt;p&gt;Is there a way to identify the specific chunk(s) that GPT used to generate the answer? Alternatively, is there a solution to get an array of chunks that may contain the answer out of the 28 available?&lt;/p&gt; &lt;p&gt;Any insights or suggestions on how to achieve this would be greatly appreciated!&lt;/p&gt; &lt;p&gt;Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dragon_4789&quot;&gt; /u/dragon_4789 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah5zg3/extracting_answer_source_chunks_from_gpt/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah5zg3/extracting_answer_source_chunks_from_gpt/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah5zg3</id><link href="https://www.reddit.com/r/LangChain/comments/1ah5zg3/extracting_answer_source_chunks_from_gpt/" /><updated>2024-02-02T15:13:34+00:00</updated><published>2024-02-02T15:13:34+00:00</published><title>Extracting Answer Source Chunks from GPT Responses in Langchain</title></entry><entry><author><name>/u/Various-Squash4836</name><uri>https://www.reddit.com/user/Various-Squash4836</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have lots of documents, they contain procedures to operate a software and it also include images. Now my question is how do i build a custom LLM that would be capable of answering the user with text and also provide the appropriate image from the document&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Various-Squash4836&quot;&gt; /u/Various-Squash4836 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah74n8/document_qa_also_include_images/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah74n8/document_qa_also_include_images/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah74n8</id><link href="https://www.reddit.com/r/LangChain/comments/1ah74n8/document_qa_also_include_images/" /><updated>2024-02-02T16:04:47+00:00</updated><published>2024-02-02T16:04:47+00:00</published><title>Document Q&amp;A, also include images</title></entry><entry><author><name>/u/phantom69_ftw</name><uri>https://www.reddit.com/user/phantom69_ftw</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agvm60/a_gentle_introduction_to_ai_chat_bot_concepts/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/Tydy7yry658D88ysN1z7n3ImZWhwg7C4Os3zDBdiMCM.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e4f33e5a5c7fac2dee07d795edc43e0b1fdf9680&quot; alt=&quot;A Gentle Introduction to AI Chat Bot Concepts: Basics of Embedding and Vector DBs&quot; title=&quot;A Gentle Introduction to AI Chat Bot Concepts: Basics of Embedding and Vector DBs&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phantom69_ftw&quot;&gt; /u/phantom69_ftw &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.dsdev.in/a-gentle-introduction-to-ai-chat-bot-concepts&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agvm60/a_gentle_introduction_to_ai_chat_bot_concepts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1agvm60</id><media:thumbnail url="https://external-preview.redd.it/Tydy7yry658D88ysN1z7n3ImZWhwg7C4Os3zDBdiMCM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e4f33e5a5c7fac2dee07d795edc43e0b1fdf9680" /><link href="https://www.reddit.com/r/LangChain/comments/1agvm60/a_gentle_introduction_to_ai_chat_bot_concepts/" /><updated>2024-02-02T04:52:13+00:00</updated><published>2024-02-02T04:52:13+00:00</published><title>A Gentle Introduction to AI Chat Bot Concepts: Basics of Embedding and Vector DBs</title></entry><entry><author><name>/u/ContributionFun3037</name><uri>https://www.reddit.com/user/ContributionFun3037</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to implement conversation buffer memory with react, but for some reason it doesn&amp;#39;t work. I followed the docs in langchain i.e &lt;a href=&quot;https://js.langchain.com/docs/modules/memory/types/buffer_window&quot;&gt;Conversation buffer window memory | ü¶úÔ∏èüîó Langchain&lt;/a&gt; , the code simply doesn&amp;#39;t work.&lt;/p&gt; &lt;p&gt;However using BufferMemory works(I followed the code as given in the docs)&lt;a href=&quot;https://js.langchain.com/docs/modules/memory/types/buffer_window&quot;&gt;Conversation buffer window memory | ü¶úÔ∏èüîó Langchain&lt;/a&gt; .&lt;/p&gt; &lt;p&gt;My code with BufferWIndow Memory&lt;/p&gt; &lt;pre&gt;&lt;code&gt;const memory = new BufferWindowMemory({ k: 1 }); console.log(memory.chatHistory); try { const chain = new ConversationChain({ llm: model, memory: memory, }); const response = await chain.call({ input: question, }); console.log(response); return { success: true, response }; } catch (error) { console.log(error); } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I&amp;#39;m using Gemini API, and I get answers from Gemini, but the memory doesn&amp;#39;t seem to work.Can anybody please tell me what I&amp;quot;m doing wrong?I tried using ChatPromptTemplate as well, but the memory isn&amp;#39;t working at all. Please help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ContributionFun3037&quot;&gt; /u/ContributionFun3037 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah180z/conversation_memory_not_working_with_react/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah180z/conversation_memory_not_working_with_react/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah180z</id><link href="https://www.reddit.com/r/LangChain/comments/1ah180z/conversation_memory_not_working_with_react/" /><updated>2024-02-02T11:06:56+00:00</updated><published>2024-02-02T11:06:56+00:00</published><title>Conversation Memory not working with react.</title></entry><entry><author><name>/u/ronittsainii</name><uri>https://www.reddit.com/user/ronittsainii</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello Everyone I have written a blog on &lt;a href=&quot;https://www.deligence.com/what_is_langchain_ai_app_development_framework_explained/&quot;&gt;What is LangChain?&lt;/a&gt; , please give it a read and let me know your thoughts on the content and relevance, as I am trying to rank it on google. Thanks!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ronittsainii&quot;&gt; /u/ronittsainii &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah071c/what_is_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah071c/what_is_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah071c</id><link href="https://www.reddit.com/r/LangChain/comments/1ah071c/what_is_langchain/" /><updated>2024-02-02T09:56:47+00:00</updated><published>2024-02-02T09:56:47+00:00</published><title>What is LangChain?</title></entry><entry><author><name>/u/HappyDataGuy</name><uri>https://www.reddit.com/user/HappyDataGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build a text to sql bot based off of llama-index. The problem is tables have 100s of columns. What llama-index does is put complete create table script of table in model context along with user question to generate sql query and subsequent answer. But if there is need to join multiples tables and they have alot of column its not very efficient and may not even work. How can I solve this problem? Also if some of those columns have enums how can I make the sql bot understand meaning of those enums?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HappyDataGuy&quot;&gt; /u/HappyDataGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agxb0u/how_to_solve_schema_problems_in_texttosql_bot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agxb0u/how_to_solve_schema_problems_in_texttosql_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agxb0u</id><link href="https://www.reddit.com/r/LangChain/comments/1agxb0u/how_to_solve_schema_problems_in_texttosql_bot/" /><updated>2024-02-02T06:32:01+00:00</updated><published>2024-02-02T06:32:01+00:00</published><title>How to solve schema problems in text-to-sql bot?</title></entry><entry><author><name>/u/Available-Dig7628</name><uri>https://www.reddit.com/user/Available-Dig7628</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to go though code of any good rag based chatbot. Can you suggest any open-source project&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Available-Dig7628&quot;&gt; /u/Available-Dig7628 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agfnox/is_there_any_good_rag_based_opensource_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agfnox/is_there_any_good_rag_based_opensource_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agfnox</id><link href="https://www.reddit.com/r/LangChain/comments/1agfnox/is_there_any_good_rag_based_opensource_chatbot/" /><updated>2024-02-01T16:56:50+00:00</updated><published>2024-02-01T16:56:50+00:00</published><title>is there any good rag based open-source chatbot codebase</title></entry><entry><author><name>/u/Chemical_Agent_6515</name><uri>https://www.reddit.com/user/Chemical_Agent_6515</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m new to the LLM world, i&amp;#39;m looking for a use case where if i provide the google sheets data, it should give suggestions like what kind of data it is and what insights can be derived from the data.&lt;/p&gt; &lt;p&gt;please help me with the model or a source that helps me&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Chemical_Agent_6515&quot;&gt; /u/Chemical_Agent_6515 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aglqsm/summary_of_the_google_sheets_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aglqsm/summary_of_the_google_sheets_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aglqsm</id><link href="https://www.reddit.com/r/LangChain/comments/1aglqsm/summary_of_the_google_sheets_data/" /><updated>2024-02-01T21:10:16+00:00</updated><published>2024-02-01T21:10:16+00:00</published><title>summary of the google sheets data</title></entry><entry><author><name>/u/CincyTriGuy</name><uri>https://www.reddit.com/user/CincyTriGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m new to building Gen AI solutions and have been learning in Vertex (I&amp;#39;m a GCP solution architect with an infrastructure focus). I&amp;#39;m even newer to LangChain. But as I&amp;#39;m reading through the LangChain documentation it looks like every Vertex integration is marked deprecated. &lt;/p&gt; &lt;p&gt;Are there any Vertex integrations that aren&amp;#39;t deprecated?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CincyTriGuy&quot;&gt; /u/CincyTriGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agoi5b/are_all_the_google_vertex_integrations_deprecated/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agoi5b/are_all_the_google_vertex_integrations_deprecated/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agoi5b</id><link href="https://www.reddit.com/r/LangChain/comments/1agoi5b/are_all_the_google_vertex_integrations_deprecated/" /><updated>2024-02-01T23:06:02+00:00</updated><published>2024-02-01T23:06:02+00:00</published><title>Are all the Google Vertex integrations deprecated?</title></entry><entry><author><name>/u/o3omoomin</name><uri>https://www.reddit.com/user/o3omoomin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The documents may be very long, resulting in errors exceeding tokens per minute&lt;/p&gt; &lt;p&gt;If I ask to translate a long document at the LangChain prompt, how can I do so efficiently?&lt;/p&gt; &lt;p&gt;I even went so far as to separate it into chunks. The current logic is hard-coded to enter prompts one by one from doc[0] to doc[5].&lt;/p&gt; &lt;p&gt;Is there a way to do this efficiently?&lt;/p&gt; &lt;p&gt;I would appreciate it if you could also provide example code.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/o3omoomin&quot;&gt; /u/o3omoomin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agr9yi/how_to_request_translation_of_a_very_long/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agr9yi/how_to_request_translation_of_a_very_long/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agr9yi</id><link href="https://www.reddit.com/r/LangChain/comments/1agr9yi/how_to_request_translation_of_a_very_long/" /><updated>2024-02-02T01:10:30+00:00</updated><published>2024-02-02T01:10:30+00:00</published><title>How to request translation of a very long document to LangChain?</title></entry></feed>