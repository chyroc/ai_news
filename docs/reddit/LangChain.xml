<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-06-25T20:43:23+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/ANil1729</name><uri>https://www.reddit.com/user/ANil1729</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have built an open-source AI agent which can handle voice calls and respond back in real-time. Can be used for many use-cases such as sales calls, customer support etc.&lt;/p&gt; &lt;p&gt;Link to project :- &lt;a href=&quot;https://github.com/Anil-matcha/AI-Voice-Agent&quot;&gt;https://github.com/Anil-matcha/AI-Voice-Agent&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ANil1729&quot;&gt; /u/ANil1729 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do81l5/opensource_ai_voice_agent_with_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do81l5/opensource_ai_voice_agent_with_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1do81l5</id><link href="https://www.reddit.com/r/LangChain/comments/1do81l5/opensource_ai_voice_agent_with_openai/" /><updated>2024-06-25T14:58:08+00:00</updated><published>2024-06-25T14:58:08+00:00</published><title>Open-source AI Voice Agent with OpenAI</title></entry><entry><author><name>/u/The404Dude</name><uri>https://www.reddit.com/user/The404Dude</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have limited experience with LangChain and LLMs, primarily building simple chatbots with Retrieval-Augmented Generation (RAG). Currently, I&amp;#39;m helping a friend build a WhatsApp chatbot that retrieves its answers from a SQL database. I&amp;#39;ve been experimenting with the SQL tutorials in LangChain, but I haven&amp;#39;t yet achieved satisfactory results for a v1. I&amp;#39;ve tried using &lt;code&gt;create_sql_query_chain&lt;/code&gt; and &lt;code&gt;create_sql_agent&lt;/code&gt;. &lt;code&gt;create_sql_query_chain&lt;/code&gt; has been very inconsistent, while &lt;code&gt;create_sql_agent&lt;/code&gt; has produced better results but still struggles with the following issues:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Ensuring the LLM restricts queries to a specific &lt;code&gt;customer_id&lt;/code&gt; obtained from the context.&lt;/li&gt; &lt;li&gt;Preventing the LLM from answering questions that are too open, generic, or related to restricted device types (the user should only be allowed to ask about device type A).&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Given these challenges, I&amp;#39;m looking for advice, ideas, and any relevant experiences you might have. Thank you&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/The404Dude&quot;&gt; /u/The404Dude &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do5f9p/chatbot_that_talks_to_sql/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do5f9p/chatbot_that_talks_to_sql/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1do5f9p</id><link href="https://www.reddit.com/r/LangChain/comments/1do5f9p/chatbot_that_talks_to_sql/" /><updated>2024-06-25T13:00:22+00:00</updated><published>2024-06-25T13:00:22+00:00</published><title>Chatbot that talks to SQL</title></entry><entry><author><name>/u/thatsusernameistaken</name><uri>https://www.reddit.com/user/thatsusernameistaken</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi&lt;/p&gt; &lt;p&gt;I’ve tried to make some agent using crewai and autogen. And now I’m trying to make something similar in langchain. &lt;/p&gt; &lt;p&gt;What I’m trying to do is to ask the chatbot a question about a topic, this topic needs to be researched (googled), the sites scraped and embedded for content, and as a result I’d like the AI to output a structured data which I can then format as markdown. &lt;/p&gt; &lt;p&gt;I’ve made this work fairly ok with crewai, but would like to do this with langchain. I am able to - search for topics (DuckDuckGo, serper) - scrape and embed a site (bs4, web scraper) - output structured data (json)&lt;/p&gt; &lt;p&gt;But I’m unable to do this in an agent chain. &lt;/p&gt; &lt;p&gt;I also have a second use case which is to make an AI access APIs for searching (self hosted content), and use that result as a context for the answer. &lt;/p&gt; &lt;p&gt;Using local models only with ollama, preferably the openapi spec api. &lt;/p&gt; &lt;p&gt;Where should I start? Trying to chain these tools together went for easy to expert way too fast! 😂&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thatsusernameistaken&quot;&gt; /u/thatsusernameistaken &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1doefau/how_to_get_started/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1doefau/how_to_get_started/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1doefau</id><link href="https://www.reddit.com/r/LangChain/comments/1doefau/how_to_get_started/" /><updated>2024-06-25T19:26:09+00:00</updated><published>2024-06-25T19:26:09+00:00</published><title>How to get started?</title></entry><entry><author><name>/u/kamishugaze</name><uri>https://www.reddit.com/user/kamishugaze</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Using the following prompt template in building a RAG based QnA application:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;template = &amp;quot;&amp;quot;&amp;quot;Use the following pieces of context to answer the question about the story at the end. If the context doesn&amp;#39;t provide enough information, just say that you don&amp;#39;t know, don&amp;#39;t try to make up an answer. Pay attention to the context of the question rather than just looking for similar keywords in the corpus. Use three sentences maximum and keep the answer as concise as possible. Always say &amp;quot;thanks for asking!&amp;quot; at the end of the answer. {context} Question: {question} Helpful Answer: &amp;quot;&amp;quot;&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After a frequent testing, this turns out to be a very primitive prompt to the llm as the responses went on to hallucinate and sometimes produced manipulated responses on asking for a misleading query i.e. to test if it corrects the user. &lt;/p&gt; &lt;p&gt;If anyone working on the same or knows how to craft complex prompt templates for an optimized response generation, please care to enlighten.&lt;/p&gt; &lt;p&gt;Besides, are there any frameworks for such templates to ease up the task of prompt engineering?&lt;/p&gt; &lt;p&gt;Thank You &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kamishugaze&quot;&gt; /u/kamishugaze &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1doecqa/creating_a_prompt_template_for_rag_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1doecqa/creating_a_prompt_template_for_rag_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1doecqa</id><link href="https://www.reddit.com/r/LangChain/comments/1doecqa/creating_a_prompt_template_for_rag_chain/" /><updated>2024-06-25T19:22:20+00:00</updated><published>2024-06-25T19:22:20+00:00</published><title>Creating a prompt template for RAG chain</title></entry><entry><author><name>/u/Jean_dta</name><uri>https://www.reddit.com/user/Jean_dta</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi community, I have some problems with my model; I used GPT-4 for do a health model with RAG; I require that my model doesn&amp;#39;t speak about: financial, techonology... I want my model only can speak about health topics.&lt;/p&gt; &lt;p&gt;I used Fine-tuning for this issue, but my model got overfitting in some cases, for example when I wrote &amp;quot;Hi, how ar you&amp;quot; their answer was &amp;quot;I can&amp;#39;t speak about that...&amp;quot;, when I passed some examples in the traning data some examples that in which model respond with &amp;quot;Hi, my name in CemGPT....&amp;quot;.&lt;/p&gt; &lt;p&gt;How could I solve this problem?&lt;/p&gt; &lt;p&gt;help me pls!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jean_dta&quot;&gt; /u/Jean_dta &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do8d7m/custom_moderation_gpt_4_model/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do8d7m/custom_moderation_gpt_4_model/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1do8d7m</id><link href="https://www.reddit.com/r/LangChain/comments/1do8d7m/custom_moderation_gpt_4_model/" /><updated>2024-06-25T15:11:24+00:00</updated><published>2024-06-25T15:11:24+00:00</published><title>Custom Moderation GPT 4 Model</title></entry><entry><author><name>/u/italian_giga_chad</name><uri>https://www.reddit.com/user/italian_giga_chad</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone!&lt;/p&gt; &lt;p&gt;I have three CSV files for a RAG project. Two of the files are interconnected by a field that acts like a relational database key. The third file contains information related to the others, but there is no clear relational ID or similar field to connect them.&lt;/p&gt; &lt;p&gt;My idea was to unify the first two files into a JSON format and then use an LLM to classify natural language queries to extract a JSON for searching and generating a response based on the results. However, I have two problems with this solution:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;How can I integrate the information from the third CSV file?&lt;/li&gt; &lt;li&gt;The customer requested using a vector database like Chroma or Pinecone.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;What do you suggest I do?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/italian_giga_chad&quot;&gt; /u/italian_giga_chad &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dod2o3/rag_system_on_3_different_csv_any_suggestions/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dod2o3/rag_system_on_3_different_csv_any_suggestions/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dod2o3</id><link href="https://www.reddit.com/r/LangChain/comments/1dod2o3/rag_system_on_3_different_csv_any_suggestions/" /><updated>2024-06-25T18:29:40+00:00</updated><published>2024-06-25T18:29:40+00:00</published><title>RAG system on 3 different CSV. Any suggestions?</title></entry><entry><author><name>/u/Present_Owl742</name><uri>https://www.reddit.com/user/Present_Owl742</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hi&lt;/p&gt; &lt;p&gt;so, I&amp;#39;ve just started this week a mini project using AWS Bedrock, Claude Haiku and Titan embedding model. It&amp;#39;s more for me to understand how things work together so no production expectations - I want to add some documentation in the knowledge base and then ask questions and be provided with a full list of steps. The steps are split in different documents and use different components of the software, somebody with 5+ years of experience would be aware of this and this is what the system prompt that I use explains. &lt;/p&gt; &lt;p&gt;I&amp;#39;ve reached the step where I ask the question in the Test Knowledge Base area and it just outputs the like for like extract from 1 single document. I tried to play with the temperature and top-p of the model but it&amp;#39;s the same answer. &lt;/p&gt; &lt;p&gt;My question is: has anyone else experience something similar and how did they improve the answers? Is it through a lot of prompting/ changing the chunking strategy or moving to using APIs and langchain directly? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Present_Owl742&quot;&gt; /u/Present_Owl742 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do2odx/aws_bedrock_building_llm_using_a_knowledge_base/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do2odx/aws_bedrock_building_llm_using_a_knowledge_base/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1do2odx</id><link href="https://www.reddit.com/r/LangChain/comments/1do2odx/aws_bedrock_building_llm_using_a_knowledge_base/" /><updated>2024-06-25T10:23:39+00:00</updated><published>2024-06-25T10:23:39+00:00</published><title>AWS Bedrock - Building LLM using a knowledge base</title></entry><entry><author><name>/u/oldyoungin</name><uri>https://www.reddit.com/user/oldyoungin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to implement a Sentence Window Retrieval method in Langchain. The best way i can figure out how to do it is to perform semantic similarity and return a chunk_id along with the page_content. I then want to retrieve documents from the vector database that correspond to chunk_id - 1 and chunk_id + 1. how can i query the vector database based on a specific value, rather than a similarity search? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/oldyoungin&quot;&gt; /u/oldyoungin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dob8va/how_can_i_search_for_a_specific_value_in_a_column/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dob8va/how_can_i_search_for_a_specific_value_in_a_column/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dob8va</id><link href="https://www.reddit.com/r/LangChain/comments/1dob8va/how_can_i_search_for_a_specific_value_in_a_column/" /><updated>2024-06-25T17:12:49+00:00</updated><published>2024-06-25T17:12:49+00:00</published><title>How can I search for a specific value in a column in a vector database without performing a semantic similarity search?</title></entry><entry><author><name>/u/The404Dude</name><uri>https://www.reddit.com/user/The404Dude</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have limited experience with LangChain and LLMs, primarily building simple chatbots with Retrieval-Augmented Generation (RAG). Currently, I&amp;#39;m helping a friend build a WhatsApp chatbot that retrieves its answers from a SQL database. I&amp;#39;ve been experimenting with the SQL tutorials in LangChain, but I haven&amp;#39;t yet achieved satisfactory results for a v1. I&amp;#39;ve tried using &lt;code&gt;create_sql_query_chain&lt;/code&gt; and &lt;code&gt;create_sql_agent&lt;/code&gt;. &lt;code&gt;create_sql_query_chain&lt;/code&gt; has been very inconsistent, while &lt;code&gt;create_sql_agent&lt;/code&gt; has produced better results but still struggles with the following issues:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Ensuring the LLM restricts queries to a specific &lt;code&gt;customer_id&lt;/code&gt; obtained from the context.&lt;/li&gt; &lt;li&gt;Preventing the LLM from answering questions that are too open, generic, or related to restricted device types (the user should only be allowed to ask about device type A).&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Given these challenges, I&amp;#39;m looking for advice, ideas, and any relevant experiences you might have. Thank you&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/The404Dude&quot;&gt; /u/The404Dude &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do5emr/chatbot_with_sql/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do5emr/chatbot_with_sql/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1do5emr</id><link href="https://www.reddit.com/r/LangChain/comments/1do5emr/chatbot_with_sql/" /><updated>2024-06-25T12:59:35+00:00</updated><published>2024-06-25T12:59:35+00:00</published><title>Chatbot with SQL</title></entry><entry><author><name>/u/WillowHefty</name><uri>https://www.reddit.com/user/WillowHefty</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Title says it all. PostgresSaver was deprecated and removed from langchain-postgres. Are there any plans on updating this or should we just stick to sqlite?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/WillowHefty&quot;&gt; /u/WillowHefty &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do889i/any_news_on_when_langgraph_checkpointing_returns/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do889i/any_news_on_when_langgraph_checkpointing_returns/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1do889i</id><link href="https://www.reddit.com/r/LangChain/comments/1do889i/any_news_on_when_langgraph_checkpointing_returns/" /><updated>2024-06-25T15:05:39+00:00</updated><published>2024-06-25T15:05:39+00:00</published><title>Any news on when langgraph checkpointing returns to langchain-postgres?</title></entry><entry><author><name>/u/Strange-Ant-4194</name><uri>https://www.reddit.com/user/Strange-Ant-4194</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Basically I&amp;#39;ve built one use case on linux desktop to simulate an AI personal assistant on the mobile phone which can automate various actions. My use case is basically that when an incoming call comes, the personal assistant determines the identity of the caller using the contact list and whether or not the user is in a meeting by checking the calendar. (Since i havent done anything on the phone, calendar contact list etc. are implemented as simple text files). Then depending on the above two factors, it either performs receive_call, send_message or mute. &lt;/p&gt; &lt;p&gt;So the final output is just one line stating the name of the action to be taken(ie send message, receive call or mute) &lt;/p&gt; &lt;p&gt;Is there any way i can display this on a mobile simulator?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Strange-Ant-4194&quot;&gt; /u/Strange-Ant-4194 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do4qmi/is_there_any_way_i_can_integrate_ollama_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do4qmi/is_there_any_way_i_can_integrate_ollama_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1do4qmi</id><link href="https://www.reddit.com/r/LangChain/comments/1do4qmi/is_there_any_way_i_can_integrate_ollama_langchain/" /><updated>2024-06-25T12:26:05+00:00</updated><published>2024-06-25T12:26:05+00:00</published><title>Is there any way i can integrate ollama, langchain and llama3 into a mobile simulator?</title></entry><entry><author><name>/u/harshit_nariya</name><uri>https://www.reddit.com/user/harshit_nariya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/harshit_nariya&quot;&gt; /u/harshit_nariya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/AnyBodyCanAI/comments/1do4eon/zero_shot_prompting_vs_few_shot_prompting/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do4g5l/zero_shot_prompting_vs_few_shot_prompting/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1do4g5l</id><link href="https://www.reddit.com/r/LangChain/comments/1do4g5l/zero_shot_prompting_vs_few_shot_prompting/" /><updated>2024-06-25T12:10:23+00:00</updated><published>2024-06-25T12:10:23+00:00</published><title>Zero shot prompting vs few shot prompting</title></entry><entry><author><name>/u/cosmic_predator</name><uri>https://www.reddit.com/user/cosmic_predator</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;m using WebBaseLoader to extract web contents from a list of 70k urls. Everytime I run it, it runs initially well and after some point, the site refuses to connect. I&amp;#39;m currently setting requests_per_second to 50.&lt;/p&gt; &lt;p&gt;Is there any way I can make it faster without hitting limits?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cosmic_predator&quot;&gt; /u/cosmic_predator &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do409j/effieicent_way_to_do_webbaseloader_for_a_list_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do409j/effieicent_way_to_do_webbaseloader_for_a_list_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1do409j</id><link href="https://www.reddit.com/r/LangChain/comments/1do409j/effieicent_way_to_do_webbaseloader_for_a_list_of/" /><updated>2024-06-25T11:45:48+00:00</updated><published>2024-06-25T11:45:48+00:00</published><title>Effieicent way to do WebBaseLoader for a list of 70k urls</title></entry><entry><author><name>/u/Informal-Victory8655</name><uri>https://www.reddit.com/user/Informal-Victory8655</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do0d7y/unable_to_delete_vectors_from_serverless_pinecone/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/XwBFGcZE3ASay1j0fNTmfW6lJmBX9Z__MYtad6ExHAg.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=85a994ab1b17700deba8a70a35ab9b6ea5f350b8&quot; alt=&quot;Unable to delete vectors from Serverless Pinecone for specific source files (like a.pdf)&quot; title=&quot;Unable to delete vectors from Serverless Pinecone for specific source files (like a.pdf)&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I&amp;#39;m unable to delete vectors for a specific source using metadata filtering with serverless pinecone as this feature is not available with serverless pinecone. And the other architecture of pinecone is not free, so I&amp;#39;m using serverless for development purposes. &lt;/p&gt; &lt;p&gt;A solution is recommended which is &lt;a href=&quot;https://docs.pinecone.io/guides/data/manage-rag-documents#delete-all-records-for-a-parent-document&quot;&gt;https://docs.pinecone.io/guides/data/manage-rag-documents#delete-all-records-for-a-parent-document&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;But this solution is not useful as I cannot pass specific metadata for deletion of vectors, instead it asks for a prefix in ids of vector. Now I don&amp;#39;t know how to make it work for my use case. I&amp;#39;ve also tried adding custom ids for vectors using name of source file + str(uuid) for each chunk and created a list which I&amp;#39;m trying to pass to pinecone.from_documents but it doesn&amp;#39;t support setting custom ids for vectors.&lt;/p&gt; &lt;p&gt;Now I also don&amp;#39;t know how they set the ids as shown in example like &amp;#39;doc1#chunk1&amp;#39; etc.... &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/34yirw1t8o8d1.png?width=1844&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c4ecf51d149179459ed2042f1694d5fee7ec462b&quot;&gt;https://preview.redd.it/34yirw1t8o8d1.png?width=1844&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c4ecf51d149179459ed2042f1694d5fee7ec462b&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Informal-Victory8655&quot;&gt; /u/Informal-Victory8655 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do0d7y/unable_to_delete_vectors_from_serverless_pinecone/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1do0d7y/unable_to_delete_vectors_from_serverless_pinecone/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1do0d7y</id><media:thumbnail url="https://external-preview.redd.it/XwBFGcZE3ASay1j0fNTmfW6lJmBX9Z__MYtad6ExHAg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=85a994ab1b17700deba8a70a35ab9b6ea5f350b8" /><link href="https://www.reddit.com/r/LangChain/comments/1do0d7y/unable_to_delete_vectors_from_serverless_pinecone/" /><updated>2024-06-25T07:40:43+00:00</updated><published>2024-06-25T07:40:43+00:00</published><title>Unable to delete vectors from Serverless Pinecone for specific source files (like a.pdf)</title></entry><entry><author><name>/u/emersounds</name><uri>https://www.reddit.com/user/emersounds</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently working on a project involving LangGraph and Gemini Pro 1.5 (Vertex AI).&lt;/p&gt; &lt;p&gt;Gemini is not returning multiple function calls for parallel execution. I need to make several tool calls (e.g., for different months). However, it processes these calls sequentially, one at a time, which significantly increases the response time and costs due to token usage. For instance, if I need data for four months, it will:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Make the first tool call&lt;/li&gt; &lt;li&gt;Wait for the response&lt;/li&gt; &lt;li&gt;Make the second tool call&lt;/li&gt; &lt;li&gt;Wait for the response&lt;/li&gt; &lt;li&gt;And so on...&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Previously, I had implemented parallel function calling with LangChain&amp;#39;s &lt;code&gt;AgentExecutor&lt;/code&gt; class, where the agent would make all the necessary calls simultaneously, wait for all responses, and then process them together. This parallel calling mechanism has stopped working with LangGraph. Maybe because now the prompt is much larger than before?&lt;/p&gt; &lt;p&gt;Any tips or advice?&lt;/p&gt; &lt;p&gt;Thanks in advance for your help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/emersounds&quot;&gt; /u/emersounds &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dnmeuy/help_parallel_function_calling_with_langgraph_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dnmeuy/help_parallel_function_calling_with_langgraph_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dnmeuy</id><link href="https://www.reddit.com/r/LangChain/comments/1dnmeuy/help_parallel_function_calling_with_langgraph_and/" /><updated>2024-06-24T19:43:01+00:00</updated><published>2024-06-24T19:43:01+00:00</published><title>[HELP] Parallel function calling with Langgraph and Gemini 1.5 Pro</title></entry><entry><author><name>/u/fantasyleaguelottery</name><uri>https://www.reddit.com/user/fantasyleaguelottery</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone implemented a working streamlit app with LangGraph? I am having issues with state management between the two. If anyone has implemented the LangGraph tutorial chatbot in streamlit, please let me know&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/fantasyleaguelottery&quot;&gt; /u/fantasyleaguelottery &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dngwkn/langgraph_streamlit_state_management/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dngwkn/langgraph_streamlit_state_management/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dngwkn</id><link href="https://www.reddit.com/r/LangChain/comments/1dngwkn/langgraph_streamlit_state_management/" /><updated>2024-06-24T15:55:45+00:00</updated><published>2024-06-24T15:55:45+00:00</published><title>LangGraph + Streamlit State Management</title></entry><entry><author><name>/u/pekkamama</name><uri>https://www.reddit.com/user/pekkamama</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on a project that requires me to build a text-2-sql code generation pipeline. I&amp;#39;ve being playing around sql agent in langchain. The chain sometimes breaks since my DB is too huge for Llama 3 context window (model input limit is 8K, hosted on bedrock). Since my pipeline to handle after retrieving the data from db is already handled using other chains, my only doubt is that:&lt;/p&gt; &lt;p&gt;How can I build an agent in Langchain that takes the natural language as input, and provided with the db schema and information about tables, generates relevant sql query. &lt;/p&gt; &lt;p&gt;I tried doing this using custom agent in langchain and have trouble defining tools for this and also, facing difficulty in getting the pipeline to work. &lt;/p&gt; &lt;p&gt;would appreciate any suggestions/help. Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pekkamama&quot;&gt; /u/pekkamama &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dnm4tc/building_a_custom_text2sql_agent_with_tool_llama_3/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dnm4tc/building_a_custom_text2sql_agent_with_tool_llama_3/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dnm4tc</id><link href="https://www.reddit.com/r/LangChain/comments/1dnm4tc/building_a_custom_text2sql_agent_with_tool_llama_3/" /><updated>2024-06-24T19:31:21+00:00</updated><published>2024-06-24T19:31:21+00:00</published><title>Building a Custom Text-2-SQL agent with tool, Llama 3</title></entry><entry><author><name>/u/filet_mign0n</name><uri>https://www.reddit.com/user/filet_mign0n</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a way to handle private data, like user input from a form without anonymouzation (eg presidio) and especially while using the regular openai API?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/filet_mign0n&quot;&gt; /u/filet_mign0n &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dno1ll/handling_private_data_without_selfhosting_etc/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dno1ll/handling_private_data_without_selfhosting_etc/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dno1ll</id><link href="https://www.reddit.com/r/LangChain/comments/1dno1ll/handling_private_data_without_selfhosting_etc/" /><updated>2024-06-24T20:50:30+00:00</updated><published>2024-06-24T20:50:30+00:00</published><title>Handling private data without self-hosting etc.</title></entry><entry><author><name>/u/Saharsha36</name><uri>https://www.reddit.com/user/Saharsha36</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have tried parsing AST of codebase to create function signatures and body and embedded it in vector database. What would be the best way to prepare the codebase? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Saharsha36&quot;&gt; /u/Saharsha36 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dnos9r/how_to_build_efficient_rag_with_codebase/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dnos9r/how_to_build_efficient_rag_with_codebase/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dnos9r</id><link href="https://www.reddit.com/r/LangChain/comments/1dnos9r/how_to_build_efficient_rag_with_codebase/" /><updated>2024-06-24T21:22:14+00:00</updated><published>2024-06-24T21:22:14+00:00</published><title>How to build efficient RAG with codebase?</title></entry><entry><author><name>/u/Vegetable_Statement7</name><uri>https://www.reddit.com/user/Vegetable_Statement7</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey! Pretty new to this. I&amp;#39;m building a sales agent that can help with e.g. lead identification, enrichment, personalised outbound email messaging, updating our CRM. I want to test it pretty rigorously before we start using it. What is the best way to do something like automated regression testing for an agent, i.e. building a dataset of tasks with &amp;#39;correct&amp;#39; answers where I can see how the agent performs after I make any changes? I could build this from scratch but I feel like most of the tasks are fairly generic and was wondering if there are available datasets or how others have approached this problem &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Vegetable_Statement7&quot;&gt; /u/Vegetable_Statement7 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dngjfm/testing_sales_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dngjfm/testing_sales_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dngjfm</id><link href="https://www.reddit.com/r/LangChain/comments/1dngjfm/testing_sales_agent/" /><updated>2024-06-24T15:40:25+00:00</updated><published>2024-06-24T15:40:25+00:00</published><title>Testing sales agent</title></entry><entry><author><name>/u/Rare_Confusion6373</name><uri>https://www.reddit.com/user/Rare_Confusion6373</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Aside from using better or larger models and employing fine-tuning, how else can we achieve improved responses from models?&lt;/p&gt; &lt;p&gt;p.s, I&amp;#39;m extremely new to this space, so any answers would be appreciated. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Rare_Confusion6373&quot;&gt; /u/Rare_Confusion6373 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dn7p4h/what_strategies_can_we_use_to_enhance_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dn7p4h/what_strategies_can_we_use_to_enhance_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dn7p4h</id><link href="https://www.reddit.com/r/LangChain/comments/1dn7p4h/what_strategies_can_we_use_to_enhance_llm/" /><updated>2024-06-24T07:24:59+00:00</updated><published>2024-06-24T07:24:59+00:00</published><title>What strategies can we use to enhance LLM responses besides fine-tuning and prompt engineering?</title></entry><entry><author><name>/u/byrocuy</name><uri>https://www.reddit.com/user/byrocuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’m working on a chatbot that interacts with an internal API, such as searching for items based on user queries. The output needs to be in a structured JSON format that I can pass to the front end. Here’s the desired structure:&lt;/p&gt; &lt;p&gt;&lt;code&gt;json { &amp;quot;type&amp;quot;: &amp;quot;message&amp;quot;, &amp;quot;message&amp;quot;: &amp;quot;Here is an item matching your search criteria&amp;quot;, &amp;quot;data&amp;quot;: [ { &amp;quot;item&amp;quot;: 1, &amp;quot;id&amp;quot;: &amp;quot;abc123&amp;quot; }, { &amp;quot;item&amp;quot;: 2, &amp;quot;id&amp;quot;: &amp;quot;def456&amp;quot; }, ... ] } &lt;/code&gt;&lt;/p&gt; &lt;p&gt;I’m struggling with extracting the assistant “message” and the item data (including the item ID) from the tools. I need to pass the data (e.g. item id) so then the front end can process it and display a custom view (card view) of items. My attempts to inject a Pydantic model and explicitly prompt to output a structured format haven’t been successful so far. &lt;/p&gt; &lt;p&gt;I am thinking to set up a specific node at the end of the graph to parse the assistant’s output, but I found that the assistant keeps discarding item details such as item id (even after I explicitly prompt not to do so). Is there a better approach to achieve this? Any advice or insights would be greatly appreciated!&lt;/p&gt; &lt;h1&gt;&lt;/h1&gt; &lt;p&gt;&lt;strong&gt;EDIT&lt;/strong&gt;: I&amp;#39;ve experimented with injecting few-shot examples into format_instructor and it has been successful so far, although there are instances where it didn&amp;#39;t produce the desired output. Here&amp;#39;s what I do (might be helpful for someone facing a similar issue):&lt;/p&gt; &lt;ol&gt; &lt;li&gt;I defined an output schema and include some examples of the desired output inside it. I found this method in &lt;a href=&quot;https://langchain-ai.github.io/langgraph/tutorials/customer-support/customer-support/#assistants&quot;&gt;langgraph customer support tutorial&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;```python class OutputMessage(BaseModel): &amp;quot;&amp;quot;&amp;quot;Output message schema. Contains the text message generated from chatbot and the data to be displayed to the user (if any).&amp;quot;&amp;quot;&amp;quot; type: Literal[&amp;quot;message&amp;quot;, &amp;quot;search_item&amp;quot;, &amp;quot;get_item_detail&amp;quot;] = Field(..., description=&amp;quot;The type of the output message&amp;quot;) message: str = Field(..., description=&amp;quot;The text message to be displayed to the user&amp;quot;) data: List = Field([], description=&amp;quot;The data to be displayed to the user&amp;quot;)&lt;/p&gt; &lt;pre&gt;&lt;code&gt;class Config: schema_extra = { &amp;quot;example&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;message&amp;quot;, &amp;quot;output&amp;quot;: &amp;quot;I can help you search item and stuff&amp;quot;, &amp;quot;data&amp;quot;: [] }, &amp;quot;example2&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;search_item&amp;quot;, &amp;quot;output&amp;quot;: &amp;quot;Here are items that might be fit your query&amp;quot;, &amp;quot;data&amp;quot;: [ { &amp;quot;id&amp;quot;: 1, &amp;quot;title&amp;quot;: &amp;quot;Item 1&amp;quot; }, { &amp;quot;id&amp;quot;: 2, &amp;quot;title&amp;quot;: &amp;quot;Item 2&amp;quot;, } ] } # Add another example &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;```&lt;/p&gt; &lt;p&gt;Next, I inject the schema into the system prompt&lt;/p&gt; &lt;p&gt;```python parser = PydanticOutputParser(pydantic_object=OutputMessage)&lt;/p&gt; &lt;p&gt;system_prompt = &amp;quot;&amp;quot;&amp;quot; Your system prompt... You can only response with valid and directly parsable json. Your output must be based on this schema:\n{format_instructions} &amp;quot;&amp;quot;&amp;quot;&lt;/p&gt; &lt;p&gt;primary_assistant_prompt = ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, system_prompt), (&amp;quot;placeholder&amp;quot;, &amp;quot;{messages}&amp;quot;), ] ).partial(format_instructions=parser.get_format_instructions()) ```&lt;/p&gt; &lt;p&gt;It&amp;#39;s not perfect, because sometimes it doesn&amp;#39;t follow the format, but I&amp;#39;ve managed to improve it by removing unnecessary prompts. If there are better implementations or some ways to enhance it further, I&amp;#39;d greatly appreciate your insight. Many thanks for the help guys, It&amp;#39;s been really helpful.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/byrocuy&quot;&gt; /u/byrocuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dna58k/need_advice_in_structuring_json_output_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dna58k/need_advice_in_structuring_json_output_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dna58k</id><link href="https://www.reddit.com/r/LangChain/comments/1dna58k/need_advice_in_structuring_json_output_in/" /><updated>2024-06-24T10:21:26+00:00</updated><published>2024-06-24T10:21:26+00:00</published><title>Need advice in Structuring JSON Output in Langgraph for Chatbot</title></entry><entry><author><name>/u/sammopus</name><uri>https://www.reddit.com/user/sammopus</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using FastAPI with langchain I am using &lt;code&gt;aconvert_to_graph_documents&lt;/code&gt; which Asynchronously convert a sequence of documents into graph documents. &lt;/p&gt; &lt;p&gt;I am not able to use Langchain&amp;#39;s ChatAnthropic in async manner, I tried using semaphore but keep getting&lt;br/&gt; anthropic.RateLimitError saying Number of concurrent connections has exceeded your rate limit.&lt;/p&gt; &lt;p&gt;Is there no way set this to a reasonable number?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sammopus&quot;&gt; /u/sammopus &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dn9ytb/number_of_concurrent_connections_has_exceeded/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dn9ytb/number_of_concurrent_connections_has_exceeded/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dn9ytb</id><link href="https://www.reddit.com/r/LangChain/comments/1dn9ytb/number_of_concurrent_connections_has_exceeded/" /><updated>2024-06-24T10:09:11+00:00</updated><published>2024-06-24T10:09:11+00:00</published><title>Number of concurrent connections has exceeded your rate limit with Anthropic with Langchain</title></entry><entry><author><name>/u/suribe06</name><uri>https://www.reddit.com/user/suribe06</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve compiled a history of chats between a user and an AI assistant in JSON format. Here’s a snippet of how the chat data looks:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;quot;2024-06-23&amp;quot;: [ { &amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;message&amp;quot;: &amp;quot;Hello! Can you suggest some tourist places to visit in Paris?&amp;quot;, &amp;quot;time&amp;quot;: &amp;quot;2024-06-23T15:30:00Z&amp;quot; }, { &amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;message&amp;quot;: &amp;quot;Hello! Paris is a beautiful city with many wonderful places to visit. Here are some top tourist attractions: ...&amp;quot;, &amp;quot;time&amp;quot;: &amp;quot;2024-06-23T15:32:00Z&amp;quot; } ] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I’m planning to create a detailed knowledge graph, and I&amp;#39;m debating between two approaches for structuring the documents: creating a document for each interaction or aggregating all interactions for each date into a single document. Currently, I lean towards the former to capture more granularity in the analysis. Here’s how I’m setting up my documents using LangChain:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain.docstore.document import Document import json def load_conversations_from_json(file_path): docs = [] with open(file_path, &amp;#39;r&amp;#39;, encoding=&amp;#39;utf-8&amp;#39;) as file: chat_data = json.load(file) for date, messages in chat_data.items(): for message in messages: role = message[&amp;#39;role&amp;#39;] text = message[&amp;#39;message&amp;#39;] time = message[&amp;#39;time&amp;#39;] # Create a document with the conversation metadata = { &amp;quot;date&amp;quot;: date, &amp;quot;time&amp;quot;: time, &amp;quot;role&amp;quot;: role } docs.append(Document(page_content=text, metadata=metadata)) return docs conversations = load_conversations_from_json(&amp;#39;chat_history.json&amp;#39;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I’m considering using &lt;code&gt;LLMGraphTransformer&lt;/code&gt; from LangChain to convert these documents into graph documents. Do you recommend creating a specific prompt for this task? Here’s a simple prompt I’m considering:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain.prompts import ChatPromptTemplate kg_prompt = ChatPromptTemplate.from_template(&amp;quot;&amp;quot;&amp;quot; You are an AI that constructs knowledge graphs from chat histories. Your task is to identify key entities and the relationships between them based on the provided conversation. Please proceed with the extraction based on the conversation provided. &amp;quot;&amp;quot;&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;How beneficial is it to use the &lt;code&gt;allowed_nodes&lt;/code&gt; and &lt;code&gt;allowed_relationships&lt;/code&gt; parameters in &lt;code&gt;LLMGraphTransformer&lt;/code&gt;? Which model would you recommend for the LLM? Currently, I’m using &lt;code&gt;gpt-4o&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;I’d appreciate any advice or insights on optimizing this process for creating a comprehensive knowledge graph. Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/suribe06&quot;&gt; /u/suribe06 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dn55j1/creating_a_knowledge_graph_from_chat_history/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dn55j1/creating_a_knowledge_graph_from_chat_history/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dn55j1</id><link href="https://www.reddit.com/r/LangChain/comments/1dn55j1/creating_a_knowledge_graph_from_chat_history/" /><updated>2024-06-24T04:35:05+00:00</updated><published>2024-06-24T04:35:05+00:00</published><title>Creating a Knowledge Graph from Chat History Using LangChain: Seeking Advice</title></entry><entry><author><name>/u/harshit_nariya</name><uri>https://www.reddit.com/user/harshit_nariya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dn86fa/build_rag_in_10_lines_of_code_with_lyzr/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/Sh8ty2pedOlOCbFwCc1efB3PEGCwHPvQ1NQQbuCBnpI.jpg&quot; alt=&quot;Build RAG in 10 Lines of Code with Lyzr&quot; title=&quot;Build RAG in 10 Lines of Code with Lyzr&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/harshit_nariya&quot;&gt; /u/harshit_nariya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/AnyBodyCanAI/comments/1dn8338/build_rag_in_10_lines_of_code_with_lyzr/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dn86fa/build_rag_in_10_lines_of_code_with_lyzr/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dn86fa</id><media:thumbnail url="https://b.thumbs.redditmedia.com/Sh8ty2pedOlOCbFwCc1efB3PEGCwHPvQ1NQQbuCBnpI.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1dn86fa/build_rag_in_10_lines_of_code_with_lyzr/" /><updated>2024-06-24T07:59:52+00:00</updated><published>2024-06-24T07:59:52+00:00</published><title>Build RAG in 10 Lines of Code with Lyzr</title></entry></feed>