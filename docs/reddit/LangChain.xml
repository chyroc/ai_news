<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-03-07T11:23:41+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/ronittsainii</name><uri>https://www.reddit.com/user/ronittsainii</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, I have written a new blog that explains how you can create a custom AI-powered chatbot using LangChain with code examples.&lt;/p&gt; &lt;p&gt;At the end of this blog, I have also given a working chatbot, that has been developed using LangChain, OpenAI API, and Pinecone that you can use and test.&lt;/p&gt; &lt;p&gt;You can read it at &lt;a href=&quot;https://www.deligence.com/langchain-chatbot/&quot;&gt;LangChain Chatbot&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Feedback appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ronittsainii&quot;&gt; /u/ronittsainii &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8rxtu/how_to_build_a_custom_chatbot_using_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8rxtu/how_to_build_a_custom_chatbot_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b8rxtu</id><link href="https://www.reddit.com/r/LangChain/comments/1b8rxtu/how_to_build_a_custom_chatbot_using_langchain/" /><updated>2024-03-07T11:01:37+00:00</updated><published>2024-03-07T11:01:37+00:00</published><title>How To Build a Custom Chatbot Using LangChain With Examples</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Could someone kindly assist me with this issue?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/langchain-ai/langchain/discussions/18722&quot;&gt;https://github.com/langchain-ai/langchain/discussions/18722&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8prsz/cant_make_the_chat_to_understand_previous_context/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8prsz/cant_make_the_chat_to_understand_previous_context/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b8prsz</id><link href="https://www.reddit.com/r/LangChain/comments/1b8prsz/cant_make_the_chat_to_understand_previous_context/" /><updated>2024-03-07T08:39:44+00:00</updated><published>2024-03-07T08:39:44+00:00</published><title>Can't make the chat to understand previous context</title></entry><entry><author><name>/u/Apprehensive_Act_707</name><uri>https://www.reddit.com/user/Apprehensive_Act_707</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi. Just starting a new journey on this, and Need some clarification. I’m building a complex rag system for many different kind of documents. The way I understand between the many commercially available vector stores, some have different strengths and advantages depending on what king of data you retrieving. There is some good comparison between then in regards of kind of data and chunk sizes? Ro help on which to choose, or this difference is negligible and we can choose whatever is easier to implement?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Apprehensive_Act_707&quot;&gt; /u/Apprehensive_Act_707 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8po5e/doubts_about_choosing_vet_for_storage/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8po5e/doubts_about_choosing_vet_for_storage/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b8po5e</id><link href="https://www.reddit.com/r/LangChain/comments/1b8po5e/doubts_about_choosing_vet_for_storage/" /><updated>2024-03-07T08:32:59+00:00</updated><published>2024-03-07T08:32:59+00:00</published><title>Doubts about choosing vet for storage</title></entry><entry><author><name>/u/o3omoomin</name><uri>https://www.reddit.com/user/o3omoomin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So far, I have implemented RAG using Langchain. In the case of Langchain’s RAG,&lt;/p&gt; &lt;p&gt;It was like this: &amp;quot;Load document -&amp;gt; Text split -&amp;gt; Chroma vector DB embedding -&amp;gt; llm.&amp;quot;&lt;/p&gt; &lt;p&gt;However, in the case of llama index, it looks like there is no vector DB embedding. Am I misunderstanding it?&lt;/p&gt; &lt;p&gt;And setting the embedding model doesn&amp;#39;t seem to exist in the llama index.&lt;/p&gt; &lt;p&gt;I would appreciate it if you could explain. or git code please&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/o3omoomin&quot;&gt; /u/o3omoomin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8iaac/what_is_the_difference_between_llama_index_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8iaac/what_is_the_difference_between_llama_index_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b8iaac</id><link href="https://www.reddit.com/r/LangChain/comments/1b8iaac/what_is_the_difference_between_llama_index_and/" /><updated>2024-03-07T02:00:55+00:00</updated><published>2024-03-07T02:00:55+00:00</published><title>What is the difference between llama index and Langchain?</title></entry><entry><author><name>/u/esraaatmeh</name><uri>https://www.reddit.com/user/esraaatmeh</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8p37d/stop_agent_from_generate_new_input/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/SRU7iXjD5f-clqYQ1WEYKTpCbg5ZF3at_ONvwFUkIpw.jpg&quot; alt=&quot;stop agent from generate new input.&quot; title=&quot;stop agent from generate new input.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How I can stop LLM Agent new input, I want just to stop the generation process and extract the first AI answer. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/xz8t0cdpbvmc1.png?width=765&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b249549b5be459acfbc4aed3b3181023fb2298dd&quot;&gt;https://preview.redd.it/xz8t0cdpbvmc1.png?width=765&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b249549b5be459acfbc4aed3b3181023fb2298dd&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/fjsfyv4abvmc1.png?width=1102&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0a5f8df8e756e7cfa6580d014bbcbf7270822af1&quot;&gt;https://preview.redd.it/fjsfyv4abvmc1.png?width=1102&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0a5f8df8e756e7cfa6580d014bbcbf7270822af1&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/esraaatmeh&quot;&gt; /u/esraaatmeh &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8p37d/stop_agent_from_generate_new_input/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8p37d/stop_agent_from_generate_new_input/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1b8p37d</id><media:thumbnail url="https://b.thumbs.redditmedia.com/SRU7iXjD5f-clqYQ1WEYKTpCbg5ZF3at_ONvwFUkIpw.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1b8p37d/stop_agent_from_generate_new_input/" /><updated>2024-03-07T07:55:43+00:00</updated><published>2024-03-07T07:55:43+00:00</published><title>stop agent from generate new input.</title></entry><entry><author><name>/u/o3omoomin</name><uri>https://www.reddit.com/user/o3omoomin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Using llama index, we wanted to implement RAG. I put the secret key in the .env file and tried to load it with dotenv, but the result was as follows.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;load_dotenv() OPENAI_API_KEY = os.getenv(&amp;quot;OPENAI_API_KEY&amp;quot;) llm = OpenAI(model=&amp;quot;gpt-4-0125-preview&amp;quot;) chunk_sizes = [128, 256, 512, 1024] nodes_list = [] vector_indices = [] for chunk_size in chunk_sizes: print(f&amp;quot;Chunk Size: {chunk_size}&amp;quot;) splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_size // 2) nodes = splitter.get_nodes_from_documents(docs) for node in nodes: node.metadata[&amp;quot;chunk_size&amp;quot;] = chunk_size node.excluded_embed_metadata_keys = [&amp;quot;chunk_size&amp;quot;] node.excluded_llm_metadata_keys = [&amp;quot;chunk_size&amp;quot;] nodes_list.append(nodes) vector_index = VectorStoreIndex(nodes) vector_indices.append(vector_index) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And below are the execution results. And what is this post 200 and url? What does this mean? Embedding? Or what?&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Chunk Size: 128 HTTP Request: POST https://api.openai.com/v1/embeddings &amp;quot;HTTP/1.1 200 OK&amp;quot; HTTP Request: POST https://api.openai.com/v1/embeddings &amp;quot;HTTP/1.1 200 OK&amp;quot; HTTP Request: POST https://api.openai.com/v1/embeddings &amp;quot;HTTP/1.1 200 OK&amp;quot; Chunk Size: 256 HTTP Request: POST https://api.openai.com/v1/embeddings &amp;quot;HTTP/1.1 200 OK&amp;quot; HTTP Request: POST https://api.openai.com/v1/embeddings &amp;quot;HTTP/1.1 200 OK&amp;quot; Chunk Size: 512 HTTP Request: POST https://api.openai.com/v1/embeddings &amp;quot;HTTP/1.1 200 OK&amp;quot; Chunk Size: 1024 HTTP Request: POST https://api.openai.com/v1/embeddings &amp;quot;HTTP/1.1 200 OK&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/o3omoomin&quot;&gt; /u/o3omoomin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8p2se/gpt_secret_key_not_working_in_llama_index_it/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8p2se/gpt_secret_key_not_working_in_llama_index_it/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b8p2se</id><link href="https://www.reddit.com/r/LangChain/comments/1b8p2se/gpt_secret_key_not_working_in_llama_index_it/" /><updated>2024-03-07T07:54:56+00:00</updated><published>2024-03-07T07:54:56+00:00</published><title>gpt secret key not working in llama index. It seems like</title></entry><entry><author><name>/u/Inevitable-Judge2642</name><uri>https://www.reddit.com/user/Inevitable-Judge2642</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8nwv8/genai_streaming_api_with_langchainjs_ollama_and/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/K3poCqV0RmekR4MCYAgcxwNtedRSjQKYQF_31nRlj_w.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7a99ffb7374d2cff74c9ccf3b039ff8ae6b3a4e5&quot; alt=&quot;GenAI streaming API with LangChainJS, Ollama and Fastify&quot; title=&quot;GenAI streaming API with LangChainJS, Ollama and Fastify&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Inevitable-Judge2642&quot;&gt; /u/Inevitable-Judge2642 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://k33g.hashnode.dev/genai-streaming-api-with-langchainjs-ollama-and-fastify&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8nwv8/genai_streaming_api_with_langchainjs_ollama_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1b8nwv8</id><media:thumbnail url="https://external-preview.redd.it/K3poCqV0RmekR4MCYAgcxwNtedRSjQKYQF_31nRlj_w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7a99ffb7374d2cff74c9ccf3b039ff8ae6b3a4e5" /><link href="https://www.reddit.com/r/LangChain/comments/1b8nwv8/genai_streaming_api_with_langchainjs_ollama_and/" /><updated>2024-03-07T06:44:20+00:00</updated><published>2024-03-07T06:44:20+00:00</published><title>GenAI streaming API with LangChainJS, Ollama and Fastify</title></entry><entry><author><name>/u/Diligent_Tonight3232</name><uri>https://www.reddit.com/user/Diligent_Tonight3232</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;As the text suggests, can I build an application for creating responses for emails when i provide them with a email text? Any advice or heads up in this direction would help me start with the project.&lt;/p&gt; &lt;p&gt;Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Diligent_Tonight3232&quot;&gt; /u/Diligent_Tonight3232 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8mfdw/building_a_email_responder_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8mfdw/building_a_email_responder_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b8mfdw</id><link href="https://www.reddit.com/r/LangChain/comments/1b8mfdw/building_a_email_responder_with_langchain/" /><updated>2024-03-07T05:22:15+00:00</updated><published>2024-03-07T05:22:15+00:00</published><title>Building a email responder with langchain?</title></entry><entry><author><name>/u/A_Feyn-man</name><uri>https://www.reddit.com/user/A_Feyn-man</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So I&amp;#39;m using an LLM = AzureChatOpenAI() and i have a .json data file that has the content of various APIs in the form : &amp;quot;2&amp;quot;: { &amp;quot;Method&amp;quot;: &amp;quot;POST&amp;quot;, &amp;quot;Path&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;FunctionName&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;FunctionCode&amp;quot;: &amp;quot;{...}&amp;quot;, &amp;quot;Queries&amp;quot;: [] } &lt;/p&gt; &lt;p&gt;I have a list of these and I&amp;#39;m using AzureOpenAI() as my embeddings model to create a vector store db and retrieve. The I&amp;#39;m initialising my agent= AutoGPT with memory as vectorstore.as_retriever.&lt;/p&gt; &lt;p&gt;My end goal is to generate end to end flow of these APIs for testing purposes for the given api and original prompt is agent.run(&amp;quot;What are the different API sequences that are possible to test the end to end flow of the API for the given APIs. The different fields that are present in the json are path, method, queries,FunctionName and FunctionCode. You cannot ask for human input.Start by using APIs wivh no prerequisitesand authentication&amp;quot;) &lt;/p&gt; &lt;p&gt;Also I&amp;#39;ve defined custom tool which @tool def get_api_based_on_index(index: int) -&amp;gt; dict: &amp;quot;&amp;quot;&amp;quot;Get API details based on the given index number&amp;quot;&amp;quot;&amp;quot; if str(index) in data: return data[str(index)]&lt;br/&gt; else: raise ValueError(f&amp;quot;Index {index} not found in the data.&amp;quot;)&lt;/p&gt; &lt;p&gt;But right now my langchain agent is hallucinating and not able to get api values and fields and is only looping around 3-4 APIs .&lt;/p&gt; &lt;p&gt;Can anyone look into this and help me such that I can get this agent to retrieve the json data as vectors and go through all of that data and generate me test flow sequences of various APIs that is generally done in end to end software testing.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/A_Feyn-man&quot;&gt; /u/A_Feyn-man &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8mans/auto_gpt_is_hallucinatinghow_to_make_autogpt_read/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8mans/auto_gpt_is_hallucinatinghow_to_make_autogpt_read/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b8mans</id><link href="https://www.reddit.com/r/LangChain/comments/1b8mans/auto_gpt_is_hallucinatinghow_to_make_autogpt_read/" /><updated>2024-03-07T05:15:06+00:00</updated><published>2024-03-07T05:15:06+00:00</published><title>Auto GPT is hallucinating.How to make AutoGPT read json data and work onto it to generate test sequences.</title></entry><entry><author><name>/u/sushilkhadakaanon</name><uri>https://www.reddit.com/user/sushilkhadakaanon</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Does indexing happen sequentially in llamindex/langchain? I mean say I&amp;#39;ve a pdf containing images and text. When I store the embeddings in the vector database, the order of text and images matters (text just below a fig. might be explaining about the fig), so is it good to go with default implementation?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sushilkhadakaanon&quot;&gt; /u/sushilkhadakaanon &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b86gzl/how_does_indexing_work/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b86gzl/how_does_indexing_work/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b86gzl</id><link href="https://www.reddit.com/r/LangChain/comments/1b86gzl/how_does_indexing_work/" /><updated>2024-03-06T18:01:46+00:00</updated><published>2024-03-06T18:01:46+00:00</published><title>How does indexing work?</title></entry><entry><author><name>/u/Sweaty-Minimum5423</name><uri>https://www.reddit.com/user/Sweaty-Minimum5423</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using assistant api as agent in the LangChain framework. I’m using gpt4-0125-preview for this agent. The reason why I use agent is because I do not want every query to search the database. And I find the assistant api agent is smarter than the ReAct agent in terms of generating responses.&lt;/p&gt; &lt;p&gt;I have only one tool for linking to a retrieval chain. When the user asks certain question, the agent invokes a chain and pass query into the retrieval system. I pass in gpt-4-preview-0125 for the retrieval chain. To improve the retrieval process, I use multi-query to help generate sub questions from the original questions to dig into the details. I use gpt3.5-1106 for the multi query retriever as this doesn’t require much reasoning. So essentially, I use the assistant api(gpt-4-0125) as agent, gpt4-0125 for the retrieval chain and gpt3.5 1106 as the multi query retriever.&lt;/p&gt; &lt;p&gt;In terms of data preparation. I use manual chunking. By manual chunking I mean I manually gather relevant content into one ‘document’. This is because I see splitter does not consider context so it’s better to do the chunking on my own. &lt;/p&gt; &lt;p&gt;The problem is that the average response time for 1000-2000 token is ranging from 10s to 30s. I tried using gpt3.5 as the agent in assistant api. Speed cuts down to 3-10s. But the generation is way worse. This one I’m not sure why as I keep the gpt4-0125 in the retrieval chain. I assume the generation should be good…&lt;/p&gt; &lt;p&gt;How should I improve my architecture to enhance speed?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sweaty-Minimum5423&quot;&gt; /u/Sweaty-Minimum5423 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b87p0i/how_to_improve_rag_speed_with_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b87p0i/how_to_improve_rag_speed_with_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b87p0i</id><link href="https://www.reddit.com/r/LangChain/comments/1b87p0i/how_to_improve_rag_speed_with_openai/" /><updated>2024-03-06T18:47:54+00:00</updated><published>2024-03-06T18:47:54+00:00</published><title>How to Improve RAG speed with OpenAI?</title></entry><entry><author><name>/u/Not-That-rpg</name><uri>https://www.reddit.com/user/Not-That-rpg</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I saw the previous discussion about using double curly braces inside a template to avoid expansion in a prompt&amp;#39;s format method.&lt;/p&gt; &lt;p&gt;However, I&amp;#39;m still having a problem with this, even with double curly-braces, when I use a `FewShotPrompt`. I have *examples* in the FSP that contain code. So I suspect what is going wrong is that the double curly-braces help when the examples are folded into the prompt, but then when the *input* is folded in, the double curly braces have been stripped and I get an error.&lt;/p&gt; &lt;p&gt;This seems like a numbskull problem on my part, so even just a pointer to some tutorial about using a FewShotPrompt with code (surely there must be one?) would be great.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Not-That-rpg&quot;&gt; /u/Not-That-rpg &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8cpcz/curly_braces_in_prompts_again/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b8cpcz/curly_braces_in_prompts_again/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b8cpcz</id><link href="https://www.reddit.com/r/LangChain/comments/1b8cpcz/curly_braces_in_prompts_again/" /><updated>2024-03-06T22:04:40+00:00</updated><published>2024-03-06T22:04:40+00:00</published><title>Curly braces in prompts again...</title></entry><entry><author><name>/u/RepresentativeNo547</name><uri>https://www.reddit.com/user/RepresentativeNo547</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Which library comes out on top? I am building a multi-agent system in production but still have not decided which framework to use&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RepresentativeNo547&quot;&gt; /u/RepresentativeNo547 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7q44y/autogen_vs_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7q44y/autogen_vs_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7q44y</id><link href="https://www.reddit.com/r/LangChain/comments/1b7q44y/autogen_vs_langgraph/" /><updated>2024-03-06T04:00:13+00:00</updated><published>2024-03-06T04:00:13+00:00</published><title>Autogen vs. LangGraph</title></entry><entry><author><name>/u/EscapedLaughter</name><uri>https://www.reddit.com/user/EscapedLaughter</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7q6u1/switch_to_and_fro_claude3_gpt4_by_changing_2/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/km0k8hnc1nmc1.gif?width=640&amp;amp;crop=smart&amp;amp;s=181d7cff9061d16d502dd5fd826a87ed4a82e3a5&quot; alt=&quot;Switch to and fro Claude-3 &amp;lt;—&amp;gt; GPT-4 by changing 2 lines of code&quot; title=&quot;Switch to and fro Claude-3 &amp;lt;—&amp;gt; GPT-4 by changing 2 lines of code&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EscapedLaughter&quot;&gt; /u/EscapedLaughter &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/km0k8hnc1nmc1.gif&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7q6u1/switch_to_and_fro_claude3_gpt4_by_changing_2/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1b7q6u1</id><media:thumbnail url="https://preview.redd.it/km0k8hnc1nmc1.gif?width=640&amp;crop=smart&amp;s=181d7cff9061d16d502dd5fd826a87ed4a82e3a5" /><link href="https://www.reddit.com/r/LangChain/comments/1b7q6u1/switch_to_and_fro_claude3_gpt4_by_changing_2/" /><updated>2024-03-06T04:03:58+00:00</updated><published>2024-03-06T04:03:58+00:00</published><title>Switch to and fro Claude-3 &lt;—&gt; GPT-4 by changing 2 lines of code</title></entry><entry><author><name>/u/Over_Fun6759</name><uri>https://www.reddit.com/user/Over_Fun6759</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;React Native is incompatible with langchain, when are we going to get an update?&lt;/p&gt; &lt;p&gt;i found this but there is no solution even the one provided with langchain maintainer himself &lt;a href=&quot;https://stackoverflow.com/questions/77307779/react-native-issue-while-implementing-langchain/77313089#77313089?newreg=6af4405652b844fd81c2d0735b49c25f&quot;&gt;https://stackoverflow.com/questions/77307779/react-native-issue-while-implementing-langchain/77313089#77313089?newreg=6af4405652b844fd81c2d0735b49c25f&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Over_Fun6759&quot;&gt; /u/Over_Fun6759 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b815jv/react_native_langchain_support/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b815jv/react_native_langchain_support/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b815jv</id><link href="https://www.reddit.com/r/LangChain/comments/1b815jv/react_native_langchain_support/" /><updated>2024-03-06T14:33:12+00:00</updated><published>2024-03-06T14:33:12+00:00</published><title>React Native Langchain support?</title></entry><entry><author><name>/u/o3omoomin</name><uri>https://www.reddit.com/user/o3omoomin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hello! Are you doing well?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Among the types of retrievers, I came across a total of four retriever methods: Multi, self, time, and parent.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Is it possible to run multiple Retrievers in one project?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;For example, if we were to create a chatbot that answers school rules, would it be possible to use multiple Multi Query and Parent functions at the same time?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Or is it possible to use only one Retriver?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;If only one Retriever is available, can you tell me why?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/o3omoomin&quot;&gt; /u/o3omoomin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7op5w/when_implementing_rag_can_i_use_various_retrievers/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7op5w/when_implementing_rag_can_i_use_various_retrievers/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7op5w</id><link href="https://www.reddit.com/r/LangChain/comments/1b7op5w/when_implementing_rag_can_i_use_various_retrievers/" /><updated>2024-03-06T02:51:22+00:00</updated><published>2024-03-06T02:51:22+00:00</published><title>When implementing RAG, can I use various retrievers?</title></entry><entry><author><name>/u/michael_daigler</name><uri>https://www.reddit.com/user/michael_daigler</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, I wanted to share some recent work I did using Langchain and LangGraph to prototype an Agent pipeline for generating a newsletter + tweets from scratch.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the link: &lt;a href=&quot;https://youtu.be/i71Rm-7oG4k?si=B4Z2hBbh386EbswC&quot;&gt;https://youtu.be/i71Rm-7oG4k?si=B4Z2hBbh386EbswC&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Hope it helps.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/michael_daigler&quot;&gt; /u/michael_daigler &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7mhy2/building_my_oneman_media_team_with_ai_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7mhy2/building_my_oneman_media_team_with_ai_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7mhy2</id><link href="https://www.reddit.com/r/LangChain/comments/1b7mhy2/building_my_oneman_media_team_with_ai_agents/" /><updated>2024-03-06T01:09:54+00:00</updated><published>2024-03-06T01:09:54+00:00</published><title>Building my One-Man Media Team with AI Agents (Using Langchain &amp; LangGraph)</title></entry><entry><author><name>/u/Every-Link6367</name><uri>https://www.reddit.com/user/Every-Link6367</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We are looking to hire a full stack developer to help us with ai projects. You must be excellent at these skills: English Langchain with Python Setting up a frontend that works coherently with the backend and can be used by multiple users. If you are interested, please message us you resume at &lt;a href=&quot;mailto:Team@dialogintelligens.dk&quot;&gt;Team@dialogintelligens.dk&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Every-Link6367&quot;&gt; /u/Every-Link6367 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7915m/hirering_full_stack_developer_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7915m/hirering_full_stack_developer_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7915m</id><link href="https://www.reddit.com/r/LangChain/comments/1b7915m/hirering_full_stack_developer_with_langchain/" /><updated>2024-03-05T16:11:26+00:00</updated><published>2024-03-05T16:11:26+00:00</published><title>Hirering full stack developer with Langchain knowledge</title></entry><entry><author><name>/u/Skeltek</name><uri>https://www.reddit.com/user/Skeltek</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;m fairly new to LangChain, and I&amp;#39;m wondering if it&amp;#39;s a use case that can be well executed with LangChain.&lt;br/&gt; I would like to create a helper/copilot (chatbot) in the first place to identify irrelevant, duplicate, or contradictory content and assist me in restructuring the navigation tree. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Skeltek&quot;&gt; /u/Skeltek &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7byjo/confluence_cleanup/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7byjo/confluence_cleanup/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7byjo</id><link href="https://www.reddit.com/r/LangChain/comments/1b7byjo/confluence_cleanup/" /><updated>2024-03-05T18:05:30+00:00</updated><published>2024-03-05T18:05:30+00:00</published><title>Confluence cleanup</title></entry><entry><author><name>/u/MotherDistrict9823</name><uri>https://www.reddit.com/user/MotherDistrict9823</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;m an intern with an ambitious project that could earn me a full-time position. Our company often engages in extensive referencing of files, documents, and web research, which is time-consuming. My solution is to automate these tasks through a bot, leveraging LangChain and GPT-4 for intelligent query processing.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Project Overview:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The bot will integrate with Microsoft Teams, enabling users to submit queries and receive document references or research results. It will serve different departments, each possibly requiring access to a vast array of data (Word, Excel, PDFs, emails, etc.). The data volumes we&amp;#39;re looking at span gigabytes to terabytes. Given this, I&amp;#39;m leaning towards using a vertical database to manage this diverse and voluminous data efficiently.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Seeking Advice on:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Vertical Database Selection:&lt;/strong&gt; Given my inclination towards a vertical database for this project, which specific vertical database systems would you recommend for handling both structured and unstructured data across such a broad spectrum of file types and sizes?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Database Structure:&lt;/strong&gt; Is it more advantageous to maintain a single comprehensive database or to deploy multiple databases, one for each department, to streamline data management and querying processes?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Project Architecture:&lt;/strong&gt; How should I structure the interaction between the vertical databases, the LangChain bot, and the GPT-4 API to ensure seamless operation and scalability? What considerations should I keep in mind to support the large data volume and diverse file types?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Managing Large Datasets:&lt;/strong&gt; Any insights on efficiently processing and retrieving information from large Excel files filled with extensive numerical data would be especially helpful. Are there particular strategies or technologies that would facilitate handling such datasets?&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I am very much open to learning from your experiences and suggestions, including any alternative approaches or tools that could enhance the project. My ultimate aim is to develop a convincing proof of concept that clearly demonstrates the potential benefits and feasibility of the initiative.&lt;/p&gt; &lt;p&gt;Thank you immensely for your guidance and support!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MotherDistrict9823&quot;&gt; /u/MotherDistrict9823 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7b57n/seeking_advice_for_rag_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7b57n/seeking_advice_for_rag_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7b57n</id><link href="https://www.reddit.com/r/LangChain/comments/1b7b57n/seeking_advice_for_rag_app/" /><updated>2024-03-05T17:33:44+00:00</updated><published>2024-03-05T17:33:44+00:00</published><title>Seeking Advice for RAG App</title></entry><entry><author><name>/u/Another___World</name><uri>https://www.reddit.com/user/Another___World</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7gjco/this_thing_annoys_me_a_lot_planandexecute/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/O8FKBrHg65IRDiNfwiOrfPAtP7Ih1sFLeMK-lFawGvI.jpg&quot; alt=&quot;This thing annoys me a lot. PlanAndExecute mistyping 'title' instead of 'query' when trying to use the retriever. The worst thing is that it happends randomly and can screw up a long chain. The prompt template for this action should be fixed. It failed a&quot; title=&quot;This thing annoys me a lot. PlanAndExecute mistyping 'title' instead of 'query' when trying to use the retriever. The worst thing is that it happends randomly and can screw up a long chain. The prompt template for this action should be fixed. It failed a&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Another___World&quot;&gt; /u/Another___World &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/gallery/1b7gjco&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7gjco/this_thing_annoys_me_a_lot_planandexecute/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1b7gjco</id><media:thumbnail url="https://b.thumbs.redditmedia.com/O8FKBrHg65IRDiNfwiOrfPAtP7Ih1sFLeMK-lFawGvI.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1b7gjco/this_thing_annoys_me_a_lot_planandexecute/" /><updated>2024-03-05T21:04:07+00:00</updated><published>2024-03-05T21:04:07+00:00</published><title>This thing annoys me a lot. PlanAndExecute mistyping 'title' instead of 'query' when trying to use the retriever. The worst thing is that it happends randomly and can screw up a long chain. The prompt template for this action should be fixed. It failed a</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/HaAPBqwuj0vi5UErvwiGWGYZarwWXASKraGcYhfRP1w.jpg&quot; alt=&quot;Update: Langtrace Preview: An opensource LLM monitoring tool - achieving better cardinality compared to Langsmith.&quot; title=&quot;Update: Langtrace Preview: An opensource LLM monitoring tool - achieving better cardinality compared to Langsmith.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is with regards to: &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b4s7cw/building_a_open_source_llm_monitoring_software/&quot;&gt;https://www.reddit.com/r/LangChain/comments/1b4s7cw/building_a_open_source_llm_monitoring_software/&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Just wanted to share an update on my open source LLM monitoring tool. I do not have a UI yet, so asked chatGPT to plot the spans of a trace I generated for a langchain example code that uses agents. Below is the screenshot of my tool&amp;#39;s trace plotted:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/xvqgcukrgemc1.png?width=2980&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0eaa0d298e047457520359017123054f65570621&quot;&gt;https://preview.redd.it/xvqgcukrgemc1.png?width=2980&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0eaa0d298e047457520359017123054f65570621&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Same output from Langsmith:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/lulyrgh6gemc1.png?width=778&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=db44f54bf8d561ed379a2ea3e1dfe2319ee9ab84&quot;&gt;https://preview.redd.it/lulyrgh6gemc1.png?width=778&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=db44f54bf8d561ed379a2ea3e1dfe2319ee9ab84&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Feedback/comments/thoughts welcome&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1b6phov</id><media:thumbnail url="https://b.thumbs.redditmedia.com/HaAPBqwuj0vi5UErvwiGWGYZarwWXASKraGcYhfRP1w.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/" /><updated>2024-03-04T23:16:58+00:00</updated><published>2024-03-04T23:16:58+00:00</published><title>Update: Langtrace Preview: An opensource LLM monitoring tool - achieving better cardinality compared to Langsmith.</title></entry><entry><author><name>/u/mariojapcorreia</name><uri>https://www.reddit.com/user/mariojapcorreia</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello guys, i am extracting information about someone using llama and then using this information to compare it to a text of requirements. For example:&lt;/p&gt; &lt;p&gt;Req: person needs to have skills A or similar.&lt;/p&gt; &lt;p&gt;What can be the best technologies to do this comparison?&lt;br/&gt; I was trying embeddings models and then calculating the l2 distance between the requirements and the skills but i seem to be getting bad scores for people that should be &amp;quot;good&amp;quot;.&lt;/p&gt; &lt;p&gt;Anyone ever dived into this realm? Can´t seem to find good info online.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mariojapcorreia&quot;&gt; /u/mariojapcorreia &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7470g/llama_plus_text_similarity/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b7470g/llama_plus_text_similarity/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b7470g</id><link href="https://www.reddit.com/r/LangChain/comments/1b7470g/llama_plus_text_similarity/" /><updated>2024-03-05T12:37:20+00:00</updated><published>2024-03-05T12:37:20+00:00</published><title>Llama plus text similarity</title></entry><entry><author><name>/u/SundaeNext1297</name><uri>https://www.reddit.com/user/SundaeNext1297</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;Is there an effective way to summarize 10k page documents. &lt;/p&gt; &lt;p&gt;So I have chunks of 300 words and their embeddings already stored in the database.&lt;/p&gt; &lt;p&gt;I can apply clustering algorithm like k means. But for such large documents, I think effective cluster size would be 100-150, with each cluster of being approximately 25-30k tokens. &lt;/p&gt; &lt;p&gt;That would mean 100 api calls to get chunk summary , and final api call yo get final summary. &lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;How can we optimize this ? Not necessarily using clustering, any other way to make it kore cost efficient. As passing 32k prompt to model is very expensive itself, and to add 100 api calls. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;For such large documents what metrics can I use to ensure summary is good and model isn&amp;#39;t hallucinating. &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Thanks! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SundaeNext1297&quot;&gt; /u/SundaeNext1297 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6fiyt/effective_way_to_summarize_10k_page_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b6fiyt/effective_way_to_summarize_10k_page_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b6fiyt</id><link href="https://www.reddit.com/r/LangChain/comments/1b6fiyt/effective_way_to_summarize_10k_page_documents/" /><updated>2024-03-04T16:41:46+00:00</updated><published>2024-03-04T16:41:46+00:00</published><title>Effective way to summarize 10k page documents</title></entry><entry><author><name>/u/Diligent_Eye1248</name><uri>https://www.reddit.com/user/Diligent_Eye1248</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We&amp;#39;ve been building LLM based tools for months, but I think that there should be efficient frameworks by now that actually add value. I tried langchain a while back but I felt like it was just an over complicated overhead where it was always simpler to make everything from scratch each time. Guidance has been the only real improvement for me as it does way more than basic prompt templating, but it is in no way a full framework.&lt;/p&gt; &lt;p&gt;Now there are LlamaIndex, TigerLab, Langchain... but I simply don&amp;#39;t have the time to test them all.&lt;/p&gt; &lt;p&gt;We need to run the models by ourselves, so no Open AI api, ideally run something compatible with TGI / VLLM. We need to connect to proper databases and vectorDB (currently using Milvus). And I&amp;#39;m looking for something that is actually useful and I don&amp;#39;t have to struggle and hack the library everytime I want to do something slightly different.&lt;/p&gt; &lt;p&gt;Does any of you have a good recommendation? Everything changes so quickly I feel like I can&amp;#39;t trust articles that are older than two months. So what are you currently using and what has been an overhyped crap?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Diligent_Eye1248&quot;&gt; /u/Diligent_Eye1248 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b67jkl/best_framework_for_llm_based_applications_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1b67jkl/best_framework_for_llm_based_applications_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1b67jkl</id><link href="https://www.reddit.com/r/LangChain/comments/1b67jkl/best_framework_for_llm_based_applications_in/" /><updated>2024-03-04T10:16:24+00:00</updated><published>2024-03-04T10:16:24+00:00</published><title>Best framework for LLM based applications in production</title></entry></feed>