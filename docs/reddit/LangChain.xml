<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-07-19T10:49:28+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/93simoon</name><uri>https://www.reddit.com/user/93simoon</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Heads up, folks! If you&amp;#39;re considering LangGraph for your projects, especially for production, here&amp;#39;s something you need to know. LangGraph has recently removed the option to self-host. This means you can only use their cloud platform from now on. &lt;/p&gt; &lt;p&gt;Here is the commit where they removed instructions on how to self host from the readme: &lt;a href=&quot;https://github.com/langchain-ai/langgraph-example/commit/215ef6eb2f653e46cfb442aeed2978c703781a01&quot;&gt;https://github.com/langchain-ai/langgraph-example/commit/215ef6eb2f653e46cfb442aeed2978c703781a01&lt;/a&gt;&lt;/p&gt; &lt;p&gt;While it might seem convenient, there are some significant risks and disadvantages you should consider.&lt;/p&gt; &lt;p&gt;First off, &lt;strong&gt;data ownership&lt;/strong&gt;. When you use their cloud service, you&amp;#39;re essentially handing over your data to them. This raises concerns about privacy and security, especially if you&amp;#39;re dealing with sensitive or proprietary information. You&amp;#39;re trusting LangGraph to handle and protect your data properly, but you lose control over how it&amp;#39;s stored and managed.&lt;/p&gt; &lt;p&gt;Secondly, you&amp;#39;re &lt;strong&gt;at the mercy of the platform&lt;/strong&gt;. If their service experiences downtime or technical issues, your system will be affected. This is a huge risk if you&amp;#39;re running a production environment where uptime is critical. Any changes they make to their service, pricing, or terms can impact you directly, and you have no say in the matter.&lt;/p&gt; &lt;p&gt;This also means that using the cloud version means you&amp;#39;re &lt;strong&gt;subject to their updates and changes&lt;/strong&gt;. They can roll out updates that might not align with your needs or even disrupt your existing setup. This lack of control can be frustrating, especially if your project relies on specific features or configurations.&lt;/p&gt; &lt;p&gt;Losing the ability to self-host means you sacrifice control over your data and are &lt;strong&gt;fully dependent on their platform&amp;#39;s reliability and policies&lt;/strong&gt;. If these risks are a concern for you, it might be worth looking into alternative solutions that offer self-hosting options or more control over your production environment.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/93simoon&quot;&gt; /u/93simoon &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6xli4/psa_langgraph_removed_the_support_for_self_hosting/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6xli4/psa_langgraph_removed_the_support_for_self_hosting/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6xli4</id><link href="https://www.reddit.com/r/LangChain/comments/1e6xli4/psa_langgraph_removed_the_support_for_self_hosting/" /><updated>2024-07-19T07:04:32+00:00</updated><published>2024-07-19T07:04:32+00:00</published><title>PSA: LangGraph removed the support for self hosting</title></entry><entry><author><name>/u/Complete-Pie5760</name><uri>https://www.reddit.com/user/Complete-Pie5760</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I am currently looking into using LLMs for a project and figured Portkey might be a good start to test out different models. With a bit of research I saw that langchain is basically the number one library for doing this kind of things, because of RAG support etc.&lt;/p&gt; &lt;p&gt;What I do not quite understand is how do I integrate Portkey-AI with Langchain? I am quite confused here, would appreciate any input on this topic. Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Complete-Pie5760&quot;&gt; /u/Complete-Pie5760 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7093e/how_to_use_langchain_with_portkey_ai_im_beginner/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7093e/how_to_use_langchain_with_portkey_ai_im_beginner/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e7093e</id><link href="https://www.reddit.com/r/LangChain/comments/1e7093e/how_to_use_langchain_with_portkey_ai_im_beginner/" /><updated>2024-07-19T10:13:55+00:00</updated><published>2024-07-19T10:13:55+00:00</published><title>How to use Langchain with Portkey AI? (I'm beginner with LLMs)</title></entry><entry><author><name>/u/kingai404</name><uri>https://www.reddit.com/user/kingai404</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Hey everyone! 🚀 I’m excited to share a new project: a Retrieval-Augmented Generation (RAG) Agent leveraging CrewAI, Composio, and ChatGPT to perform web searches and compile research reports.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Objectives&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This project aims to create an intelligent agent that can enhance research capabilities by combining powerful AI tools to search the web and generate comprehensive reports.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Implementation Details&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Tools Used&lt;/strong&gt;: Composio, CrewAI, ChatGPT, Python&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Setup&lt;/strong&gt;: &lt;ol&gt; &lt;li&gt;Navigate to the project directory.&lt;/li&gt; &lt;li&gt;Run the setup file.&lt;/li&gt; &lt;li&gt;Fill in the &lt;code&gt;.env&lt;/code&gt; file with your secrets.&lt;/li&gt; &lt;li&gt;Run the Python script.&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The RAG agent streamlines the process of conducting web searches and generating research reports, making it a valuable tool for researchers, students, and professionals.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://git.new/RAGagent&quot;&gt;REPO LINK&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kingai404&quot;&gt; /u/kingai404 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6umwn/guide_to_create_a_rag_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6umwn/guide_to_create_a_rag_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6umwn</id><link href="https://www.reddit.com/r/LangChain/comments/1e6umwn/guide_to_create_a_rag_agent/" /><updated>2024-07-19T04:00:02+00:00</updated><published>2024-07-19T04:00:02+00:00</published><title>Guide to create a RAG Agent</title></entry><entry><author><name>/u/phan_ngt</name><uri>https://www.reddit.com/user/phan_ngt</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6yz2y/how_to_trace_cost_of_ragas_i_am_using_langfuse/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/Mb-jWXlU_2XOlcFtNYrP9PSDlPgW56VysAlhtOZNW68.jpg&quot; alt=&quot;How to trace cost of RAGAS? ( I am using LANGFUSE)&quot; title=&quot;How to trace cost of RAGAS? ( I am using LANGFUSE)&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I use this code and decorator &lt;strong&gt;&lt;em&gt;observe()&lt;/em&gt;&lt;/strong&gt; to trace ragas cost. However, as you can see the result below. Total cost is 0$ for function &lt;strong&gt;&lt;em&gt;score_with_ragas()&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Any simple ideas to help? Thank you. &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/lvjrbdgeufdd1.png?width=2594&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=948f921caf2cb56f5592ec39f161f4527438d286&quot;&gt;https://preview.redd.it/lvjrbdgeufdd1.png?width=2594&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=948f921caf2cb56f5592ec39f161f4527438d286&lt;/a&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from app.core.services.openai import llm from ragas.embeddings import LangchainEmbeddingsWrapper from ragas.llms import LangchainLLMWrapper from ragas.metrics import answer_relevancy, faithfulness, context_utilization from ragas.metrics.critique import harmfulness from app.biz.performance.base import init_ragas_metrics from app.core.services.store import embeddings # metrics you chose metrics = [faithfulness, answer_relevancy, context_utilization, harmfulness] init_ragas_metrics( metrics, llm=LangchainLLMWrapper(llm), embedding=LangchainEmbeddingsWrapper(embeddings), ) import asyncio from langfuse.decorators import observe from app.core.datasets.main import dataset, langfuse from app.core.services.performance import metrics @observe(as_type=&amp;quot;generation&amp;quot;) async def score_with_ragas(query, chunks, answer, ground_truths): scores = {} for m in metrics: print(f&amp;quot;calculating {m.name}&amp;quot;) scores[m.name] = await m.ascore( row={&amp;quot;question&amp;quot;: query, &amp;quot;contexts&amp;quot;: chunks, &amp;quot;answer&amp;quot;: answer, &amp;quot;ground_truths&amp;quot;: ground_truths} ) return scores # Function to handle the full process including scoring async def main(): for row in dataset: question, contexts, answer, ground_truths = (row[&amp;quot;question&amp;quot;], row[&amp;quot;contexts&amp;quot;], row[&amp;quot;answer&amp;quot;], row[&amp;#39;ground_truths&amp;#39;]) trace = langfuse.trace(name=&amp;quot;rag&amp;quot;, input=question, output={ &amp;quot;answer&amp;quot;: answer, &amp;quot;contexts&amp;quot;: contexts }) # pass it as span trace.span( name=&amp;quot;retrieval&amp;quot;, input={&amp;#39;question&amp;#39;: question, &amp;#39;ground_truths&amp;#39;: ground_truths}, output={&amp;#39;contexts&amp;#39;: contexts} ) # use llm to generate a answer with the chunks # answer = get_response_from_llm(question, chunks) answer = row[&amp;#39;answer&amp;#39;] trace.span( name=&amp;quot;generation&amp;quot;, input={&amp;#39;question&amp;#39;: question, &amp;#39;contexts&amp;#39;: contexts, &amp;#39;ground_truths&amp;#39;: ground_truths}, output={&amp;#39;answer&amp;#39;: answer} ) ragas_scores = await score_with_ragas(question, contexts, answer, ground_truths) for m in metrics: trace.score(name=m.name, value=ragas_scores[m.name]) # Run the main function asyncio.run(main()) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phan_ngt&quot;&gt; /u/phan_ngt &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6yz2y/how_to_trace_cost_of_ragas_i_am_using_langfuse/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6yz2y/how_to_trace_cost_of_ragas_i_am_using_langfuse/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1e6yz2y</id><media:thumbnail url="https://a.thumbs.redditmedia.com/Mb-jWXlU_2XOlcFtNYrP9PSDlPgW56VysAlhtOZNW68.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1e6yz2y/how_to_trace_cost_of_ragas_i_am_using_langfuse/" /><updated>2024-07-19T08:44:03+00:00</updated><published>2024-07-19T08:44:03+00:00</published><title>How to trace cost of RAGAS? ( I am using LANGFUSE)</title></entry><entry><author><name>/u/gentleseahorse</name><uri>https://www.reddit.com/user/gentleseahorse</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2309.07864&quot;&gt;There’s been a huge rise in papers on LLM-based agents in the two years,&lt;/a&gt; showing obvious benefits in output quality and complexity of the task that can be handled. There are 2 obvious problems:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Latency: because agents are talking to each other — usually sequentially — output generation will take longer.&lt;/li&gt; &lt;li&gt;Cost: much more tokens are being spent on feeding one output to another input. Over and over.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;But these are exactly the things GPT 4o Mini concerns itself with. I’m actually incorporating it right now into some preprocessing workflows we have at &lt;a href=&quot;https://adorno.ai/&quot;&gt;adorno.ai&lt;/a&gt;. On principle, I dislike OpenAI, but it seems they&amp;#39;ve hit the ball out of the park? Again. I&amp;#39;m looking for criticism against 4o Mini? Right now it&amp;#39;s just rainbows and unicorns, but why is it overhyped?&lt;/p&gt; &lt;p&gt;(I&amp;#39;ve got a full blog post on the subject here: &lt;a href=&quot;https://chrisjanwust.medium.com/at-15c-million-tokens-will-gpt-4o-mini-be-the-foundation-of-agentic-workflows-7fd189138da4&quot;&gt;https://chrisjanwust.medium.com/at-15c-million-tokens-will-gpt-4o-mini-be-the-foundation-of-agentic-workflows-7fd189138da4&lt;/a&gt; )&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gentleseahorse&quot;&gt; /u/gentleseahorse &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6pizc/why_gpt_4o_mini_not_be_the_foundation_of_agentic/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6pizc/why_gpt_4o_mini_not_be_the_foundation_of_agentic/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6pizc</id><link href="https://www.reddit.com/r/LangChain/comments/1e6pizc/why_gpt_4o_mini_not_be_the_foundation_of_agentic/" /><updated>2024-07-18T23:36:19+00:00</updated><published>2024-07-18T23:36:19+00:00</published><title>Why GPT 4o Mini not be the foundation of Agentic Workflows?</title></entry><entry><author><name>/u/AdAway2620</name><uri>https://www.reddit.com/user/AdAway2620</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Helllo guys, i am trying to create a PDF chatbot using Huggingface models. Open source embeddings and Open source LLM. Have anyone does this before or have similar kind of project ? I would be grateful if you help me . &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AdAway2620&quot;&gt; /u/AdAway2620 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6zj3b/arabic_pdf_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6zj3b/arabic_pdf_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6zj3b</id><link href="https://www.reddit.com/r/LangChain/comments/1e6zj3b/arabic_pdf_rag/" /><updated>2024-07-19T09:23:38+00:00</updated><published>2024-07-19T09:23:38+00:00</published><title>Arabic PDF RAG</title></entry><entry><author><name>/u/Big_Barracuda_6753</name><uri>https://www.reddit.com/user/Big_Barracuda_6753</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;# Reranker def reRanker(): compressor = CohereRerank(client=cohere_client) compression_retriever = ContextualCompressionRetriever( base_compressor=compressor, base_retriever=vectorStore.as_retriever( search_kwargs={&amp;quot;k&amp;quot;: 5}, ), ) return compression_retriever # Initialize store if not in session state if &amp;quot;store&amp;quot; not in st.session_state: st.session_state.store = {} ### Statefully manage chat history ### store = {} def get_session_history(session_id: str) -&amp;gt; BaseChatMessageHistory: if session_id not in st.session_state.store: st.session_state.store[session_id] = ChatMessageHistory() return st.session_state.store[session_id] contextualize_q_system_prompt = ( &amp;quot;Given a chat history and the latest user question &amp;quot; &amp;quot;which might reference context in the chat history, &amp;quot; &amp;quot;formulate a standalone question which can be understood &amp;quot; &amp;quot;without the chat history. Do NOT answer the question, &amp;quot; &amp;quot;just reformulate it if needed and otherwise return it as is.&amp;quot; ) contextualize_q_prompt = ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, contextualize_q_system_prompt), MessagesPlaceholder(&amp;quot;chat_history&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;), ] ) compression_retriever = reRanker() history_aware_retriever = create_history_aware_retriever( llm, compression_retriever, contextualize_q_prompt ) system_prompt = ( &amp;quot;You are an assistant for question-answering tasks specifically about the provided PDF documents.&amp;quot; &amp;quot;Use ONLY the following pieces of retrieved context to answer the question.&amp;quot; &amp;quot;Provide answers exactly as they are written in the PDF, quoting or paraphrasing text directly from the provided context.&amp;quot; &amp;quot;If you can&amp;#39;t find the answer in the given context, say &amp;#39;I&amp;#39;m sorry, but I couldn&amp;#39;t find information about that in the provided PDF documents.&amp;#39; &amp;quot; &amp;quot; Do not use any external knowledge.&amp;quot; &amp;quot;\n\n&amp;quot; &amp;quot;{context}&amp;quot; ) chatPrompt = ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, system_prompt), MessagesPlaceholder(&amp;quot;chat_history&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;), ] ) question_answer_chain = create_stuff_documents_chain(llm, chatPrompt) rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain) conversational_rag_chain = RunnableWithMessageHistory( rag_chain, get_session_history, input_messages_key=&amp;quot;input&amp;quot;, output_messages_key=&amp;quot;answer&amp;quot;, history_messages_key=&amp;quot;chat_history&amp;quot;, ) # generate response def generate_response(prompt: str) : for chunk in conversational_rag_chain.stream(input={&amp;quot;input&amp;quot;: prompt},config={&amp;#39;configurable&amp;#39;: {&amp;#39;session_id&amp;#39;: &amp;quot;uniqueValue1234&amp;quot;}}): answer_chunk = chunk.get(&amp;quot;answer&amp;quot;) if answer_chunk: yield answer_chunk # Render chat history session_id = &amp;quot;uniqueValue1234&amp;quot; # Define your session ID if &amp;quot;chat_history&amp;quot; not in st.session_state: st.session_state.chat_history = [] # Conversation History for message in st.session_state.chat_history: if isinstance(message,HumanMessage): with st.chat_message(&amp;quot;Human&amp;quot;): st.markdown(message.content) else: with st.chat_message(&amp;quot;AI&amp;quot;): st.markdown(message.content) prompt = st.chat_input(&amp;quot;Hey, What&amp;#39;s up?&amp;quot;) if prompt is not None and prompt !=&amp;quot;&amp;quot; : st.session_state.chat_history.append(HumanMessage(prompt)) with st.chat_message(&amp;quot;Human&amp;quot;): st.markdown(prompt) if len(pc.list_indexes()) == 0: st.error(&amp;quot;Please upload some files first!&amp;quot;) else: with st.chat_message(&amp;quot;AI&amp;quot;): ai_response = st.write_stream(generate_response(prompt)) st.session_state.chat_history.append(AIMessage(ai_response)) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For those seeing my post first time , Hi , I&amp;#39;m a web dev learning AI , currently developing a PDF RAG app. &lt;/p&gt; &lt;p&gt;I want the answer to my queries should come from pdf only . If there is no answer for a query , AI should return something like &amp;quot; Answer is not in the provided document ... etc &amp;quot; .&lt;/p&gt; &lt;p&gt;current state of my app is that sometimes it fails to answer questions from my pdf which are present in the pdf and sometimes it answers general questions that it shouldn&amp;#39;t answer .&lt;/p&gt; &lt;p&gt;I&amp;#39;ve a system prompt in which I asked AI to not give answers of any other questions outside pdf . &lt;/p&gt; &lt;p&gt;But it&amp;#39;s not working .&lt;/p&gt; &lt;p&gt;Now ,&lt;/p&gt; &lt;p&gt;Is my code OK ? What did I do wrong ?&lt;/p&gt; &lt;p&gt;Is system prompt alone not enough to stop RAG from giving answers to general questions ?&lt;/p&gt; &lt;p&gt;What is the way to stop it from answering general questions ? Do I need to use Agents for this ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Big_Barracuda_6753&quot;&gt; /u/Big_Barracuda_6753 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6yskw/why_my_rag_is_a_bad_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6yskw/why_my_rag_is_a_bad_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6yskw</id><link href="https://www.reddit.com/r/LangChain/comments/1e6yskw/why_my_rag_is_a_bad_rag/" /><updated>2024-07-19T08:30:15+00:00</updated><published>2024-07-19T08:30:15+00:00</published><title>Why my RAG is a bad RAG ?</title></entry><entry><author><name>/u/Odd_Research_6995</name><uri>https://www.reddit.com/user/Odd_Research_6995</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Odd_Research_6995&quot;&gt; /u/Odd_Research_6995 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6yc72/i_want_to_build_a_ecommerce_assistanti_have_tried/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6yc72/i_want_to_build_a_ecommerce_assistanti_have_tried/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6yc72</id><link href="https://www.reddit.com/r/LangChain/comments/1e6yc72/i_want_to_build_a_ecommerce_assistanti_have_tried/" /><updated>2024-07-19T07:56:56+00:00</updated><published>2024-07-19T07:56:56+00:00</published><title>I want to build a ecommerce assistant.i have tried self queryand all.its not fetching as expected.can you suggest some way to fix the issues with rag?or some better rag approach?</title></entry><entry><author><name>/u/blogger786amd</name><uri>https://www.reddit.com/user/blogger786amd</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;HI&lt;/p&gt; &lt;p&gt;I am learning langchain these days and what I observe in youtube tutorials that they create chat applications mostly in which you get different responses like changing the tone of customer language, get replies to queries from documents etc..&lt;/p&gt; &lt;p&gt;This is what we can do with chatgpt, co-pilot as well. Then how we use langchain in pratical life? Also is there any tutorial on youtube which really create something which we actually use for businesses?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/blogger786amd&quot;&gt; /u/blogger786amd &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6x8mb/routing_use_of_langchain_application/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6x8mb/routing_use_of_langchain_application/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6x8mb</id><link href="https://www.reddit.com/r/LangChain/comments/1e6x8mb/routing_use_of_langchain_application/" /><updated>2024-07-19T06:40:53+00:00</updated><published>2024-07-19T06:40:53+00:00</published><title>Routing Use of Langchain Application</title></entry><entry><author><name>/u/ksaimohan2k</name><uri>https://www.reddit.com/user/ksaimohan2k</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am able to upload the pdf file using the unstrucutred loader and query the PDf file, but I ask something like, Can you mention the source file to LLM? It is not answering.&lt;/p&gt; &lt;p&gt;The workflow is&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Uploading files using an unstructured loader, Text Splitter&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Creating Embeddings&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Storing in Vector DB&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;creating a retriever (as_retriever)&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Creating a Tool&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;creating a conversational agent.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Is there any way to do it?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ksaimohan2k&quot;&gt; /u/ksaimohan2k &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6vqw0/retreiving_metadata_from_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6vqw0/retreiving_metadata_from_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6vqw0</id><link href="https://www.reddit.com/r/LangChain/comments/1e6vqw0/retreiving_metadata_from_documents/" /><updated>2024-07-19T05:04:57+00:00</updated><published>2024-07-19T05:04:57+00:00</published><title>Retreiving Metadata from Documents</title></entry><entry><author><name>/u/FigureClassic6675</name><uri>https://www.reddit.com/user/FigureClassic6675</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello!&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently planning to develop a medical RAG chatbot.&lt;/p&gt; &lt;p&gt;The user will start by filling out a comprehensive questionnaire that includes details such as their name, age, blood group, blood test results, medical history, and other relevant medical records.&lt;/p&gt; &lt;p&gt;After the user submits this form, their responses will be processed by an LLM to generate personalized treatment plans, exercise routines, meal recommendations, and sleep schedules, among other tailored advice.&lt;/p&gt; &lt;p&gt;Any assistance or suggestions for relevant open-source repositories would be greatly appreciated.&lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FigureClassic6675&quot;&gt; /u/FigureClassic6675 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6bic0/how_can_i_create_medical_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6bic0/how_can_i_create_medical_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6bic0</id><link href="https://www.reddit.com/r/LangChain/comments/1e6bic0/how_can_i_create_medical_rag_chatbot/" /><updated>2024-07-18T13:31:23+00:00</updated><published>2024-07-18T13:31:23+00:00</published><title>How can i create Medical RAG chatbot.</title></entry><entry><author><name>/u/Yeddine</name><uri>https://www.reddit.com/user/Yeddine</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e5z34y/should_i_open_source_this_tool/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/N0-_rhm56nZrU4qPFiBJlPcihF5IfMJX86dQjUd8vVM.jpg&quot; alt=&quot;Should I open source this tool?&quot; title=&quot;Should I open source this tool?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys - I started building an AI tool for myself to talk to my data with SQL and RAG and need your feedback to know if it&amp;#39;s worth turning into an open-source project and/or SaaS.&lt;/p&gt; &lt;p&gt;The way it works is that you can connect a lot of data sources, structured or unstructured such as PostgreSQL, Snowflake, Notion, Facebook Ads, Shopify, PDFs... and you can chat with it, visualize it with tables and charts.&lt;/p&gt; &lt;p&gt;Do you see value in this, should I keep going?&lt;/p&gt; &lt;p&gt;Would love to hear your feedback and if you&amp;#39;d be interested in contributing or trying it for free&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://i.redd.it/14o76c00i6dd1.gif&quot;&gt;Text-to-SQL + RAG + Visualization&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Yeddine&quot;&gt; /u/Yeddine &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e5z34y/should_i_open_source_this_tool/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e5z34y/should_i_open_source_this_tool/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1e5z34y</id><media:thumbnail url="https://b.thumbs.redditmedia.com/N0-_rhm56nZrU4qPFiBJlPcihF5IfMJX86dQjUd8vVM.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1e5z34y/should_i_open_source_this_tool/" /><updated>2024-07-18T01:18:49+00:00</updated><published>2024-07-18T01:18:49+00:00</published><title>Should I open source this tool?</title></entry><entry><author><name>/u/Typical-Scene-5794</name><uri>https://www.reddit.com/user/Typical-Scene-5794</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi &lt;a href=&quot;/r/langchain&quot;&gt;r/langchain&lt;/a&gt;,&lt;/p&gt; &lt;p&gt;Microsoft SharePoint is to enterprises what Google Drive is to consumers. Happy to share my work on an app template that makes it easy to build applications that deliver up-to-date answers using your RAG pipeline with SharePoint data. &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Repo Link: &lt;a href=&quot;https://pathway.com/developers/templates/enterprise_rag_sharepoint&quot;&gt;~https://pathway.com/developers/templates/enterprise_rag_sharepoint~&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Thousands of employees at large corporations collaborate and make changes in the documents stored in Microsoft SharePoint folders – making it a valuable data source for dynamic RAG/Gen AI applications to boost productivity. &lt;/p&gt; &lt;p&gt;However, existing connectors for SharePoint lack necessary security features. My template covers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Real-Time Sync with changes in your SharePoint files, with the help of Pathway (link: &lt;a href=&quot;https://python.langchain.com/v0.2/docs/integrations/vectorstores/pathway/&quot;&gt;~Pathway Vector Store on LangChain~&lt;/a&gt;).&lt;/li&gt; &lt;li&gt;Step by step process to setup Entra ID and SSL authentication. &lt;/li&gt; &lt;li&gt;Security and Scalability, given the choice of frameworks and minimalistic architecture.&lt;/li&gt; &lt;li&gt;Ease of Setup to help you run the app template in Docker within minutes.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I plan to further refine this by using:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://pathway.com/developers/templates/adaptive-rag&quot;&gt;~Adaptive RAG~&lt;/a&gt;: Implementing cost-effective strategies without sacrificing accuracy.&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://pathway.com/developers/user-guide/llm-xpack/overview/#rerankers&quot;&gt;~Pathway Rerankers~&lt;/a&gt;: Integrating advanced reranking techniques for improved results.&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/pathwaycom/llm-app/tree/main/examples/pipelines/slides_ai_search&quot;&gt;~Multimodal Pipelines with Hybrid Indexes~&lt;/a&gt;: Using advanced parsing capabilities and indexing techniques&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;🤝 Let&amp;#39;s Discuss! I&amp;#39;m open to your questions and feedback!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Typical-Scene-5794&quot;&gt; /u/Typical-Scene-5794 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6aby5/template_to_use_microsoft_sharepoint_as_a_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6aby5/template_to_use_microsoft_sharepoint_as_a_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6aby5</id><link href="https://www.reddit.com/r/LangChain/comments/1e6aby5/template_to_use_microsoft_sharepoint_as_a_data/" /><updated>2024-07-18T12:35:22+00:00</updated><published>2024-07-18T12:35:22+00:00</published><title>Template to use Microsoft SharePoint as a data source for Enterprise RAG pipelines</title></entry><entry><author><name>/u/theguywithyoda</name><uri>https://www.reddit.com/user/theguywithyoda</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;My company has a support team to which we want to transition our application to. My task is to automate the process of creating the FMEA document. I started using genetic RAG with both code tool and documents tool. For code I used summaryindex and set relationships using references of function calls. For documents I used vector index. My hope is to prompt it the right way to get the failure mode created but the problem is the agent is using one tool or the other but never combined the two. Also when it is making some observations that sounds useful but is not in the final answer. How do I go about fixing this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/theguywithyoda&quot;&gt; /u/theguywithyoda &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6sdyi/analyze_failure_modes_in_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6sdyi/analyze_failure_modes_in_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6sdyi</id><link href="https://www.reddit.com/r/LangChain/comments/1e6sdyi/analyze_failure_modes_in_code/" /><updated>2024-07-19T01:58:39+00:00</updated><published>2024-07-19T01:58:39+00:00</published><title>Analyze failure modes in code</title></entry><entry><author><name>/u/Standard-Society-568</name><uri>https://www.reddit.com/user/Standard-Society-568</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been noticing more and more people are using GraphRAG instead of embedding and vector databases...is it really helpful or just the hype?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Standard-Society-568&quot;&gt; /u/Standard-Society-568 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e66e9r/graphrag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e66e9r/graphrag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e66e9r</id><link href="https://www.reddit.com/r/LangChain/comments/1e66e9r/graphrag/" /><updated>2024-07-18T08:30:22+00:00</updated><published>2024-07-18T08:30:22+00:00</published><title>GraphRAG</title></entry><entry><author><name>/u/PalpitationOk8657</name><uri>https://www.reddit.com/user/PalpitationOk8657</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;As the title suggests , please recommend a tutorial / course to implement a RAG.&lt;br/&gt; I wnat to query a large csv data set using a langchain&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/PalpitationOk8657&quot;&gt; /u/PalpitationOk8657 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6gyij/where_can_i_start_learning_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6gyij/where_can_i_start_learning_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6gyij</id><link href="https://www.reddit.com/r/LangChain/comments/1e6gyij/where_can_i_start_learning_langchain/" /><updated>2024-07-18T17:25:03+00:00</updated><published>2024-07-18T17:25:03+00:00</published><title>Where can i start learning Langchain?</title></entry><entry><author><name>/u/D_40</name><uri>https://www.reddit.com/user/D_40</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Are you able to create a tool using create_pandas_dataframe_agent?&lt;/p&gt; &lt;p&gt;I am looking to create a chat agent that will be able to tell if it should use the create_pandas_dataframe_agent to answer data about specific data, or use a retrieval tool and RAG if that is the correct route to extract the desired data.&lt;/p&gt; &lt;p&gt;I have gotten the pandas agent and the retrieval tool to work independently of each other, but can not get them to work as one agent. Is this the correct way of going about solving this problem? Is it even possible?&lt;/p&gt; &lt;p&gt;Any help would be greatly appreciated. Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/D_40&quot;&gt; /u/D_40 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6hrjb/using_create_pandas_dataframe_agent_as_a_tool/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6hrjb/using_create_pandas_dataframe_agent_as_a_tool/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6hrjb</id><link href="https://www.reddit.com/r/LangChain/comments/1e6hrjb/using_create_pandas_dataframe_agent_as_a_tool/" /><updated>2024-07-18T18:02:30+00:00</updated><published>2024-07-18T18:02:30+00:00</published><title>Using create_pandas_dataframe_agent as a tool</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This video demonstrates how GraphRAG (using LangChain) can be implemented for CSV files with example and code explanation using LLMGraphTransformer : &lt;a href=&quot;https://youtu.be/3B6VjDtbsbw?si=ubuyOD-_bAmP-IAg&quot;&gt;https://youtu.be/3B6VjDtbsbw?si=ubuyOD-_bAmP-IAg&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e627bz/graphrag_using_csv_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e627bz/graphrag_using_csv_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e627bz</id><link href="https://www.reddit.com/r/LangChain/comments/1e627bz/graphrag_using_csv_langchain/" /><updated>2024-07-18T03:58:46+00:00</updated><published>2024-07-18T03:58:46+00:00</published><title>GraphRAG using CSV, LangChain</title></entry><entry><author><name>/u/Nerabh_2602</name><uri>https://www.reddit.com/user/Nerabh_2602</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have two indexes with my pinecone vector databases, one has the sensitive and private data of my org, while other has embeddings related to open data.&lt;/p&gt; &lt;p&gt;I want to divert the IP address accordingly, if a user belongs to my org (which is noted because of particular IP address range) he must be directed to index which has private and org specific data, while a non-org user must be routed to different index which has public data.&lt;/p&gt; &lt;p&gt;Based on the above requirements I have two questions :-&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Can we achieve it without building and leveraging on AWS architectures AWS Sagemaker, if yes then how?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;If we use AWS sagemaker and deploy this rag+llm model on AWS or build my model by using foundational model of AWS then how can this be achieved.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Looking forward for the views.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Nerabh_2602&quot;&gt; /u/Nerabh_2602 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6hls9/ip_address_range_filter_for_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6hls9/ip_address_range_filter_for_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6hls9</id><link href="https://www.reddit.com/r/LangChain/comments/1e6hls9/ip_address_range_filter_for_rag/" /><updated>2024-07-18T17:52:06+00:00</updated><published>2024-07-18T17:52:06+00:00</published><title>IP address range filter for RAG</title></entry><entry><author><name>/u/thanghaimeow</name><uri>https://www.reddit.com/user/thanghaimeow</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I gave a workshop recently and managed to record it&lt;/p&gt; &lt;p&gt;You can do hybrid search (e.g combining similarity search with keywords search - your traditional search) in many ways and not just in Pinecone or Weaviate.&lt;/p&gt; &lt;p&gt;You can even do your own setup of hybrid search in Postgres too (with Supabase, for example)&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the video: &lt;a href=&quot;https://www.youtube.com/watch?v=d_WwEdxyuGs&quot;&gt;https://www.youtube.com/watch?v=d_WwEdxyuGs&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the Jupyter notebook: &lt;a href=&quot;https://github.com/trancethehuman/ai-workshop-code/blob/main/Hybrid_Search_Workshop.ipynb&quot;&gt;https://github.com/trancethehuman/ai-workshop-code/blob/main/Hybrid_Search_Workshop.ipynb&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Enjoy.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thanghaimeow&quot;&gt; /u/thanghaimeow &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e65b82/code_included_if_youre_doing_rag_and_your_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e65b82/code_included_if_youre_doing_rag_and_your_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e65b82</id><link href="https://www.reddit.com/r/LangChain/comments/1e65b82/code_included_if_youre_doing_rag_and_your_search/" /><updated>2024-07-18T07:13:33+00:00</updated><published>2024-07-18T07:13:33+00:00</published><title>(Code included) If you're doing RAG and your search queries are sometimes very specific, then you want to do hybrid search (here're are a few setups that makes sense)</title></entry><entry><author><name>/u/Better_Run_1295</name><uri>https://www.reddit.com/user/Better_Run_1295</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am implementing RAG using two separate approaches: one with Vector DB and another with Serp API. I have found that Serp API is better at capturing the context of the query. I would like to know the use cases for when to use Vector DB and when to use Serp API for document search. I know perplexity uses only Serp API and not Vector DB.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Better_Run_1295&quot;&gt; /u/Better_Run_1295 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6bz6y/vectordb_vs_serpapi/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6bz6y/vectordb_vs_serpapi/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6bz6y</id><link href="https://www.reddit.com/r/LangChain/comments/1e6bz6y/vectordb_vs_serpapi/" /><updated>2024-07-18T13:52:11+00:00</updated><published>2024-07-18T13:52:11+00:00</published><title>VectorDB vs SerpAPI</title></entry><entry><author><name>/u/Plane_Past129</name><uri>https://www.reddit.com/user/Plane_Past129</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m implementing a RAG with mongo and SQL as data connectors. Each store different entities of data. Now, I want to retrieve data based on question asked by user. I tried an approach initially. I used an LLM to conditionally route to specific data source based on the question user asked. Then, for mongo, I used vector database from mongo and for SQL I generated SQL query using LLM and pass the retrieved data to an LLM to generate an answer. &lt;/p&gt; &lt;p&gt;I know this is a basic approach and main issue is it is taking so much time. Is there any better and efficient methods to perform a same task.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Plane_Past129&quot;&gt; /u/Plane_Past129 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6g04p/how_to_implement_a_rag_with_different_data_sources/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6g04p/how_to_implement_a_rag_with_different_data_sources/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6g04p</id><link href="https://www.reddit.com/r/LangChain/comments/1e6g04p/how_to_implement_a_rag_with_different_data_sources/" /><updated>2024-07-18T16:45:57+00:00</updated><published>2024-07-18T16:45:57+00:00</published><title>How to implement a RAG with different data sources</title></entry><entry><author><name>/u/Kind-Worry3072</name><uri>https://www.reddit.com/user/Kind-Worry3072</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for examples of Python code that demonstrate parsing Excel files into SQLite databases using eparser. I&amp;#39;ve come across the Excelparser package, but I&amp;#39;m unsure how to use it as the documentation primarily provides shell prompts rather than Python code examples.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Kind-Worry3072&quot;&gt; /u/Kind-Worry3072 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e67x37/eparser_parsing_to_sqllite/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e67x37/eparser_parsing_to_sqllite/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e67x37</id><link href="https://www.reddit.com/r/LangChain/comments/1e67x37/eparser_parsing_to_sqllite/" /><updated>2024-07-18T10:16:25+00:00</updated><published>2024-07-18T10:16:25+00:00</published><title>eparser parsing to sqllite</title></entry><entry><author><name>/u/vuongagiflow</name><uri>https://www.reddit.com/user/vuongagiflow</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;If you’re a developer working 9-5 job and have young kids, finding time to upskill with LLMs can be challenging. With only 15-30 minutes a day, what approaches would you recommend?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/vuongagiflow&quot;&gt; /u/vuongagiflow &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e633xx/practical_approach_to_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e633xx/practical_approach_to_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e633xx</id><link href="https://www.reddit.com/r/LangChain/comments/1e633xx/practical_approach_to_llm/" /><updated>2024-07-18T04:49:51+00:00</updated><published>2024-07-18T04:49:51+00:00</published><title>Practical approach to LLM?</title></entry><entry><author><name>/u/Phoenix_20_23</name><uri>https://www.reddit.com/user/Phoenix_20_23</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello guys, I am working on project for chatting with your documents (PDF mostly), so i built a basic RAG system using langchain, Unstructured for extraction, qdrant db for indexing and Nvidia qa embedding for embedding, and it’s good but it’s not fascinating especially in the chunking and retrieving parts btw i used recursive text splitter, so guys can you help me and tell me some advanced approaches for chatting with your pdf, and make it more accurate &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Phoenix_20_23&quot;&gt; /u/Phoenix_20_23 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6eqrb/the_best_way_to_create_ask_your_document_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e6eqrb/the_best_way_to_create_ask_your_document_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e6eqrb</id><link href="https://www.reddit.com/r/LangChain/comments/1e6eqrb/the_best_way_to_create_ask_your_document_rag/" /><updated>2024-07-18T15:48:26+00:00</updated><published>2024-07-18T15:48:26+00:00</published><title>The best way to create ask your document RAG system</title></entry></feed>