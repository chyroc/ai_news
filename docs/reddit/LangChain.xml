<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-02-01T16:44:39+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey what been one of the most trendiest and cool apps made using LangChain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag8rpx/what_are_the_coolest_apps_made_on_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag8rpx/what_are_the_coolest_apps_made_on_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag8rpx</id><link href="https://www.reddit.com/r/LangChain/comments/1ag8rpx/what_are_the_coolest_apps_made_on_langchain/" /><updated>2024-02-01T11:22:39+00:00</updated><published>2024-02-01T11:22:39+00:00</published><title>What are the coolest apps made on LangChain?</title></entry><entry><author><name>/u/sarthak_uchiha</name><uri>https://www.reddit.com/user/sarthak_uchiha</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can we get all the chunks from the azure search vector db ? Without doing any similarity search just retrieve all the chunks from the vector db ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sarthak_uchiha&quot;&gt; /u/sarthak_uchiha &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agcymb/azuresearch/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agcymb/azuresearch/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agcymb</id><link href="https://www.reddit.com/r/LangChain/comments/1agcymb/azuresearch/" /><updated>2024-02-01T15:00:55+00:00</updated><published>2024-02-01T15:00:55+00:00</published><title>Azure-search</title></entry><entry><author><name>/u/travel-nerd-05</name><uri>https://www.reddit.com/user/travel-nerd-05</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;If I create embeddings of a context, can I pass the embeddings directly to OpenAi and execute the prompt on top of conext without requiring to put the embeddings into vector db and then pull again from there to be sent as a retrieval chain?&lt;/p&gt; &lt;p&gt;Tried to look through but all examples seems to use a vector db.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/travel-nerd-05&quot;&gt; /u/travel-nerd-05 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agayui/can_we_use_langchain_without_vector_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agayui/can_we_use_langchain_without_vector_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agayui</id><link href="https://www.reddit.com/r/LangChain/comments/1agayui/can_we_use_langchain_without_vector_db/" /><updated>2024-02-01T13:27:06+00:00</updated><published>2024-02-01T13:27:06+00:00</published><title>Can we use langchain without vector db?</title></entry><entry><author><name>/u/Striking_Paper5259</name><uri>https://www.reddit.com/user/Striking_Paper5259</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to create an assistant for code completion on private codebase.&lt;/p&gt; &lt;p&gt;i am finding difficult to get correct context from regular embeddings.&lt;/p&gt; &lt;p&gt;is there better way to embed, index and retrieve code efficiently from codebase?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Striking_Paper5259&quot;&gt; /u/Striking_Paper5259 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag8kqg/what_works_best_for_creating_code_completion/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag8kqg/what_works_best_for_creating_code_completion/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag8kqg</id><link href="https://www.reddit.com/r/LangChain/comments/1ag8kqg/what_works_best_for_creating_code_completion/" /><updated>2024-02-01T11:10:00+00:00</updated><published>2024-02-01T11:10:00+00:00</published><title>what works best for creating code completion assistant using RAG over Codebase.</title></entry><entry><author><name>/u/DonutMysterious</name><uri>https://www.reddit.com/user/DonutMysterious</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;in my company, before we used LLMs, we had a deterministic bot with intent recognition. Examples:&lt;/p&gt; &lt;p&gt;A user asked if our company offers credits cards. If yes, the bot should tell infos about the cards and offer him to order one. If he¬¥s interested, he will get an offer for xyz. The complexity about this system is that there were multiple steps involved in the process, which different paths/routes to take.&lt;/p&gt; &lt;p&gt;In my team, we want to build a new, LLM-based Bot with OpenAI models. The system itself already works pretty good, but we have absolutely no clue how to integrate that behaviour paths into an LLM based system. &lt;/p&gt; &lt;p&gt;The prefered way would be to define the intends and the follow up routes in some kind of yaml file or maybe directly in Code. I am pretty sure, that we are not the only company who want some kind of sales funnel into their Bot. &lt;/p&gt; &lt;p&gt;Does anyone have experience and/or example code or just a suggestion how to tackle this issue?&lt;/p&gt; &lt;p&gt;Thanks :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DonutMysterious&quot;&gt; /u/DonutMysterious &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ageri4/deterministic_behaviour_in_an_llm_salesfunnel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ageri4/deterministic_behaviour_in_an_llm_salesfunnel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ageri4</id><link href="https://www.reddit.com/r/LangChain/comments/1ageri4/deterministic_behaviour_in_an_llm_salesfunnel/" /><updated>2024-02-01T16:19:16+00:00</updated><published>2024-02-01T16:19:16+00:00</published><title>Deterministic behaviour in an LLM (Salesfunnel)</title></entry><entry><author><name>/u/borrito3179</name><uri>https://www.reddit.com/user/borrito3179</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/borrito3179&quot;&gt; /u/borrito3179 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ChatGPT/comments/1ag67kn/any_custom_gpts_for_crypto_defi/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag6alz/any_custom_gpts_for_crypto_defi/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag6alz</id><link href="https://www.reddit.com/r/LangChain/comments/1ag6alz/any_custom_gpts_for_crypto_defi/" /><updated>2024-02-01T08:28:15+00:00</updated><published>2024-02-01T08:28:15+00:00</published><title>Any custom GPTs for crypto / defi?</title></entry><entry><author><name>/u/minhbtc</name><uri>https://www.reddit.com/user/minhbtc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/minhbtc&quot;&gt; /u/minhbtc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/LangChain/comments/1762tkr/a_chatbot_using_langchain_to_integrate_llm_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag5pus/a_chatbot_using_langchain_to_integrate_llm_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag5pus</id><link href="https://www.reddit.com/r/LangChain/comments/1ag5pus/a_chatbot_using_langchain_to_integrate_llm_with/" /><updated>2024-02-01T07:47:42+00:00</updated><published>2024-02-01T07:47:42+00:00</published><title>A Chatbot using Langchain to integrate LLM with MongoDB memory and LangSmith to tracing LLM calls.</title></entry><entry><author><name>/u/mercuretony</name><uri>https://www.reddit.com/user/mercuretony</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello üëãüèæ!&lt;/p&gt; &lt;p&gt;I&amp;#39;m looking forward to build a chatbot that can:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Interact with my class note: indeed, I&amp;#39;m at university and would like to chat with the bot and ask questions about some class notes. &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Requirements: it has to be able to read PDF, docx, word and sometimes HTML files.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;I might be interested in the future to add interaction with my calendar so that I can ask questions about my day.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Requirements: it has to take in account my calendar informations.&lt;/p&gt; &lt;p&gt;Do you think I should use llama index or Langchain.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mercuretony&quot;&gt; /u/mercuretony &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag34dc/help_for_a_project_llama_index_or_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag34dc/help_for_a_project_llama_index_or_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag34dc</id><link href="https://www.reddit.com/r/LangChain/comments/1ag34dc/help_for_a_project_llama_index_or_langchain/" /><updated>2024-02-01T05:05:29+00:00</updated><published>2024-02-01T05:05:29+00:00</published><title>Help for a project! Llama Index or Langchain ?</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Currently, I am using Chroma DB in production as a vector database. However, I am facing challenges, including delayed responses from the API and potential issues with semantic search, leading to results that do not meet our expectations. Can you suggest a robust database suitable for production, and do you have any additional insights or recommendations based on your expertise?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afkc5g/which_vector_databases_are_widely_used_in_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afkc5g/which_vector_databases_are_widely_used_in_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afkc5g</id><link href="https://www.reddit.com/r/LangChain/comments/1afkc5g/which_vector_databases_are_widely_used_in_the/" /><updated>2024-01-31T15:24:47+00:00</updated><published>2024-01-31T15:24:47+00:00</published><title>Which vector databases are widely used in the industry and are considered suitable for production purposes?</title></entry><entry><author><name>/u/DBAdvice123</name><uri>https://www.reddit.com/user/DBAdvice123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Titled &amp;quot;&lt;a href=&quot;https://www.datastax.com/resources/whitepaper/an-llm-agent-reference-architecture-demystifying-llm-based-systems?utm_medium=social_organic&amp;amp;utm_source=reddit&amp;amp;utm_campaign=wp&amp;amp;utm_content=putv&quot;&gt;An LLM Agent Reference Architecture: Demystifying LLM-based Systems&lt;/a&gt;&amp;quot;&lt;/p&gt; &lt;p&gt;The paper gives some design patterns, in-depth architectural examples, and things to keep in mind when architecting LLM-based systems. Worth a read!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DBAdvice123&quot;&gt; /u/DBAdvice123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afmbdu/new_whitepaper_written_by_langchain_datastax/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afmbdu/new_whitepaper_written_by_langchain_datastax/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afmbdu</id><link href="https://www.reddit.com/r/LangChain/comments/1afmbdu/new_whitepaper_written_by_langchain_datastax/" /><updated>2024-01-31T16:49:42+00:00</updated><published>2024-01-31T16:49:42+00:00</published><title>New Whitepaper written by LangChain &amp; DataStax</title></entry><entry><author><name>/u/salmenus</name><uri>https://www.reddit.com/user/salmenus</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Reddit! This is about a new &lt;a href=&quot;https://github.com/nluxai/nlux&quot;&gt;open source project&lt;/a&gt; I&amp;#39;m starting for a React JS / Javascript library that makes it &lt;strong&gt;super simple to create conversational AI interfaces&lt;/strong&gt; using LangChain&amp;#39;s &lt;strong&gt;LangServe&lt;/strong&gt;, HuggingFace, or any other LLM.&lt;/p&gt; &lt;p&gt;The project is called NLUX (for &lt;em&gt;Natural Language User Experience&lt;/em&gt;) and you can already start using it to create a web app for your LC backend, or embed LLMs into your web app.&lt;/p&gt; &lt;p&gt;Project Website:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://nlux.ai/&quot;&gt;NLUX.ai&lt;/a&gt; ‚Äî for docs, examples, source code, etc.&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.nlux.ai/examples/langchain-langserve-adapter&quot;&gt;Example here&lt;/a&gt; using LangServe + React JS&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;What you can do with NLUX:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Build AI Chat Interfaces In Minutes&lt;/strong&gt; ‚Äî High quality conversational AI UI in a few lines of code.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Flexible LLM Adapters&lt;/strong&gt; ‚Äî For LangServe, HuggingFace, ChatGPT .. and more coming soon.&lt;/li&gt; &lt;li&gt;An API to &lt;strong&gt;Create Your Own Adapter&lt;/strong&gt; ‚Äî for any LLM or custom backend.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Chatbot Personas&lt;/strong&gt; ‚Äî Configure the bot and user profiles for personalised interactions.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Zero Dependencies&lt;/strong&gt; ‚Äî Lightweight codebase, with zero-dep ! except for LLM front-end libraries.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Give it a try and let me know what you think!&lt;/p&gt; &lt;p&gt;Questions, ideas or feedback? I&amp;#39;m all ears in the comments! üôÇ ‚öõÔ∏è&lt;/p&gt; &lt;p&gt;&lt;em&gt;PS: I‚Äôm may give this post a little promo to get some early adopters. The project is and will always remain free, open source, and self-funded.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;SalmenLead Developer&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/salmenus&quot;&gt; /u/salmenus &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afk4dr/reactjs_langchain_new_js_lib_to_create_frontends/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afk4dr/reactjs_langchain_new_js_lib_to_create_frontends/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afk4dr</id><link href="https://www.reddit.com/r/LangChain/comments/1afk4dr/reactjs_langchain_new_js_lib_to_create_frontends/" /><updated>2024-01-31T15:15:29+00:00</updated><published>2024-01-31T15:15:29+00:00</published><title>ReactJS + LangChain: New JS Lib To Create Frontends Powered by LangServe</title></entry><entry><author><name>/u/austin_at_focused</name><uri>https://www.reddit.com/user/austin_at_focused</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag1cy1/chat_with_your_pdfs_an_end_to_end_langchain/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/5DiO8oU-9Phdh4pr4kT6CosZBN3PpI9Y5Bhp2oMIUxE.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=323f40f767d5a97cce6fa9601752f76e918cde05&quot; alt=&quot;Chat With Your PDFs - An End to End LangChain Tutorial - Part 1&quot; title=&quot;Chat With Your PDFs - An End to End LangChain Tutorial - Part 1&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/austin_at_focused&quot;&gt; /u/austin_at_focused &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtube.com/watch?v=UwgZmrRAgQ4&amp;amp;si=eC1j7yWuxIGcavVs&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag1cy1/chat_with_your_pdfs_an_end_to_end_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ag1cy1</id><media:thumbnail url="https://external-preview.redd.it/5DiO8oU-9Phdh4pr4kT6CosZBN3PpI9Y5Bhp2oMIUxE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=323f40f767d5a97cce6fa9601752f76e918cde05" /><link href="https://www.reddit.com/r/LangChain/comments/1ag1cy1/chat_with_your_pdfs_an_end_to_end_langchain/" /><updated>2024-02-01T03:32:40+00:00</updated><published>2024-02-01T03:32:40+00:00</published><title>Chat With Your PDFs - An End to End LangChain Tutorial - Part 1</title></entry><entry><author><name>/u/ChoicePermission6770</name><uri>https://www.reddit.com/user/ChoicePermission6770</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afox49/langdao_lang/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/f7ngtg3tktfc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=61a66b916cd44d42a335aec4df0bd35e7afbd595&quot; alt=&quot;LangDAO ‚Ä¶ $LANG&quot; title=&quot;LangDAO ‚Ä¶ $LANG&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Last week, I saw a post about LangDAO, something that could be a type of crypto used to compensate contributions in the langchain community. This week, I&amp;#39;m trying to find the posts and threads on X, but I don&amp;#39;t see anything. Any idea what might have happened?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ChoicePermission6770&quot;&gt; /u/ChoicePermission6770 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/f7ngtg3tktfc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afox49/langdao_lang/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1afox49</id><media:thumbnail url="https://preview.redd.it/f7ngtg3tktfc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=61a66b916cd44d42a335aec4df0bd35e7afbd595" /><link href="https://www.reddit.com/r/LangChain/comments/1afox49/langdao_lang/" /><updated>2024-01-31T18:34:09+00:00</updated><published>2024-01-31T18:34:09+00:00</published><title>LangDAO ‚Ä¶ $LANG</title></entry><entry><author><name>/u/EconBro95</name><uri>https://www.reddit.com/user/EconBro95</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all,&lt;/p&gt; &lt;p&gt;I am implementing a data system for retrieval and thought to get opinions given how fast the field is moving.&lt;/p&gt; &lt;p&gt;So background, I have a bunch of data in the form of documents, tables (think a lot of csv‚Äôs/excel files), and other text data.&lt;/p&gt; &lt;p&gt;My question relates mainly to the tabular data that I have, the text data I will embed and store in a vector db.&lt;/p&gt; &lt;p&gt;The two approaches possible for the tabular data are:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;More traditional:&lt;/li&gt; &lt;/ol&gt; &lt;ul&gt; &lt;li&gt;Transform into a common structure and pass into a traditional relational database (Postgres, etc).&lt;/li&gt; &lt;li&gt;After that using the metadata from each table with Llama Index: SQLAutoVectorQueryEngine to get the data that I need for each question regarding the data&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Pro‚Äôs:&lt;br/&gt; I can tell exactly what is being queried to get what results and I have more control over the databases themselves and their associated metadata and description.&lt;/p&gt; &lt;p&gt;Con‚Äôs:&lt;br/&gt; A lot harder to scale the structural data portion of this as more data floats in as CSV‚Äôs/xlsx files.&lt;br/&gt; Will there be confusion as to how to use the combination of the text/document data in the vectordb combined with the relational data in the warehouse?&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Knowledge graph and graph DB‚Äôs:&lt;br/&gt; Rather than structure the data for consumption into a Relational database, use Llama Index and unstructured to convert the tabular data into a format capable of being used as a knowledge graph and graph DB.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I BELIEVE that the process for creating such graph‚Äôs is fairly automated by LLama Index and Langchain.&lt;/p&gt; &lt;p&gt;Pro‚Äôs:&lt;br/&gt; Easier to scale.&lt;br/&gt; The relationships might make it easier to pull the relevant data especially given the scale.&lt;/p&gt; &lt;p&gt;Con‚Äôs&lt;br/&gt; I am not sure how well numeric data, the type that is generally stored in relational databases for storage does in a graph DB. Are they able to build relationships easily and accurately?&lt;/p&gt; &lt;p&gt;Would love some thoughts and opinions,&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EconBro95&quot;&gt; /u/EconBro95 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afu4qa/rag_for_structured_data_querying_rd_vs_knowledge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afu4qa/rag_for_structured_data_querying_rd_vs_knowledge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afu4qa</id><link href="https://www.reddit.com/r/LangChain/comments/1afu4qa/rag_for_structured_data_querying_rd_vs_knowledge/" /><updated>2024-01-31T22:04:09+00:00</updated><published>2024-01-31T22:04:09+00:00</published><title>RAG for structured data (querying RD vs. knowledge graph/graph db)</title></entry><entry><author><name>/u/OkMeeting8253</name><uri>https://www.reddit.com/user/OkMeeting8253</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a chat history between a client and a coach. I need to create an ability for a coach to quickly recall details from previous conversations. Example: User asks: &amp;quot;remember i told you about mom&amp;quot; Imagine it was two months ago - coach who has multiple clients can&amp;#39;t remember everything, so she need a quick search in a chat history and calls transcripts to get a summary of everything the client has told about her mom.&lt;/p&gt; &lt;p&gt;How would you split and organize chat history and calls transcripts to chunks?&lt;/p&gt; &lt;p&gt;based on what?&lt;/p&gt; &lt;p&gt;when it something that user says it&amp;#39;s seems straight forward. but imagine something like this:&lt;/p&gt; &lt;p&gt;coach: was you close with her? client: yes&lt;/p&gt; &lt;p&gt;so client only says yes, i need somehow keep the ref to the question.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OkMeeting8253&quot;&gt; /u/OkMeeting8253 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afs1kz/how_would_you_organize_a_dialogues_documents_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afs1kz/how_would_you_organize_a_dialogues_documents_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afs1kz</id><link href="https://www.reddit.com/r/LangChain/comments/1afs1kz/how_would_you_organize_a_dialogues_documents_in/" /><updated>2024-01-31T20:39:39+00:00</updated><published>2024-01-31T20:39:39+00:00</published><title>How would you organize a dialogues documents in chunks?</title></entry><entry><author><name>/u/Axiomatic_Inspector_</name><uri>https://www.reddit.com/user/Axiomatic_Inspector_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I just made an AI search engine with Spring Boot and LangChain4J inspired by the project search-with-lepton&lt;/p&gt; &lt;p&gt;If you are interest in it, you can visit it here &lt;a href=&quot;https://github.com/vlinx-io/infinite-search&quot;&gt;https://github.com/vlinx-io/infinite-search&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Axiomatic_Inspector_&quot;&gt; /u/Axiomatic_Inspector_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1affs5p/an_open_source_ai_search_engine/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1affs5p/an_open_source_ai_search_engine/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1affs5p</id><link href="https://www.reddit.com/r/LangChain/comments/1affs5p/an_open_source_ai_search_engine/" /><updated>2024-01-31T11:30:36+00:00</updated><published>2024-01-31T11:30:36+00:00</published><title>An open source AI Search Engine</title></entry><entry><author><name>/u/ashpreetbedi</name><uri>https://www.reddit.com/user/ashpreetbedi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afja1t/building_a_pdf_ai_using_function_calling/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/yR_EBM4rBjE22hpN5-A5fhPvBw6wZRhYGuMrD9XamP0.jpg&quot; alt=&quot;Building a PDF AI using function calling&quot; title=&quot;Building a PDF AI using function calling&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Chat with PDFs is the todo app of AI and i‚Äôve been thinking about building an advanced one using function calling. What do you think of this flow:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;LLM first determines if it needs to search docs or the web for context&lt;/li&gt; &lt;li&gt;Then decides if it needs a specific doc or the latest one&lt;/li&gt; &lt;li&gt;Then decides to search a doc or get context to summarize&lt;/li&gt; &lt;li&gt;Produces an answer using this context&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Using this flow the LLM can search specific docs, summarize, or bring in web context to enhance the answer. Thoughts? &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/rhni60skesfc1.png?width=1812&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=010b2403811e6729e27a2c1f04f3c407f523ff27&quot;&gt;https://preview.redd.it/rhni60skesfc1.png?width=1812&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=010b2403811e6729e27a2c1f04f3c407f523ff27&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashpreetbedi&quot;&gt; /u/ashpreetbedi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afja1t/building_a_pdf_ai_using_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afja1t/building_a_pdf_ai_using_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1afja1t</id><media:thumbnail url="https://a.thumbs.redditmedia.com/yR_EBM4rBjE22hpN5-A5fhPvBw6wZRhYGuMrD9XamP0.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1afja1t/building_a_pdf_ai_using_function_calling/" /><updated>2024-01-31T14:37:37+00:00</updated><published>2024-01-31T14:37:37+00:00</published><title>Building a PDF AI using function calling</title></entry><entry><author><name>/u/No-Gear-1874</name><uri>https://www.reddit.com/user/No-Gear-1874</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Hey &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; &lt;a href=&quot;/r/LlamaIndex&quot;&gt;r/LlamaIndex&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I&amp;#39;m diving into an exciting venture for a non-profit university project where we aim to build an application generating quizzes from medical course PDFs. The concept is simple: users choose a course in a user-friendly interface, click &amp;quot;Generate,&amp;quot; and watch quiz questions come to life.&lt;/p&gt; &lt;p&gt;However, I&amp;#39;m currently stuck on the most effective strategy for &amp;quot;&lt;strong&gt;chunking&lt;/strong&gt;&amp;quot; and &amp;quot;&lt;strong&gt;retrieving&lt;/strong&gt;&amp;quot; information from the pre-saved PDFs within the application. If you&amp;#39;ve got experience with similar app development or ideas on the best approach, I&amp;#39;d greatly appreciate your input.&lt;/p&gt; &lt;p&gt;I think to use llm and embeddings &lt;/p&gt; &lt;p&gt;Any suggestions, links to helpful resources, or shared experiences would be immensely valuable. This is a non-profit initiative at the university, and your guidance can make a significant impact. Thanks in advance for your invaluable help! üåê‚ú®&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No-Gear-1874&quot;&gt; /u/No-Gear-1874 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afm8zg/developing_a_quiz_generator_from_medical_course/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afm8zg/developing_a_quiz_generator_from_medical_course/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afm8zg</id><link href="https://www.reddit.com/r/LangChain/comments/1afm8zg/developing_a_quiz_generator_from_medical_course/" /><updated>2024-01-31T16:47:06+00:00</updated><published>2024-01-31T16:47:06+00:00</published><title>Developing a Quiz Generator from Medical Course PDFs</title></entry><entry><author><name>/u/modularmindapp</name><uri>https://www.reddit.com/user/modularmindapp</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afrolj/live_webinar_futureforward_24_dive_into_the/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/eYRqtFhZZg4D2W9wEytd77-hP3CHzsLLkfojUpWZF2s.jpg&quot; alt=&quot;[Live webinar] FutureForward '24 - Dive into the latest advancements&quot; title=&quot;[Live webinar] FutureForward '24 - Dive into the latest advancements&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/modularmindapp&quot;&gt; /u/modularmindapp &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://join.modularmind.app/ff24&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afrolj/live_webinar_futureforward_24_dive_into_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1afrolj</id><media:thumbnail url="https://b.thumbs.redditmedia.com/eYRqtFhZZg4D2W9wEytd77-hP3CHzsLLkfojUpWZF2s.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1afrolj/live_webinar_futureforward_24_dive_into_the/" /><updated>2024-01-31T20:25:15+00:00</updated><published>2024-01-31T20:25:15+00:00</published><title>[Live webinar] FutureForward '24 - Dive into the latest advancements</title></entry><entry><author><name>/u/MareaNeagra</name><uri>https://www.reddit.com/user/MareaNeagra</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi! I am new to this and I do not know how to bypass the limitation of tokens. I should split my prompt in multiple chunks? Is there a method: refine or map-reduce? I have a large prompt and I do not know how to split it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MareaNeagra&quot;&gt; /u/MareaNeagra &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afmn9r/bypass_4096_tokens/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afmn9r/bypass_4096_tokens/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afmn9r</id><link href="https://www.reddit.com/r/LangChain/comments/1afmn9r/bypass_4096_tokens/" /><updated>2024-01-31T17:02:50+00:00</updated><published>2024-01-31T17:02:50+00:00</published><title>Bypass 4096 tokens</title></entry><entry><author><name>/u/YOLOLJJ</name><uri>https://www.reddit.com/user/YOLOLJJ</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using GPT 3.5-Turbo-Instinct and feeding in my dataschema into the prompt. I am creating my SQL query using create_sql_chain and then running the query in the database through JDBC. So far, it is working okay however, if I am looking to push this to production, I need the model to not return anything if it is not confident in its answer or if the query being asked is too vague.&lt;/p&gt; &lt;p&gt;For instance, if I ask my text to sql model &amp;quot;how many rows are there&amp;quot;, it should return back something saying &amp;quot;this query is too vague&amp;quot;. Likewise, if I were to ask it a question such as, &amp;quot;Return the GPA and Networth of Nadir&amp;quot;, how do I get it to do &amp;quot;WHERE LastName = &amp;#39;Nadir&amp;#39; rather than &amp;quot;WHERE FirstName = &amp;#39;Nadir&amp;#39;. I thought that by potentially getting confidence scores I could explore and find a threshold where the human needs to clarify what they meant until the model had a confident enough query&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/YOLOLJJ&quot;&gt; /u/YOLOLJJ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afkz4o/how_to_build_a_text_to_sql_model_that_asks_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afkz4o/how_to_build_a_text_to_sql_model_that_asks_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afkz4o</id><link href="https://www.reddit.com/r/LangChain/comments/1afkz4o/how_to_build_a_text_to_sql_model_that_asks_for/" /><updated>2024-01-31T15:52:38+00:00</updated><published>2024-01-31T15:52:38+00:00</published><title>How to build a Text to SQL Model that asks for more information if the query is too vague</title></entry><entry><author><name>/u/litchiTheGreat</name><uri>https://www.reddit.com/user/litchiTheGreat</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hey, I am new to langhchain and using it in my nodejs application , I have used langchain to successfully split the documents into chunks with recursive vector splitting, I want to add another metadata before embedding it, is langchain suitable for this? I have previously done this manually but it takes a lot of time and i want to try this in the library way. I am looking for something parallel to the ingestingPipeline feature in llamaIndex. would really appricate any guidlelines!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/litchiTheGreat&quot;&gt; /u/litchiTheGreat &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afiba1/metadata_tagging_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afiba1/metadata_tagging_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afiba1</id><link href="https://www.reddit.com/r/LangChain/comments/1afiba1/metadata_tagging_with_langchain/" /><updated>2024-01-31T13:51:45+00:00</updated><published>2024-01-31T13:51:45+00:00</published><title>metadata tagging with langchain,</title></entry><entry><author><name>/u/OnlyBadKarma</name><uri>https://www.reddit.com/user/OnlyBadKarma</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using LangChain QA Retrieval using map-reduce chain. I want to replace/ stuff the documents received through retriever to make my answers better. But I am not able to figure out the way.&lt;/p&gt; &lt;p&gt;&lt;code&gt;question_prompt = PromptTemplate.from_template(&amp;quot;&amp;quot;&amp;quot;Check the summary to tell how it is answering the question. You can just say that it doesn&amp;#39;t answer the question directly.&lt;/code&gt; &lt;/p&gt; &lt;p&gt;&lt;code&gt;{context}&lt;/code&gt; &lt;/p&gt; &lt;p&gt;&lt;code&gt;Original question: {question}&amp;quot;&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;# Loading the Annoy DB from disk.&lt;/code&gt;&lt;br/&gt; &lt;code&gt;vectordb = Annoy.load_local(persist_directory, embeddings=embedding)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;combine_custom_prompt = PromptTemplate.from_template(&amp;quot;&amp;quot;&amp;quot;Out of these summaries. If you don&amp;#39;t know the answer, just say that you don&amp;#39;t know. Don&amp;#39;t try to make up an answer.&lt;/code&gt;&lt;br/&gt; &lt;code&gt;QUESTION IS: {question}&lt;/code&gt;&lt;br/&gt; &lt;code&gt;=========&lt;/code&gt;&lt;br/&gt; &lt;code&gt;{summaries}&lt;/code&gt;&lt;br/&gt; &lt;code&gt;=========&lt;/code&gt;&lt;br/&gt; &lt;code&gt;FINAL ANSWER:&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;&amp;quot;&amp;quot;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;chain_type_kwargs = {&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;verbose&amp;quot;: True,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;question_prompt&amp;quot;: question_prompt,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;combine_prompt&amp;quot;: combine_custom_prompt,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;combine_document_variable_name&amp;quot;: &amp;quot;summaries&amp;quot;,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;map_reduce_document_variable_name&amp;quot;: &amp;quot;context&amp;quot;,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;}&lt;/code&gt;&lt;br/&gt; &lt;code&gt;retriever = vectordb.as_retriever(search_kwargs={&amp;quot;k&amp;quot;: 10})&lt;/code&gt;&lt;br/&gt; &lt;code&gt;print(&amp;quot;Type of retriever&amp;quot;, type(retriever))&lt;/code&gt;&lt;br/&gt; &lt;code&gt;refine = RetrievalQA.from_chain_type(llm=OpenAI(),&lt;/code&gt;&lt;br/&gt; &lt;code&gt;chain_type=&amp;quot;map_reduce&amp;quot;,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;return_source_documents=True,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;chain_type_kwargs=chain_type_kwargs,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;retriever=retriever,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;verbose=True)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;print(refine(&amp;quot;Random Question&amp;quot;))&lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OnlyBadKarma&quot;&gt; /u/OnlyBadKarma &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afe337/how_to_replacestuff_the_content_inside_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afe337/how_to_replacestuff_the_content_inside_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afe337</id><link href="https://www.reddit.com/r/LangChain/comments/1afe337/how_to_replacestuff_the_content_inside_the/" /><updated>2024-01-31T09:33:24+00:00</updated><published>2024-01-31T09:33:24+00:00</published><title>How to replace/stuff the content inside the document in QAReteriver with a map-reduce chain?</title></entry><entry><author><name>/u/tiagomlopes</name><uri>https://www.reddit.com/user/tiagomlopes</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on enhancing a chatbot&amp;#39;s user experience by integrating dynamic quick replies for instances where certain information is missing for function/tool execution.&lt;/p&gt; &lt;p&gt;For example, consider a function &lt;code&gt;search_movies&lt;/code&gt; that has an optional parameter &lt;code&gt;genre&lt;/code&gt;. When a user writes &amp;quot;I want to watch a movie&amp;quot; without specifying a genre, I&amp;#39;d like the chatbot to present a list of available genres as quick replies in the UI, rather than having the user type out their preference. &lt;/p&gt; &lt;p&gt;The conceptual solution involves:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;pausing the chatbot&amp;#39;s execution from the function and saving its state when additional info is needed.&lt;/li&gt; &lt;li&gt;Once the user picks an option, the chatbot&amp;#39;s state is restored, the relevant function (in this case &lt;code&gt;search_movies&lt;/code&gt;) is invoked with the new input, and the conversation continues.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Some tutorials have similar &amp;quot;pause&amp;quot; functionality to get user inputs, but they only work when the script runs on a terminal. In the scenario above, the code will be behind an API so it&amp;#39;s not possible to keep a connection open waiting for an answer.&lt;/p&gt; &lt;p&gt;Is this approach viable with LangChain? Are there other better approaches?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/tiagomlopes&quot;&gt; /u/tiagomlopes &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afgjex/enhancing_chatbot_ux_with_dynamic_quick_replies/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afgjex/enhancing_chatbot_ux_with_dynamic_quick_replies/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afgjex</id><link href="https://www.reddit.com/r/LangChain/comments/1afgjex/enhancing_chatbot_ux_with_dynamic_quick_replies/" /><updated>2024-01-31T12:17:24+00:00</updated><published>2024-01-31T12:17:24+00:00</published><title>Enhancing Chatbot UX with Dynamic Quick Replies in LangChain - Feasible?</title></entry><entry><author><name>/u/IsseBisse</name><uri>https://www.reddit.com/user/IsseBisse</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m quite new to LangChain, trying it out to see what all the fuzz is about. I recently followed the &lt;a href=&quot;https://python.langchain.com/docs/expression_language/cookbook/memory&quot;&gt;Adding memory cookbook&lt;/a&gt; from the docs. I&amp;#39;m running it inside a simple while loop to provide consecutive inputs to the chain. &lt;/p&gt; &lt;p&gt;Is there any way to update the memory inside the chain? I don&amp;#39;t much care for the &lt;/p&gt; &lt;pre&gt;&lt;code&gt;memory.save_context(inputs, {&amp;quot;output&amp;quot;: response.content}) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;step outside of the chain. That seems to go against the whole point of containing everything LLM related inside the chain. Or am I missing something?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/IsseBisse&quot;&gt; /u/IsseBisse &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afdjc2/cleaner_memory_handling_in_lcel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afdjc2/cleaner_memory_handling_in_lcel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afdjc2</id><link href="https://www.reddit.com/r/LangChain/comments/1afdjc2/cleaner_memory_handling_in_lcel/" /><updated>2024-01-31T08:53:55+00:00</updated><published>2024-01-31T08:53:55+00:00</published><title>Cleaner memory handling in LCEL</title></entry></feed>