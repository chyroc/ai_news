<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-16T07:56:08+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Difficult-Card767</name><uri>https://www.reddit.com/user/Difficult-Card767</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;As a newcomer to LangChain, I&amp;#39;m finding the learning curve to be quite steep. I&amp;#39;ve been sifting through the documentation and various forums for guidance, but it feels like I&amp;#39;m piecing together a puzzle without all the pieces.&lt;/p&gt; &lt;p&gt;I&amp;#39;m curious to know if there are others out there who feel the same way. Is there a better way to approach learning LangChain that I&amp;#39;m missing? Any resources or tips would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Difficult-Card767&quot;&gt; /u/Difficult-Card767 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197u4wp/struggling_with_langchains_learning_curve/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197u4wp/struggling_with_langchains_learning_curve/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_197u4wp</id><link href="https://www.reddit.com/r/LangChain/comments/197u4wp/struggling_with_langchains_learning_curve/" /><updated>2024-01-16T04:38:01+00:00</updated><published>2024-01-16T04:38:01+00:00</published><title>Struggling with LangChain's learning curve</title></entry><entry><author><name>/u/Trick-Asparagus-9260</name><uri>https://www.reddit.com/user/Trick-Asparagus-9260</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to get the similarity scores using below func. My vector index is FAISS. I get an error: &lt;/p&gt; &lt;p&gt;retriever = local_db.as_retriever(&lt;/p&gt; &lt;p&gt;search_type=&amp;quot;similarity_search_with_relevant_score&amp;quot;&lt;/p&gt; &lt;p&gt;)&lt;/p&gt; &lt;p&gt;&lt;strong&gt;ValidationError&lt;/strong&gt;: 1 validation error for VectorStoreRetriever __root__ search_type of similarity_search_with_score not allowed. Valid values are: (&amp;#39;similarity&amp;#39;, &amp;#39;similarity_score_threshold&amp;#39;, &amp;#39;mmr&amp;#39;) (type=value_error)[26]: &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Trick-Asparagus-9260&quot;&gt; /u/Trick-Asparagus-9260 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197wxp9/doesnt_langchain_retriever_support_similarity/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197wxp9/doesnt_langchain_retriever_support_similarity/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_197wxp9</id><link href="https://www.reddit.com/r/LangChain/comments/197wxp9/doesnt_langchain_retriever_support_similarity/" /><updated>2024-01-16T07:14:09+00:00</updated><published>2024-01-16T07:14:09+00:00</published><title>Doesn't langchain retriever support 'similarity_search_with_relevant_scores' using FAISS?</title></entry><entry><author><name>/u/SensitiveFel</name><uri>https://www.reddit.com/user/SensitiveFel</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The inner workings of &lt;code&gt;RedisChatMessageHistory&lt;/code&gt;,I&amp;#39;m trying to find out if it uses summary internally like &lt;code&gt;ConversationSummaryMemory&lt;/code&gt;, or if he&amp;#39;s simply adding historical data to the context.&lt;/p&gt; &lt;p&gt;This may cause the token to exceed the limit, is there anything I can do to avoid this? I don&amp;#39;t see an internal description of this in the documentation.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SensitiveFel&quot;&gt; /u/SensitiveFel &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197wlgo/the_inner_workings_of_redischatmessagehistory/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197wlgo/the_inner_workings_of_redischatmessagehistory/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_197wlgo</id><link href="https://www.reddit.com/r/LangChain/comments/197wlgo/the_inner_workings_of_redischatmessagehistory/" /><updated>2024-01-16T06:53:07+00:00</updated><published>2024-01-16T06:53:07+00:00</published><title>The inner workings of RedisChatMessageHistory</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Learning LangChain so figured I would love to see how llms learn my writing and as a bonus would write about how i built this?&lt;/p&gt; &lt;p&gt;So need help with a few questions from the community&lt;/p&gt; &lt;p&gt;1) Which LLM would be best other than OpenAi models as I want to experiment with opensource models&lt;/p&gt; &lt;p&gt;2) list of tools, agents and chains which would help me do this? &lt;/p&gt; &lt;p&gt;3) Bonus my content has code embedded in it and visualizations, anyway I could tell the LLM to do it for me?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197eq8d/i_am_a_technical_blogger_and_want_to_train_an_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197eq8d/i_am_a_technical_blogger_and_want_to_train_an_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_197eq8d</id><link href="https://www.reddit.com/r/LangChain/comments/197eq8d/i_am_a_technical_blogger_and_want_to_train_an_llm/" /><updated>2024-01-15T17:44:01+00:00</updated><published>2024-01-15T17:44:01+00:00</published><title>I am a technical blogger and want to train an LLM on my blogs.</title></entry><entry><author><name>/u/ep3gotts</name><uri>https://www.reddit.com/user/ep3gotts</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to understand why Reranking is often needed in RAG technique and why it can&amp;#39;t be just skipped completely.&lt;/p&gt; &lt;p&gt;Would Reranking still exist if LLM models were bigger and better at creating embeddings(converting prompts into vectors in space)? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ep3gotts&quot;&gt; /u/ep3gotts &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1978ywu/why_reranking_exists_in_the_first_place/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1978ywu/why_reranking_exists_in_the_first_place/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1978ywu</id><link href="https://www.reddit.com/r/LangChain/comments/1978ywu/why_reranking_exists_in_the_first_place/" /><updated>2024-01-15T13:40:27+00:00</updated><published>2024-01-15T13:40:27+00:00</published><title>Why Reranking exists in the first place?</title></entry><entry><author><name>/u/PlanktonPretend6772</name><uri>https://www.reddit.com/user/PlanktonPretend6772</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hello&lt;br/&gt; I&amp;#39;m trying to use the Mistral 7B model for question-answer generation using the QAGeneration Chain &lt;/p&gt; &lt;p&gt;&lt;code&gt;def llm_question_generation_pipeline(chunks):&lt;/code&gt;&lt;br/&gt; &lt;code&gt;documents = [Document(page_content=chunk) for chunk in chunks]&lt;/code&gt;&lt;br/&gt; &lt;code&gt;repo_id = &amp;quot;mistralai/Mistral-7B-v0.1&amp;quot;&lt;/code&gt;&lt;br/&gt; &lt;code&gt;llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={&amp;quot;temperature&amp;quot;: 0.5, &amp;quot;max_length&amp;quot;: 512})&lt;/code&gt;&lt;br/&gt; &lt;code&gt;qa_chain = QAGenerationChain.from_llm(llm = llm, verbose = True)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;raw_output = qa_chain.run(documents[0].page_content)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;print(&amp;quot;Raw Output:&amp;quot;, raw_output)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;this is my code, but I&amp;#39;m getting this error frequently&lt;br/&gt; &lt;code&gt;raise JSONDecodeError(&amp;quot;Expecting value&amp;quot;, s, err.value) from None&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1)&lt;/code&gt; &lt;/p&gt; &lt;p&gt;this is the prompt created by QAGeneration chain&lt;br/&gt; &lt;code&gt;Prompt after formatting:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;You are a smart assistant designed to help high school teachers come up with reading comprehension questions.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Given a piece of text, you must come up with a question and answer pair that can be used to test a student&amp;#39;s reading comprehension abilities.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;When coming up with this question/answer pair, you must respond in the following format:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;\&lt;/code&gt;```&lt;/p&gt; &lt;p&gt;&lt;code&gt;{&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;&amp;quot;question&amp;quot;: &amp;quot;$YOUR_QUESTION_HERE&amp;quot;,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;&amp;quot;answer&amp;quot;: &amp;quot;$THE_ANSWER_HERE&amp;quot;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;}&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;\&lt;/code&gt;```&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Everything between the \&lt;/code&gt;`` must be valid json.`&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Please come up with a question/answer pair, in the specified JSON format, for the following text:&lt;/code&gt; &lt;/p&gt; &lt;p&gt;I searched for this error, it is saying that it could be possible if the LLM is not giving proper JSON formated output&lt;br/&gt; Would anyone be able to help me solve this error?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/PlanktonPretend6772&quot;&gt; /u/PlanktonPretend6772 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197j354/mistral_7b_qageneration_chain_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197j354/mistral_7b_qageneration_chain_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_197j354</id><link href="https://www.reddit.com/r/LangChain/comments/197j354/mistral_7b_qageneration_chain_langchain/" /><updated>2024-01-15T20:33:21+00:00</updated><published>2024-01-15T20:33:21+00:00</published><title>Mistral 7B QAGeneration Chain Langchain - JSONDecode Error</title></entry><entry><author><name>/u/Maheidem</name><uri>https://www.reddit.com/user/Maheidem</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Guys,&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I did a little side project to help me on my project, I&amp;#39;m doing a database parser agent using Clause 2.1 on bedrock that uses Python to query Druid with a LOT of contexts.&lt;/p&gt; &lt;p&gt;Been struggling quite a lot with documentation with anything that is not open ai.&lt;/p&gt; &lt;p&gt;So I created a Custom GPT to help me where it can.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;It&amp;#39;s not perfect, but it&amp;#39;s been helping me a little so I wanted to share it with you all.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://chat.openai.com/g/g-yqSII6PUj-langchain-specialist&quot;&gt;Langchain Specialist&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Maheidem&quot;&gt; /u/Maheidem &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1979xgt/custom_gpt_to_assist_with_langchain_development/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1979xgt/custom_gpt_to_assist_with_langchain_development/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1979xgt</id><link href="https://www.reddit.com/r/LangChain/comments/1979xgt/custom_gpt_to_assist_with_langchain_development/" /><updated>2024-01-15T14:25:28+00:00</updated><published>2024-01-15T14:25:28+00:00</published><title>Custom GPT to assist with langchain development</title></entry><entry><author><name>/u/hamnarif</name><uri>https://www.reddit.com/user/hamnarif</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://python.langchain.com/docs/use_cases/question_answering/chat_history&quot;&gt;https://python.langchain.com/docs/use_cases/question_answering/chat_history&lt;/a&gt;&lt;br/&gt; I am referring to these docs for chat history&lt;br/&gt; I]this code is giving me error on this &amp;quot;chat_history.extend([HumanMessage(content=question), ai_msg])&lt;br/&gt; line&amp;quot;&lt;/p&gt; &lt;p&gt;chat_history = []&lt;br/&gt; question = &amp;quot;What is function of form nec?&amp;quot;&lt;br/&gt; ai_msg = rag_chain.invoke({&amp;quot;question&amp;quot;: question, &amp;quot;chat_history&amp;quot;: chat_history})&lt;br/&gt; chat_history.extend([HumanMessage(content=question), ai_msg])&lt;br/&gt; second_question = &amp;quot;is there anything else about it?&amp;quot;&lt;br/&gt; rag_chain.invoke({&amp;quot;question&amp;quot;: second_question, &amp;quot;chat_history&amp;quot;: chat_history})&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hamnarif&quot;&gt; /u/hamnarif &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19777hm/getting_error_on_chat_history_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19777hm/getting_error_on_chat_history_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19777hm</id><link href="https://www.reddit.com/r/LangChain/comments/19777hm/getting_error_on_chat_history_langchain/" /><updated>2024-01-15T12:05:14+00:00</updated><published>2024-01-15T12:05:14+00:00</published><title>Getting error on chat history langchain. ValueError: variable chat_history should be a list of base messages, got [HumanMessage(content='somthing') '\nAI: retreived text.']</title></entry><entry><author><name>/u/Downtown-Crab271</name><uri>https://www.reddit.com/user/Downtown-Crab271</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What I want to achieve? User can improve code quality and refactoring for give source code repository.&lt;/p&gt; &lt;p&gt;Input - code repository (python, java, dotnet, etc.) Db - chromadb or pinecone Embeddeding - sentence transformer model Top k results - MMR search Key - Azureopnai key n endpoint &lt;/p&gt; &lt;p&gt;Kindly suggest LLM and retrieval in best way if possible. Any link or references from Microsoft is also fine.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Downtown-Crab271&quot;&gt; /u/Downtown-Crab271 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197b58d/need_suggestions_on_code_understanding_by_llm_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/197b58d/need_suggestions_on_code_understanding_by_llm_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_197b58d</id><link href="https://www.reddit.com/r/LangChain/comments/197b58d/need_suggestions_on_code_understanding_by_llm_and/" /><updated>2024-01-15T15:19:16+00:00</updated><published>2024-01-15T15:19:16+00:00</published><title>Need suggestions on code understanding by llm and output.</title></entry><entry><author><name>/u/wilyx11</name><uri>https://www.reddit.com/user/wilyx11</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What is the difference between a similarty search and similarty search with relevancy score?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/wilyx11&quot;&gt; /u/wilyx11 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19795k7/what_is_similarity_search_with_relevancy_score/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19795k7/what_is_similarity_search_with_relevancy_score/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19795k7</id><link href="https://www.reddit.com/r/LangChain/comments/19795k7/what_is_similarity_search_with_relevancy_score/" /><updated>2024-01-15T13:49:40+00:00</updated><published>2024-01-15T13:49:40+00:00</published><title>What is similarity search with relevancy score</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I want to fine-tune a Mistral or Mixtral model on my companies data. Specifically the model should write bullet-points to full texts. I was wondering how the training data has to look like for this task?&lt;/p&gt; &lt;p&gt;Is it a valid way to let a LLM create bullet points out of a text and use these bullet-points-full-text-examples for training? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1973jxk/finetune_mixtral_on_enterprise_data_how_does_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1973jxk/finetune_mixtral_on_enterprise_data_how_does_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1973jxk</id><link href="https://www.reddit.com/r/LangChain/comments/1973jxk/finetune_mixtral_on_enterprise_data_how_does_the/" /><updated>2024-01-15T08:05:19+00:00</updated><published>2024-01-15T08:05:19+00:00</published><title>Finetune Mixtral on Enterprise data - How does the training data should look like?</title></entry><entry><author><name>/u/msze21</name><uri>https://www.reddit.com/user/msze21</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been able to get all other local models, running with Ollama, working with LangChain. However, Yi-34B never returns a response.&lt;/p&gt; &lt;p&gt;I&amp;#39;m running an RTX 3090 and it is fitting in VRAM according to nvtop (20GB used).&lt;/p&gt; &lt;p&gt;Something simple like this never finishes (the last line is the one that never finishes):&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain_community.llms import Ollama ollama_model_name = &amp;quot;yi:34b-chat-q4_K_M&amp;quot; llm = Ollama(model=ollama_model_name, temperature=0.1) llm.invoke(&amp;quot;why is the sky blue?&amp;quot;) # This line never finishes... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I run it directly with Ollama and it responds instantly:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ ollama run yi:34b-chat-q4_K_M &amp;gt;&amp;gt;&amp;gt; why is the sky blue? The sky appears blue to us because of a phenomenon called Rayleigh scattering. This occurs when light from the sun interacts with the molecules of the Earth&amp;#39;s atmosphere, which are composed primarily of nitrogen and oxygen. These molecules are much smaller than the wavelength of visible light, so they can scatter light very efficiently. When sunlight enters the atmosphere, it strikes these atmospheric particles and is scattered in different directions. The shorter wavelengths of blue light are scattered more than longer wavelengths of red light because they have higher energy and thus a greater probability to interact with the molecules. This means that more blue light gets scattered relative to other colors, which is why we see a blue sky most of the time. The intensity of Rayleigh scattering also depends on the angle at which light hits an atmospheric molecule. Scattering is most effective when light hits molecules nearly head-on, which preferentially scatters light in all directions away from the sun. This scattered blue light then reaches our eyes after being scattered multiple times by different air molecules, giving us the perception of a blue sky. The color we see also depends on the observer&amp;#39;s line of sight relative to the sun. When the sun is high in the sky, more blue light scatters directly into our eyes, making the sky appear very blue. As the sun approaches the horizon, the light has to pass through more air and is scattered less efficiently, which means that more red light reaches our eyes, resulting in a reddish sky at sunset and sunrise. Additionally, other factors can influence the color of the sky, such as pollution or dust particles in the atmosphere, which can scatter light differently and change the appearance of the sky. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Any ideas?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/msze21&quot;&gt; /u/msze21 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196vqu3/anyone_have_yi34b_running_with_ollama_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196vqu3/anyone_have_yi34b_running_with_ollama_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_196vqu3</id><link href="https://www.reddit.com/r/LangChain/comments/196vqu3/anyone_have_yi34b_running_with_ollama_with/" /><updated>2024-01-15T01:01:37+00:00</updated><published>2024-01-15T01:01:37+00:00</published><title>Anyone have Yi-34B (running with Ollama) with LangChain working</title></entry><entry><author><name>/u/Secret_Wave6520</name><uri>https://www.reddit.com/user/Secret_Wave6520</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;can i get an invite code for langsmith please , been waiting forever&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Secret_Wave6520&quot;&gt; /u/Secret_Wave6520 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196nq3r/can_i_get_an_invite_code_for_langsmith_please/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196nq3r/can_i_get_an_invite_code_for_langsmith_please/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_196nq3r</id><link href="https://www.reddit.com/r/LangChain/comments/196nq3r/can_i_get_an_invite_code_for_langsmith_please/" /><updated>2024-01-14T19:20:45+00:00</updated><published>2024-01-14T19:20:45+00:00</published><title>can i get an invite code for langsmith please , been waiting forever</title></entry><entry><author><name>/u/R3X_35</name><uri>https://www.reddit.com/user/R3X_35</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have some experience in programming, mostly in nodeJS. Basically I want to create a chatbot that 1. qualifies leads by asking questions 2. answers questions from my knowledge base using RAG. 3. If the user wants to set up an appointment, it extracts the information and stores it in a table. &lt;/p&gt; &lt;p&gt;I want the bot to handle multiple conversations concurrently. &lt;/p&gt; &lt;p&gt;Read through langchain documentation but still confused how to approach this. If you&amp;#39;ve made anything similar, please share some insight!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/R3X_35&quot;&gt; /u/R3X_35 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196uo2k/chatbot_for_potential_customers/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196uo2k/chatbot_for_potential_customers/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_196uo2k</id><link href="https://www.reddit.com/r/LangChain/comments/196uo2k/chatbot_for_potential_customers/" /><updated>2024-01-15T00:11:37+00:00</updated><published>2024-01-15T00:11:37+00:00</published><title>Chatbot for potential customers</title></entry><entry><author><name>/u/wwwy3y3</name><uri>https://www.reddit.com/user/wwwy3y3</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently working on an internal project at my company. My goal is to develop a chat-based solution that allows business users to query the data warehouse (we&amp;#39;re using BigQuery) through conversation. I’m trying to make this project more production-ready, rather than being an experiment. I’m using LangChain and followed guides in documentation &amp;amp; blogs (ex: &lt;a href=&quot;https://python.langchain.com/docs/use_cases/qa_structured/sql&quot;&gt;https://python.langchain.com/docs/use_cases/qa_structured/sql&lt;/a&gt;) to achieve the first version and I could really use some inputs:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Data Privacy and Access Control&lt;/strong&gt;: One of our top priorities is to ensure data privacy and appropriate access controls. Tagging a column like “revenue” to be private might work for simple scenarios, but real-life scenarios are more complex, for example, how do you let users from the marketing department see the “email” column of customers, while others see redacted email? What about row-level security?&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Reviewing Generated SQL Queries&lt;/strong&gt;: Our data analysts have raised concerns about the difficulty in reviewing SQL statements generated by LLMs. These queries can be complex and hard to interpret. Any suggestions for making this process more manageable and transparent? Perhaps a SQL lineage tool to show the visibility of the SQL ?&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Semantic Integration with Database Tables and Columns&lt;/strong&gt;: Lastly, I&amp;#39;m wondering about the best way to integrate semantics into our database tables and columns. Seems that feeding dbt models (including description) directly to the LLM can work at first, but is there any solution that I can let business users define these metadata themselves ? Does it mean I need to build an internal tool that allows users to update the metadata ?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Any feedback, insights, or experiences you can share regarding these challenges are appreciated.&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/wwwy3y3&quot;&gt; /u/wwwy3y3 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196lhv9/seeking_advice_for_developing_a_texttosql/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196lhv9/seeking_advice_for_developing_a_texttosql/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_196lhv9</id><link href="https://www.reddit.com/r/LangChain/comments/196lhv9/seeking_advice_for_developing_a_texttosql/" /><updated>2024-01-14T17:45:49+00:00</updated><published>2024-01-14T17:45:49+00:00</published><title>Seeking advice for developing a text-to-sql application</title></entry><entry><author><name>/u/Fancy-Welcome-9064</name><uri>https://www.reddit.com/user/Fancy-Welcome-9064</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Sorry I am new to langchain. And I found all the examples are OpenAI. But I think the value of langchain is mainly on local llm. Otherwise, why not using GPTs? I’m very curious about it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fancy-Welcome-9064&quot;&gt; /u/Fancy-Welcome-9064 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1966yxv/why_langchain_focuses_on_openai_rather_than_local/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1966yxv/why_langchain_focuses_on_openai_rather_than_local/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1966yxv</id><link href="https://www.reddit.com/r/LangChain/comments/1966yxv/why_langchain_focuses_on_openai_rather_than_local/" /><updated>2024-01-14T04:08:01+00:00</updated><published>2024-01-14T04:08:01+00:00</published><title>Why langchain focuses on OpenAI rather than local llm?</title></entry><entry><author><name>/u/hxh6749</name><uri>https://www.reddit.com/user/hxh6749</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;My employer is doing a Hackathon soon and the focus is on GenAI. Like most orgs, they’ve created a spin off LLM for employee use running on GPT-4 that we can use in our daily tasks (and hackathon practice). There’s a document upload feature where I’ve been providing context about the platform we support (microservices in FinTech) along with a small dataset of information related to successful processing of requests, time taken data, and application error log data for maybe a 15 minute sample and would them prompt it with a question like “Customer XYZ reported some issues at 11:30am, was anything going on?” I’d get a pretty decent response back where it would point out an increase in failed requests and some errors logged around that same time. &lt;/p&gt; &lt;p&gt;My question is how do I expand upon this?&lt;/p&gt; &lt;p&gt;I’m still working on the DataBricks notebook that will pull this data in a consistent format based on the requested time and eventually stream this of some sort. &lt;/p&gt; &lt;p&gt;More so though, it’s the context needed to accurately answer needs applied each time I test a new snippet of data. That lead me to vector databases, HuggingFace models, LangChain, and Faiss. It all feels very overwhelming to logically connect these dots. &lt;/p&gt; &lt;p&gt;Is there an ELI5 of how this would conceptually work regarding the data generated, the context, and answering the prompt?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hxh6749&quot;&gt; /u/hxh6749 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196lcjp/a_vision/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196lcjp/a_vision/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_196lcjp</id><link href="https://www.reddit.com/r/LangChain/comments/196lcjp/a_vision/" /><updated>2024-01-14T17:39:25+00:00</updated><published>2024-01-14T17:39:25+00:00</published><title>A Vision</title></entry><entry><author><name>/u/Fleischkluetensuppe</name><uri>https://www.reddit.com/user/Fleischkluetensuppe</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195qyv6/iteratively_synchronize_git_changes_with_faiss_to/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/OGk4a2JmcWtiOGNjMcdr_-oj80y4bsuac6-ehVUcxyrYyzYeAiBSfRNoFk_T.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fb92b91a18681e7728b385919e96057e49f00ad9&quot; alt=&quot;Iteratively synchronize git changes with faiss to incorporate LLMs for chat and semantic search locally&quot; title=&quot;Iteratively synchronize git changes with faiss to incorporate LLMs for chat and semantic search locally&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fleischkluetensuppe&quot;&gt; /u/Fleischkluetensuppe &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/s1l9iq2gb8cc1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195qyv6/iteratively_synchronize_git_changes_with_faiss_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_195qyv6</id><media:thumbnail url="https://external-preview.redd.it/OGk4a2JmcWtiOGNjMcdr_-oj80y4bsuac6-ehVUcxyrYyzYeAiBSfRNoFk_T.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb92b91a18681e7728b385919e96057e49f00ad9" /><link href="https://www.reddit.com/r/LangChain/comments/195qyv6/iteratively_synchronize_git_changes_with_faiss_to/" /><updated>2024-01-13T15:52:36+00:00</updated><published>2024-01-13T15:52:36+00:00</published><title>Iteratively synchronize git changes with faiss to incorporate LLMs for chat and semantic search locally</title></entry><entry><author><name>/u/Wild-Market9571</name><uri>https://www.reddit.com/user/Wild-Market9571</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m utilizing Cohere AI for a project, and I have a text file that I want to embed. While I&amp;#39;m aware that Langchain has chunking functions, I believe Tiktoken might be more effective. However, I&amp;#39;m unsure about how Tiktoken works or if it would be suitable for Cohere.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Wild-Market9571&quot;&gt; /u/Wild-Market9571 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195yneb/optimizing_text_embedding_for_cohere_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195yneb/optimizing_text_embedding_for_cohere_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_195yneb</id><link href="https://www.reddit.com/r/LangChain/comments/195yneb/optimizing_text_embedding_for_cohere_ai/" /><updated>2024-01-13T21:26:47+00:00</updated><published>2024-01-13T21:26:47+00:00</published><title>Optimizing Text Embedding for Cohere AI</title></entry><entry><author><name>/u/Overall-Charity-4896</name><uri>https://www.reddit.com/user/Overall-Charity-4896</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks, &lt;/p&gt; &lt;p&gt;I&amp;#39;ve been pondering the process of embedding in a RAG app using various models. When examining examples, I noticed that some models (the most popular ones) include their embeddings. However, if I want to perform embedding with a different foundation model or an instructive one, what&amp;#39;s the procedure? Do I need to extract the truncated version of the LLM to create the embedding model, or is there a process I&amp;#39;m not familiar with? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Overall-Charity-4896&quot;&gt; /u/Overall-Charity-4896 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195rest/mastering_rag_app_embedding_with_custom_models/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195rest/mastering_rag_app_embedding_with_custom_models/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_195rest</id><link href="https://www.reddit.com/r/LangChain/comments/195rest/mastering_rag_app_embedding_with_custom_models/" /><updated>2024-01-13T16:11:52+00:00</updated><published>2024-01-13T16:11:52+00:00</published><title>Mastering RAG App Embedding with Custom Models</title></entry><entry><author><name>/u/iceburg51</name><uri>https://www.reddit.com/user/iceburg51</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello LLM enthusiasts! I&amp;#39;m eager to hear about the creative and innovative ways you&amp;#39;ve been using Large Language Models (LLMs) in your projects. Lang Chain, has been a game-changer in bringing these applications from the drawing board to real-world use. Have you developed something unique, solved a complex problem, or simply experimented with something fun? Let&amp;#39;s inspire each other by sharing our experiences and discussing how Lang Chain has facilitated our journey with LLMs!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/iceburg51&quot;&gt; /u/iceburg51 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1958znq/show_and_tell_what_have_you_built_with_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1958znq/show_and_tell_what_have_you_built_with_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1958znq</id><link href="https://www.reddit.com/r/LangChain/comments/1958znq/show_and_tell_what_have_you_built_with_llms/" /><updated>2024-01-12T23:19:55+00:00</updated><published>2024-01-12T23:19:55+00:00</published><title>Show and Tell: What have you built with LLMs?</title></entry><entry><author><name>/u/VarietyElderberry</name><uri>https://www.reddit.com/user/VarietyElderberry</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am surprised to see many posts like &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193oz8b/holy_f_i_have_never_seen_such_spaghetti_code_in/&quot;&gt;this one&lt;/a&gt;, or &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18eukhc/i_just_had_the_displeasure_of_implementing/&quot;&gt;this one&lt;/a&gt;, expressing negative sentiments about LangChain and in particular the agreement about the negativity in the comment section. For a community that comes together for the LangChain package and ecosystem, there seems to be a surprising amount of people that don&amp;#39;t like it. The advice given is often to not use LangChain at all.&lt;/p&gt; &lt;p&gt;Personally, I have been impressed by the developer&amp;#39;s willingness to listen to the community, and would expect this to lead to a positive mindset in the community. For example the introduction of LCEL is an attempt to improve the code quality and reduce the complexity of applications build with LangChain. However, &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18t3jn9/do_we_really_need_lcel/&quot;&gt;the community does not seem to see its value&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;While I understand some of the criticism, I don&amp;#39;t believe the amount of negativity is justified. Moreover, it seems there is little willingness for constructive feedback that could be used to improve the situation. This post is a plea to improve this mindset for the betterment of the LangChain ecosystem and the community that uses it. With LangChain having just released version 0.1, I think this is a good moment in time for this community to reflect on what it expects from LangChain going forward. Let me know what you think.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/VarietyElderberry&quot;&gt; /u/VarietyElderberry &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194u376/lets_dicsuss_this_subs_negative_feelings_towards/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194u376/lets_dicsuss_this_subs_negative_feelings_towards/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_194u376</id><link href="https://www.reddit.com/r/LangChain/comments/194u376/lets_dicsuss_this_subs_negative_feelings_towards/" /><updated>2024-01-12T12:39:18+00:00</updated><published>2024-01-12T12:39:18+00:00</published><title>Let's dicsuss this sub's negative feelings towards LangChain</title></entry><entry><author><name>/u/danipudani</name><uri>https://www.reddit.com/user/danipudani</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195392c/intro_to_langchain_full_documentation_overview/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/sVTHLyvfg970cr9MD_72wQqkiADi53dPj4mMz7rqK4w.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=362f231282720dbda6fe4de5188bd10440805d1e&quot; alt=&quot;Intro to LangChain - Full Documentation Overview&quot; title=&quot;Intro to LangChain - Full Documentation Overview&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/danipudani&quot;&gt; /u/danipudani &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/dXP841pBcJw?si=V03bfGxR0E2DVOA8&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195392c/intro_to_langchain_full_documentation_overview/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_195392c</id><media:thumbnail url="https://external-preview.redd.it/sVTHLyvfg970cr9MD_72wQqkiADi53dPj4mMz7rqK4w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=362f231282720dbda6fe4de5188bd10440805d1e" /><link href="https://www.reddit.com/r/LangChain/comments/195392c/intro_to_langchain_full_documentation_overview/" /><updated>2024-01-12T19:19:37+00:00</updated><published>2024-01-12T19:19:37+00:00</published><title>Intro to LangChain - Full Documentation Overview</title></entry><entry><author><name>/u/MysteriousApricot991</name><uri>https://www.reddit.com/user/MysteriousApricot991</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am new to langchain. Can someone please explain to me how to use hugging face models like Microsoft phi-2 with langchain? The official documentation talks about openAI and other inference API based LLMs but how about locally running models?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MysteriousApricot991&quot;&gt; /u/MysteriousApricot991 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1954q8y/langchain_with_hugging_face_models/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1954q8y/langchain_with_hugging_face_models/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1954q8y</id><link href="https://www.reddit.com/r/LangChain/comments/1954q8y/langchain_with_hugging_face_models/" /><updated>2024-01-12T20:20:36+00:00</updated><published>2024-01-12T20:20:36+00:00</published><title>Langchain with Hugging face models</title></entry><entry><author><name>/u/qa_anaaq</name><uri>https://www.reddit.com/user/qa_anaaq</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi. I&amp;#39;m tasked with building a chatbot for work. We are an HR tech company. &lt;/p&gt; &lt;p&gt;I&amp;#39;m using Retrieval QA, trying different chunking sizes, testing both Pinecone and Supabase for vector Retrieval. &lt;/p&gt; &lt;p&gt;However, I&amp;#39;m of the opinion that our data sucks. Our API docs have like 50 words per page at most, and there are maybe 30 pages. We have a lot of support tickets, like 500, but only 20% have actual answers written out to the ticket reason. So I get maybe 20-50 words per useable ticket. Lastly, our community sourced internal documentation is fragmentation and inconsistently designed. &lt;/p&gt; &lt;p&gt;I&amp;#39;ve engineered all the text into consistent structures. The purpose is Q/A, like &amp;quot;If a user is complaining X isn&amp;#39;t working in their dashboard, what might be the cause?&amp;quot;&lt;/p&gt; &lt;p&gt;But is there anything realistic I can do with this situation when the data is so low volume and poor quality? Any technical approaches that don&amp;#39;t require a manual documentation overhaul, that is. &lt;/p&gt; &lt;p&gt;Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/qa_anaaq&quot;&gt; /u/qa_anaaq &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1957t7r/trying_to_solve_for_bad_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1957t7r/trying_to_solve_for_bad_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1957t7r</id><link href="https://www.reddit.com/r/LangChain/comments/1957t7r/trying_to_solve_for_bad_data/" /><updated>2024-01-12T22:30:31+00:00</updated><published>2024-01-12T22:30:31+00:00</published><title>Trying to solve for bad data</title></entry></feed>