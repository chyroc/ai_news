<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-22T21:18:13+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/shardblaster</name><uri>https://www.reddit.com/user/shardblaster</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I was checking out the function calling capability of the new Mistral model and was wondering how to integrate this into a ReAct agent flow that uses AgentExecutor. &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3&quot;&gt;https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Anyone got any hints? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/shardblaster&quot;&gt; /u/shardblaster &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy9zxh/chatcompletionrequest_in_agentexecutor/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy9zxh/chatcompletionrequest_in_agentexecutor/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cy9zxh</id><link href="https://www.reddit.com/r/LangChain/comments/1cy9zxh/chatcompletionrequest_in_agentexecutor/" /><updated>2024-05-22T20:09:42+00:00</updated><published>2024-05-22T20:09:42+00:00</published><title>ChatCompletionRequest in AgentExecutor</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy8w14/chat_with_your_csv_using_duckdb_and_vannaai/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/-gzuU1y9GWL058um9nTBzoVDwIEuu-YHXn6UnGV80IY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8ea6756e3c6a5be354553fbbc5c4e63d96bdce6d&quot; alt=&quot;Chat with your CSV using DuckDB and Vanna.ai&quot; title=&quot;Chat with your CSV using DuckDB and Vanna.ai&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://arslanshahid-1997.medium.com/chat-with-your-csv-using-duckdb-and-vanna-ai-a5cef3762261&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy8w14/chat_with_your_csv_using_duckdb_and_vannaai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cy8w14</id><media:thumbnail url="https://external-preview.redd.it/-gzuU1y9GWL058um9nTBzoVDwIEuu-YHXn6UnGV80IY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8ea6756e3c6a5be354553fbbc5c4e63d96bdce6d" /><link href="https://www.reddit.com/r/LangChain/comments/1cy8w14/chat_with_your_csv_using_duckdb_and_vannaai/" /><updated>2024-05-22T19:24:33+00:00</updated><published>2024-05-22T19:24:33+00:00</published><title>Chat with your CSV using DuckDB and Vanna.ai</title></entry><entry><author><name>/u/ur_nightmare69</name><uri>https://www.reddit.com/user/ur_nightmare69</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, &lt;/p&gt; &lt;p&gt;I am an engineering student currently doing my end of studies internship, and I am working on a project that involves RAG system using LLM for my company and my mission now is to evaluate and test different parameters in the process of retrieving and generating like evaluating the embeddings , the different LLM models etc, to finally choose what&amp;#39;s best to use. So, while doing my researches I found Langsmith and few others I want to know if some of you used one of these platforms and how was your experience and which one do you prefer and why .&lt;/p&gt; &lt;p&gt;Your feedback will greatly assist me in my work and research so if you have any information feel free to share it .&lt;/p&gt; &lt;p&gt;THANK YOU&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ur_nightmare69&quot;&gt; /u/ur_nightmare69 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy83us/testing_and_evaluating_llm_rag_systems/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy83us/testing_and_evaluating_llm_rag_systems/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cy83us</id><link href="https://www.reddit.com/r/LangChain/comments/1cy83us/testing_and_evaluating_llm_rag_systems/" /><updated>2024-05-22T18:52:59+00:00</updated><published>2024-05-22T18:52:59+00:00</published><title>Testing And Evaluating LLM RAG Systems</title></entry><entry><author><name>/u/Mohseen365</name><uri>https://www.reddit.com/user/Mohseen365</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m a software developer who&amp;#39;s learned about Gen AI stuff (Langchain, LLM, RAG, Agents,etc), and copywriting. Now I&amp;#39;m combining all these skills and looking for career advice or anyone going through the same thing and wants to connect&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mohseen365&quot;&gt; /u/Mohseen365 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy24vw/career_advice_for_software_development_gen_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy24vw/career_advice_for_software_development_gen_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cy24vw</id><link href="https://www.reddit.com/r/LangChain/comments/1cy24vw/career_advice_for_software_development_gen_ai/" /><updated>2024-05-22T14:51:40+00:00</updated><published>2024-05-22T14:51:40+00:00</published><title>Career Advice for Software Development + Gen AI + Copywriting skills</title></entry><entry><author><name>/u/Thegunsmith98</name><uri>https://www.reddit.com/user/Thegunsmith98</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;As the title suggests I want to perform EDA using Langchain on a large dataframe. Im currently using Pandas Dataframe Agent , however it is not that efficent when using with large datasets. Can someone please suggest an alternative that works well. Thankyou &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Thegunsmith98&quot;&gt; /u/Thegunsmith98 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy29kb/any_way_to_make_a_chatbot_that_does_eda_on_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy29kb/any_way_to_make_a_chatbot_that_does_eda_on_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cy29kb</id><link href="https://www.reddit.com/r/LangChain/comments/1cy29kb/any_way_to_make_a_chatbot_that_does_eda_on_a/" /><updated>2024-05-22T14:57:17+00:00</updated><published>2024-05-22T14:57:17+00:00</published><title>Any way to make a Chatbot that does EDA on a large dataframe similar to Pandas Dataframe Agent.</title></entry><entry><author><name>/u/cr33dcode</name><uri>https://www.reddit.com/user/cr33dcode</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have 100 PDFs that I need to index and make a report of every single week. I need a rag to help me get the info from the PDFs in a neat manner but also pull up the images and the PDF associated with the query. I needed the text to be highlighted as well and the pg numbers. &lt;/p&gt; &lt;p&gt;can someone please guide me with the stack? im thinking langchain and memgraph for DB but more tools and options and stack? thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cr33dcode&quot;&gt; /u/cr33dcode &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy1w8q/i_want_to_build_a_graph_rag_with_document/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cy1w8q/i_want_to_build_a_graph_rag_with_document/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cy1w8q</id><link href="https://www.reddit.com/r/LangChain/comments/1cy1w8q/i_want_to_build_a_graph_rag_with_document/" /><updated>2024-05-22T14:41:12+00:00</updated><published>2024-05-22T14:41:12+00:00</published><title>I want to build a graph rag with document browsing capability of the PDF its referencing from.</title></entry><entry><author><name>/u/wahnsinnwanscene</name><uri>https://www.reddit.com/user/wahnsinnwanscene</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What is everyone using to extract the KG from unstructured data and into which database? For a local setup.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/wahnsinnwanscene&quot;&gt; /u/wahnsinnwanscene &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxqa3f/knowledge_graph_generation_and_database/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxqa3f/knowledge_graph_generation_and_database/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cxqa3f</id><link href="https://www.reddit.com/r/LangChain/comments/1cxqa3f/knowledge_graph_generation_and_database/" /><updated>2024-05-22T03:04:08+00:00</updated><published>2024-05-22T03:04:08+00:00</published><title>Knowledge graph generation and database</title></entry><entry><author><name>/u/pratham1443</name><uri>https://www.reddit.com/user/pratham1443</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to parse the LLM output to a particular JSON Schema But I am getting this error&lt;/p&gt; &lt;pre&gt;&lt;code&gt;{ &amp;quot;name&amp;quot;: &amp;quot;ValidationError&amp;quot;, &amp;quot;message&amp;quot;: &amp;quot;1 validation error for Generation text str type expected (type=type_error.str)&amp;quot;, &amp;quot;stack&amp;quot;: &amp;quot;--------------------------------------------------------------------------- ValidationError Traceback (most recent call last) /Users/pratham/LLMApi/pd_agent/ExcelParser.py in line 1 ----&amp;gt; &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/pd_agent/ExcelParser.py?line=167&amp;#39;&amp;gt;168&amp;lt;/a&amp;gt; top_rows = get_top_rows(doc_df, ChatOpenAI(model=\&amp;quot;gpt-3.5-turbo\&amp;quot;, temperature=0)) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/pd_agent/ExcelParser.py?line=168&amp;#39;&amp;gt;169&amp;lt;/a&amp;gt; top_rows /Users/pratham/LLMApi/pd_agent/ExcelParser.py in line 13, in get_top_rows(df, llm) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/pd_agent/ExcelParser.py?line=45&amp;#39;&amp;gt;46&amp;lt;/a&amp;gt; print(parser.get_format_instructions()) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/pd_agent/ExcelParser.py?line=46&amp;#39;&amp;gt;47&amp;lt;/a&amp;gt; chain = prompt | df_agent | parser ---&amp;gt; &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/pd_agent/ExcelParser.py?line=47&amp;#39;&amp;gt;48&amp;lt;/a&amp;gt; json_output = chain.invoke( &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/pd_agent/ExcelParser.py?line=48&amp;#39;&amp;gt;49&amp;lt;/a&amp;gt; { &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/pd_agent/ExcelParser.py?line=49&amp;#39;&amp;gt;50&amp;lt;/a&amp;gt; \&amp;quot;format_instructions\&amp;quot;: parser.get_format_instructions() &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/pd_agent/ExcelParser.py?line=50&amp;#39;&amp;gt;51&amp;lt;/a&amp;gt; } &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/pd_agent/ExcelParser.py?line=51&amp;#39;&amp;gt;52&amp;lt;/a&amp;gt; ) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/pd_agent/ExcelParser.py?line=52&amp;#39;&amp;gt;53&amp;lt;/a&amp;gt; return json_output[\&amp;quot;number_of_top_rows\&amp;quot;] File ~/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2499, in RunnableSequence.invoke(self, input, config) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2496&amp;#39;&amp;gt;2497&amp;lt;/a&amp;gt; try: &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2497&amp;#39;&amp;gt;2498&amp;lt;/a&amp;gt; for i, step in enumerate(self.steps): -&amp;gt; &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2498&amp;#39;&amp;gt;2499&amp;lt;/a&amp;gt; input = step.invoke( &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2499&amp;#39;&amp;gt;2500&amp;lt;/a&amp;gt; input, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2500&amp;#39;&amp;gt;2501&amp;lt;/a&amp;gt; # mark each step as a child run &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2501&amp;#39;&amp;gt;2502&amp;lt;/a&amp;gt; patch_config( &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2502&amp;#39;&amp;gt;2503&amp;lt;/a&amp;gt; config, callbacks=run_manager.get_child(f\&amp;quot;seq:step:{i+1}\&amp;quot;) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2503&amp;#39;&amp;gt;2504&amp;lt;/a&amp;gt; ), &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2504&amp;#39;&amp;gt;2505&amp;lt;/a&amp;gt; ) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2505&amp;#39;&amp;gt;2506&amp;lt;/a&amp;gt; # finish the root run &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=2506&amp;#39;&amp;gt;2507&amp;lt;/a&amp;gt; except BaseException as e: File ~/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py:178, in BaseOutputParser.invoke(self, input, config) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=168&amp;#39;&amp;gt;169&amp;lt;/a&amp;gt; return self._call_with_config( &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=169&amp;#39;&amp;gt;170&amp;lt;/a&amp;gt; lambda inner_input: self.parse_result( &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=170&amp;#39;&amp;gt;171&amp;lt;/a&amp;gt; [ChatGeneration(message=inner_input)] (...) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=174&amp;#39;&amp;gt;175&amp;lt;/a&amp;gt; run_type=\&amp;quot;parser\&amp;quot;, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=175&amp;#39;&amp;gt;176&amp;lt;/a&amp;gt; ) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=176&amp;#39;&amp;gt;177&amp;lt;/a&amp;gt; else: --&amp;gt; &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=177&amp;#39;&amp;gt;178&amp;lt;/a&amp;gt; return self._call_with_config( &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=178&amp;#39;&amp;gt;179&amp;lt;/a&amp;gt; lambda inner_input: self.parse_result([Generation(text=inner_input)]), &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=179&amp;#39;&amp;gt;180&amp;lt;/a&amp;gt; input, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=180&amp;#39;&amp;gt;181&amp;lt;/a&amp;gt; config, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=181&amp;#39;&amp;gt;182&amp;lt;/a&amp;gt; run_type=\&amp;quot;parser\&amp;quot;, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=182&amp;#39;&amp;gt;183&amp;lt;/a&amp;gt; ) File ~/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:1626, in Runnable._call_with_config(self, func, input, config, run_type, **kwargs) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1621&amp;#39;&amp;gt;1622&amp;lt;/a&amp;gt; context = copy_context() &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1622&amp;#39;&amp;gt;1623&amp;lt;/a&amp;gt; context.run(var_child_runnable_config.set, child_config) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1623&amp;#39;&amp;gt;1624&amp;lt;/a&amp;gt; output = cast( &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1624&amp;#39;&amp;gt;1625&amp;lt;/a&amp;gt; Output, -&amp;gt; &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1625&amp;#39;&amp;gt;1626&amp;lt;/a&amp;gt; context.run( &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1626&amp;#39;&amp;gt;1627&amp;lt;/a&amp;gt; call_func_with_variable_args, # type: ignore[arg-type] &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1627&amp;#39;&amp;gt;1628&amp;lt;/a&amp;gt; func, # type: ignore[arg-type] &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1628&amp;#39;&amp;gt;1629&amp;lt;/a&amp;gt; input, # type: ignore[arg-type] &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1629&amp;#39;&amp;gt;1630&amp;lt;/a&amp;gt; config, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1630&amp;#39;&amp;gt;1631&amp;lt;/a&amp;gt; run_manager, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1631&amp;#39;&amp;gt;1632&amp;lt;/a&amp;gt; **kwargs, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1632&amp;#39;&amp;gt;1633&amp;lt;/a&amp;gt; ), &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1633&amp;#39;&amp;gt;1634&amp;lt;/a&amp;gt; ) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1634&amp;#39;&amp;gt;1635&amp;lt;/a&amp;gt; except BaseException as e: &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py?line=1635&amp;#39;&amp;gt;1636&amp;lt;/a&amp;gt; run_manager.on_chain_error(e) File ~/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:347, in call_func_with_variable_args(func, input, config, run_manager, **kwargs) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/config.py?line=344&amp;#39;&amp;gt;345&amp;lt;/a&amp;gt; if run_manager is not None and accepts_run_manager(func): &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/config.py?line=345&amp;#39;&amp;gt;346&amp;lt;/a&amp;gt; kwargs[\&amp;quot;run_manager\&amp;quot;] = run_manager --&amp;gt; &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/runnables/config.py?line=346&amp;#39;&amp;gt;347&amp;lt;/a&amp;gt; return func(input, **kwargs) File ~/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py:179, in BaseOutputParser.invoke.&amp;lt;locals&amp;gt;.&amp;lt;lambda&amp;gt;(inner_input) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=168&amp;#39;&amp;gt;169&amp;lt;/a&amp;gt; return self._call_with_config( &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=169&amp;#39;&amp;gt;170&amp;lt;/a&amp;gt; lambda inner_input: self.parse_result( &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=170&amp;#39;&amp;gt;171&amp;lt;/a&amp;gt; [ChatGeneration(message=inner_input)] (...) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=174&amp;#39;&amp;gt;175&amp;lt;/a&amp;gt; run_type=\&amp;quot;parser\&amp;quot;, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=175&amp;#39;&amp;gt;176&amp;lt;/a&amp;gt; ) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=176&amp;#39;&amp;gt;177&amp;lt;/a&amp;gt; else: &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=177&amp;#39;&amp;gt;178&amp;lt;/a&amp;gt; return self._call_with_config( --&amp;gt; &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=178&amp;#39;&amp;gt;179&amp;lt;/a&amp;gt; lambda inner_input: self.parse_result([Generation(text=inner_input)]), &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=179&amp;#39;&amp;gt;180&amp;lt;/a&amp;gt; input, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=180&amp;#39;&amp;gt;181&amp;lt;/a&amp;gt; config, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=181&amp;#39;&amp;gt;182&amp;lt;/a&amp;gt; run_type=\&amp;quot;parser\&amp;quot;, &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py?line=182&amp;#39;&amp;gt;183&amp;lt;/a&amp;gt; ) File ~/LLMApi/venv/lib/python3.12/site-packages/pydantic/main.py:341, in BaseModel.__init__(__pydantic_self__, **data) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/pydantic/main.py?line=338&amp;#39;&amp;gt;339&amp;lt;/a&amp;gt; values, fields_set, validation_error = validate_model(__pydantic_self__.__class__, data) &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/pydantic/main.py?line=339&amp;#39;&amp;gt;340&amp;lt;/a&amp;gt; if validation_error: --&amp;gt; &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/pydantic/main.py?line=340&amp;#39;&amp;gt;341&amp;lt;/a&amp;gt; raise validation_error &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/pydantic/main.py?line=341&amp;#39;&amp;gt;342&amp;lt;/a&amp;gt; try: &amp;lt;a href=&amp;#39;file:///Users/pratham/LLMApi/venv/lib/python3.12/site-packages/pydantic/main.py?line=342&amp;#39;&amp;gt;343&amp;lt;/a&amp;gt; object_setattr(__pydantic_self__, &amp;#39;__dict__&amp;#39;, values) ValidationError: 1 validation error for Generation text str type expected (type=type_error.str)&amp;quot; } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Agent Output:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Entering new AgentExecutor chain...&lt;br/&gt; {&lt;br/&gt; &amp;quot;number_of_top_rows&amp;quot;: &amp;quot;2&amp;quot;&lt;br/&gt; }&lt;/p&gt; &lt;p&gt;Finished chain.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Pydantic Object:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;class NumberofTopRows(BaseModel): number_of_top_rows: str = Field(description=&amp;quot;Number of top rows of the dataframe that should be header rows as string datatype&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This works fine for other schemas but not for this one. I am unable to figure out what is the problem. Has anyone faced similar issue? Please help in resolving this error.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pratham1443&quot;&gt; /u/pratham1443 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxxvvc/json_output_parser_error_please_help/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxxvvc/json_output_parser_error_please_help/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cxxvvc</id><link href="https://www.reddit.com/r/LangChain/comments/1cxxvvc/json_output_parser_error_please_help/" /><updated>2024-05-22T11:25:59+00:00</updated><published>2024-05-22T11:25:59+00:00</published><title>JSON Output Parser Error Please help!</title></entry><entry><author><name>/u/Zheng_SJ</name><uri>https://www.reddit.com/user/Zheng_SJ</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi! I am working on a project called Pluto, which is a cloud-native application development tool. It simplifies cloud application development by providing a streamlined programming interface for leveraging cloud features and building business logic. Developers can define their dependent services and resources, such as Lambda, Bucket, and etc. by defining a variable. Pluto will automatically provision the resources and deploy the application to the cloud. Developer use the Pluto without need to learn complex cloud technologies, such as Terraform, Pulumi or AWS CDK.&lt;/p&gt; &lt;p&gt;To help the LangServe app developers that don&amp;#39;t have much experience with cloud to deploy their apps on the cloud, I&amp;#39;d like to introduce Pluto as a potential option for deploying LangServe apps.&lt;/p&gt; &lt;p&gt;In summary, there are two steps to adapt the LangServe application to the Pluto application so that Pluto can deploy it to AWS.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;First, put the code related to the FastAPI app into a function and make this function return the FastAPI app instance. Here we assume that the function name is &lt;code&gt;return_fastapi_app&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Then, replace the entire if &lt;code&gt;__name__ == &amp;quot;__main__&amp;quot;&lt;/code&gt; code block with the following 4 statements. The &lt;code&gt;router_name&lt;/code&gt; can be modified. It is related to the name of the Api Gateway instance created on AWS.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;```python from mangum import Mangum from pluto_client import Router&lt;/p&gt; &lt;p&gt;router = Router(&amp;quot;router_name&amp;quot;) router.all(&amp;quot;/&lt;em&gt;&amp;quot;, lambda *args, *&lt;/em&gt;kwargs: Mangum(return_fastapi_app(), api_gateway_base_path=&amp;quot;/dev&amp;quot;)(&lt;em&gt;args, *&lt;/em&gt;kwargs), raw=True) ```&lt;/p&gt; &lt;p&gt;For more information, please refer to &lt;a href=&quot;https://pluto-lang.vercel.app/cookbook/deploy-langserve-to-aws&quot;&gt;this link&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I&amp;#39;m not entirely sure if this is an optimal interface for developing LangServe applications. Do you believe it&amp;#39;s an effective method for LangServe app developers to deploy their applications in the cloud? I would appreciate any suggestions or queries that you might have. Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zheng_SJ&quot;&gt; /u/Zheng_SJ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxuc3g/rfc_introduce_pluto_as_a_deployment_option_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxuc3g/rfc_introduce_pluto_as_a_deployment_option_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cxuc3g</id><link href="https://www.reddit.com/r/LangChain/comments/1cxuc3g/rfc_introduce_pluto_as_a_deployment_option_for/" /><updated>2024-05-22T07:15:42+00:00</updated><published>2024-05-22T07:15:42+00:00</published><title>[RFC] Introduce Pluto as a deployment option for LangServe apps</title></entry><entry><author><name>/u/Whole_Reference_96</name><uri>https://www.reddit.com/user/Whole_Reference_96</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Title says pretty much. By agent I mean the concept, not exclusively langchain agent. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Whole_Reference_96&quot;&gt; /u/Whole_Reference_96 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxkl24/are_multi_agents_systems_also_meant_to_be_used_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxkl24/are_multi_agents_systems_also_meant_to_be_used_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cxkl24</id><link href="https://www.reddit.com/r/LangChain/comments/1cxkl24/are_multi_agents_systems_also_meant_to_be_used_in/" /><updated>2024-05-21T22:21:18+00:00</updated><published>2024-05-21T22:21:18+00:00</published><title>Are multi agents systems also meant to be used in chatbots with continuous conversation?</title></entry><entry><author><name>/u/Annie_Loves_Money</name><uri>https://www.reddit.com/user/Annie_Loves_Money</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Annie_Loves_Money&quot;&gt; /u/Annie_Loves_Money &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/aipromptprogramming/comments/1cxsuz7/how_do_i_create_a_structured_data_workflow_for_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxswai/how_do_i_create_a_structured_data_workflow_for_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cxswai</id><link href="https://www.reddit.com/r/LangChain/comments/1cxswai/how_do_i_create_a_structured_data_workflow_for_a/" /><updated>2024-05-22T05:38:24+00:00</updated><published>2024-05-22T05:38:24+00:00</published><title>How do I create a structured data workflow for a Topic-wise article summarizer?</title></entry><entry><author><name>/u/Ancient-Analysis2909</name><uri>https://www.reddit.com/user/Ancient-Analysis2909</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone! I&amp;#39;m working in educational research, specifically using large language models (LLMs) to determine if questions require collaboration between students (like if I give different info to Student A and Student B, and they need to work together to answer). I&amp;#39;ve been running several LLMs on various questions and now I&amp;#39;m planning to use DSPy to tweak the prompts to hopefully get better accuracy. I can handle the basic DSPy stuff, but I&amp;#39;m stumped on how it actually improves the prompts. I get that prompts with higher metric scores are supposed to be better, but what&amp;#39;s the actual strategy DSPy uses to enhance them?&lt;/p&gt; &lt;p&gt;Also, my questions often go beyond simple Q&amp;amp;A—they can get pretty lengthy. Do you think DSPy is suitable for this kind of complex scenario? Any advice would be super helpful. Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ancient-Analysis2909&quot;&gt; /u/Ancient-Analysis2909 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxo55v/how_dspy_tuning_the_prompts/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxo55v/how_dspy_tuning_the_prompts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cxo55v</id><link href="https://www.reddit.com/r/LangChain/comments/1cxo55v/how_dspy_tuning_the_prompts/" /><updated>2024-05-22T01:12:00+00:00</updated><published>2024-05-22T01:12:00+00:00</published><title>How DSPy tuning the prompts?</title></entry><entry><author><name>/u/Sebstian76</name><uri>https://www.reddit.com/user/Sebstian76</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Trying to create a Langchain v1 app with Gemini 1.5 but have hit a wall and can&amp;#39;t even get a hello world running. I can&amp;#39;t find ANY useful information anywhere and the only thing I can get working is vertex AI&amp;#39;s API, which is rudimentary wrt to pydantic etc. plus I won&amp;#39;t be able to migrate to other models later on. &lt;/p&gt; &lt;p&gt;What do you guys do? Any hints, tricks and links are warmly received.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sebstian76&quot;&gt; /u/Sebstian76 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxl70h/is_langchain_gemini_15_even_possible_with_python/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxl70h/is_langchain_gemini_15_even_possible_with_python/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cxl70h</id><link href="https://www.reddit.com/r/LangChain/comments/1cxl70h/is_langchain_gemini_15_even_possible_with_python/" /><updated>2024-05-21T22:49:04+00:00</updated><published>2024-05-21T22:49:04+00:00</published><title>Is Langchain + Gemini 1.5 even possible (with python)?</title></entry><entry><author><name>/u/cyyeh</name><uri>https://www.reddit.com/user/cyyeh</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I would like to ask what are your experience in doing prompt optimization/automation when designing ai pipelines? In my experience, if your pipeline is composed of large enough number of LLMs, that means it’s getting harder to manually creat prompts that make the system work. What’s worse is that you even cannot predict and control how the system might suddenly break or have worse performance if you change any of the prompts! I’ve played around with DSPy a few weeks before; however, I am not sure if it can really help me in the real world use case? Or do you have other tools that can recommend to me? Thanks for kindly sharing your thoughts on the topic!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cyyeh&quot;&gt; /u/cyyeh &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxcln7/llm_prompt_optimization/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxcln7/llm_prompt_optimization/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cxcln7</id><link href="https://www.reddit.com/r/LangChain/comments/1cxcln7/llm_prompt_optimization/" /><updated>2024-05-21T16:51:29+00:00</updated><published>2024-05-21T16:51:29+00:00</published><title>LLM prompt optimization</title></entry><entry><author><name>/u/nocodeblackbox</name><uri>https://www.reddit.com/user/nocodeblackbox</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all, i&amp;#39;ve seen some mention&amp;#39;s around here briefly about comparing LangChain&amp;#39;s tooling (or even just building out your retrieval models yourself by removing abstractions) to the current state of assistant&amp;#39;s API (w/ v2)&lt;/p&gt; &lt;p&gt;At the time of release I could see why more leaned towards langhain&amp;#39;s framework, but with the recent advancements of assistant&amp;#39;s api (v2), including improved retrieval systems, new vector stores, as well as function calling via tool_choice. I&amp;#39;m really considering using their endpoint for a new project considering costs, latency, and retrieval system&amp;#39;s will get better over time.&lt;/p&gt; &lt;p&gt;I used LangChain&amp;#39;s Js framework when it first came out, and we sort of transitioned to creating our own functions to avoid some of the abstraction layers, but now it almost seems archaic to build your own. At least for the majority of use-cases I see. And of course, I could see cost as a factor here, considering assistants is significantly more expensive, especially if you&amp;#39;re using code interpreter, but you also have to consider the opportunity cost you&amp;#39;d save not building out your own tooling system. Definetly a cost trade-off to consider here for firms (and not just dev&amp;#39;s building their own projects).&lt;/p&gt; &lt;p&gt;So user&amp;#39;s of OpenAI model&amp;#39;s, I&amp;#39;d love to learn why you went one route or the other for some projects. Is it cost? quality of responses? latency? or just don&amp;#39;t like the idea of being vendor-locked to an api? All idea&amp;#39;s/statements are welcome. Genuinely trying to learn here.&lt;/p&gt; &lt;p&gt;EDIT/TLDR: It seems like from a lot of the comment&amp;#39;s below, assistant&amp;#39;s is the way for more production grade LLMs and less tinkering. The reduced dev effort may be worth the cost trade-off for a company to make the system more light-weight. May be different scenario if you&amp;#39;re building the project yourself and what additional tooling that LangChain Provides&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nocodeblackbox&quot;&gt; /u/nocodeblackbox &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1ln4/langchain_framework_vs_new_assistants_api_with_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1ln4/langchain_framework_vs_new_assistants_api_with_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx1ln4</id><link href="https://www.reddit.com/r/LangChain/comments/1cx1ln4/langchain_framework_vs_new_assistants_api_with_rag/" /><updated>2024-05-21T06:51:41+00:00</updated><published>2024-05-21T06:51:41+00:00</published><title>LangChain Framework vs New Assistants API with RAG</title></entry><entry><author><name>/u/lambdalife</name><uri>https://www.reddit.com/user/lambdalife</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Every langgraph example I&amp;#39;ve seen so far uses a tool interface to facilitate switching between nodes in the graph. AWS Bedrock doesn&amp;#39;t yet fully support Anthropic&amp;#39;s beta tool calling APIs. Conceptually or practically speaking, how might one make, for example, a supervisor agent that delegates work to other nodes - &lt;em&gt;without tool-calling&lt;/em&gt;?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/lambdalife&quot;&gt; /u/lambdalife &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx9jpu/conceptual_question_is_langgraphs_utility/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx9jpu/conceptual_question_is_langgraphs_utility/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx9jpu</id><link href="https://www.reddit.com/r/LangChain/comments/1cx9jpu/conceptual_question_is_langgraphs_utility/" /><updated>2024-05-21T14:42:23+00:00</updated><published>2024-05-21T14:42:23+00:00</published><title>Conceptual question - is LangGraph's utility dependent on the ability to call tools?</title></entry><entry><author><name>/u/alcatraz0411</name><uri>https://www.reddit.com/user/alcatraz0411</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey All, I’m looking for recommendations on courses/tutorials/materials in order to gain some understanding of the Framework and get some hands on under my belt. The ones on youtube are not very in-depth, took a couple of courses from Deeplearning.ai but even those were not very extensive. I do have couple of Basic RAG, Text2Sql projects using Langchain but i don’t think thats good enough. I’m trying to get into tools, agents, function calling and advanced stuff. Any recommendations on courses, tutorials or channels would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/alcatraz0411&quot;&gt; /u/alcatraz0411 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx7n6v/recommendations_for_langchain_courses/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx7n6v/recommendations_for_langchain_courses/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx7n6v</id><link href="https://www.reddit.com/r/LangChain/comments/1cx7n6v/recommendations_for_langchain_courses/" /><updated>2024-05-21T13:15:39+00:00</updated><published>2024-05-21T13:15:39+00:00</published><title>Recommendations For Langchain Courses</title></entry><entry><author><name>/u/AnEdgeLordWeeb</name><uri>https://www.reddit.com/user/AnEdgeLordWeeb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxl689/errors_developing_langgraph_chatbot_need_urgent/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/9XPfVC4D8q57KFpK0CAjPsI0uYDrO8rzXHuPnzyY-6c.jpg&quot; alt=&quot;Errors developing LangGraph chatbot - need urgent help, please!&quot; title=&quot;Errors developing LangGraph chatbot - need urgent help, please!&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! Before I start, I&amp;#39;m really thankful to everyone who took their time to read this and hopefully help/guide me with my project, you&amp;#39;re saviour. For context, this chatbot is supposed to be my bachelor&amp;#39;s final year project, so it really matters a lot to me that I know it&amp;#39;s functioning well.&lt;/p&gt; &lt;p&gt;Now unto my chatbot and what it is about; I&amp;#39;m trying to develop a chatbot specialized in offering the user video games recomendations based on his preferences. For this task, I though that going with LangGraph would prove to be a smart move.&lt;/p&gt; &lt;p&gt;For a better understanding of it, I&amp;#39;ll attach the diagram that I&amp;#39;ve made of how it should behave and work, and here&amp;#39;s a brief explanation on the chatbot&amp;#39;s workflow and steps:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;User Query&lt;/strong&gt;: The user inputs a query about video game recommendations.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Input Assistant&lt;/strong&gt;: The &lt;code&gt;input_assistant&lt;/code&gt; checks if the query is relevant to video game recommendations using a classification prompt. &lt;ul&gt; &lt;li&gt;If relevant, the query proceeds to the next step.&lt;/li&gt; &lt;li&gt;If not, the user is asked to provide a more specific query.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Game Search Assistant&lt;/strong&gt;: The &lt;code&gt;game_search_assistant&lt;/code&gt; uses the Tavily API to find games based on the user&amp;#39;s query and returns their titles.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Parallel Agents&lt;/strong&gt;: Several agents run in parallel to gather detailed information about the recommended games (also making use of Tavily API): &lt;ul&gt; &lt;li&gt;&lt;code&gt;game_description_assistant&lt;/code&gt;: Fetches game descriptions.&lt;/li&gt; &lt;li&gt;&lt;code&gt;game_platform_assistant&lt;/code&gt;: Fetches platform availability and store details.&lt;/li&gt; &lt;li&gt;&lt;code&gt;game_genre_assistant&lt;/code&gt;: Fetches game genres.&lt;/li&gt; &lt;li&gt;&lt;code&gt;game_developer_publisher_assistant&lt;/code&gt;: Fetches developer and publisher information.&lt;/li&gt; &lt;li&gt;&lt;code&gt;game_metacritic_assistant&lt;/code&gt;: Fetches Metacritic scores.&lt;/li&gt; &lt;li&gt;&lt;code&gt;game_age_restriction_assistant&lt;/code&gt;: Fetches age restriction details.&lt;/li&gt; &lt;li&gt;&lt;code&gt;game_trailer_assistant&lt;/code&gt;: Fetches trailer links.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Output Assistant&lt;/strong&gt;: The &lt;code&gt;output_assistant&lt;/code&gt; compiles the gathered information into a comprehensive response and returns it to the user.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Diagram:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/duyi2195zu1d1.png?width=2382&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0333f1e13fff4e4d112518d8aca027117ec537fa&quot;&gt;https://preview.redd.it/duyi2195zu1d1.png?width=2382&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0333f1e13fff4e4d112518d8aca027117ec537fa&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Problem is, I&amp;#39;m facing some errors, the current one being &amp;quot;list indices must be integers or slices, not str&amp;quot;. I&amp;#39;m very new to working with this framework, or even adventuring in this sphere of LLM apps, so please, forgive me for my stupidity.&lt;/p&gt; &lt;p&gt;The code implementation of this chatbot can be accessed by clicking on this link: &lt;a href=&quot;https://github.com/MOUNAJEDK/GameSeeker-Chatbot&quot;&gt;https://github.com/MOUNAJEDK/GameSeeker-Chatbot&lt;/a&gt;&lt;/p&gt; &lt;p&gt;It would mean a lot if you gave it some of your time and go through what I&amp;#39;ve written there and give me the needed feedback!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnEdgeLordWeeb&quot;&gt; /u/AnEdgeLordWeeb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxl689/errors_developing_langgraph_chatbot_need_urgent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxl689/errors_developing_langgraph_chatbot_need_urgent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cxl689</id><media:thumbnail url="https://b.thumbs.redditmedia.com/9XPfVC4D8q57KFpK0CAjPsI0uYDrO8rzXHuPnzyY-6c.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1cxl689/errors_developing_langgraph_chatbot_need_urgent/" /><updated>2024-05-21T22:48:04+00:00</updated><published>2024-05-21T22:48:04+00:00</published><title>Errors developing LangGraph chatbot - need urgent help, please!</title></entry><entry><author><name>/u/shadeelodin</name><uri>https://www.reddit.com/user/shadeelodin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;does anyone know why langsmith tracing doesn&amp;#39;t work when deployed in the cloud?&lt;/p&gt; &lt;p&gt;It works fine when i run my graphs locally by setting these: &lt;/p&gt; &lt;p&gt;&lt;code&gt;# Set your Langsmith traces&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;LANGCHAIN_TRACING_V2 = True&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;LANGCHAIN_ENDPOINT = os.getenv(&amp;quot;LANGCHAIN_ENDPOINT&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;LANGCHAIN_API_KEY = os.getenv(&amp;quot;LANGCHAIN_API_KEY&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;LANGCHAIN_PROJECT = os.getenv(&amp;quot;LANGCHAIN_PROJECT&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;When we deploy the same code in a severless environment (lambda) and including the above envs, we just don&amp;#39;t get any tracing info on langsmith.&lt;/p&gt; &lt;p&gt;I&amp;#39;m not sure what we&amp;#39;re missing?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/shadeelodin&quot;&gt; /u/shadeelodin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx7rv6/langsmith_not_tracing/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx7rv6/langsmith_not_tracing/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx7rv6</id><link href="https://www.reddit.com/r/LangChain/comments/1cx7rv6/langsmith_not_tracing/" /><updated>2024-05-21T13:21:37+00:00</updated><published>2024-05-21T13:21:37+00:00</published><title>Langsmith not tracing</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I see both ParentDocumentRetriever and Reranking as promising techniques for improving the RAG system. Has anyone tried to combine these two techniques, so first use the ParentDocumentRetreiver and then rerank the results, e.g. with ColBERT?&lt;/p&gt; &lt;p&gt;I think one limitation is the max_tokens of Colbert that do not fit to the retrieved, bigger chunks. One think would be to first rerank the smaller chunks, but I am not sure how to implement this with langchain.&lt;/p&gt; &lt;p&gt;But would be interesting to see which experiences you guys have.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx37pi/anyone_tried_parentdocumentretreiver_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx37pi/anyone_tried_parentdocumentretreiver_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx37pi</id><link href="https://www.reddit.com/r/LangChain/comments/1cx37pi/anyone_tried_parentdocumentretreiver_with/" /><updated>2024-05-21T08:48:46+00:00</updated><published>2024-05-21T08:48:46+00:00</published><title>Anyone tried ParentDocumentRetreiver with Reranking</title></entry><entry><author><name>/u/Vissidarte_2021</name><uri>https://www.reddit.com/user/Vissidarte_2021</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx0pqy/ocr_and_document_parsing_rag_engine_ragflow_v060/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/TE-1_AgX-OAAo1YOAgrT7H6HrjwTDsbIkrvCckmm9RY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=90306a1b43428e283da0b003ba5af50779f4c44e&quot; alt=&quot;OCR and document parsing RAG engine RAGFlow v0.6.0 released&quot; title=&quot;OCR and document parsing RAG engine RAGFlow v0.6.0 released&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Vissidarte_2021&quot;&gt; /u/Vissidarte_2021 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/infiniflow/ragflow&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx0pqy/ocr_and_document_parsing_rag_engine_ragflow_v060/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cx0pqy</id><media:thumbnail url="https://external-preview.redd.it/TE-1_AgX-OAAo1YOAgrT7H6HrjwTDsbIkrvCckmm9RY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=90306a1b43428e283da0b003ba5af50779f4c44e" /><link href="https://www.reddit.com/r/LangChain/comments/1cx0pqy/ocr_and_document_parsing_rag_engine_ragflow_v060/" /><updated>2024-05-21T05:50:18+00:00</updated><published>2024-05-21T05:50:18+00:00</published><title>OCR and document parsing RAG engine RAGFlow v0.6.0 released</title></entry><entry><author><name>/u/ZuckyFox</name><uri>https://www.reddit.com/user/ZuckyFox</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a way to use the Google/flan-t5-xxl model with context of over 1024 tokens. I am using hugging face inference api and it has that limitations.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ZuckyFox&quot;&gt; /u/ZuckyFox &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxbehz/can_we_use_more_than_1024_input_tokens_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cxbehz/can_we_use_more_than_1024_input_tokens_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cxbehz</id><link href="https://www.reddit.com/r/LangChain/comments/1cxbehz/can_we_use_more_than_1024_input_tokens_in/" /><updated>2024-05-21T16:01:10+00:00</updated><published>2024-05-21T16:01:10+00:00</published><title>Can we use more than 1024 input tokens in flan-t5-xxl</title></entry><entry><author><name>/u/Sweaty-Wolf2228</name><uri>https://www.reddit.com/user/Sweaty-Wolf2228</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I&amp;#39;m trying to develop a rag system using llama3, but my base knowledge contains pdfs, ppt, images and videos (tutorials). So how can i achieve that.&lt;/p&gt; &lt;p&gt;I would appreciate any help, links for similar projects...&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sweaty-Wolf2228&quot;&gt; /u/Sweaty-Wolf2228 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx6eox/multimodal_rag_system_using_open_source_models/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx6eox/multimodal_rag_system_using_open_source_models/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx6eox</id><link href="https://www.reddit.com/r/LangChain/comments/1cx6eox/multimodal_rag_system_using_open_source_models/" /><updated>2024-05-21T12:14:01+00:00</updated><published>2024-05-21T12:14:01+00:00</published><title>Multimodal rag system using Open Source models</title></entry><entry><author><name>/u/hwchase17</name><uri>https://www.reddit.com/user/hwchase17</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all! One of the constant things we&amp;#39;ve heard from the community here is a desire for better docs. We&amp;#39;ve spent a lot of time over the past two weeks overhauling the documentation for 0.2. Some things include: versioned docs, a conceptual guide, much simpler navigation and organization, &amp;quot;langchain over time&amp;quot;, etc&lt;/p&gt; &lt;p&gt;We wrote a blog going through some of these two things as well as our thought process: &lt;a href=&quot;https://blog.langchain.dev/documentation-refresh-for-langchain-v0-2/&quot;&gt;https://blog.langchain.dev/documentation-refresh-for-langchain-v0-2/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;We genuinely would love any feedback, no matter how small, on the new docs and ways to keep on improving them. A lot of the changes have been directly influenced by the community here - we really appreciate the feedback and ideas, so I hope you all know that :) Docs are a key focus of ours going forward, and we&amp;#39;ll be monitoring this thread pretty actively for ideas to implement!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hwchase17&quot;&gt; /u/hwchase17 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwkaq9/02_docs_refresh/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwkaq9/02_docs_refresh/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cwkaq9</id><link href="https://www.reddit.com/r/LangChain/comments/1cwkaq9/02_docs_refresh/" /><updated>2024-05-20T16:52:27+00:00</updated><published>2024-05-20T16:52:27+00:00</published><title>0.2 docs refresh</title></entry><entry><author><name>/u/No-Hat-9739</name><uri>https://www.reddit.com/user/No-Hat-9739</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, I&amp;#39;m looking to build a flexible, customizable, and high-performing chatbot using LangChain/LangGraph and LLM technology. I&amp;#39;m currently torn between two options: using the Vercel AI SDK with Next.js or Chainlit with Python. Which solution do you think is the best for building a chatbot today, considering factors like ease of use, scalability, and performance? Thanks in advance for your insights!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No-Hat-9739&quot;&gt; /u/No-Hat-9739 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1fdd/vercel_ai_sdk_vs_chainlit_for_chatbot_project/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1fdd/vercel_ai_sdk_vs_chainlit_for_chatbot_project/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx1fdd</id><link href="https://www.reddit.com/r/LangChain/comments/1cx1fdd/vercel_ai_sdk_vs_chainlit_for_chatbot_project/" /><updated>2024-05-21T06:39:23+00:00</updated><published>2024-05-21T06:39:23+00:00</published><title>Vercel AI SDK vs chainlit for chatbot project</title></entry></feed>