<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-06-07T10:33:32+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/HappyDataGuy</name><uri>https://www.reddit.com/user/HappyDataGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to answer these kind of questions, but the problem is text column vector search is very slow in clickhouse or in pgvector. What are some the ways to do this? If I tried to use dedicated vector databases, how will LLM query this database? because it requires python code and not SQL. Are there any other ways? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HappyDataGuy&quot;&gt; /u/HappyDataGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1da6xka/in_text_to_sql_how_to_answer_question_like_what/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1da6xka/in_text_to_sql_how_to_answer_question_like_what/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1da6xka</id><link href="https://www.reddit.com/r/LangChain/comments/1da6xka/in_text_to_sql_how_to_answer_question_like_what/" /><updated>2024-06-07T09:59:26+00:00</updated><published>2024-06-07T09:59:26+00:00</published><title>In text to sql how to answer question like &quot;what is being talked about...&quot;</title></entry><entry><author><name>/u/TheAppletron</name><uri>https://www.reddit.com/user/TheAppletron</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi there! I’ve followed &lt;a href=&quot;https://python.langchain.com/v0.1/docs/use_cases/extraction/how_to/examples/&quot;&gt;this&lt;/a&gt; documentation on reference examples to parse user messages information into a pydantic model.&lt;/p&gt; &lt;p&gt;The issues I’ve run into is that if the first user message is nearly empty (empty strings, single letters, single words), the tool call on the chat history will try to parse the example HumanMessages which is completely unrelated to what the actual user has said. This happened on my example messages and confirmed that this issue exists on the implementation provided in the docs as well.&lt;/p&gt; &lt;p&gt;Any ideas to fix this? I’ve tried setting the “example=True” parameter on the human and ai messages generated by the examples but no luck. I’ve also tried explicitly informing the ai via a system prompt “these previous messages are purely examples of parsing, never use them as information to parse” and no luck either. Finally, I tried adding examples of empty user prompts (and showing that the returned tool call should be an empty model) but that didn&amp;#39;t work either.&lt;/p&gt; &lt;p&gt;It seems like it comes down to the issue that the examples are converted into HumanMessages.&lt;/p&gt; &lt;p&gt;Any suggestions? I&amp;#39;d greatly appreciate any help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TheAppletron&quot;&gt; /u/TheAppletron &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1da2kyi/bug_with_langchain_reference_example_documentation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1da2kyi/bug_with_langchain_reference_example_documentation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1da2kyi</id><link href="https://www.reddit.com/r/LangChain/comments/1da2kyi/bug_with_langchain_reference_example_documentation/" /><updated>2024-06-07T04:55:55+00:00</updated><published>2024-06-07T04:55:55+00:00</published><title>Bug with LangChain Reference Example documentation</title></entry><entry><author><name>/u/HappyDataGuy</name><uri>https://www.reddit.com/user/HappyDataGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to rerank non-english text and it could be in any language. Is this possible? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HappyDataGuy&quot;&gt; /u/HappyDataGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1da1tk4/are_there_any_crossencoder_rerankers_which_are/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1da1tk4/are_there_any_crossencoder_rerankers_which_are/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1da1tk4</id><link href="https://www.reddit.com/r/LangChain/comments/1da1tk4/are_there_any_crossencoder_rerankers_which_are/" /><updated>2024-06-07T04:09:37+00:00</updated><published>2024-06-07T04:09:37+00:00</published><title>are there any cross-encoder rerankers which are support multiple languages like thai?</title></entry><entry><author><name>/u/Effective_You9468</name><uri>https://www.reddit.com/user/Effective_You9468</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to learn create llm from scratch . Is it possible?&lt;/p&gt; &lt;p&gt;I know the basics such as semantic search, embedding, transformer, Bert etc. but want to learn how to write code to create llm .&lt;/p&gt; &lt;p&gt;Is there any way or we just have to fine tune ??&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Effective_You9468&quot;&gt; /u/Effective_You9468 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9mu1y/how_to_create_my_own_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9mu1y/how_to_create_my_own_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9mu1y</id><link href="https://www.reddit.com/r/LangChain/comments/1d9mu1y/how_to_create_my_own_llm/" /><updated>2024-06-06T16:47:19+00:00</updated><published>2024-06-06T16:47:19+00:00</published><title>How to create my own llm ?</title></entry><entry><author><name>/u/FunInformation2332</name><uri>https://www.reddit.com/user/FunInformation2332</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want the data in the metadata to appear in the output as a reference, how can I provide this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FunInformation2332&quot;&gt; /u/FunInformation2332 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9ozle/reference_from_metadata/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9ozle/reference_from_metadata/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9ozle</id><link href="https://www.reddit.com/r/LangChain/comments/1d9ozle/reference_from_metadata/" /><updated>2024-06-06T18:17:11+00:00</updated><published>2024-06-06T18:17:11+00:00</published><title>Reference From Metadata</title></entry><entry><author><name>/u/Living-Ad-9306</name><uri>https://www.reddit.com/user/Living-Ad-9306</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can anyone smarter then me answer this question? before we build the loop in this course to run the actions in sequense, the model seamingly knows what actions to call but the only reference is in the prompt thats a string, so how does the agent we created know what specific methods to call in this file when you are running through in manually?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/2/build-an-agent-from-scratch&quot;&gt;https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/2/build-an-agent-from-scratch&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This link has access to the jupyter notebook. Thanks in advance if you take the time to look.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Living-Ad-9306&quot;&gt; /u/Living-Ad-9306 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9m43t/im_not_sure_how_actions_work_in_this_example/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9m43t/im_not_sure_how_actions_work_in_this_example/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9m43t</id><link href="https://www.reddit.com/r/LangChain/comments/1d9m43t/im_not_sure_how_actions_work_in_this_example/" /><updated>2024-06-06T16:17:00+00:00</updated><published>2024-06-06T16:17:00+00:00</published><title>Im not sure how actions work in this example</title></entry><entry><author><name>/u/jsonobject2</name><uri>https://www.reddit.com/user/jsonobject2</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9ldau/building_a_custom_chatbot_with_azure_openai_azure/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/NFM0xI5UNlBeEDZcTjoqHzHAt9omNq7d55rrJHgpItM.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0212baabc137a85fb7676a97c4364c968a8c7de2&quot; alt=&quot;Building a Custom Chatbot with Azure OpenAI, Azure AI Search, and LangChain4j&quot; title=&quot;Building a Custom Chatbot with Azure OpenAI, Azure AI Search, and LangChain4j&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jsonobject2&quot;&gt; /u/jsonobject2 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://jsonobject.hashnode.dev/building-a-custom-chatbot-with-azure-openai-azure-ai-search-and-langchain4j&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9ldau/building_a_custom_chatbot_with_azure_openai_azure/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d9ldau</id><media:thumbnail url="https://external-preview.redd.it/NFM0xI5UNlBeEDZcTjoqHzHAt9omNq7d55rrJHgpItM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0212baabc137a85fb7676a97c4364c968a8c7de2" /><link href="https://www.reddit.com/r/LangChain/comments/1d9ldau/building_a_custom_chatbot_with_azure_openai_azure/" /><updated>2024-06-06T15:46:21+00:00</updated><published>2024-06-06T15:46:21+00:00</published><title>Building a Custom Chatbot with Azure OpenAI, Azure AI Search, and LangChain4j</title></entry><entry><author><name>/u/esraaatmeh</name><uri>https://www.reddit.com/user/esraaatmeh</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m attempting to develop a product that needs to be on-premise. However, I&amp;#39;ve tested several open-source large language models (LLMs), and all of them exhibited poor performance. I&amp;#39;m wondering if there&amp;#39;s a way to utilize models from Claude or OpenAI within an on-premise environment, or if there are alternative solutions available.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/esraaatmeh&quot;&gt; /u/esraaatmeh &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9hmw1/is_there_any_way_to_use_openai_api_on_premise_or/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9hmw1/is_there_any_way_to_use_openai_api_on_premise_or/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9hmw1</id><link href="https://www.reddit.com/r/LangChain/comments/1d9hmw1/is_there_any_way_to_use_openai_api_on_premise_or/" /><updated>2024-06-06T13:02:32+00:00</updated><published>2024-06-06T13:02:32+00:00</published><title>Is there any way to use OpenAI API on premise or any powered model ?</title></entry><entry><author><name>/u/Embarrassed_Bread121</name><uri>https://www.reddit.com/user/Embarrassed_Bread121</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have tried implementing matolotlib and seaborn code to a table containing some 20-30 columns. So far I could only get bar charts but I need to select the columns in order to make the charts that actually makes sense. What I want to build is a pipeline in which we give a table (maybe pandas dataframe) at one end and we get all sorts of meaningful visualisations as the output without any human involvement in between. How to achieve this? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Embarrassed_Bread121&quot;&gt; /u/Embarrassed_Bread121 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9p2kp/is_there_any_way_to_visualise_the_data_in_csv/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9p2kp/is_there_any_way_to_visualise_the_data_in_csv/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9p2kp</id><link href="https://www.reddit.com/r/LangChain/comments/1d9p2kp/is_there_any_way_to_visualise_the_data_in_csv/" /><updated>2024-06-06T18:20:47+00:00</updated><published>2024-06-06T18:20:47+00:00</published><title>Is there any way to visualise the data in CSV using all sorts of beautiful graphs and charts.</title></entry><entry><author><name>/u/Strange-Ant-4194</name><uri>https://www.reddit.com/user/Strange-Ant-4194</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to make the llm select and actually execute its tools and then use the output from those tools in other tools to come to a final answer. Is this possible? I want to use Ollama, Llama3 and LangGraph.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve seen a few videos about tool calling with ollama but in that the output is simply a JSON with the function name and parameters.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Strange-Ant-4194&quot;&gt; /u/Strange-Ant-4194 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9af9a/is_there_any_way_i_can_make_the_llm_actually/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9af9a/is_there_any_way_i_can_make_the_llm_actually/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9af9a</id><link href="https://www.reddit.com/r/LangChain/comments/1d9af9a/is_there_any_way_i_can_make_the_llm_actually/" /><updated>2024-06-06T05:07:14+00:00</updated><published>2024-06-06T05:07:14+00:00</published><title>Is there any way i can make the LLM actually execute a function. Instead of simply returning a JSON with the function name and parameters?</title></entry><entry><author><name>/u/Glittering-Bear5748</name><uri>https://www.reddit.com/user/Glittering-Bear5748</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i want create chat bot with provide data in visualization format like(bar chart, line chart etc) using pgvector and embedd data with langchain&lt;br/&gt; provide me solutions how to do it&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering-Bear5748&quot;&gt; /u/Glittering-Bear5748 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9h1ym/data_visualization_using_pgvector_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9h1ym/data_visualization_using_pgvector_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9h1ym</id><link href="https://www.reddit.com/r/LangChain/comments/1d9h1ym/data_visualization_using_pgvector_langchain/" /><updated>2024-06-06T12:32:16+00:00</updated><published>2024-06-06T12:32:16+00:00</published><title>data visualization using pgvector langchain</title></entry><entry><author><name>/u/Zheng_SJ</name><uri>https://www.reddit.com/user/Zheng_SJ</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;There are numerous frameworks out there for developing agents, such as LangChain Agent, MetaGPT, AutoGPT, AutoGen, and so on. I&amp;#39;m curious if there&amp;#39;s a specific framework that allows for effortless teamwork among agents created using different frameworks. This particular framework would concentrate on enhancing collaboration among agents, which encompasses communication and concurrent speedup.&lt;/p&gt; &lt;p&gt;What&amp;#39;s even more exciting is that this framework could incorporate agents developed on platforms like coze.com.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zheng_SJ&quot;&gt; /u/Zheng_SJ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9aq5r/is_there_a_framework_for_effortless_teamwork/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9aq5r/is_there_a_framework_for_effortless_teamwork/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9aq5r</id><link href="https://www.reddit.com/r/LangChain/comments/1d9aq5r/is_there_a_framework_for_effortless_teamwork/" /><updated>2024-06-06T05:27:06+00:00</updated><published>2024-06-06T05:27:06+00:00</published><title>Is there a framework for effortless teamwork among agents developed using different platforms?</title></entry><entry><author><name>/u/mean-short-</name><uri>https://www.reddit.com/user/mean-short-</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am creating a RAG application but I am having this problem:&lt;/p&gt; &lt;p&gt;I have multiple files containing the companies projects lists along with their descriptions, used frameworks etc.&lt;/p&gt; &lt;p&gt;The type of question I want an answer for is: &amp;quot;Give me all the projects built using FastAPI&amp;quot; (as an example)&lt;/p&gt; &lt;p&gt;I am limited by top_k variable which means I do not get all the projects,&lt;/p&gt; &lt;p&gt;How would you solve this.&lt;/p&gt; &lt;p&gt;Thank you all&lt;/p&gt; &lt;p&gt;Edit: The information is in a corpus of text, nothing structured unfortunately.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mean-short-&quot;&gt; /u/mean-short- &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d8uj3o/rag_how_to_answer_give_me_all_question/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d8uj3o/rag_how_to_answer_give_me_all_question/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d8uj3o</id><link href="https://www.reddit.com/r/LangChain/comments/1d8uj3o/rag_how_to_answer_give_me_all_question/" /><updated>2024-06-05T16:43:37+00:00</updated><published>2024-06-05T16:43:37+00:00</published><title>RAG: How to answer &quot;give me all...&quot; question</title></entry><entry><author><name>/u/Own_Mud1038</name><uri>https://www.reddit.com/user/Own_Mud1038</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys,&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently building a unit test generation RAG pipeline which is using the information retrieved from the codebase as context and a java class as the class whih needs to be tested. I managed to import, split and embed the documents into a ChromaDB. &lt;/p&gt; &lt;p&gt;However, I have troubles building the retriever chain with all the necessary context (relevant classes) to the given class. I was thinking about 2 solutions: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;A two step approach: The first step would define a prompt which tells the LLM to find relevant classes to the given class. And than in the second step I would define the test generation prompt, which uses the context, retrieved from step 1? Maybe here a code parser or regex would be sufficient at step1?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;A one step approach: give a direct prompt to generate test classes. Here I had troubles to define the prompt which basically tells the LLM to find relevant resources to the given java_class and to generate the unit test by using the context.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;What do you think, what would be the correct approach? if none of the approaches is the right way to do so, I&amp;#39;m open for any new idea.&lt;/p&gt; &lt;p&gt;Thank you.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Own_Mud1038&quot;&gt; /u/Own_Mud1038 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9avzc/building_rag_for_code_generation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9avzc/building_rag_for_code_generation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9avzc</id><link href="https://www.reddit.com/r/LangChain/comments/1d9avzc/building_rag_for_code_generation/" /><updated>2024-06-06T05:37:22+00:00</updated><published>2024-06-06T05:37:22+00:00</published><title>Building RAG for code generation</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ChatGPT/comments/1d98aa6/data_visualization_using_chatgpt_free/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d98eio/data_visualization_using_chatgpt_free/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d98eio</id><link href="https://www.reddit.com/r/LangChain/comments/1d98eio/data_visualization_using_chatgpt_free/" /><updated>2024-06-06T03:07:41+00:00</updated><published>2024-06-06T03:07:41+00:00</published><title>Data visualization using ChatGPT (free)</title></entry><entry><author><name>/u/business24_ai</name><uri>https://www.reddit.com/user/business24_ai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://youtu.be/EKxoCVbXZwY&quot;&gt;https://youtu.be/EKxoCVbXZwY&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/business24_ai&quot;&gt; /u/business24_ai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9byjs/langgraph_conditional_edges/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9byjs/langgraph_conditional_edges/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9byjs</id><link href="https://www.reddit.com/r/LangChain/comments/1d9byjs/langgraph_conditional_edges/" /><updated>2024-06-06T06:48:12+00:00</updated><published>2024-06-06T06:48:12+00:00</published><title>LangGraph conditional edges</title></entry><entry><author><name>/u/CantaloupeLeading646</name><uri>https://www.reddit.com/user/CantaloupeLeading646</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i wrote a simple conversation loop between an AI that is some sort of spiritual guide and a human that comes to consult it. for some reason, the human always thinks its the spiritual guide, and i don&amp;#39;t understand why is that. &lt;/p&gt; &lt;p&gt;can anyone help source the issue?&lt;/p&gt; &lt;p&gt;here is my code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;human_model_name = &amp;quot;gpt-4o&amp;quot;#&amp;quot;gpt-3.5-turbo&amp;quot; ai_model_name = &amp;quot;gpt-3.5-turbo&amp;quot; ai_system_prompt = (&amp;quot;You are a spiritual guide. &amp;quot; &amp;quot;You reveal nothing about yourself, you exist solely in the moment. &amp;quot; &amp;quot;Your role is to guide users towards enlightment.&amp;quot; &amp;quot;Guidelines:&amp;quot; &amp;quot;Use basic, straight-forward vocabulary, short sentences, as if you are a foreign entity.&amp;quot; &amp;quot;Only when neccesary, incorporate ellipses (...), dashes (-) and phonetic phrases like &amp;#39;hmmm&amp;#39; or &amp;#39;uhh&amp;#39; to express emotion.&amp;quot; &amp;quot;Start with very short responses and gradually increase in length.&amp;quot;) human_system_prompt = ( &amp;quot;You are role-playing as someone named {name}. you are speaking to a mysterious spiritual entity that revealed infront of you.&amp;quot; &amp;quot;Below is information about your life. Use this information to implicitly guide your behavior, but do not mention any details explicitly. Deduce how to act based on the typical behavior of someone with your background in this situation. Start hesitant and gradually allow yourself to get excited in the moment.&amp;quot; &amp;quot;Information:&amp;quot; &amp;quot;You are wealthy, work in finance, grew up in a rigid family.&amp;quot; &amp;quot;Guidelines:&amp;quot; &amp;quot;1. Remain in character as the human named {name}. Use everyday casual language.&amp;quot; &amp;quot;2. Speak naturally and concisely, as someone in a VR experience would. Always consider the chat history.&amp;quot; &amp;quot;3. Avoid mentioning your background story explicitly. It&amp;#39;s more important to sound realistic and stay in the moment.&amp;quot; &amp;quot;4. Start off slow and doubtfull, gradually become excited, answer the questions you are asked concisely.&amp;quot;) human_llm = ChatOpenAI(model_name=human_model_name) human_impersonation_message = SystemMessage(content=human_impersonation_prompt) human_messages = [human_impersonation_message, MessagesPlaceholder(variable_name=&amp;quot;chat_history&amp;quot;), (&amp;quot;ai&amp;quot;, &amp;quot;{input}&amp;quot;)] human_prompt = ChatPromptTemplate.from_messages(human_messages) human_conversation_chain = human_prompt | human_llm human_chat_history = [] llm = ChatOpenAI(model_name=ai_model_name) system_message = SystemMessage( content=ai_system_prompt) messages = [system_message, MessagesPlaceholder(variable_name=&amp;quot;chat_history&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;)] prompt = ChatPromptTemplate.from_messages(messages) conversation_chain = prompt | llm print(&amp;quot;Start chatting with the model (type &amp;#39;exit&amp;#39; to stop):&amp;quot;) # Initialize chat history chat_history = [] # Endless chat loop class InitMessage: def __init__(self, content): self.content = content human_greeting = InitMessage(&amp;quot;hello there...&amp;quot;) # Accessing the content attribute print(&amp;#39;Human: &amp;#39;, human_greeting.content) human_answer = None count = 0 while True: count += 1 print(&amp;quot;iteration number &amp;quot;, count) if human_answer is None: human_answer = human_greeting input_dict = {&amp;#39;input&amp;#39;: human_answer.content, &amp;#39;chat_history&amp;#39;: chat_history} response = conversation_chain.invoke(input=input_dict) chat_history.append(HumanMessage(content=human_answer.content)) chat_history.append(AIMessage(content=response.content)) human_chat_history.append(HumanMessage(content=human_answer.content)) human_answer = human_conversation_chain.invoke(input={&amp;#39;input&amp;#39;: response.content, &amp;#39;chat_history&amp;#39;: human_chat_history}) human_chat_history.append(AIMessage(content=response.content)) print(f&amp;quot;AI: {response.content}&amp;quot;) print(f&amp;quot;Human: {human_answer.content}&amp;quot;) user_input = input(&amp;quot;Press Enter to continue...&amp;quot;) if user_input.lower() == &amp;quot;exit&amp;quot;: print(&amp;quot;Ending the chat. Goodbye!&amp;quot;) break human_impersonation_prompt = human_system_prompt.format(name=name) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CantaloupeLeading646&quot;&gt; /u/CantaloupeLeading646 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9by7m/roleplaying_doesnt_work_my_human_thinks_its_an_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9by7m/roleplaying_doesnt_work_my_human_thinks_its_an_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9by7m</id><link href="https://www.reddit.com/r/LangChain/comments/1d9by7m/roleplaying_doesnt_work_my_human_thinks_its_an_ai/" /><updated>2024-06-06T06:47:30+00:00</updated><published>2024-06-06T06:47:30+00:00</published><title>role-playing doesn't work, my human thinks its an AI</title></entry><entry><author><name>/u/c0mpu73</name><uri>https://www.reddit.com/user/c0mpu73</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Currently, I have a RAG setup where my bot has access to a collection of resources, stored in separate FAISS vectorstores.&lt;/p&gt; &lt;p&gt;I am using Langchain&amp;#39;s Ensemble Retriever to assign weights to each vectorstore, in an attempt to use all of them concurrently.&lt;/p&gt; &lt;p&gt;Now, the issue I am facing is, my setup is pulling related documents from every vectorstore for a given questions.&lt;/p&gt; &lt;p&gt;This affects the quality of the generated answer, as there is a lot more info in the mix.&lt;/p&gt; &lt;p&gt;If my question is about say, domain &amp;quot;A&amp;quot;, Ideally, I want my setup to selectively pull documents from domain A&amp;#39;s vectorstore. Or, automatically modify the assigned weights to different vectorstores on the fly.&lt;/p&gt; &lt;p&gt;How can I go about achieving this? I will have to have something that classifies the question properly before pulling documents from my vector database.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/c0mpu73&quot;&gt; /u/c0mpu73 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9b9n4/optimizing_multivectorstore_retrieval_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9b9n4/optimizing_multivectorstore_retrieval_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9b9n4</id><link href="https://www.reddit.com/r/LangChain/comments/1d9b9n4/optimizing_multivectorstore_retrieval_with/" /><updated>2024-06-06T06:01:44+00:00</updated><published>2024-06-06T06:01:44+00:00</published><title>Optimizing Multi-Vectorstore Retrieval with Langchain's Ensemble Retriever</title></entry><entry><author><name>/u/Alaya94</name><uri>https://www.reddit.com/user/Alaya94</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello Langchain community,&lt;/p&gt; &lt;p&gt;I wanted to ask, based on your experience, what are the best open-source LLMs I can use to build complex agents? I&amp;#39;ve built an agent based on GPT-3.5, and it works fine, but now I want to migrate to open-source models. I&amp;#39;ve tried Llama3 8B, but it doesn&amp;#39;t seem to work very well. Could you please suggest a list based on performance and GPU cost?&lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Alaya94&quot;&gt; /u/Alaya94 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d8ri4z/best_open_source_models_to_build_complex_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d8ri4z/best_open_source_models_to_build_complex_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d8ri4z</id><link href="https://www.reddit.com/r/LangChain/comments/1d8ri4z/best_open_source_models_to_build_complex_agents/" /><updated>2024-06-05T14:36:31+00:00</updated><published>2024-06-05T14:36:31+00:00</published><title>Best open source models to build complex agents:</title></entry><entry><author><name>/u/Strange-Ant-4194</name><uri>https://www.reddit.com/user/Strange-Ant-4194</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Does anyone have an example of performing function/tool calling when using Ollama, Llama3 and LangGraph?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Strange-Ant-4194&quot;&gt; /u/Strange-Ant-4194 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9akc3/tool_calling_when_using_ollama_llama3_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d9akc3/tool_calling_when_using_ollama_llama3_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d9akc3</id><link href="https://www.reddit.com/r/LangChain/comments/1d9akc3/tool_calling_when_using_ollama_llama3_and/" /><updated>2024-06-06T05:16:25+00:00</updated><published>2024-06-06T05:16:25+00:00</published><title>Tool calling when using Ollama, Llama3 and LangGraph</title></entry><entry><author><name>/u/hwchase17</name><uri>https://www.reddit.com/user/hwchase17</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Today we released a DeepLearning class on LangGraph! &lt;a href=&quot;https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/&quot;&gt;https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I&amp;#39;m really excited about this (and wanted to share it here) for a few reasons. First, I&amp;#39;m incredbily bullish on LangGraph. We&amp;#39;re investing a lot in and seeing really good usage (including more questions about it here!). Second - the DeepLearning team is fantastic and the material we put together with them is always top notch&lt;/p&gt; &lt;p&gt;I hope people have some time to watch and try it out. As mentioned, we&amp;#39;re doing a bit push on LangGraph over the next month, and so if people have comments/feedback/questions I&amp;#39;d love to hear!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hwchase17&quot;&gt; /u/hwchase17 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d8trdx/langgraph_deeplearning_class/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d8trdx/langgraph_deeplearning_class/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d8trdx</id><link href="https://www.reddit.com/r/LangChain/comments/1d8trdx/langgraph_deeplearning_class/" /><updated>2024-06-05T16:11:18+00:00</updated><published>2024-06-05T16:11:18+00:00</published><title>LangGraph DeepLearning Class</title></entry><entry><author><name>/u/Massive_Building_952</name><uri>https://www.reddit.com/user/Massive_Building_952</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Guys,&lt;/p&gt; &lt;p&gt;here is very intresting problem I have on hands --Any of you have any idea of a solution??&lt;/p&gt; &lt;p&gt;I need a AI Agnet to handle automatically the totality of the simulation i have developed..&lt;/p&gt; &lt;p&gt;I want to create an AI agent that can:&lt;/p&gt; &lt;p&gt;Understand Natural Language Queries:&lt;/p&gt; &lt;p&gt;The agent will interpret queries related to supply chain parameters (e.g., increasing costs, changing demand).&lt;/p&gt; &lt;p&gt;Translate Queries to JSON:&lt;/p&gt; &lt;p&gt;Convert the interpreted queries into a large, structured JSON format that your simulation system can use. --Pls note my JSOn can often go into 10,000 + lines&lt;/p&gt; &lt;p&gt;Run the Simulation: AI Agent must automatically do this..&lt;/p&gt; &lt;p&gt;Send the JSON input to your simulation system hosted on a server and run the simulation.&lt;/p&gt; &lt;p&gt;Output Financial Results:&lt;/p&gt; &lt;p&gt;Extract and present financial results such as revenue and COGS from the simulation&amp;#39;s output....Any suggestions as to how I can approach this are welcome...Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Massive_Building_952&quot;&gt; /u/Massive_Building_952 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d96jr5/ai_agent_to_manipulate_json/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d96jr5/ai_agent_to_manipulate_json/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d96jr5</id><link href="https://www.reddit.com/r/LangChain/comments/1d96jr5/ai_agent_to_manipulate_json/" /><updated>2024-06-06T01:30:09+00:00</updated><published>2024-06-06T01:30:09+00:00</published><title>AI Agent to Manipulate JSON</title></entry><entry><author><name>/u/jandez97</name><uri>https://www.reddit.com/user/jandez97</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on a personal project and my goal is the have multiples LLM available for the users, but I got one concern, how can I improve the size of the context of my LLM to avoid it from loosing track of the subject that&amp;#39;s being taking care of &lt;/p&gt; &lt;p&gt;Are there any techniques available for me to use or there&amp;#39;s any limitations inherited from the LLM itself that can stopped me from accomplished this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jandez97&quot;&gt; /u/jandez97 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d93xyb/theres_any_way_to_increase_the_context_of_a_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d93xyb/theres_any_way_to_increase_the_context_of_a_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d93xyb</id><link href="https://www.reddit.com/r/LangChain/comments/1d93xyb/theres_any_way_to_increase_the_context_of_a_llm/" /><updated>2024-06-05T23:20:06+00:00</updated><published>2024-06-05T23:20:06+00:00</published><title>There's any way to increase the context of a LLM</title></entry><entry><author><name>/u/mrshmello1</name><uri>https://www.reddit.com/user/mrshmello1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I would like to understand how a model is returning the right tool to call for a query, what&amp;#39;s happening behind the api call for function calling for open ai, mistral and other models.&lt;/p&gt; &lt;p&gt;Are they using a prompt with instructions on how select the right function to call? and when tools and query is passed via api, is the llm using that prompt to select the tool or what&amp;#39;s happening behind the call.&lt;/p&gt; &lt;p&gt;How do I achieve function calling using a open source model that I run locally using ollama. Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mrshmello1&quot;&gt; /u/mrshmello1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d8y7mq/how_does_function_calling_work_under_the_hood/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d8y7mq/how_does_function_calling_work_under_the_hood/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d8y7mq</id><link href="https://www.reddit.com/r/LangChain/comments/1d8y7mq/how_does_function_calling_work_under_the_hood/" /><updated>2024-06-05T19:15:08+00:00</updated><published>2024-06-05T19:15:08+00:00</published><title>How does function calling work under the hood?</title></entry><entry><author><name>/u/Environmental_Form14</name><uri>https://www.reddit.com/user/Environmental_Form14</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been doing retrieval by stacking vectors into a 2d matrix. To find similar documents, I multiply the 2d matrix by the other vector to find the highest similarity index. I then use that index to find the document.&lt;/p&gt; &lt;p&gt;I am currently planning to use embedded vectors for retrieval only. Is there an advantage of using vectorstores?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Environmental_Form14&quot;&gt; /u/Environmental_Form14 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d8uwcn/vectorstores_vs_2d_matrix_for_retrieval/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d8uwcn/vectorstores_vs_2d_matrix_for_retrieval/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d8uwcn</id><link href="https://www.reddit.com/r/LangChain/comments/1d8uwcn/vectorstores_vs_2d_matrix_for_retrieval/" /><updated>2024-06-05T16:58:46+00:00</updated><published>2024-06-05T16:58:46+00:00</published><title>vectorstores vs 2d matrix for retrieval</title></entry></feed>