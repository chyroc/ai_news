<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-23T05:58:23+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Accomplished_Pin_626</name><uri>https://www.reddit.com/user/Accomplished_Pin_626</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build rag solution for a user guide I have worked with chromadb and OpenAI but I want to build something robust step by step Can you suggest something for me Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Accomplished_Pin_626&quot;&gt; /u/Accomplished_Pin_626 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d11xt/create_full_rag_solution_tutorial/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d11xt/create_full_rag_solution_tutorial/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19d11xt</id><link href="https://www.reddit.com/r/LangChain/comments/19d11xt/create_full_rag_solution_tutorial/" /><updated>2024-01-22T17:29:21+00:00</updated><published>2024-01-22T17:29:21+00:00</published><title>Create full RAG solution tutorial</title></entry><entry><author><name>/u/altruios</name><uri>https://www.reddit.com/user/altruios</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to embed a prompt, invert the sign of each embedding, then turn that new embedding back into text.&lt;/p&gt; &lt;p&gt;I am getting stuck on getting the embedding transformed back into words...&lt;/p&gt; &lt;p&gt;how do you do that?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/altruios&quot;&gt; /u/altruios &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d3z4g/vec2word/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d3z4g/vec2word/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19d3z4g</id><link href="https://www.reddit.com/r/LangChain/comments/19d3z4g/vec2word/" /><updated>2024-01-22T19:28:13+00:00</updated><published>2024-01-22T19:28:13+00:00</published><title>vec2word</title></entry><entry><author><name>/u/Appropriate_Egg6118</name><uri>https://www.reddit.com/user/Appropriate_Egg6118</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have built RAG chatbot entirely from scratch NO langchain involved. The docs are retrieved for every query, I want to Stop docs Retrieval for Greeting messenges.&lt;/p&gt; &lt;p&gt;I have tried conditional check by storing all Greeting messages in a list which worked fine But what if user enters different greeting message that&amp;#39;s not in list, what if he enters with spelling mistakes. This will definitely fail.&lt;/p&gt; &lt;p&gt;How to handle this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Appropriate_Egg6118&quot;&gt; /u/Appropriate_Egg6118 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d9d6t/how_to_stop_document_retrieval_in_a_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d9d6t/how_to_stop_document_retrieval_in_a_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19d9d6t</id><link href="https://www.reddit.com/r/LangChain/comments/19d9d6t/how_to_stop_document_retrieval_in_a_rag_chatbot/" /><updated>2024-01-22T23:08:36+00:00</updated><published>2024-01-22T23:08:36+00:00</published><title>How to Stop Document Retrieval in a RAG chatbot for Greeting input from user Like Hi, Hello, Good Morning etc</title></entry><entry><author><name>/u/danipudani</name><uri>https://www.reddit.com/user/danipudani</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d26e0/mistral_7b_from_mistralai_full_whitepaper_overview/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/FhC_y-oxVeC6HGqk8BsT7wthO6-z0HqQsR-HgQeRTXo.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6d9b98acf968232120730892defc7e42319e3130&quot; alt=&quot;Mistral 7B from Mistral.AI - FULL WHITEPAPER OVERVIEW&quot; title=&quot;Mistral 7B from Mistral.AI - FULL WHITEPAPER OVERVIEW&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/danipudani&quot;&gt; /u/danipudani &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/rSUqg5X4SAU?si=xoXyfmrDUu7idHI3&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d26e0/mistral_7b_from_mistralai_full_whitepaper_overview/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19d26e0</id><media:thumbnail url="https://external-preview.redd.it/FhC_y-oxVeC6HGqk8BsT7wthO6-z0HqQsR-HgQeRTXo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6d9b98acf968232120730892defc7e42319e3130" /><link href="https://www.reddit.com/r/LangChain/comments/19d26e0/mistral_7b_from_mistralai_full_whitepaper_overview/" /><updated>2024-01-22T18:14:13+00:00</updated><published>2024-01-22T18:14:13+00:00</published><title>Mistral 7B from Mistral.AI - FULL WHITEPAPER OVERVIEW</title></entry><entry><author><name>/u/WinterStatistician70</name><uri>https://www.reddit.com/user/WinterStatistician70</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am building a chatbot using Azure OpenAI API. Is there a way I can integrate the memory module of the Langchain framework into my chat application? Currently, I am using summarization to implement the short-term memory but I would like to expand the memory implications to a long-term memory and also manage the summarization using the buffer memory methods in Langchain. My conversations are currently stored in a Redis cache.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/WinterStatistician70&quot;&gt; /u/WinterStatistician70 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d72dg/llm_based_chatbots_with_memory/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d72dg/llm_based_chatbots_with_memory/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19d72dg</id><link href="https://www.reddit.com/r/LangChain/comments/19d72dg/llm_based_chatbots_with_memory/" /><updated>2024-01-22T21:34:36+00:00</updated><published>2024-01-22T21:34:36+00:00</published><title>LLM based ChatBots with Memory</title></entry><entry><author><name>/u/TelephoneParty5934</name><uri>https://www.reddit.com/user/TelephoneParty5934</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently trying to build an app (python) using local llms I tried Mistral 7b instruct. I have tried few prompts asking the model to generate code snippets and functions. But now i have to test the model if it can give source code to build an app (let&amp;#39;s say a chatbot for instance). Basically the input would be a use case in natural language&lt;/p&gt; &lt;p&gt;For example: Build an end to end chatbot that can answer customer&amp;#39;s queries and help with the issues.&lt;/p&gt; &lt;p&gt;What should be my approach ? How to get this done ? Please provide suggestions since I&amp;#39;m really new to LLMs. If possible provide any tutorials or guides.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TelephoneParty5934&quot;&gt; /u/TelephoneParty5934 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d64ek/developing_an_app_using_open_source_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d64ek/developing_an_app_using_open_source_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19d64ek</id><link href="https://www.reddit.com/r/LangChain/comments/19d64ek/developing_an_app_using_open_source_llms/" /><updated>2024-01-22T20:57:04+00:00</updated><published>2024-01-22T20:57:04+00:00</published><title>Developing an app using open source LLMs</title></entry><entry><author><name>/u/SensitiveFel</name><uri>https://www.reddit.com/user/SensitiveFel</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I found that using RAG to search for documents through a vector store definitely loses some of the information, such as context, because it has no way to look at your problem based on the whole document. langchain There is a concept proposed in that, which is &lt;code&gt;Parent Document Retriever&lt;/code&gt;. But even so, I think he may not be as effective as passing all the data as context to LLM,then this also derives a maximum token problem, then does it mean: the model that supports the most tokens is better at searching, something like &lt;code&gt;CLAUDE2&lt;/code&gt; vs &lt;code&gt;ChatGPT&lt;/code&gt;. It feels like the simplest and crudest is instead the most effective&lt;/p&gt; &lt;p&gt;EditÔºö Or maybe this is the way to go. &lt;a href=&quot;https://medium.com/@akriti.upadhyay/building-advanced-rag-applications-using-falkordb-langchain-diffbot-api-and-openai-083fa1b6a96c&quot;&gt;advanced-rag&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SensitiveFel&quot;&gt; /u/SensitiveFel &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cpvw6/rag_vs_full_context/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cpvw6/rag_vs_full_context/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19cpvw6</id><link href="https://www.reddit.com/r/LangChain/comments/19cpvw6/rag_vs_full_context/" /><updated>2024-01-22T07:07:05+00:00</updated><published>2024-01-22T07:07:05+00:00</published><title>RAG vs. full context</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;in a RAG application, I am using FAISS as retriever:&lt;/p&gt; &lt;p&gt;&lt;code&gt;retriever = vectorstore.as_retriever(search_kwargs={&amp;#39;k&amp;#39;: 3, &amp;#39;score_treshold&amp;#39;: 0.9}, search_type=&amp;quot;similarity&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;retriever.get_relevant_documents(&amp;quot;- I am Karl and I play soccer&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;However when changing the Score-Treshold I am still getting back the same documents. So there is no difference if I set it to 0.1 or 0.9.&lt;/p&gt; &lt;p&gt;In my understanding it should work as follows:&lt;/p&gt; &lt;p&gt;- Search the top 3 docs that have a similarity score of 0.9 or higher.&lt;/p&gt; &lt;p&gt;- If for example only one doc has a higher similarity than 0.9, only retrieve one doc.&lt;/p&gt; &lt;p&gt;- But: it is always retrieving 3 Docs, even if they are not similar&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Is this assumption correct or how can I make it work?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ctf42/faiss_as_retriever_score_treshold_not_working/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ctf42/faiss_as_retriever_score_treshold_not_working/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ctf42</id><link href="https://www.reddit.com/r/LangChain/comments/19ctf42/faiss_as_retriever_score_treshold_not_working/" /><updated>2024-01-22T11:20:30+00:00</updated><published>2024-01-22T11:20:30+00:00</published><title>FAISS as Retriever: Score Treshold not working</title></entry><entry><author><name>/u/PrimaryHeat5864</name><uri>https://www.reddit.com/user/PrimaryHeat5864</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m now working in an AI company, and we&amp;#39;re developing infra products to enhance RAG. As the product marketing, it&amp;#39;s important to hear from the community. I want to know:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;How necessary do you think the RAG project can be for your current business?&lt;/li&gt; &lt;li&gt;What are the primary challenges you face with the current implementation of RAG?&lt;/li&gt; &lt;li&gt;Which embedding model you are using nowÔºü&lt;/li&gt; &lt;li&gt;Have you considered finding a better Embedding model to get better results from RAG?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I&amp;#39;m looking forward to seeing your reply from anyone who is exploring RAG for real production. You are also welcome to share your insights via the &lt;a href=&quot;https://forms.gle/xkyBpruTC7twZxSz7&quot;&gt;survey&lt;/a&gt;, and I‚Äòll then contact you to discuss future collaboration opportunities. You may find more information about our product, the Jina Embeddings model in the survey form. And our Embeddings have been integrated into Langchain already. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/PrimaryHeat5864&quot;&gt; /u/PrimaryHeat5864 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19crogm/survey_about_retrieval_augmented_generation_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19crogm/survey_about_retrieval_augmented_generation_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19crogm</id><link href="https://www.reddit.com/r/LangChain/comments/19crogm/survey_about_retrieval_augmented_generation_rag/" /><updated>2024-01-22T09:16:43+00:00</updated><published>2024-01-22T09:16:43+00:00</published><title>Survey about Retrieval Augmented Generation (RAG) in Real Production</title></entry><entry><author><name>/u/Adam-Schroeder</name><uri>https://www.reddit.com/user/Adam-Schroeder</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/Tm3xcm8pFutyjWhY5DD2viOOuO0c_TRKig3pFRimUEw.jpg&quot; alt=&quot;Create AI Chatbots for Websites in Python - EmbedChain Dash&quot; title=&quot;Create AI Chatbots for Websites in Python - EmbedChain Dash&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Everyone,I just created a free video tutorial showing how to build an AI Chatbots for Beginners in Python. We&amp;#39;ll use the EmbedChain (built on top of LangChain) and Dash libraries, and we&amp;#39;ll learn the core principles of training and interacting with your bot. I hope you learn a lot.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/tmOmTBEdNrE&quot;&gt;https://youtu.be/tmOmTBEdNrE&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/tq1ovgfihxdc1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b4e1593532e2f396d0397ec80161020a30d14b69&quot;&gt;https://preview.redd.it/tq1ovgfihxdc1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b4e1593532e2f396d0397ec80161020a30d14b69&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Adam-Schroeder&quot;&gt; /u/Adam-Schroeder &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19coe4m</id><media:thumbnail url="https://b.thumbs.redditmedia.com/Tm3xcm8pFutyjWhY5DD2viOOuO0c_TRKig3pFRimUEw.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/" /><updated>2024-01-22T05:33:29+00:00</updated><published>2024-01-22T05:33:29+00:00</published><title>Create AI Chatbots for Websites in Python - EmbedChain Dash</title></entry><entry><author><name>/u/Downtown_Repeat7455</name><uri>https://www.reddit.com/user/Downtown_Repeat7455</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cus3v/wht_chat_histrory/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/3aqbGyeHXrqzX7N29Gq7PgrtI1O-3TAwp1vfiPLX5GU.jpg&quot; alt=&quot;wht chat_histrory&quot; title=&quot;wht chat_histrory&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I know this is not related langchain. somehow i am unable to post in python group. why the hell this is showing error. chat_history I declared at 99. why its showingerror at 106 but not at 108&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/4e8lqlgolzdc1.png?width=1324&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=277c36af1e06d189b047d50ada64a7b07001ed8c&quot;&gt;https://preview.redd.it/4e8lqlgolzdc1.png?width=1324&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=277c36af1e06d189b047d50ada64a7b07001ed8c&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Downtown_Repeat7455&quot;&gt; /u/Downtown_Repeat7455 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cus3v/wht_chat_histrory/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cus3v/wht_chat_histrory/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19cus3v</id><media:thumbnail url="https://b.thumbs.redditmedia.com/3aqbGyeHXrqzX7N29Gq7PgrtI1O-3TAwp1vfiPLX5GU.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/19cus3v/wht_chat_histrory/" /><updated>2024-01-22T12:42:03+00:00</updated><published>2024-01-22T12:42:03+00:00</published><title>wht chat_histrory</title></entry><entry><author><name>/u/HelicopterNext3726</name><uri>https://www.reddit.com/user/HelicopterNext3726</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on an innovative gym app that incorporates AI for personalized workout plans and diet charts, sourced from a gym owner&amp;#39;s knowledge base.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the scoop: &lt;/p&gt; &lt;p&gt;Users can input their daily attendance, receive workout plans(from trainers), track meals, and chat with an AI bot. &lt;/p&gt; &lt;p&gt;The Ai bot should consider knowledge based and user&amp;#39;s previous history texts and their database(their workout and meal history and plan(weightloss) and their Medical condition(optional) ) and provide optimal answers according to the users queries&lt;/p&gt; &lt;p&gt;My tech arsenal I like to use includes &lt;/p&gt; &lt;p&gt;Rag, LangChain, Supabase, supabase - VectorDB, and Next.js. I&amp;#39;m eager to hear your thoughts and insights on how to make this ambitious project a reality. Any advice, suggestions, or experiences you can share would be immensely helpful! Thanks a ton! üí™ü§ñ&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HelicopterNext3726&quot;&gt; /u/HelicopterNext3726 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19csujt/developing_an_aipowered_gym_chat_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19csujt/developing_an_aipowered_gym_chat_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19csujt</id><link href="https://www.reddit.com/r/LangChain/comments/19csujt/developing_an_aipowered_gym_chat_app/" /><updated>2024-01-22T10:42:11+00:00</updated><published>2024-01-22T10:42:11+00:00</published><title>Developing an AI-Powered Gym chat app</title></entry><entry><author><name>/u/Zestyclose-Bid-487</name><uri>https://www.reddit.com/user/Zestyclose-Bid-487</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zestyclose-Bid-487&quot;&gt; /u/Zestyclose-Bid-487 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cs6vb/any_support_for_agent_with_ope_source_models_such/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cs6vb/any_support_for_agent_with_ope_source_models_such/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19cs6vb</id><link href="https://www.reddit.com/r/LangChain/comments/19cs6vb/any_support_for_agent_with_ope_source_models_such/" /><updated>2024-01-22T09:55:03+00:00</updated><published>2024-01-22T09:55:03+00:00</published><title>any support for Agent with ope source models such as mistral,lama 2 ?</title></entry><entry><author><name>/u/LARGE_LANGUE_MODEL</name><uri>https://www.reddit.com/user/LARGE_LANGUE_MODEL</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I already have some basic knowledge about langchain and LLM. Now I want to apply it to a production environment, but I realize that basic knowledge is not enough. I want to make a news Q&amp;amp;A chatbot application using RAG and use API access tools to get real-time information about cryptocurrencies. Does anyone have a sample repo that I can refer to? Thank you very much&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LARGE_LANGUE_MODEL&quot;&gt; /u/LARGE_LANGUE_MODEL &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cgrpd/chatbot_rag_and_tool_about_crypto/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cgrpd/chatbot_rag_and_tool_about_crypto/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19cgrpd</id><link href="https://www.reddit.com/r/LangChain/comments/19cgrpd/chatbot_rag_and_tool_about_crypto/" /><updated>2024-01-21T23:11:18+00:00</updated><published>2024-01-21T23:11:18+00:00</published><title>Chatbot RAG and tool about crypto</title></entry><entry><author><name>/u/modularmindapp</name><uri>https://www.reddit.com/user/modularmindapp</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cusqq/experience_the_versatility_of_modular_mind_the_ai/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/NjR1cTJtZWlsemRjMfKU9fdxNNxIwelASad_pYPHkm1Xj5ZQoOTC5K5c6sEP.png?width=140&amp;amp;height=140&amp;amp;crop=140:140,smart&amp;amp;format=jpg&amp;amp;v=enabled&amp;amp;lthumb=true&amp;amp;s=68c525b161d30bb346e07e13a95594398118726d&quot; alt=&quot;Experience the versatility of Modular Mind, the AI platform that supercharges competitor analysis, content generation, and research automation, in seconds.&quot; title=&quot;Experience the versatility of Modular Mind, the AI platform that supercharges competitor analysis, content generation, and research automation, in seconds.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/modularmindapp&quot;&gt; /u/modularmindapp &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/k2lhvgwflzdc1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cusqq/experience_the_versatility_of_modular_mind_the_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19cusqq</id><media:thumbnail url="https://external-preview.redd.it/NjR1cTJtZWlsemRjMfKU9fdxNNxIwelASad_pYPHkm1Xj5ZQoOTC5K5c6sEP.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=68c525b161d30bb346e07e13a95594398118726d" /><link href="https://www.reddit.com/r/LangChain/comments/19cusqq/experience_the_versatility_of_modular_mind_the_ai/" /><updated>2024-01-22T12:43:09+00:00</updated><published>2024-01-22T12:43:09+00:00</published><title>Experience the versatility of Modular Mind, the AI platform that supercharges competitor analysis, content generation, and research automation, in seconds.</title></entry><entry><author><name>/u/redd-dev</name><uri>https://www.reddit.com/user/redd-dev</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, what framework or tools do I use if I wanted to build an open-sourced LLM chatbot which is enterprise scalable to multiple users?&lt;/p&gt; &lt;p&gt;A framework/tool I am thinking of is Langchain. There won‚Äôt be any fine-tuning for my chatbot so I am not sure if I need to use Langchain.&lt;/p&gt; &lt;p&gt;Would there be a different suitable framework to use if I wanted to build for a small to mid sized enterprise compared to a large enterprise?&lt;/p&gt; &lt;p&gt;I am thinking of using AWS to host the LLM model. &lt;/p&gt; &lt;p&gt;Any help would really be appreciated. Many thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/redd-dev&quot;&gt; /u/redd-dev &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bzgh1/what_framework_to_use_to_build_an_opensourced_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bzgh1/what_framework_to_use_to_build_an_opensourced_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bzgh1</id><link href="https://www.reddit.com/r/LangChain/comments/19bzgh1/what_framework_to_use_to_build_an_opensourced_llm/" /><updated>2024-01-21T09:11:44+00:00</updated><published>2024-01-21T09:11:44+00:00</published><title>What framework to use to build an open-sourced LLM chatbot which is enterprise scalable to multiple users</title></entry><entry><author><name>/u/sharrajesh</name><uri>https://www.reddit.com/user/sharrajesh</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Not sure where to ask this question&lt;/p&gt; &lt;p&gt;Why: I am seeing mild success with openai assistant api on their portal platform.openai.com. However it&amp;#39;s impossible to test custom functions on their portal. DevX of that api is not straightforward. I seem to like Langchain attempts to wrap this capability. However it&amp;#39;s missing this ability to register custom functions. &lt;/p&gt; &lt;p&gt;Please guide me if there&amp;#39;s a work around?&lt;/p&gt; &lt;hr/&gt; &lt;h2&gt;Feature Request created by chat.langchain.com after I couldn&amp;#39;t get my answer on this help portal&lt;/h2&gt; &lt;p&gt;Subject: Feature Request: Custom Function Registration in Langchain Dear Langchain Team, I hope this message finds you well. I am a user of the Langchain platform and have been exploring the capabilities of the OpenAI Assistant integration. While working with the platform, I noticed that there is no explicit documentation or mention of a register_function method for registering custom functions with the OpenAI Assistant. I believe that having the ability to register custom functions would greatly enhance the flexibility and extensibility of the OpenAI Assistant. This feature would allow users to define their own functions and seamlessly integrate them into the assistant&amp;#39;s conversational flow. Specifically, I envision a method similar to register_function that would enable users to define custom functions in Python and register them with the OpenAI Assistant. These registered functions could then be invoked during the conversation, allowing for more dynamic and interactive interactions with the assistant. I kindly request that the Langchain team consider adding this feature to the platform. It would empower users to create more tailored and specialized conversational experiences with the OpenAI Assistant. Thank you for your attention to this feature request. I appreciate your dedication to continuously improving the Langchain platform and look forward to any updates or feedback regarding this request. Best regards, [Your Name]&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sharrajesh&quot;&gt; /u/sharrajesh &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19c9969/request_to_improve_integration_with_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19c9969/request_to_improve_integration_with_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19c9969</id><link href="https://www.reddit.com/r/LangChain/comments/19c9969/request_to_improve_integration_with_openai/" /><updated>2024-01-21T17:57:50+00:00</updated><published>2024-01-21T17:57:50+00:00</published><title>Request to improve integration with openai assistant api to add custom functions registered inside platform.openai.com</title></entry><entry><author><name>/u/ep3gotts</name><uri>https://www.reddit.com/user/ep3gotts</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;*Guidance Scale* Stable diffusion setting, ‚Äúprompt strength‚Äù&lt;/p&gt; &lt;p&gt;&amp;gt; Guidance Scale: controls how similar the generated image will be to the prompt. A higher guidance scale means the model will try to generate an image that follows the prompt more strictly. A lower guidance scale means the model will have more creativity.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ep3gotts&quot;&gt; /u/ep3gotts &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bz3o1/is_llm_temperature_setting_similar_to_guidance/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bz3o1/is_llm_temperature_setting_similar_to_guidance/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bz3o1</id><link href="https://www.reddit.com/r/LangChain/comments/19bz3o1/is_llm_temperature_setting_similar_to_guidance/" /><updated>2024-01-21T08:47:06+00:00</updated><published>2024-01-21T08:47:06+00:00</published><title>Is LLM &quot;temperature&quot; setting similar to &quot;Guidance scale&quot; from Stable Diffusion?</title></entry><entry><author><name>/u/Sensitive-Garden6776</name><uri>https://www.reddit.com/user/Sensitive-Garden6776</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys,&lt;/p&gt; &lt;p&gt;I am deciding to implement RAG pipeline into my code&lt;/p&gt; &lt;p&gt;between Langchain and Llama Index, what RAG capability yield better performance and what&amp;#39;s the main different?&lt;/p&gt; &lt;p&gt;Thanks a lot guys!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sensitive-Garden6776&quot;&gt; /u/Sensitive-Garden6776 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bnjnz/langchain_vs_llama_index/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bnjnz/langchain_vs_llama_index/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bnjnz</id><link href="https://www.reddit.com/r/LangChain/comments/19bnjnz/langchain_vs_llama_index/" /><updated>2024-01-20T22:18:19+00:00</updated><published>2024-01-20T22:18:19+00:00</published><title>Langchain vs Llama Index</title></entry><entry><author><name>/u/cambridgecoder415</name><uri>https://www.reddit.com/user/cambridgecoder415</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Title, is chatGPT the best llm to help with the python API?&lt;/p&gt; &lt;p&gt;üôè&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cambridgecoder415&quot;&gt; /u/cambridgecoder415 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bqj57/is_there_a_chat_to_help_with_the_langchain_api/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bqj57/is_there_a_chat_to_help_with_the_langchain_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bqj57</id><link href="https://www.reddit.com/r/LangChain/comments/19bqj57/is_there_a_chat_to_help_with_the_langchain_api/" /><updated>2024-01-21T00:34:19+00:00</updated><published>2024-01-21T00:34:19+00:00</published><title>Is there a chat to help with the langchain API?</title></entry><entry><author><name>/u/bigluzer</name><uri>https://www.reddit.com/user/bigluzer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;first time long time. love the platform.&lt;/p&gt; &lt;p&gt;we have build custom tools and agents.&lt;/p&gt; &lt;p&gt;i am trying to extend our implementation with the following&lt;/p&gt; &lt;p&gt;- custom meta-prompts - that are stored on the firm or individual level and could be used as part of a workflow&lt;/p&gt; &lt;p&gt;- Custom meta-data storage - like a list of URLs. this would allow the user to edit this list, and then a custom agent (web scraper, etc) could reference it&lt;/p&gt; &lt;p&gt;- multi-agents? our function calls can only do one thing at a time (one scrape, etc). is there a way to run multiple, in parallel, and return together?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bigluzer&quot;&gt; /u/bigluzer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bfisz/langchain_questions_advanced_use_cases/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bfisz/langchain_questions_advanced_use_cases/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bfisz</id><link href="https://www.reddit.com/r/LangChain/comments/19bfisz/langchain_questions_advanced_use_cases/" /><updated>2024-01-20T16:28:10+00:00</updated><published>2024-01-20T16:28:10+00:00</published><title>LangChain Questions - Advanced Use Cases</title></entry><entry><author><name>/u/rahabash</name><uri>https://www.reddit.com/user/rahabash</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Howdy. I have a project which initially made use of LlamaIndex and GithubRepositoryReader to locally persist a vector store containing the contents of a github code repository that I will now be looking to instead integrate into Azure AI search service.&lt;/p&gt; &lt;p&gt;Does anyone know of any resources they can point me to which demonstrates such a project (generating embeddings for a code repo, uploading the docs to azure ai search, q&amp;amp;a against said search service)&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rahabash&quot;&gt; /u/rahabash &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bn28q/integrating_azure_ai_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bn28q/integrating_azure_ai_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bn28q</id><link href="https://www.reddit.com/r/LangChain/comments/19bn28q/integrating_azure_ai_search/" /><updated>2024-01-20T21:56:54+00:00</updated><published>2024-01-20T21:56:54+00:00</published><title>Integrating Azure AI search</title></entry><entry><author><name>/u/99OG121314</name><uri>https://www.reddit.com/user/99OG121314</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have tested two retriever methods, 1) Pinecone Hybrid Search and 2) ParentDocument Retriever.&lt;/p&gt; &lt;p&gt;Generally, the ParentDocument Retriever performs a lot better but there are instances where the Hybrid search finds interesting nuggets.&lt;/p&gt; &lt;p&gt;I wanted to know, if using the ensemble retriever, I can do a combination of BM25 and ParentDocument? Has anyone tried this?&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/99OG121314&quot;&gt; /u/99OG121314 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bjuov/ensemble_retriever_with_parentdoc/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bjuov/ensemble_retriever_with_parentdoc/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bjuov</id><link href="https://www.reddit.com/r/LangChain/comments/19bjuov/ensemble_retriever_with_parentdoc/" /><updated>2024-01-20T19:36:22+00:00</updated><published>2024-01-20T19:36:22+00:00</published><title>Ensemble Retriever with ParentDoc</title></entry><entry><author><name>/u/Sim_Check</name><uri>https://www.reddit.com/user/Sim_Check</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;d like to modify the model path using GPT4AllEmbeddings and use a model I already downloading from the browser (the all-MiniLM-L6-v2-f16.gguf model, the same that GPT4AllEmbeddings downloads by default).&lt;/p&gt; &lt;p&gt;I need it to create RAG chatbot completely offline.&lt;/p&gt; &lt;p&gt;The langchain documentation chatbot suggests me to use:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;from langchain_community.embeddings &lt;strong&gt;import&lt;/strong&gt; GPT4AllEmbeddings&lt;br/&gt; model_path = &amp;quot;/path/to/your/model.bin&amp;quot;&lt;br/&gt; gpt4all_embd = GPT4AllEmbeddings(model=model_path)&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;I tried it but it does not work. It completely ignore the model path.&lt;/p&gt; &lt;p&gt;Is there something I&amp;#39;m missing?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sim_Check&quot;&gt; /u/Sim_Check &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19biswa/gpt4allembeddings_modify_model_path/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19biswa/gpt4allembeddings_modify_model_path/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19biswa</id><link href="https://www.reddit.com/r/LangChain/comments/19biswa/gpt4allembeddings_modify_model_path/" /><updated>2024-01-20T18:51:23+00:00</updated><published>2024-01-20T18:51:23+00:00</published><title>GPT4AllEmbeddings modify model path</title></entry><entry><author><name>/u/worldender999</name><uri>https://www.reddit.com/user/worldender999</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Howdy. I am an experienced software engineer working on my first ever project using an LLM. My goal is to use it to replace a rules engine for transaction categorization in an application I have. I will feed in the new transactions, list of categories, plus data on past categorized transactions, to produce the new output. All results will go through manual review prior to being accepted, which is the current behavior with the existing rules engine anyway.&lt;/p&gt; &lt;p&gt;This will be deployed to my home server which has a powerful CPU, lots of RAM, but a shit GPU. Because of this, my plan is to use a cloud LLM like ChatGPT. However I want to run the Vector database (Cassandra, chroma, etc. haven&amp;#39;t picked yet) on the server. I know the embeddings will be generated by the LLM and just stored in the Vector DB, so I don&amp;#39;t need to worry about the hardware needs for that.&lt;/p&gt; &lt;p&gt;My question is around querying the Vector DB. Are there special hardware requirements (ie, GPU-preferred operations) for running those queries? I&amp;#39;m not worried about operations that a CPU can handle well, only stuff that requires a beefier GPU.&lt;/p&gt; &lt;p&gt;Thanks in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/worldender999&quot;&gt; /u/worldender999 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bcztd/question_about_hardware_requirements_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bcztd/question_about_hardware_requirements_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bcztd</id><link href="https://www.reddit.com/r/LangChain/comments/19bcztd/question_about_hardware_requirements_for/" /><updated>2024-01-20T14:31:50+00:00</updated><published>2024-01-20T14:31:50+00:00</published><title>Question about hardware requirements for LangChain and vector DBs</title></entry></feed>