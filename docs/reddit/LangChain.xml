<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-04-17T12:55:56+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/rockstarflo</name><uri>https://www.reddit.com/user/rockstarflo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I just stumbled upon this:&lt;br/&gt; &lt;a href=&quot;https://r.jina.ai&quot;&gt;https://r.jina.ai&lt;/a&gt;&amp;lt;website\_url here&amp;gt;&lt;/p&gt; &lt;p&gt;You can convert URLs to Markdown. This format is then better understood by LLMs compared to HTML. I think it can be used for Agents or RAG with web searches. I use it to generate synthetic data for a specific website.&lt;br/&gt; Example usage&lt;br/&gt; &lt;a href=&quot;https://r.jina.ai/https://en.wikipedia.org/wiki/Monkey_Island&quot;&gt;https://r.jina.ai/https://en.wikipedia.org/wiki/Monkey_Island&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rockstarflo&quot;&gt; /u/rockstarflo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c691qg/reader_llmfriendly_websites/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c691qg/reader_llmfriendly_websites/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c691qg</id><link href="https://www.reddit.com/r/LangChain/comments/1c691qg/reader_llmfriendly_websites/" /><updated>2024-04-17T12:52:19+00:00</updated><published>2024-04-17T12:52:19+00:00</published><title>Reader - LLM-Friendly websites</title></entry><entry><author><name>/u/LaAlice</name><uri>https://www.reddit.com/user/LaAlice</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build an LCEL chain. However, at the n-th step, a cypher graph query gets generated. The next step in the chain should be that the query gets executed and the result gets passed on to the next step. I have a Neo4jGraph object, but I don&amp;#39;t know how to integrate it into the chain. I thought about writing a function that gets the query, executes it and returns the result, but I don&amp;#39;t know how to pass the graph to that function. Is there some element, for example a retriever, that I can use?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LaAlice&quot;&gt; /u/LaAlice &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68ye8/include_graph_query_into_lcel_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68ye8/include_graph_query_into_lcel_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c68ye8</id><link href="https://www.reddit.com/r/LangChain/comments/1c68ye8/include_graph_query_into_lcel_chain/" /><updated>2024-04-17T12:48:04+00:00</updated><published>2024-04-17T12:48:04+00:00</published><title>Include graph query into LCEL chain</title></entry><entry><author><name>/u/cerebriumBoss</name><uri>https://www.reddit.com/user/cerebriumBoss</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68lce/creating_an_executive_assistant_using_langchain/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/iiaz5GsigQoVvtdwJm2jDbRcDCFphCRBecbfTzMEjw8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1b8f1a1d24dc2aaa9b27e6f4a84ecc64f4a97656&quot; alt=&quot;Creating an Executive Assistant using LangChain, LangSmith, Cerebrium and Cal.com&quot; title=&quot;Creating an Executive Assistant using LangChain, LangSmith, Cerebrium and Cal.com&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cerebriumBoss&quot;&gt; /u/cerebriumBoss &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.cerebrium.ai/blog/creating-an-executive-assistant-using-langchain-langsmith-cerebrium-and-cal-com&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68lce/creating_an_executive_assistant_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c68lce</id><media:thumbnail url="https://external-preview.redd.it/iiaz5GsigQoVvtdwJm2jDbRcDCFphCRBecbfTzMEjw8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1b8f1a1d24dc2aaa9b27e6f4a84ecc64f4a97656" /><link href="https://www.reddit.com/r/LangChain/comments/1c68lce/creating_an_executive_assistant_using_langchain/" /><updated>2024-04-17T12:30:10+00:00</updated><published>2024-04-17T12:30:10+00:00</published><title>Creating an Executive Assistant using LangChain, LangSmith, Cerebrium and Cal.com</title></entry><entry><author><name>/u/mutexs</name><uri>https://www.reddit.com/user/mutexs</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, guys!&lt;/p&gt; &lt;p&gt;I&amp;#39;m a newbie in LangChain and need help.&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on a Next.js project for a chatbot where I&amp;#39;m using a RetrievalQAChain. Now, I also want to make external API requests. For that, I&amp;#39;m implementing an APIChain. However, I&amp;#39;m struggling to combine both chains to return the output as a single chain.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mutexs&quot;&gt; /u/mutexs &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68juh/seeking_assistance_in_combining_two_chains/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68juh/seeking_assistance_in_combining_two_chains/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c68juh</id><link href="https://www.reddit.com/r/LangChain/comments/1c68juh/seeking_assistance_in_combining_two_chains/" /><updated>2024-04-17T12:28:03+00:00</updated><published>2024-04-17T12:28:03+00:00</published><title>Seeking assistance in combining two chains</title></entry><entry><author><name>/u/GrizzyLizz</name><uri>https://www.reddit.com/user/GrizzyLizz</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Im still new to Langchain and making use of it (though I am proficient enough with Python). I wanted to build a chatbot application where user inputs to the AI would make use of some provided image. As per my understanding, this is what RAG is for. However, I cant find an example where an LLM application is retreiving images passed to it. Here is the workflow I want to be able to implement:&lt;/p&gt; &lt;p&gt;- User provides some prompt with an image. This image gets stored in the backend by the application. The LLM part of the application then uses this image or any previously provided images as contextual information to reply to the prompt.&lt;/p&gt; &lt;p&gt;- If the prompt requests for one of the images back for e.g. &amp;quot;Can you go through the images and get back the one which is in black and white&amp;quot;, then the application finds such an image and returns it or replies with a negative&lt;/p&gt; &lt;p&gt;Is the second part of this flow achievable using Langchain? Or would I have to do it some other way?&lt;br/&gt; Note: i dont specifically want a model which can identify black and white images but basically perform some kind of semantic search through the images. The prompt may be &amp;quot;Find all the images I provided and give back the ones with a tree in it&amp;quot;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/GrizzyLizz&quot;&gt; /u/GrizzyLizz &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c66lrw/can_an_llm_application_retrieve_imagesusing_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c66lrw/can_an_llm_application_retrieve_imagesusing_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c66lrw</id><link href="https://www.reddit.com/r/LangChain/comments/1c66lrw/can_an_llm_application_retrieve_imagesusing_rag/" /><updated>2024-04-17T10:41:13+00:00</updated><published>2024-04-17T10:41:13+00:00</published><title>Can an LLM application retrieve images(using RAG or some other technique)?</title></entry><entry><author><name>/u/J-Kob</name><uri>https://www.reddit.com/user/J-Kob</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks!&lt;/p&gt; &lt;p&gt;We&amp;#39;re continuing to iterate on our documentation structure to make it easier to find relevant pages. We&amp;#39;re wondering what people think of top-level &amp;quot;tutorial&amp;quot;, &amp;quot;how to guides&amp;quot;, &amp;quot;conceptual guide&amp;quot; distinctions.&lt;/p&gt; &lt;p&gt;Page content is still WIP, but we were hoping to get feedback on &lt;strong&gt;the structure&lt;/strong&gt; sooner rather than later.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve linked the build we&amp;#39;re iterating on below. Please let us know if you have any thoughts or reactions - do you think this would help you find the information you need more effectively?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://langchain-git-harrison-new-docs-langchain.vercel.app/docs/get_started/introduction&quot;&gt;https://langchain-git-harrison-new-docs-langchain.vercel.app/docs/get_started/introduction&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/J-Kob&quot;&gt; /u/J-Kob &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5l53d/feedback_wanted_langchain_documentation_structure/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5l53d/feedback_wanted_langchain_documentation_structure/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5l53d</id><link href="https://www.reddit.com/r/LangChain/comments/1c5l53d/feedback_wanted_langchain_documentation_structure/" /><updated>2024-04-16T16:57:06+00:00</updated><published>2024-04-16T16:57:06+00:00</published><title>Feedback wanted: LangChain documentation structure</title></entry><entry><author><name>/u/FartingUnicyclist</name><uri>https://www.reddit.com/user/FartingUnicyclist</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys,&lt;/p&gt; &lt;p&gt;Does anyone know how to stream the output from each of the runnable components for a LCEL implementation of a chain? Like what happens when you turn on verbose=true for an agent and it outputs all the steps it is taking. Or like how each runnables are traced in Langsmith.&lt;/p&gt; &lt;p&gt;I need to do this because the full chain takes 50 secs on average to run and this is a bad UX. Using streaming endpoint is not helpful because the final response from the chain is not alot, so I am not looking for the output streaming but streaming of the individual runnables in the LCEL.&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FartingUnicyclist&quot;&gt; /u/FartingUnicyclist &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c64rf2/streaming_individual_runnable_component_for_lcel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c64rf2/streaming_individual_runnable_component_for_lcel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c64rf2</id><link href="https://www.reddit.com/r/LangChain/comments/1c64rf2/streaming_individual_runnable_component_for_lcel/" /><updated>2024-04-17T08:37:19+00:00</updated><published>2024-04-17T08:37:19+00:00</published><title>Streaming individual runnable component for LCEL</title></entry><entry><author><name>/u/ZuckyFox</name><uri>https://www.reddit.com/user/ZuckyFox</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there any small language models available in AWS? I was searching but mostly I found llms? We need some slm like flan-t5 models that can be used for classification task.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ZuckyFox&quot;&gt; /u/ZuckyFox &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c62c2a/slm_in_aws/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c62c2a/slm_in_aws/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c62c2a</id><link href="https://www.reddit.com/r/LangChain/comments/1c62c2a/slm_in_aws/" /><updated>2024-04-17T05:53:09+00:00</updated><published>2024-04-17T05:53:09+00:00</published><title>SLM in AWS?</title></entry><entry><author><name>/u/hedonist_kid</name><uri>https://www.reddit.com/user/hedonist_kid</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello&lt;/p&gt; &lt;p&gt;So I am able to connect a live postgres database and use the sql agent with open ai to a wide variety answer questions about the database and generate sql queries as well. I wanted to know if there are any other useful agents for databases maybe something to visualize, I used llamaindex in collab with a pandas dataframe and got very good results. Also would it be worthwhile to try and build your own agent. I would also want to know if anyone has tried open source models with tje langchain sql agent. &lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hedonist_kid&quot;&gt; /u/hedonist_kid &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5vyfk/what_are_some_agents_which_can_be_used_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5vyfk/what_are_some_agents_which_can_be_used_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5vyfk</id><link href="https://www.reddit.com/r/LangChain/comments/1c5vyfk/what_are_some_agents_which_can_be_used_in/" /><updated>2024-04-17T00:21:59+00:00</updated><published>2024-04-17T00:21:59+00:00</published><title>What are some agents which can be used in addition to the sql agent for rag on db.</title></entry><entry><author><name>/u/Cool_Bhidu</name><uri>https://www.reddit.com/user/Cool_Bhidu</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Guys&lt;br/&gt; I have interview scheduled next week about Langchain. But I am not sure what will be asked? I wanted your inputs on what should I prepare. &lt;/p&gt; &lt;p&gt;My background - I have built multi-doc RAG. Technologies used - Langchain, Chroma, Streamlit, &lt;a href=&quot;https://unstrctured.io&quot;&gt;unstrctured.io&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Please any help is appreciated &lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Cool_Bhidu&quot;&gt; /u/Cool_Bhidu &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5r9qj/langchain_interview_what_things_to_prepare/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5r9qj/langchain_interview_what_things_to_prepare/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5r9qj</id><link href="https://www.reddit.com/r/LangChain/comments/1c5r9qj/langchain_interview_what_things_to_prepare/" /><updated>2024-04-16T21:03:01+00:00</updated><published>2024-04-16T21:03:01+00:00</published><title>Langchain Interview. What things to prepare</title></entry><entry><author><name>/u/TheGreatZorbo</name><uri>https://www.reddit.com/user/TheGreatZorbo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let&amp;#39;s say I have a service I want to access inside a tool. Or I want to pass in a session ID or some session based state that I don&amp;#39;t want to pass via the agent. &lt;/p&gt; &lt;p&gt;I could obviously declare some things globally, but that isn&amp;#39;t appropriate for everything. &lt;/p&gt; &lt;p&gt;My first thought was wrapping tools in a class that contains their dependencies. I&amp;#39;ve tried different variants of this, but seem to hit all kinds of issues. The documentation contains trivial use cases where we&amp;#39;re passing basic types around, nothing more complex.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;What are people doing for tools which have more complex dependencies? How are they injecting those into tools, in a langchain supported way, without making everything global?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TheGreatZorbo&quot;&gt; /u/TheGreatZorbo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5slrj/whats_the_best_way_to_pass_dependencies_into/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5slrj/whats_the_best_way_to_pass_dependencies_into/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5slrj</id><link href="https://www.reddit.com/r/LangChain/comments/1c5slrj/whats_the_best_way_to_pass_dependencies_into/" /><updated>2024-04-16T21:57:12+00:00</updated><published>2024-04-16T21:57:12+00:00</published><title>what's the best way to pass dependencies into langchain tools?</title></entry><entry><author><name>/u/Temporary-Size7310</name><uri>https://www.reddit.com/user/Temporary-Size7310</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, I must use old langchain method to generate an output:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;agent_executor = initialize_agent( tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, max_execution_time=4, early_stopping_method=&amp;quot;generate&amp;quot;, verbose=False, handle_parsing_errors=True, memory=memory, ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;early_stopping_method works well using &amp;quot;generate&amp;quot; at the 4th iteration. &lt;/p&gt; &lt;p&gt;If I use new method:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;agent = create_react_agent(llm, tools, prompt) agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False, handle_parsing_errors=True, early_stopping_method=&amp;quot;generate&amp;quot;, max_iterations=4) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It&amp;#39;s like &amp;quot;generate&amp;quot; is not implemented:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;quot;/python3.11/site-packages/langchain/agents/agent.py&amp;quot;, line 127, in return_stopped_response raise ValueError( ValueError: Got unsupported early_stopping_method `generate` &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If I use &amp;quot;force&amp;quot; with and without max_iterations:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Agent stopped due to iteration limit or time limit. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The main issue is i&amp;#39;m using date_time variable, so value change every second for others tools it works like a charm.&lt;/p&gt; &lt;p&gt;Has anyone solved this issue ? Or maybe myearly stopping method is outdated&lt;br/&gt; Thank you in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Temporary-Size7310&quot;&gt; /u/Temporary-Size7310 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5ljzo/early_stopping_method_generate/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5ljzo/early_stopping_method_generate/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5ljzo</id><link href="https://www.reddit.com/r/LangChain/comments/1c5ljzo/early_stopping_method_generate/" /><updated>2024-04-16T17:13:24+00:00</updated><published>2024-04-16T17:13:24+00:00</published><title>Early stopping method : generate</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Check out this demo on how I developed a Multi-Agent system to first generate an Interview panel given job role and than these interviewers interview the candidate one by one (sequentially) , give feedback and eventually all the feedbacks are combined to select the candidate. Find the code explanations &amp;amp; demo for automated interview for Junior Product Manager here : &lt;a href=&quot;https://youtu.be/or36qevjxGE?si=cM1LMhe5J_hnpyFO&quot;&gt;https://youtu.be/or36qevjxGE?si=cM1LMhe5J_hnpyFO&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5csx7/multiagent_interview_panel_using_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5csx7/multiagent_interview_panel_using_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5csx7</id><link href="https://www.reddit.com/r/LangChain/comments/1c5csx7/multiagent_interview_panel_using_langgraph/" /><updated>2024-04-16T10:33:21+00:00</updated><published>2024-04-16T10:33:21+00:00</published><title>Multi-Agent Interview Panel using LangGraph</title></entry><entry><author><name>/u/Equivalent-West-9389</name><uri>https://www.reddit.com/user/Equivalent-West-9389</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am trying to develop an application that requires function calling and responding in everyday language based on the context of user input. I see in langchain we have &lt;a href=&quot;https://js.langchain.com/docs/integrations/chat/ollama&quot;&gt;Ollama&lt;/a&gt; and &lt;a href=&quot;https://js.langchain.com/docs/integrations/chat/ollama_functions&quot;&gt;Ollama functions&lt;/a&gt;; I would like to use the Ollama Function first to check if the user needs to execute any function, then if not respond with regular Ollama, and if it does, get the function data and pass it into Ollama and response usually.&lt;/p&gt; &lt;p&gt;How is this possible?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Equivalent-West-9389&quot;&gt; /u/Equivalent-West-9389 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5n0aw/use_2_llm_1_for_function_calling_and_1_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5n0aw/use_2_llm_1_for_function_calling_and_1_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5n0aw</id><link href="https://www.reddit.com/r/LangChain/comments/1c5n0aw/use_2_llm_1_for_function_calling_and_1_for/" /><updated>2024-04-16T18:10:50+00:00</updated><published>2024-04-16T18:10:50+00:00</published><title>Use 2 LLM, 1 for function calling and 1 for Contextual Response.</title></entry><entry><author><name>/u/ArcuisAlezanzo</name><uri>https://www.reddit.com/user/ArcuisAlezanzo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Im trying building RAG LLM app for support analyst,my primary data is excel sheet with more than 6000 incidents(rows) with columns [Descrietion, Pesolution, Work notes]. Description column explains Incident Description Resolution column explains resolution provided to that Incident Work Notes column steps taken to solve incident.&lt;/p&gt; &lt;p&gt;User provides the new incident as prompt to the APP, expected functionality need to search similar incidents from data , then use that similar incident to generate approx resolution.&lt;/p&gt; &lt;p&gt;Resources available uses uses Azure ai search (for vector search) GPT 4&lt;/p&gt; &lt;p&gt;Should I clean data like, 1. Like removing special characters 2. Lowercase the all letters letters 3.lemmatization 4. Removing stop words like a , an &lt;/p&gt; &lt;p&gt;My major doubt if I embed the description of each incident as one document , does similarity search , take top k documents &lt;/p&gt; &lt;p&gt;What will K be? Will k be higher number or smaller number &lt;/p&gt; &lt;p&gt;Or any idea other cluster similar incidents ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ArcuisAlezanzo&quot;&gt; /u/ArcuisAlezanzo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5mrr1/need_architecture_help/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5mrr1/need_architecture_help/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5mrr1</id><link href="https://www.reddit.com/r/LangChain/comments/1c5mrr1/need_architecture_help/" /><updated>2024-04-16T18:01:37+00:00</updated><published>2024-04-16T18:01:37+00:00</published><title>Need architecture Help</title></entry><entry><author><name>/u/supreet02</name><uri>https://www.reddit.com/user/supreet02</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5l21i/rag_masterclass_practical_insights_from_exmeta/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/3NBtlITDQBL0okCx94aFnDP-6XwWLkbg5yC1f_F7G7U.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=da003574c667de720e0dfa6d36a9cdc3e5e00a96&quot; alt=&quot;RAG Masterclass: Practical Insights from Ex-Meta Pioneers on April 18th&quot; title=&quot;RAG Masterclass: Practical Insights from Ex-Meta Pioneers on April 18th&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/supreet02&quot;&gt; /u/supreet02 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://lu.ma/cognita-rag&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5l21i/rag_masterclass_practical_insights_from_exmeta/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c5l21i</id><media:thumbnail url="https://external-preview.redd.it/3NBtlITDQBL0okCx94aFnDP-6XwWLkbg5yC1f_F7G7U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=da003574c667de720e0dfa6d36a9cdc3e5e00a96" /><link href="https://www.reddit.com/r/LangChain/comments/1c5l21i/rag_masterclass_practical_insights_from_exmeta/" /><updated>2024-04-16T16:53:40+00:00</updated><published>2024-04-16T16:53:40+00:00</published><title>RAG Masterclass: Practical Insights from Ex-Meta Pioneers on April 18th</title></entry><entry><author><name>/u/LaAlice</name><uri>https://www.reddit.com/user/LaAlice</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Edit: This was solved by updating the langchain python package&lt;/p&gt; &lt;p&gt;This is my first time using langchain for QA on a csv file. My steps were CSVLoader --&amp;gt; RecursiveCharacterTextSplitter --&amp;gt; Chroma Vectorstore When I searched for a keyword on the vectorstore with vectorstore.search(&amp;quot;keyword&amp;quot;, search-type=&amp;quot;similarity&amp;quot;), a few documents were found. However, then I tried using a retriever with retriever=vectorstore.as_retriever(search_type=&amp;quot;similarity&amp;quot;). If I search for the same keyword I used before with retriever.invoke(&amp;quot;keyword&amp;quot;), I get the error AttributeError: &amp;#39;NoneType&amp;#39; object has no attribute &amp;#39;get&amp;#39; But I don&amp;#39;t understand why, as it worked directly on the vectorstore.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LaAlice&quot;&gt; /u/LaAlice &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5hzvh/retriever_gives_an_error/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5hzvh/retriever_gives_an_error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5hzvh</id><link href="https://www.reddit.com/r/LangChain/comments/1c5hzvh/retriever_gives_an_error/" /><updated>2024-04-16T14:49:39+00:00</updated><published>2024-04-16T14:49:39+00:00</published><title>Retriever gives an error</title></entry><entry><author><name>/u/Sensitive_Let_4239</name><uri>https://www.reddit.com/user/Sensitive_Let_4239</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, im new to all of this but i have retreived contact info from paper with a OCR into a .txt file but due to the OCR being inaccurate its all unorganised and stuff. Is it possbile to use Langchain to organise this data and make it more accurate (the &amp;quot;i&amp;quot; is often replaced with &amp;quot;l&amp;quot;) in a csv?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sensitive_Let_4239&quot;&gt; /u/Sensitive_Let_4239 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5e0ok/can_you_organize_data_into_a_csv_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5e0ok/can_you_organize_data_into_a_csv_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5e0ok</id><link href="https://www.reddit.com/r/LangChain/comments/1c5e0ok/can_you_organize_data_into_a_csv_with_langchain/" /><updated>2024-04-16T11:44:59+00:00</updated><published>2024-04-16T11:44:59+00:00</published><title>Can you organize data into a csv with langchain?</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am experimenting with different chunking techniques like RecursiveCharacterSplitter or &lt;a href=&quot;https://Unstructured.IO&quot;&gt;Unstructured.IO&lt;/a&gt; chunking with &amp;quot;by_title&amp;quot;. Theoretically I think the second option to chunk by title will be the most promising one.&lt;/p&gt; &lt;p&gt;But I would be interested of your experiences? The PDFs I am using are all complex and many come with a completely different structure, so manually checking for every PDF is no choice. &lt;/p&gt; &lt;p&gt;Happy to discuss with your experiences!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4nizz/your_experience_best_chunking_technique_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4nizz/your_experience_best_chunking_technique_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c4nizz</id><link href="https://www.reddit.com/r/LangChain/comments/1c4nizz/your_experience_best_chunking_technique_for/" /><updated>2024-04-15T14:24:47+00:00</updated><published>2024-04-15T14:24:47+00:00</published><title>Your Experience: Best Chunking Technique for complex PDFs</title></entry><entry><author><name>/u/jaagoBohutHuaIntezar</name><uri>https://www.reddit.com/user/jaagoBohutHuaIntezar</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Anyone has any recommendation for course/book/tutorial, free or paid? I have a decent idea about deep learning concepts. But, my current job is in backend with python, so naturally looking to expand my skillset! Thanks. &lt;/p&gt; &lt;p&gt;I just want enough to get a custom chatbot with guardrails up and running on my system. I tried with ollama but am stuck at generating embedding for my dataset &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jaagoBohutHuaIntezar&quot;&gt; /u/jaagoBohutHuaIntezar &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4s19w/coursesbooks_to_get_into_generative_ai_genai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4s19w/coursesbooks_to_get_into_generative_ai_genai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c4s19w</id><link href="https://www.reddit.com/r/LangChain/comments/1c4s19w/coursesbooks_to_get_into_generative_ai_genai/" /><updated>2024-04-15T17:29:08+00:00</updated><published>2024-04-15T17:29:08+00:00</published><title>Courses/books to get into Generative AI (GenAI)? Looking to get familiar with tools like Langchain, vector databases, LLM APIs etc.</title></entry><entry><author><name>/u/benizzy1</name><uri>https://www.reddit.com/user/benizzy1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/dagworks-inc/burr&quot;&gt;https://github.com/dagworks-inc/burr&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; We created Burr to make it easier to build and debug AI applications that carry state/make complex decisions. It is similar in concept to Langgraph, and works with any framework you want (Langchain, etc...). It comes with OS telemetry. We&amp;#39;re looking for users, contributors, and feedback.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The problem(s):&lt;/strong&gt; A lot of tools in the LLM space (DSPY, superagents, etc...) end up burying what you actually want to see behind a layer of complexity and prompt manipulation. While making applications that make decisions naturally requires complexity, we wanted to make it easier to logically model, view telemetry, manage state, etc... while not imposing any restrictions on what you can do or how to interact with LLM APIs. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;We built Burr&lt;/strong&gt; to solve these problems. With Burr, you represent your application as a state machine of python functions/objects and specify transitions/state manipulation between them. We designed it with the following capabilities in mind:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Manage application memory: Burr&amp;#39;s state abstraction allows you to prune memory/feed it to your LLM (in whatever way you want)&lt;/li&gt; &lt;li&gt;Persist/reload state: Burr allows you to load from any point in an application&amp;#39;s run so you can debug/restart from failure&lt;/li&gt; &lt;li&gt;Monitor application decisions: Burr comes with a telemetry UI that you can use to debug your app in real-time&lt;/li&gt; &lt;li&gt;Integrate with your favorite tooling: Burr is just stitching together python primitives -- classes + functions, so you can write whatever you want. Use langchain and dive into the OpenAI/other APIs when you need.&lt;/li&gt; &lt;li&gt;Gather eval data: Burr has logging capabilities to ensure you capture data for fine-tuning/eval&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;It is meant to be a lightweight python library (zero dependencies), with a host of plugins. You can get started by running: &lt;code&gt;pip install &amp;quot;burr[start]&amp;quot; &amp;amp;&amp;amp; burr&lt;/code&gt; -- this will start the telemetry server with a few demos (click on &lt;em&gt;demos&lt;/em&gt; to play with a chatbot + watch telemetry at the same time).&lt;/p&gt; &lt;p&gt;Then, check out the following resources:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;a href=&quot;https://burr.dagworks.io/getting_started/&quot;&gt;Burr&amp;#39;s documentation/getting started&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/DAGWorks-Inc/burr/tree/main/examples/multi-agent-collaboration/lcel&quot;&gt;Multi-agent-collaboration example using LCEL&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/DAGWorks-Inc/burr/tree/main/examples/web-server&quot;&gt;Fairly complex control-flow example that uses AI + human feedback to draft an email&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;We&amp;#39;re really excited&lt;/strong&gt; about the initial reception and are hoping to get more feedback/OS users/contributors -- feel free to DM me or comment here if you have any questions, and happy developing!&lt;/p&gt; &lt;p&gt;PS -- the name &lt;em&gt;Burr&lt;/em&gt; is a play on the project we OSed called &lt;a href=&quot;https://github.com/dagworks-inc/hamilton&quot;&gt;Hamilton&lt;/a&gt; that you may be familiar with. They actually work nicely together!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/benizzy1&quot;&gt; /u/benizzy1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4ssou/burr_an_os_framework_for_building_and_debugging/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4ssou/burr_an_os_framework_for_building_and_debugging/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c4ssou</id><link href="https://www.reddit.com/r/LangChain/comments/1c4ssou/burr_an_os_framework_for_building_and_debugging/" /><updated>2024-04-15T17:59:26+00:00</updated><published>2024-04-15T17:59:26+00:00</published><title>Burr: an OS framework for building and debugging AI apps faster (manage memory, persist state, monitor decisions, use your own code, gather eval data)</title></entry><entry><author><name>/u/VegetableAddendum888</name><uri>https://www.reddit.com/user/VegetableAddendum888</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So guys My team has participated in a hackathon and we require Ideas to built a RAG chatbot on. Your suggestions might help us alot….Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/VegetableAddendum888&quot;&gt; /u/VegetableAddendum888 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4t5ks/any_suggestions_for_idea_to_built_a_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4t5ks/any_suggestions_for_idea_to_built_a_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c4t5ks</id><link href="https://www.reddit.com/r/LangChain/comments/1c4t5ks/any_suggestions_for_idea_to_built_a_rag_chatbot/" /><updated>2024-04-15T18:12:48+00:00</updated><published>2024-04-15T18:12:48+00:00</published><title>Any Suggestions for idea to built a RAG chatbot in a Hackathon?</title></entry><entry><author><name>/u/busterorwha</name><uri>https://www.reddit.com/user/busterorwha</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there any tutorials of a way to define metadata data to specific chunks to better compare documents so that there is less contamination with RAG&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/busterorwha&quot;&gt; /u/busterorwha &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4rvge/adding_metadata_to_chunks/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4rvge/adding_metadata_to_chunks/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c4rvge</id><link href="https://www.reddit.com/r/LangChain/comments/1c4rvge/adding_metadata_to_chunks/" /><updated>2024-04-15T17:22:35+00:00</updated><published>2024-04-15T17:22:35+00:00</published><title>Adding metadata to chunks</title></entry><entry><author><name>/u/heybigeyes123</name><uri>https://www.reddit.com/user/heybigeyes123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We&amp;#39;ve been trying pandas dataframe agent and have been experiencing some problems in productions. Are there better alternatives?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/heybigeyes123&quot;&gt; /u/heybigeyes123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4ij67/what_are_the_best_sql_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4ij67/what_are_the_best_sql_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c4ij67</id><link href="https://www.reddit.com/r/LangChain/comments/1c4ij67/what_are_the_best_sql_agents/" /><updated>2024-04-15T10:08:14+00:00</updated><published>2024-04-15T10:08:14+00:00</published><title>What are the best SQL agents</title></entry><entry><author><name>/u/Beginning_Rock_1906</name><uri>https://www.reddit.com/user/Beginning_Rock_1906</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I often heard that there are problems with navigating through LangChain and that working with the source code directly brings most benefits which is very hard work though. I thought it makes sense to maybe fine tune a model on the code and use RAG to interact with the source code and understand it better. Any feedback on whether this is a good idea or even possible? The source code might be around 5 million tokens all in all. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Beginning_Rock_1906&quot;&gt; /u/Beginning_Rock_1906 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4jl1c/rag_and_langchain_source_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4jl1c/rag_and_langchain_source_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c4jl1c</id><link href="https://www.reddit.com/r/LangChain/comments/1c4jl1c/rag_and_langchain_source_code/" /><updated>2024-04-15T11:14:14+00:00</updated><published>2024-04-15T11:14:14+00:00</published><title>RAG and LangChain Source code</title></entry></feed>