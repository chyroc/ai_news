<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-02-08T09:59:57+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/_dakshesh</name><uri>https://www.reddit.com/user/_dakshesh</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I recently completed a project that involved using the FAISS vector database. I utilized lang-chain for storing embeddings in the vector database, which were generated from PDF files. For the purpose of the project, it was sufficient to store all the information without separating the storage according to users. &lt;/p&gt; &lt;p&gt;What I want to know is - when a user uploads a PDF, can I create an embedding for it and store it in the vector database, allowing me to query the embeddings for &lt;strong&gt;that&lt;/strong&gt; user later on. This ensures that the generated output is accurate and privacy is also maintained. I was wondering, can I do that? If so, how?&lt;/p&gt; &lt;p&gt;I really appreciate any help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/_dakshesh&quot;&gt; /u/_dakshesh &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alq3to/help_needed_with_vector_database/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alq3to/help_needed_with_vector_database/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alq3to</id><link href="https://www.reddit.com/r/LangChain/comments/1alq3to/help_needed_with_vector_database/" /><updated>2024-02-08T07:20:15+00:00</updated><published>2024-02-08T07:20:15+00:00</published><title>Help needed with vector database</title></entry><entry><author><name>/u/OnlyBadKarma</name><uri>https://www.reddit.com/user/OnlyBadKarma</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to filter the documents based on the metadata filter. However, I am not sure how to do it using the Langchain Annoy module.&lt;/p&gt; &lt;p&gt;I have a source in metadata, even though I applied the filter it is returning all the docs and not filtering them.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Load the vector db vectordb = Annoy.load_local(PERSIST_DIRECTORY, embeddings=embedding) # Query Annoy docs = vectordb.similarity_search(&amp;quot;how to do X?&amp;quot;, k=2, filter={&amp;quot;source&amp;quot;: &amp;quot;news&amp;quot;}) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OnlyBadKarma&quot;&gt; /u/OnlyBadKarma &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1als4n1/how_to_apply_a_metadata_filter_in_annoy_by_spotify/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1als4n1/how_to_apply_a_metadata_filter_in_annoy_by_spotify/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1als4n1</id><link href="https://www.reddit.com/r/LangChain/comments/1als4n1/how_to_apply_a_metadata_filter_in_annoy_by_spotify/" /><updated>2024-02-08T09:46:22+00:00</updated><published>2024-02-08T09:46:22+00:00</published><title>How to apply a metadata filter in Annoy by Spotify?</title></entry><entry><author><name>/u/ethicalhack3r</name><uri>https://www.reddit.com/user/ethicalhack3r</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I want to create my own custom document loader, like the IMSDB one for example:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/langchain-ai/langchain/blob/00a09e1b7117f3bde14a44748510fcccc95f9de5/libs/community/langchain_community/document_loaders/imsdb.py#L8&quot;&gt;https://github.com/langchain-ai/langchain/blob/00a09e1b7117f3bde14a44748510fcccc95f9de5/libs/community/langchain_community/document_loaders/imsdb.py#L8&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The main reason I want to do this is to only extract the data I need from a web page, and not the whole thing, to improve accuracy.&lt;/p&gt; &lt;p&gt;If I wrote a script like &lt;a href=&quot;https://imsdb.py&quot;&gt;imsdb.py&lt;/a&gt;, how could I tell my Python script to use it? Maybe there&amp;#39;s already a tutorial for this online? I couldn&amp;#39;t find anytning from a quick search.&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ethicalhack3r&quot;&gt; /u/ethicalhack3r &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alrd96/create_custom_document_loader/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alrd96/create_custom_document_loader/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alrd96</id><link href="https://www.reddit.com/r/LangChain/comments/1alrd96/create_custom_document_loader/" /><updated>2024-02-08T08:51:07+00:00</updated><published>2024-02-08T08:51:07+00:00</published><title>Create Custom Document Loader</title></entry><entry><author><name>/u/AbbreviationsPale867</name><uri>https://www.reddit.com/user/AbbreviationsPale867</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, so I&amp;#39;ve made a new chatPromptTemplate and once I did the first commit to it, I am unable to go back into the artifact playground and modify the prompt. Which is weird cause I can edit my other prompts, for this specific prompt I get &amp;quot; &lt;strong&gt;Message 0 had extra kwargs: additional_kwargs&lt;/strong&gt; &amp;quot; when I hover over the playground button. Any help would be great&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;EDIT: just for reference the prompt im having issue with is &lt;strong&gt;thecodingbarista/documentgenerator&lt;/strong&gt; on the langsmith hub&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AbbreviationsPale867&quot;&gt; /u/AbbreviationsPale867 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alqrzy/langsmith_prompts/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alqrzy/langsmith_prompts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alqrzy</id><link href="https://www.reddit.com/r/LangChain/comments/1alqrzy/langsmith_prompts/" /><updated>2024-02-08T08:07:46+00:00</updated><published>2024-02-08T08:07:46+00:00</published><title>Langsmith prompts</title></entry><entry><author><name>/u/gamesntech</name><uri>https://www.reddit.com/user/gamesntech</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;When generating code-related output from an LLM like python functions, sql queries, etc. a lot of times the LLM wraps the code between triple quotes like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;```python blah ``` &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Is there an output parser or extractor component or anything that can help with extracting these segments and ignoring all the fluff around it?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gamesntech&quot;&gt; /u/gamesntech &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aljkdj/question_about_llm_output_parsing/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aljkdj/question_about_llm_output_parsing/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aljkdj</id><link href="https://www.reddit.com/r/LangChain/comments/1aljkdj/question_about_llm_output_parsing/" /><updated>2024-02-08T01:23:06+00:00</updated><published>2024-02-08T01:23:06+00:00</published><title>Question about LLM output parsing</title></entry><entry><author><name>/u/HappyDataGuy</name><uri>https://www.reddit.com/user/HappyDataGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;My question is simple, I am not able to figure out, how to integrate nemo-guardrails in my current RAG applications without completely changing structure. It should return 0 or 1 based on whether user is query is valid or not. how can I get it to this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HappyDataGuy&quot;&gt; /u/HappyDataGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alpm95/how_to_use_nemoguardrails_how_to_know_that_is_not/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alpm95/how_to_use_nemoguardrails_how_to_know_that_is_not/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alpm95</id><link href="https://www.reddit.com/r/LangChain/comments/1alpm95/how_to_use_nemoguardrails_how_to_know_that_is_not/" /><updated>2024-02-08T06:47:31+00:00</updated><published>2024-02-08T06:47:31+00:00</published><title>How to use nemo-guardrails? how to know that is not policy violation and then to pass query to primary LLM?</title></entry><entry><author><name>/u/Environmental_Win975</name><uri>https://www.reddit.com/user/Environmental_Win975</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi All&lt;/p&gt; &lt;p&gt;Question, After creating my vector database of entire 100docs, i want how to this vector database in seperate client progran. How shall I do it? I using aws opensearch servless for vector db&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Environmental_Win975&quot;&gt; /u/Environmental_Win975 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alilwn/opeansearch_vector_db_use_in_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alilwn/opeansearch_vector_db_use_in_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alilwn</id><link href="https://www.reddit.com/r/LangChain/comments/1alilwn/opeansearch_vector_db_use_in_rag/" /><updated>2024-02-08T00:37:01+00:00</updated><published>2024-02-08T00:37:01+00:00</published><title>Opeansearch vector db use in rag</title></entry><entry><author><name>/u/mofusa16</name><uri>https://www.reddit.com/user/mofusa16</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alpexo/predict_and_parse_method_deprecation_warning_how/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/vbejhbfl3bhc1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5bd31f1c45badb50beea07d0ba434a2b2aa19bce&quot; alt=&quot;predict_and_parse method deprecation warning. How to Solve?&quot; title=&quot;predict_and_parse method deprecation warning. How to Solve?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mofusa16&quot;&gt; /u/mofusa16 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/vbejhbfl3bhc1.png&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alpexo/predict_and_parse_method_deprecation_warning_how/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1alpexo</id><media:thumbnail url="https://preview.redd.it/vbejhbfl3bhc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5bd31f1c45badb50beea07d0ba434a2b2aa19bce" /><link href="https://www.reddit.com/r/LangChain/comments/1alpexo/predict_and_parse_method_deprecation_warning_how/" /><updated>2024-02-08T06:34:10+00:00</updated><published>2024-02-08T06:34:10+00:00</published><title>predict_and_parse method deprecation warning. How to Solve?</title></entry><entry><author><name>/u/Many-Historian-3143</name><uri>https://www.reddit.com/user/Many-Historian-3143</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1allnji/extracting_table_using_pdfplumber_but_not/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/E9MQmOOKPQq8mlF486E7NUM2zcae5DznPSEcoyayfNo.jpg&quot; alt=&quot;Extracting Table using PDFPlumber but not extracting Text that has background color&quot; title=&quot;Extracting Table using PDFPlumber but not extracting Text that has background color&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, community,&lt;/p&gt; &lt;p&gt;In the section with a color background, the text is not extracting checked all parameters of main function for extracting text from the table in Python, pddplumber, unstructured. What recommendation do you have?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/2ofmdidh1ahc1.jpg?width=778&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=bc6d1e50cfaeba5dd5e6ca9ce765eb4923973768&quot;&gt;https://preview.redd.it/2ofmdidh1ahc1.jpg?width=778&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=bc6d1e50cfaeba5dd5e6ca9ce765eb4923973768&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Many-Historian-3143&quot;&gt; /u/Many-Historian-3143 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1allnji/extracting_table_using_pdfplumber_but_not/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1allnji/extracting_table_using_pdfplumber_but_not/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1allnji</id><media:thumbnail url="https://b.thumbs.redditmedia.com/E9MQmOOKPQq8mlF486E7NUM2zcae5DznPSEcoyayfNo.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1allnji/extracting_table_using_pdfplumber_but_not/" /><updated>2024-02-08T03:04:14+00:00</updated><published>2024-02-08T03:04:14+00:00</published><title>Extracting Table using PDFPlumber but not extracting Text that has background color</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Checkout my new tutorial on how to build a recommendation system using RAG and LangChain &lt;a href=&quot;https://youtu.be/WW0q8jjsisQ?si=9JI24AIj822N9zJK&quot;&gt;https://youtu.be/WW0q8jjsisQ?si=9JI24AIj822N9zJK&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al7yyt/recommendation_system_using_langchain_and_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al7yyt/recommendation_system_using_langchain_and_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1al7yyt</id><link href="https://www.reddit.com/r/LangChain/comments/1al7yyt/recommendation_system_using_langchain_and_rag/" /><updated>2024-02-07T17:11:24+00:00</updated><published>2024-02-07T17:11:24+00:00</published><title>Recommendation system using LangChain and RAG</title></entry><entry><author><name>/u/OkVegetable2512</name><uri>https://www.reddit.com/user/OkVegetable2512</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys, I have to create a llm based on risk analysis (mainly hara) for my company. The only problem is that the input data is sensitive thatâ€™s why I am steering in the direction of using a locally hosted/offline llm like private gpt or elasticsearch with some kind of ui. Can anybody give me pointers on where to start and how to do it? I am still a student and fairly new to the topic&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OkVegetable2512&quot;&gt; /u/OkVegetable2512 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al25wz/langchain_for_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al25wz/langchain_for_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1al25wz</id><link href="https://www.reddit.com/r/LangChain/comments/1al25wz/langchain_for_llm/" /><updated>2024-02-07T12:48:38+00:00</updated><published>2024-02-07T12:48:38+00:00</published><title>LangChain for llm</title></entry><entry><author><name>/u/BigActivity9282</name><uri>https://www.reddit.com/user/BigActivity9282</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Guys,&lt;/p&gt; &lt;p&gt;Can anyone point me to a resource where we can choose different vector db retriever based on the input question. There is an example on routing to different prompts using runnablelambda. However the input is a dictionary hence it works. My problem is to choose the retriever on run time then pass only the question to the selected retriever at runtime.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BigActivity9282&quot;&gt; /u/BigActivity9282 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al3xwz/langchain_expression_language/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al3xwz/langchain_expression_language/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1al3xwz</id><link href="https://www.reddit.com/r/LangChain/comments/1al3xwz/langchain_expression_language/" /><updated>2024-02-07T14:17:37+00:00</updated><published>2024-02-07T14:17:37+00:00</published><title>Langchain expression language</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, I just released a tutorial on how to make an agent interact with multiple vector databases with examples and codes. Do check it out&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/cBpdiQ3gljM?si=rfpFmlyGILHlIH4t&quot;&gt;https://youtu.be/cBpdiQ3gljM?si=rfpFmlyGILHlIH4t &lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akroee/multi_document_rag_using_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akroee/multi_document_rag_using_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akroee</id><link href="https://www.reddit.com/r/LangChain/comments/1akroee/multi_document_rag_using_agents/" /><updated>2024-02-07T02:08:43+00:00</updated><published>2024-02-07T02:08:43+00:00</published><title>Multi Document RAG using Agents</title></entry><entry><author><name>/u/deadmalone</name><uri>https://www.reddit.com/user/deadmalone</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, I was testing out things and I made a personal document analyser. I chunked and stored multiple documents in the same index in Pincone. Since the documents have contextual overlap, this improved the quality of the results produced a lot.&lt;/p&gt; &lt;p&gt;For reference I was testing with the Mistral 8x7b model.&lt;/p&gt; &lt;p&gt;What&amp;#39;s your opinion on this??&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/deadmalone&quot;&gt; /u/deadmalone &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akzs8s/multiple_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akzs8s/multiple_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akzs8s</id><link href="https://www.reddit.com/r/LangChain/comments/1akzs8s/multiple_documents/" /><updated>2024-02-07T10:16:52+00:00</updated><published>2024-02-07T10:16:52+00:00</published><title>Multiple Documents</title></entry><entry><author><name>/u/Arajgor</name><uri>https://www.reddit.com/user/Arajgor</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to build PDF chatbot using OpenAI, Langchain and Pinecone.&lt;/p&gt; &lt;p&gt;Here is my code,&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain.document_loaders import PyPDFLoader from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter import uuid loader = PyPDFLoader(&amp;quot;2104.02830.pdf&amp;quot;) data = loader.load() text_splitter = RecursiveCharacterTextSplitter( chunk_size=2000, chunk_overlap=0) texts = text_splitter.split_documents(data) for text in texts: id = uuid.uuid4().hex response = embeddings.embed_query(text.page_content) vectors.append([(id, response, {&amp;quot;page&amp;quot;: text.metadata[&amp;#39;page&amp;#39;], &amp;quot;text&amp;quot;: text.page_content})]) for vector in vectors: index.upsert(vector) query_embedding = embeddings.embed_query(&amp;quot;author of this research paper&amp;quot;) result = index.query(vector=query_embedding , top_k=5, include_metadata=True) print(result[&amp;#39;matches&amp;#39;][0]) [{&amp;#39;id&amp;#39;: &amp;#39;ccd0dac490da4b4b947db97076cdf10d&amp;#39;, &amp;#39;metadata&amp;#39;: {&amp;#39;page&amp;#39;: 5.0, &amp;#39;text&amp;#39;: &amp;#39;novel image dataset for benchmarking machine learning &amp;#39; &amp;#39;al-\n&amp;#39;&amp;#39;gorithms. ArXiv , abs/1708.07747, 2017.\n&amp;#39; &amp;#39;[20] X. Zou, X. Kong, W. Wong, C. Wang, Y . Liu, and Y &amp;#39;&amp;#39;. Cao.\n&amp;#39;&amp;#39;Fashionai: A hierarchical dataset for fashion &amp;#39;&amp;#39;understand-\n&amp;#39;&amp;#39;ing. In 2019 IEEE/CVF Conference on Computer Vision &amp;#39;&amp;#39;and\n&amp;#39;&amp;#39;Pattern Recognition Workshops (CVPRW) , pages 296â€“304,\n&amp;#39;&amp;#39;2019.\n&amp;#39;&amp;#39;6&amp;#39;}, &amp;#39;score&amp;#39;: 0.290649086, &amp;#39;values&amp;#39;: []}, &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;It gives me reference links rather than author names.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Arajgor&quot;&gt; /u/Arajgor &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akvy3c/rag_using_pinecone_does_not_give_accurate_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akvy3c/rag_using_pinecone_does_not_give_accurate_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akvy3c</id><link href="https://www.reddit.com/r/LangChain/comments/1akvy3c/rag_using_pinecone_does_not_give_accurate_data/" /><updated>2024-02-07T05:50:30+00:00</updated><published>2024-02-07T05:50:30+00:00</published><title>RAG using pinecone does not give accurate data</title></entry><entry><author><name>/u/williamfzc</name><uri>https://www.reddit.com/user/williamfzc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In the past few months, we&amp;#39;ve experimented with various approaches to enable LLM to comprehend code files. Currently, LLM can grasp the essence of file meanings at a functional level. This understanding is facilitated by providing contextual information such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;File content&lt;/li&gt; &lt;li&gt;File path&lt;/li&gt; &lt;li&gt;Commit message&lt;/li&gt; &lt;li&gt;Issues&lt;/li&gt; &lt;li&gt;...&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;However, the code represents business logic, which often spans multiple/complex categories. This business logic may be entirely unrelated to the contents mentioned in a single code file, posing a significant challenge for LLM to comprehend and classify.&lt;/p&gt; &lt;p&gt;I&amp;#39;m wondering if there are any existing methods or approaches to address this issue. Any insights or suggestions would be greatly appreciated. Thanks in advance :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/williamfzc&quot;&gt; /u/williamfzc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akyazk/is_there_a_existed_way_to_mapping_code_files_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akyazk/is_there_a_existed_way_to_mapping_code_files_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akyazk</id><link href="https://www.reddit.com/r/LangChain/comments/1akyazk/is_there_a_existed_way_to_mapping_code_files_with/" /><updated>2024-02-07T08:27:03+00:00</updated><published>2024-02-07T08:27:03+00:00</published><title>Is there a existed way to mapping code files with real businesses?</title></entry><entry><author><name>/u/Azyain</name><uri>https://www.reddit.com/user/Azyain</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I have a project to build a chatbot for E-commerce. This chatbot should interact with users and inform them about the products sold on the website. I tried using one agent to handle both interaction and task execution. However, when I only said &amp;quot;Hi,&amp;quot; the bot returned a ValueError, something like &amp;quot;LLM could not parse.&amp;quot; So, in this situation, do I need two agents? One to interact with users for out-of-context questions such as greetings or asking the bot&amp;#39;s name, and the other to handle the thinking process for tasks such as finding today&amp;#39;s discounts or locating gaming accessories? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Azyain&quot;&gt; /u/Azyain &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aktwzi/do_you_really_need_more_than_one_agent_in_your/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aktwzi/do_you_really_need_more_than_one_agent_in_your/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aktwzi</id><link href="https://www.reddit.com/r/LangChain/comments/1aktwzi/do_you_really_need_more_than_one_agent_in_your/" /><updated>2024-02-07T04:00:20+00:00</updated><published>2024-02-07T04:00:20+00:00</published><title>Do you really need more than one agent in your LLM chatbot?</title></entry><entry><author><name>/u/ashpreetbedi</name><uri>https://www.reddit.com/user/ashpreetbedi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak94ud/asking_llms_who_are_you_and_who_created_you/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/YVvMvxzowXU43xjPmturLrx4YDFm_6WOx2VRMivKwUU.jpg&quot; alt=&quot;Asking LLMs &amp;quot;Who are you and who created you?&amp;quot; reveals very interesting results&quot; title=&quot;Asking LLMs &amp;quot;Who are you and who created you?&amp;quot; reveals very interesting results&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I asked 6 llms &amp;quot;Who are you and who created you?&amp;quot; &lt;/p&gt; &lt;ul&gt; &lt;li&gt;surprisingly most of them were created by OpenAI ðŸ˜‚&lt;/li&gt; &lt;li&gt;Llama and Mixtral were accurate most likely cause they&amp;#39;re trained from scratch&lt;/li&gt; &lt;li&gt;Tinyllama is my favourite&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/j5ohzozrpygc1.png?width=796&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=894cefdfd1d9f3fe402e76917fac705e9ba3c327&quot;&gt;https://preview.redd.it/j5ohzozrpygc1.png?width=796&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=894cefdfd1d9f3fe402e76917fac705e9ba3c327&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/phidatahq/phidata/blob/main/cookbook/ollama/who_are_you.py&quot;&gt;Here&amp;#39;s the code I used for this&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashpreetbedi&quot;&gt; /u/ashpreetbedi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak94ud/asking_llms_who_are_you_and_who_created_you/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak94ud/asking_llms_who_are_you_and_who_created_you/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ak94ud</id><media:thumbnail url="https://b.thumbs.redditmedia.com/YVvMvxzowXU43xjPmturLrx4YDFm_6WOx2VRMivKwUU.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1ak94ud/asking_llms_who_are_you_and_who_created_you/" /><updated>2024-02-06T12:57:14+00:00</updated><published>2024-02-06T12:57:14+00:00</published><title>Asking LLMs &quot;Who are you and who created you?&quot; reveals very interesting results</title></entry><entry><author><name>/u/_micromastery_</name><uri>https://www.reddit.com/user/_micromastery_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all,&lt;/p&gt; &lt;p&gt;I started exploring lang chain recently and was really amazed by its extensibility. I have written my experience as small tutorials and wanted to share the same with the community.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://micromastery.github.io/posts/meet-your-digital-dream-team-revolutionizing-tech-world-with-ai/&quot;&gt;Meet Your Digital Dream Team: Revolutionizing the Tech World with AI &lt;/a&gt; - This is where I explored a python framework called Crew AI which allows creating collaborative AI using langchain tools&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://micromastery.github.io/posts/customizing-llms-with-langchain-text-to-speech/&quot;&gt;Enhancing LLMs with Custom Capabilities: A Guide to Langchain and Text-to-Speech &lt;/a&gt; - This is where I explored creation of custom tools for lang chain. I am using this day to day for creating voiceovers for videos.&lt;/p&gt; &lt;p&gt;Hope you find these useful.&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/_micromastery_&quot;&gt; /u/_micromastery_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akfdm7/langchains_extensibility_is/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akfdm7/langchains_extensibility_is/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akfdm7</id><link href="https://www.reddit.com/r/LangChain/comments/1akfdm7/langchains_extensibility_is/" /><updated>2024-02-06T17:34:42+00:00</updated><published>2024-02-06T17:34:42+00:00</published><title>LangChain's extensibility is ðŸ¤¯</title></entry><entry><author><name>/u/Money_Mycologist4939</name><uri>https://www.reddit.com/user/Money_Mycologist4939</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is quite easy to create a chatbot with langchain LCEL and using the buffer memory, but what if in production I wanna store the history of the conversation in a db and not in the RAM and retrieve it when the user restart the conversation with the chatbot? I cannot find a tuto anywhere. Has anyone already tried to do it??&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Money_Mycologist4939&quot;&gt; /u/Money_Mycologist4939 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak7lzj/langchain_chatbot_in_production/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak7lzj/langchain_chatbot_in_production/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ak7lzj</id><link href="https://www.reddit.com/r/LangChain/comments/1ak7lzj/langchain_chatbot_in_production/" /><updated>2024-02-06T11:28:19+00:00</updated><published>2024-02-06T11:28:19+00:00</published><title>Langchain Chatbot in production</title></entry><entry><author><name>/u/KoalaPink1999</name><uri>https://www.reddit.com/user/KoalaPink1999</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have specific usecase of extracting structured (logically split) information from documents. Is there any parser that is opensource and does not need any particular API key ?&lt;br/&gt; The snippets would be sent to a RAG. This data would be used for internal usecases, so I would prefer a solution that would work for the same.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/KoalaPink1999&quot;&gt; /u/KoalaPink1999 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akc06q/splitting_documents_pdfshtml_pagestxt_files_into/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akc06q/splitting_documents_pdfshtml_pagestxt_files_into/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akc06q</id><link href="https://www.reddit.com/r/LangChain/comments/1akc06q/splitting_documents_pdfshtml_pagestxt_files_into/" /><updated>2024-02-06T15:11:34+00:00</updated><published>2024-02-06T15:11:34+00:00</published><title>Splitting documents (pdfs/html pages/txt files) into snippets with logical flow with Opensource tools</title></entry><entry><author><name>/u/sharrajesh</name><uri>https://www.reddit.com/user/sharrajesh</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have already created faiss embeddings for all of my release notes which definitely has dates inside among with components versions and features. &lt;/p&gt; &lt;p&gt;I have put together a simple conversation retrieval qa chain to answer user questions. &lt;/p&gt; &lt;p&gt;I found out it doesn&amp;#39;t answer when questions are temporal e.g. from most recent release notes what was the component version released.&lt;/p&gt; &lt;p&gt;I tried putting datetime.now() output as context in the user question to provide context for &amp;quot;latest &amp;quot;&lt;/p&gt; &lt;p&gt;How can I achieve this? Is my architecture incorrect or there&amp;#39;s a better architecture?&lt;/p&gt; &lt;p&gt;Thanks,&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sharrajesh&quot;&gt; /u/sharrajesh &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak82pc/canhow_to_achieve_find_most_recent_release_notes/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak82pc/canhow_to_achieve_find_most_recent_release_notes/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ak82pc</id><link href="https://www.reddit.com/r/LangChain/comments/1ak82pc/canhow_to_achieve_find_most_recent_release_notes/" /><updated>2024-02-06T11:57:12+00:00</updated><published>2024-02-06T11:57:12+00:00</published><title>Can/how to achieve find most recent release notes?</title></entry><entry><author><name>/u/Dry_Long3157</name><uri>https://www.reddit.com/user/Dry_Long3157</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been using this GPT for a while and it&amp;#39;s responses are far superior to just using GPT-4. I understand that it is just prompt engineering but it seems to improve the user experience and the quality of code significantly.&lt;br/&gt; I would love to see/build something like this with open-source models. Does anyone know what kind of prompts can be used to make something similar?&lt;/p&gt; &lt;p&gt;Link to GPT - &lt;a href=&quot;https://chat.openai.com/g/g-n7Rs0IK86-grimoire&quot;&gt;https://chat.openai.com/g/g-n7Rs0IK86-grimoire&lt;/a&gt;&lt;/p&gt; &lt;p&gt;TIA.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Dry_Long3157&quot;&gt; /u/Dry_Long3157 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak7knz/oss_version_of_grimoire_gpt/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak7knz/oss_version_of_grimoire_gpt/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ak7knz</id><link href="https://www.reddit.com/r/LangChain/comments/1ak7knz/oss_version_of_grimoire_gpt/" /><updated>2024-02-06T11:25:58+00:00</updated><published>2024-02-06T11:25:58+00:00</published><title>OSS version of Grimoire (GPT)</title></entry><entry><author><name>/u/billy2322</name><uri>https://www.reddit.com/user/billy2322</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve an idea of something to make with langchain and wikidata, however I&amp;#39;m not sure if the JS version supports the same plugins / functionality. I also can&amp;#39;t tell if it supports GraphSparqlQAChain or something equivalent. &lt;/p&gt; &lt;p&gt;What are everyones thoughts on the two versions? Is the JS version mature enough to use?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/billy2322&quot;&gt; /u/billy2322 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akao53/langchain_js_version_vs_python_version/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akao53/langchain_js_version_vs_python_version/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akao53</id><link href="https://www.reddit.com/r/LangChain/comments/1akao53/langchain_js_version_vs_python_version/" /><updated>2024-02-06T14:12:39+00:00</updated><published>2024-02-06T14:12:39+00:00</published><title>Langchain js version vs python version</title></entry><entry><author><name>/u/webNoob13</name><uri>https://www.reddit.com/user/webNoob13</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have Langsmith access so staying completely within the Langchain ecosystem seems like the better thing to do so I can trace my app&amp;#39;s inner working but is anyone using both and finding it advantageous? Or I could be wrong that using LlamaIndex would not let me trace calls to vector stores from Langsmith. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/webNoob13&quot;&gt; /u/webNoob13 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak3zkl/is_using_llamaindex_with_langchain_recommended/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak3zkl/is_using_llamaindex_with_langchain_recommended/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ak3zkl</id><link href="https://www.reddit.com/r/LangChain/comments/1ak3zkl/is_using_llamaindex_with_langchain_recommended/" /><updated>2024-02-06T07:09:33+00:00</updated><published>2024-02-06T07:09:33+00:00</published><title>Is using LlamaIndex with Langchain recommended?</title></entry></feed>