<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-04T06:07:17+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Tiny-Ad-5694</name><uri>https://www.reddit.com/user/Tiny-Ad-5694</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve built a code search tool for anyone using LangChain to search its source code and find LangChain actual use case code examples. This isn&amp;#39;t an AI chat bot;&lt;br/&gt; I built this because when I first used LangChain, I constantly needed to search for and utilize sample code blocks and delve into the LangChain source code for insights into my project&lt;/p&gt; &lt;p&gt;Currently it can only search LangChain related content. Let me know your thoughts&lt;br/&gt; Here is link: &lt;a href=&quot;http://solidsearchportal.azurewebsites.net&quot;&gt;solidsearchportal.azurewebsites.net&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Tiny-Ad-5694&quot;&gt; /u/Tiny-Ad-5694 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjncxr/a_code_search_tool_for_langchain_developer/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjncxr/a_code_search_tool_for_langchain_developer/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjncxr</id><link href="https://www.reddit.com/r/LangChain/comments/1cjncxr/a_code_search_tool_for_langchain_developer/" /><updated>2024-05-04T00:19:34+00:00</updated><published>2024-05-04T00:19:34+00:00</published><title>A code search tool for LangChain developer</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1cjqb4f/llms_cant_play_tictactoe_why_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjqbn4/llms_cant_play_tictactoe_why_explained_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjqbn4</id><link href="https://www.reddit.com/r/LangChain/comments/1cjqbn4/llms_cant_play_tictactoe_why_explained_langgraph/" /><updated>2024-05-04T02:57:15+00:00</updated><published>2024-05-04T02:57:15+00:00</published><title>LLMs can't play tic-tac-toe. Why? Explained (LangGraph experiment)</title></entry><entry><author><name>/u/atomacht</name><uri>https://www.reddit.com/user/atomacht</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am working with a Dev on a project and he explained to me that no all OpenAI Chat Models are supported by Langchain, especially not the newer ones (e.g. GPT4-Turbo) when they come out.&lt;/p&gt; &lt;p&gt;I was under the impression that Langchain works with all Chat Models that OpenAI offers via the API.&lt;/p&gt; &lt;p&gt;Can&amp;#39;t find this info in the docs. &lt;/p&gt; &lt;p&gt;Any input from the community is highly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/atomacht&quot;&gt; /u/atomacht &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjt6lt/openai_chat_models/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjt6lt/openai_chat_models/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjt6lt</id><link href="https://www.reddit.com/r/LangChain/comments/1cjt6lt/openai_chat_models/" /><updated>2024-05-04T05:45:02+00:00</updated><published>2024-05-04T05:45:02+00:00</published><title>OpenAI Chat Models</title></entry><entry><author><name>/u/Crafty-Investment417</name><uri>https://www.reddit.com/user/Crafty-Investment417</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjszsn/getting_import_error_in_importing_llamaindex/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/9e6q5kg3jcyc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=95f40a7897e9b7696519b615cc6393b2439f6d11&quot; alt=&quot;Getting import error in importing llamaindex vector stores &quot; title=&quot;Getting import error in importing llamaindex vector stores &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using jupyter notebook anaconda windows python. I am trying to import qdrant vector store and ollama embeddings after installing them in virtual environment but I am getting module not found error. Similar error with other llm embeddings and llms and vector stores. How to resolve this. I am using import functions mentioned in llama index documentation.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Crafty-Investment417&quot;&gt; /u/Crafty-Investment417 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/9e6q5kg3jcyc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjszsn/getting_import_error_in_importing_llamaindex/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cjszsn</id><media:thumbnail url="https://preview.redd.it/9e6q5kg3jcyc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=95f40a7897e9b7696519b615cc6393b2439f6d11" /><link href="https://www.reddit.com/r/LangChain/comments/1cjszsn/getting_import_error_in_importing_llamaindex/" /><updated>2024-05-04T05:32:51+00:00</updated><published>2024-05-04T05:32:51+00:00</published><title>Getting import error in importing llamaindex vector stores</title></entry><entry><author><name>/u/JimZerChapirov</name><uri>https://www.reddit.com/user/JimZerChapirov</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj7j7y/using_lowerlevel_tools_makes_better_genai_apps_an/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/uWX5oFoKEnjBx53i5EEmGlw1iSAsf2On7x5mBJCG3ws.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2eb07213afc1aa854d453368c168981164872406&quot; alt=&quot;Using lower-level tools makes better GenAI apps: an alternative to the LangChain way&quot; title=&quot;Using lower-level tools makes better GenAI apps: an alternative to the LangChain way&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/JimZerChapirov&quot;&gt; /u/JimZerChapirov &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/VSfehUJUWQY&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj7j7y/using_lowerlevel_tools_makes_better_genai_apps_an/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cj7j7y</id><media:thumbnail url="https://external-preview.redd.it/uWX5oFoKEnjBx53i5EEmGlw1iSAsf2On7x5mBJCG3ws.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2eb07213afc1aa854d453368c168981164872406" /><link href="https://www.reddit.com/r/LangChain/comments/1cj7j7y/using_lowerlevel_tools_makes_better_genai_apps_an/" /><updated>2024-05-03T12:32:16+00:00</updated><published>2024-05-03T12:32:16+00:00</published><title>Using lower-level tools makes better GenAI apps: an alternative to the LangChain way</title></entry><entry><author><name>/u/hasteiswaste</name><uri>https://www.reddit.com/user/hasteiswaste</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m more or less completely new to LangChain, but I envision it as the best tool to solve the following task. What I&amp;#39;m trying to create is a script that takes two PDF documents, where one is the application criteria and the other is the application itself, and compares the content to determine what is omitted in one document and addressed in the other. It concerns a fairly extensive application procedure where it would be very useful to have autogenerated insights into what the application lacks.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve attempted to modify the script here with various prompts (&lt;a href=&quot;https://python.langchain.com/docs/integrations/toolkits/document%5C_comparison%5C_toolkit/&quot;&gt;https://python.langchain.com/docs/integrations/toolkits/document\_comparison\_toolkit/&lt;/a&gt;), and while I get somewhat useful responses, none of them manage to list the deficiencies in the application comprehensively. The document outlining the application criteria is structured with points, whereas the application document may have responses that overlap and are arranged in a way that makes it difficult to compare point by point.&lt;/p&gt; &lt;p&gt;Suggestions for approach or how to tackle the challenge would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hasteiswaste&quot;&gt; /u/hasteiswaste &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjkchx/comparing_two_documents_and_finding_the_diff/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjkchx/comparing_two_documents_and_finding_the_diff/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjkchx</id><link href="https://www.reddit.com/r/LangChain/comments/1cjkchx/comparing_two_documents_and_finding_the_diff/" /><updated>2024-05-03T21:57:44+00:00</updated><published>2024-05-03T21:57:44+00:00</published><title>Comparing two documents and finding the diff</title></entry><entry><author><name>/u/UpvoteBeast</name><uri>https://www.reddit.com/user/UpvoteBeast</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjr0xy/how_rag_architecture_overcomes_llm_limitations/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/dQl7-TauXBI9Vl5SEA2wORLVhC6T_s1Q4Vhw-WmKfC4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2c756b18e6de96109083b4e4ceab0f2aff65b413&quot; alt=&quot;How RAG Architecture Overcomes LLM Limitations&quot; title=&quot;How RAG Architecture Overcomes LLM Limitations&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpvoteBeast&quot;&gt; /u/UpvoteBeast &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://dly.to/CkHPBlwHuPo&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjr0xy/how_rag_architecture_overcomes_llm_limitations/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cjr0xy</id><media:thumbnail url="https://external-preview.redd.it/dQl7-TauXBI9Vl5SEA2wORLVhC6T_s1Q4Vhw-WmKfC4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c756b18e6de96109083b4e4ceab0f2aff65b413" /><link href="https://www.reddit.com/r/LangChain/comments/1cjr0xy/how_rag_architecture_overcomes_llm_limitations/" /><updated>2024-05-04T03:36:38+00:00</updated><published>2024-05-04T03:36:38+00:00</published><title>How RAG Architecture Overcomes LLM Limitations</title></entry><entry><author><name>/u/Calm-Number5851</name><uri>https://www.reddit.com/user/Calm-Number5851</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m sad to admit it, but the facts answer in the negative: AI devices are useless and unnecessary. At least not right now. I love unusual gadgets, actively follow what&amp;#39;s happening in the AR and VR world, and love testing new form factors. But the problem with AI devices is that our smartphones are very good, and it&amp;#39;s too hard to compete with them for a place in our pockets.&lt;/p&gt; &lt;p&gt;I see it this way: developers should think about how to create a gadget that goes beyond the devices we&amp;#39;re familiar with. Something similar is being done by Apple with the Vision Pro, as well as companies developing AR glasses and lenses. With these devices, we (well, sometimes) see clear advantages over smartphones and understand why we should buy them.&lt;/p&gt; &lt;blockquote&gt; &lt;/blockquote&gt; &lt;p&gt;Let&amp;#39;s wait a bit. Sooner or later, we&amp;#39;ll surely see someone who will change the way we think about AI devices. Again, I just hope so.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm-Number5851&quot;&gt; /u/Calm-Number5851 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjf7q8/ai_devices_will_never_be_useful/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjf7q8/ai_devices_will_never_be_useful/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjf7q8</id><link href="https://www.reddit.com/r/LangChain/comments/1cjf7q8/ai_devices_will_never_be_useful/" /><updated>2024-05-03T18:03:56+00:00</updated><published>2024-05-03T18:03:56+00:00</published><title>AI Devices Will Never be Useful?</title></entry><entry><author><name>/u/Desperate_Fact_5574</name><uri>https://www.reddit.com/user/Desperate_Fact_5574</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, I am kind of new to the concept of LLM and RAG. I want to make a program that use stored instructions in a document. This will be the data the RAG will use as context for the LLM. What I have read about until now, is that you can do this and then the user can pass a query about the stored document. However, I want to be able to send the text from my documents into the RAG and then let the RAG respond to if the document is correcg based on the instructions as mentioned. &lt;/p&gt; &lt;p&gt;What is the best approach here? Do I just pass the whole text from the document as a query and ask the RAG to decide if the text is correct based on the context?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Desperate_Fact_5574&quot;&gt; /u/Desperate_Fact_5574 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjlflw/passing_text_from_a_document_to_a_rag_to_validate/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjlflw/passing_text_from_a_document_to_a_rag_to_validate/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjlflw</id><link href="https://www.reddit.com/r/LangChain/comments/1cjlflw/passing_text_from_a_document_to_a_rag_to_validate/" /><updated>2024-05-03T22:46:23+00:00</updated><published>2024-05-03T22:46:23+00:00</published><title>Passing text from a document to a RAG to validate document</title></entry><entry><author><name>/u/Designer_Athlete7286</name><uri>https://www.reddit.com/user/Designer_Athlete7286</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve tried to look for this in docs but couldn&amp;#39;t find any examples on how to do so. Is this possible in the first place? &lt;/p&gt; &lt;p&gt;My plan if to deploy a chatbot with tool access including a rag using LangServe. Do I need to make my cahtbot into a runnable chain using LCEL?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Designer_Athlete7286&quot;&gt; /u/Designer_Athlete7286 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjgce9/openai_tool_calling_agent_as_an_lcel_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjgce9/openai_tool_calling_agent_as_an_lcel_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjgce9</id><link href="https://www.reddit.com/r/LangChain/comments/1cjgce9/openai_tool_calling_agent_as_an_lcel_chain/" /><updated>2024-05-03T18:52:14+00:00</updated><published>2024-05-03T18:52:14+00:00</published><title>OpenAI Tool Calling Agent as an LCEL chain?</title></entry><entry><author><name>/u/Only-Requirement619</name><uri>https://www.reddit.com/user/Only-Requirement619</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I came across a gpt in OpenAI called stoic gpt. It’s based off the words of Marcus Ariellius, Seneca and a couple other prominent legends. I wanted to create a similar gpt with the words of some prominent athletes. I know the simple way would be to collect as much data and embed it into a custom gpt, but is there a better way to capture all data including from podcasts, yt etc &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Only-Requirement619&quot;&gt; /u/Only-Requirement619 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjfrvr/embedding_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjfrvr/embedding_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjfrvr</id><link href="https://www.reddit.com/r/LangChain/comments/1cjfrvr/embedding_data/" /><updated>2024-05-03T18:27:49+00:00</updated><published>2024-05-03T18:27:49+00:00</published><title>EMBEDDING data</title></entry><entry><author><name>/u/wiseduckling</name><uri>https://www.reddit.com/user/wiseduckling</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So I have a RAG app that&amp;#39;s working but I need to optimize it. &lt;/p&gt; &lt;p&gt;Right now I take a doc --&amp;gt; chunk it --&amp;gt; summarize chunks --&amp;gt; build page summaries and doc summarize from those chunks --&amp;gt; vectorize everything. &lt;/p&gt; &lt;p&gt;The docs are stored in an S3 bucket and the chunks + their vectors in redis. &lt;/p&gt; &lt;p&gt;I need to reduce the content I m storing in redis as it won&amp;#39;t scale in terms of cost so my plan is to only store the summaries and their vectors for each chunk, page, doc. &lt;/p&gt; &lt;p&gt;My question is then, after identifying the where the relevant content is, where should I pull that content from. Are you guys pulling it directly from PDF docs or storing it in a seperate SQL db somewhere else? I think a db will ultimately be less resource intensive but I m not sure thats the best approach. &lt;/p&gt; &lt;p&gt;db process would be:&lt;br/&gt; Identify where relevant content is through vector search on redis.&lt;br/&gt; Pull rows in the db referenced by redis with the content. &lt;/p&gt; &lt;p&gt;accessing document directly:&lt;/p&gt; &lt;p&gt;Identify relevant content (doc, page, paragraphs)&lt;br/&gt; Get pdf from s3, pull relevant content&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/wiseduckling&quot;&gt; /u/wiseduckling &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj5fbp/where_do_you_pull_your_content_from_for_feeding/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj5fbp/where_do_you_pull_your_content_from_for_feeding/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cj5fbp</id><link href="https://www.reddit.com/r/LangChain/comments/1cj5fbp/where_do_you_pull_your_content_from_for_feeding/" /><updated>2024-05-03T10:35:57+00:00</updated><published>2024-05-03T10:35:57+00:00</published><title>Where do you pull your content from for feeding context in your RAG app?</title></entry><entry><author><name>/u/the-room-is-on-fire</name><uri>https://www.reddit.com/user/the-room-is-on-fire</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’m interested in building a RAG tool for internal company documents, and I intend on using a locally hosted LLM using ollama or LMstudio. From what I can tell, there wouldn’t be any data privacy concerns so long as I’m not using an API key for some LLM, but I’m not completely sure. Would my company’s data be secure?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/the-room-is-on-fire&quot;&gt; /u/the-room-is-on-fire &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj9nbx/langchain_for_data_privacy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj9nbx/langchain_for_data_privacy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cj9nbx</id><link href="https://www.reddit.com/r/LangChain/comments/1cj9nbx/langchain_for_data_privacy/" /><updated>2024-05-03T14:10:49+00:00</updated><published>2024-05-03T14:10:49+00:00</published><title>Langchain for data privacy?</title></entry><entry><author><name>/u/MidnightCS172</name><uri>https://www.reddit.com/user/MidnightCS172</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; If you&amp;#39;re a founder / enthusiast / just curious about the AI space, you can try using Llama 3 to automate your work.&lt;/p&gt; &lt;p&gt;Hey everyone! Launched my SaaS a few months back that helps businesses integrate AI.&lt;/p&gt; &lt;p&gt;Just wanted to share that we&amp;#39;re now housing Llama 3 for free thanks to a recent partnership!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;For those who are new to AI and ask why Llama 3? Why not GPT?&lt;/strong&gt;- open-sourced (you essentially can&amp;#39;t get locked out / censored)- higher standard benchmark than GPT 4 &lt;a href=&quot;https://www.techrepublic.com/article/what-is-llama-3/#&quot;&gt;(81.7 vs 67)&lt;/a&gt;- better code generation / lower misinformation rate- affordable / cost-efficient&lt;/p&gt; &lt;p&gt;Weave was made to be intuitive to non-coders, so don&amp;#39;t be too worried if coding isn&amp;#39;t your thing. Just select Llama 3 in the LLM library and input your instructions as you would in GPT 4 to test it out.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the link if anyone&amp;#39;s interested,&lt;a href=&quot;https://weave.chasm.net/&quot;&gt;https://weave.chasm.net/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MidnightCS172&quot;&gt; /u/MidnightCS172 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj9hbt/free_llama_3_workflow_builder/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj9hbt/free_llama_3_workflow_builder/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cj9hbt</id><link href="https://www.reddit.com/r/LangChain/comments/1cj9hbt/free_llama_3_workflow_builder/" /><updated>2024-05-03T14:03:33+00:00</updated><published>2024-05-03T14:03:33+00:00</published><title>Free Llama 3 Workflow Builder</title></entry><entry><author><name>/u/Unrealnooob</name><uri>https://www.reddit.com/user/Unrealnooob</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to build a chatbot with Langchain ,Flask and angular, How do I stream the data with the source documents?&lt;br/&gt; this is my chain&lt;/p&gt; &lt;pre&gt;&lt;code&gt; chain = ConversationalRetrievalChain.from_llm( llm=llm, retriever=retriever, combine_docs_chain_kwargs={&amp;quot;prompt&amp;quot;: qa_prompt}, verbose=True, memory=memory, return_source_documents=True ) result= chain.invoke({&amp;quot;question&amp;quot;: question}) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I tried with SSE, couldn&amp;#39;t make it work,ig its better to go with flask socket io, dk how to go with that, any help will be appreciated&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Unrealnooob&quot;&gt; /u/Unrealnooob &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj349m/how_do_i_stream_with_flask_and_langchain_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj349m/how_do_i_stream_with_flask_and_langchain_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cj349m</id><link href="https://www.reddit.com/r/LangChain/comments/1cj349m/how_do_i_stream_with_flask_and_langchain_with/" /><updated>2024-05-03T07:55:05+00:00</updated><published>2024-05-03T07:55:05+00:00</published><title>How do i stream with Flask and Langchain with Socket.io</title></entry><entry><author><name>/u/help-me-grow</name><uri>https://www.reddit.com/user/help-me-grow</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/help-me-grow&quot;&gt; /u/help-me-grow &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/AI_Agents/comments/1ciraov/seven_starter_notebooks_for_ai_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cirbgb/seven_starter_notebooks_for_ai_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cirbgb</id><link href="https://www.reddit.com/r/LangChain/comments/1cirbgb/seven_starter_notebooks_for_ai_agents/" /><updated>2024-05-02T21:25:47+00:00</updated><published>2024-05-02T21:25:47+00:00</published><title>Seven starter notebooks for AI Agents</title></entry><entry><author><name>/u/Wild_Plantain528</name><uri>https://www.reddit.com/user/Wild_Plantain528</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I made an open-source tool (k8sAI) using langchain agents. One of the issues I’ve seen is that the agent pretty often responds to users that it can’t perform an action that one of its tools clearly states that it can. And then if asked to do it, it will do it. &lt;/p&gt; &lt;p&gt;Has anyone else seen this come up? Is it mainly down to the system prompt or the tool description? Or are there other things to tweak?&lt;/p&gt; &lt;p&gt;Appreciate any advice and if you do any work with k8s, feel free to give the tool a go! It’s on GitHub.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Wild_Plantain528&quot;&gt; /u/Wild_Plantain528 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1civdv4/suggestions_for_improving_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1civdv4/suggestions_for_improving_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1civdv4</id><link href="https://www.reddit.com/r/LangChain/comments/1civdv4/suggestions_for_improving_agents/" /><updated>2024-05-03T00:29:56+00:00</updated><published>2024-05-03T00:29:56+00:00</published><title>Suggestions for improving agents</title></entry><entry><author><name>/u/OGbeeper99</name><uri>https://www.reddit.com/user/OGbeeper99</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, I have built a RAG application using llama-index, GPT3.5 and LanceDB. I want to integrate it into my company’s website. I wanted to know how can I do this? I’m open to using AWS if required for deploying it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OGbeeper99&quot;&gt; /u/OGbeeper99 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cimzf9/integrating_rag_app_into_an_existing_html_website/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cimzf9/integrating_rag_app_into_an_existing_html_website/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cimzf9</id><link href="https://www.reddit.com/r/LangChain/comments/1cimzf9/integrating_rag_app_into_an_existing_html_website/" /><updated>2024-05-02T18:29:33+00:00</updated><published>2024-05-02T18:29:33+00:00</published><title>Integrating RAG app into an existing HTML website</title></entry><entry><author><name>/u/Binary-Blue</name><uri>https://www.reddit.com/user/Binary-Blue</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciz0n1/issue_with_tool_naming_in_nlatoolkit/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/evqW4t9IDxVptNQFkghbNiP1zkIa8PQfSM5Qkv3eTTk.jpg&quot; alt=&quot;Issue with tool naming in NLA-Toolkit&quot; title=&quot;Issue with tool naming in NLA-Toolkit&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi I&amp;#39;m trying to use an open-api spec with the NLA toolkit but i get the below error: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;openai.BadRequestError: Error code: 400 - {&amp;#39;error&amp;#39;: {&amp;#39;message&amp;#39;: &amp;quot;&amp;#39;Ingress_API_v1.events&amp;#39; does not match &amp;#39;^[a-zA-Z0-9_-]{1,64}$&amp;#39; - &amp;#39;tools.1.function.name&amp;#39;&amp;quot;, &amp;#39;type&amp;#39;: &amp;#39;invalid_request_error&amp;#39;, &amp;#39;param&amp;#39;: None, &amp;#39;code&amp;#39;: None}} &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I believe this is because there is a &lt;/p&gt; &lt;pre&gt;&lt;code&gt;. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;in the tool name and that does not match the validation regex &lt;/p&gt; &lt;pre&gt;&lt;code&gt;^[a-zA-Z0-9_-]{1,64}$ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;? But when i did do some digging i found that the period is added intentionally by one of the tool creator functions , not sure if we need to update the regex or the naming str template?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/axm51v8dt4yc1.png?width=2228&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ad0d90e441d8ebb61611a1fe6f761543a5b22dfc&quot;&gt;https://preview.redd.it/axm51v8dt4yc1.png?width=2228&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ad0d90e441d8ebb61611a1fe6f761543a5b22dfc&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Binary-Blue&quot;&gt; /u/Binary-Blue &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciz0n1/issue_with_tool_naming_in_nlatoolkit/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciz0n1/issue_with_tool_naming_in_nlatoolkit/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ciz0n1</id><media:thumbnail url="https://b.thumbs.redditmedia.com/evqW4t9IDxVptNQFkghbNiP1zkIa8PQfSM5Qkv3eTTk.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1ciz0n1/issue_with_tool_naming_in_nlatoolkit/" /><updated>2024-05-03T03:36:44+00:00</updated><published>2024-05-03T03:36:44+00:00</published><title>Issue with tool naming in NLA-Toolkit</title></entry><entry><author><name>/u/mathieumaxime</name><uri>https://www.reddit.com/user/mathieumaxime</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m wondering if Langchain is made to build a chatbot with own trained data. I want to train a chabot with my company data. Similaire to GPTs, is it the good solution ? Thank you&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mathieumaxime&quot;&gt; /u/mathieumaxime &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciqzuc/building_chatbot_with_own_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciqzuc/building_chatbot_with_own_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ciqzuc</id><link href="https://www.reddit.com/r/LangChain/comments/1ciqzuc/building_chatbot_with_own_data/" /><updated>2024-05-02T21:12:10+00:00</updated><published>2024-05-02T21:12:10+00:00</published><title>Building chatbot with own data</title></entry><entry><author><name>/u/Healthy-Succotash458</name><uri>https://www.reddit.com/user/Healthy-Succotash458</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;br/&gt; I am creating an Agent RAG chatbot application which uses Tools.&lt;br/&gt; An example of the documents I expect to retrieve: &lt;/p&gt; &lt;p&gt;&lt;code&gt;Document(page_content=&amp;#39;Contents of lecture 1&amp;#39;, metadata={&amp;#39;source&amp;#39;: &amp;#39;Lecture-1.pdf&amp;#39;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;and the user&amp;#39;s request will look something like:&lt;/p&gt; &lt;p&gt;&lt;code&gt;Input(query=&amp;#39;summarize this lecture&amp;#39;,document_chosen=&amp;#39;Lecture-1.pdf&amp;#39;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;and I need to search ONLY on documents with the metadata source equal to &amp;#39;Lecture-1.pdf&amp;#39;.&lt;/p&gt; &lt;p&gt;I have seen in tutorials about VectorStoreRetrievers having this filtering functionality this way:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Use a filter to only retrieve documents from a specific metadata field db.as_retriever( search_kwargs={&amp;#39;filter&amp;#39;: {&amp;#39;source&amp;#39;:&amp;#39;Lecture-1.pdf&amp;#39;}} ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and this would solve the issue if I was directly invoking the retrievers. However for Agent, I cannot use the retrievers directly, and I need to wrap the retriever in a Tool (using create_retriever_tool) in order to use the agent and run a query: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain.tools.retriever import create_retriever_tool search_tool = create_retriever_tool( lecture_retriever, &amp;quot;search_lecture_database&amp;quot;, &amp;quot;&amp;quot;&amp;quot;Searches and returns lecture information.&amp;quot;&amp;quot;&amp;quot;, ) tools = [search_tool] agent = create_react_agent(llm,tools,prompt) agent_executor = AgentExecutor(agent=agent, tools=tools) response = agent_executor.invoke({&amp;quot;input&amp;quot;:&amp;quot;Summarise this lecture&amp;quot;}) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;So with my setup, how can I pass the metadata (in this case, the name of the file) filter to the retrievers from the Agent, when the retrievers are converted to Tools? &lt;/p&gt; &lt;p&gt;Any help or comments would be much appreciated&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Healthy-Succotash458&quot;&gt; /u/Healthy-Succotash458 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciizv7/agents_rag_search_with_tools_using_metadata/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciizv7/agents_rag_search_with_tools_using_metadata/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ciizv7</id><link href="https://www.reddit.com/r/LangChain/comments/1ciizv7/agents_rag_search_with_tools_using_metadata/" /><updated>2024-05-02T15:47:25+00:00</updated><published>2024-05-02T15:47:25+00:00</published><title>Agents: RAG search with tools using Metadata Filtering</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for a vectorDB for a RAG that am building. Needs to ingest a lot of data and should be optimized for retrieval. What are my options ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cijx8f</id><link href="https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/" /><updated>2024-05-02T16:24:21+00:00</updated><published>2024-05-02T16:24:21+00:00</published><title>What vectorDB do you all use?</title></entry><entry><author><name>/u/Standard_Vehicle_29</name><uri>https://www.reddit.com/user/Standard_Vehicle_29</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building a RAG based chatbot for some geographical data, can someone suggested me what kind of testing can I do to validate the chatbot &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Standard_Vehicle_29&quot;&gt; /u/Standard_Vehicle_29 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cisa8u/testing_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cisa8u/testing_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cisa8u</id><link href="https://www.reddit.com/r/LangChain/comments/1cisa8u/testing_rag_chatbot/" /><updated>2024-05-02T22:06:42+00:00</updated><published>2024-05-02T22:06:42+00:00</published><title>Testing RAG chatbot</title></entry><entry><author><name>/u/Junior_Reward2594</name><uri>https://www.reddit.com/user/Junior_Reward2594</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building an RAG system with over 100,000 startup pitch decks, and I want to be able to ask questions related to the graphs, diagrams, and illustrations in the pitch deck. For example, if I have a competitor slide with an x- and y-axis, I want my RAG system to understand that.&lt;/p&gt; &lt;p&gt;Is there something like a visual parser that can extract the visual meaning from each slide, chunk + embed it?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Junior_Reward2594&quot;&gt; /u/Junior_Reward2594 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciryrj/help_how_do_you_parse_visual_content_from_pitch/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciryrj/help_how_do_you_parse_visual_content_from_pitch/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ciryrj</id><link href="https://www.reddit.com/r/LangChain/comments/1ciryrj/help_how_do_you_parse_visual_content_from_pitch/" /><updated>2024-05-02T21:53:19+00:00</updated><published>2024-05-02T21:53:19+00:00</published><title>Help: How do you parse visual content from pitch decks for RAG?</title></entry><entry><author><name>/u/Brave-Guide-7470</name><uri>https://www.reddit.com/user/Brave-Guide-7470</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/e41kBpbrClfdwFjhQbFO0lBPyR2D-CYfc9oUqEt2ksQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3aa90a5396a7a8ad789e42874ec0066d7974dc44&quot; alt=&quot;Test your prompts through the terminal&quot; title=&quot;Test your prompts through the terminal&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys!&lt;/p&gt; &lt;p&gt;I&amp;#39;ve developed a helper CLI tool that allows you to test prompts on both ChatGPT and Anthropic models through a simple API.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/56s9aibuc0yc1.png?width=1597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d5408e2cd05ff382ea671c0816b67567cd53cbf0&quot;&gt;https://preview.redd.it/56s9aibuc0yc1.png?width=1597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d5408e2cd05ff382ea671c0816b67567cd53cbf0&lt;/a&gt;&lt;/p&gt; &lt;p&gt;To test it, just run:&lt;/p&gt; &lt;p&gt;pip install dialog-lib&lt;/p&gt; &lt;p&gt;export OPENAI_API_KEY=sk-YOUR_API_KEY&lt;/p&gt; &lt;p&gt;dialog openai --prompt &amp;quot;Your prompt that you want to test, here!&amp;quot;&lt;/p&gt; &lt;p&gt;Here is a link to a quick demo: &lt;a href=&quot;https://www.linkedin.com/feed/update/urn:li:activity:7191776208651489282/&quot;&gt;https://www.linkedin.com/feed/update/urn:li:activity:7191776208651489282/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Brave-Guide-7470&quot;&gt; /u/Brave-Guide-7470 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cielku</id><media:thumbnail url="https://external-preview.redd.it/e41kBpbrClfdwFjhQbFO0lBPyR2D-CYfc9oUqEt2ksQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3aa90a5396a7a8ad789e42874ec0066d7974dc44" /><link href="https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/" /><updated>2024-05-02T12:37:09+00:00</updated><published>2024-05-02T12:37:09+00:00</published><title>Test your prompts through the terminal</title></entry></feed>