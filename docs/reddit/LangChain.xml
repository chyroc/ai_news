<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-08-08T10:23:05+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Embarrassed_Bread121</name><uri>https://www.reddit.com/user/Embarrassed_Bread121</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks. I am a Machine Learning Engineer looking for open opportunities in Bangalore. I have 1 year of experience in developing and deploying ML solutions convering basic ML fundamentals like regression models and data analysis to building RAG applications using vector DB and Langchain. I have worked in shaping ideas into POCs using Machine Learning and Deep Learning. &lt;/p&gt; &lt;p&gt;My tech stack includes Python, Jupyter Notebook, Sci-kit Learn, Langchain, Vector DB, fine-tuning LLMs for specific use cases.&lt;/p&gt; &lt;p&gt;I am also experienced in developing &amp;amp; deploying the end to end LLM applications to AWS cloud. I am passionate about ML.&lt;/p&gt; &lt;p&gt;Any leads would be appreciated. Thank You &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Embarrassed_Bread121&quot;&gt; /u/Embarrassed_Bread121 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en1s8v/ml_engineer_1_yoe_looking_for_an_open_opportunity/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en1s8v/ml_engineer_1_yoe_looking_for_an_open_opportunity/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en1s8v</id><link href="https://www.reddit.com/r/LangChain/comments/1en1s8v/ml_engineer_1_yoe_looking_for_an_open_opportunity/" /><updated>2024-08-08T09:44:44+00:00</updated><published>2024-08-08T09:44:44+00:00</published><title>ML Engineer (1 YOE) looking for an open opportunity</title></entry><entry><author><name>/u/abhinavkimothi</name><uri>https://www.reddit.com/user/abhinavkimothi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em6m7e/embeddings_the_blueprint_of_contextual_ai/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/QKVGsXwodAGF0k5YNnyDIcsDJJeG9DZ2QpyUcA904NE.jpg&quot; alt=&quot;Embeddings : The blueprint of Contextual AI&quot; title=&quot;Embeddings : The blueprint of Contextual AI&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/abhinavkimothi&quot;&gt; /u/abhinavkimothi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/gallery/1em6m7e&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em6m7e/embeddings_the_blueprint_of_contextual_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1em6m7e</id><media:thumbnail url="https://b.thumbs.redditmedia.com/QKVGsXwodAGF0k5YNnyDIcsDJJeG9DZ2QpyUcA904NE.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1em6m7e/embeddings_the_blueprint_of_contextual_ai/" /><updated>2024-08-07T08:34:09+00:00</updated><published>2024-08-07T08:34:09+00:00</published><title>Embeddings : The blueprint of Contextual AI</title></entry><entry><author><name>/u/Gokulander</name><uri>https://www.reddit.com/user/Gokulander</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all, I have been trying to use Langchain Summarization chain with Open ai, it does summarises the document but it translates it to english. &lt;/p&gt; &lt;p&gt;And the same llm works, fine for RAG or normal llm.invoke. It is giving me answer in English, but only for Summarization it is sending me russian response.&lt;/p&gt; &lt;p&gt;Please help&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Gokulander&quot;&gt; /u/Gokulander &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en1mx5/russian_response_when_generating_summary_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en1mx5/russian_response_when_generating_summary_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en1mx5</id><link href="https://www.reddit.com/r/LangChain/comments/1en1mx5/russian_response_when_generating_summary_using/" /><updated>2024-08-08T09:34:38+00:00</updated><published>2024-08-08T09:34:38+00:00</published><title>Russian response when generating summary using langchain and openai</title></entry><entry><author><name>/u/Initial-Advantage-88</name><uri>https://www.reddit.com/user/Initial-Advantage-88</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can anyone tell me some ways to pass down the schema of the table to the chain, I am passing it in query checker(reference below) but could not make a full chain to pass it initially too. &lt;/p&gt; &lt;h1&gt;&lt;a href=&quot;https://python.langchain.com/v0.1/docs/use%5C_cases/sql/query%5C_checking/&quot;&gt;https://python.langchain.com/v0.1/docs/use\_cases/sql/query\_checking/&lt;/a&gt;&lt;/h1&gt; &lt;p&gt;Good thing is the schema of my table is fixed so is there any other method you folks having in mind which can enable me make a fully local genAI text-to-SQL model.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Initial-Advantage-88&quot;&gt; /u/Initial-Advantage-88 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emxori/trying_to_build_a_natural_language_to_sql_model/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emxori/trying_to_build_a_natural_language_to_sql_model/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emxori</id><link href="https://www.reddit.com/r/LangChain/comments/1emxori/trying_to_build_a_natural_language_to_sql_model/" /><updated>2024-08-08T05:13:56+00:00</updated><published>2024-08-08T05:13:56+00:00</published><title>Trying to build a Natural Language to SQL model using langchain's &quot;create_sql_query_chain&quot;.</title></entry><entry><author><name>/u/kush_sahu_2020</name><uri>https://www.reddit.com/user/kush_sahu_2020</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks!&lt;/p&gt; &lt;p&gt;Just wanted to know, has anyone have worked with langgraph for supervisor agentic framework using AWS Bedrock models like Mistral large or Claude 3.5. For me, any model I use from AWS Bedrock with Agents it&amp;#39;s giving &amp;#39;Validation Error while calling InvokeModel operation&amp;#39; although I am giving correct prompt format for the models.&lt;/p&gt; &lt;p&gt;Please help me on this, inform me if you need more information. Thanks in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kush_sahu_2020&quot;&gt; /u/kush_sahu_2020 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en13pm/langgraph_with_aws_bedrock/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en13pm/langgraph_with_aws_bedrock/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en13pm</id><link href="https://www.reddit.com/r/LangChain/comments/1en13pm/langgraph_with_aws_bedrock/" /><updated>2024-08-08T08:59:22+00:00</updated><published>2024-08-08T08:59:22+00:00</published><title>Langgraph with AWS Bedrock</title></entry><entry><author><name>/u/smtabatabaie</name><uri>https://www.reddit.com/user/smtabatabaie</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, i&amp;#39;m trying to create a prompt in langchain hub from an already existing public prompt by just copying and pasting its content into a new prompt. This is the first prompt I&amp;#39;m trying to create and it seems though I tried to duplicate the original prompt, My prompt is different from the original prompt.&lt;br/&gt; Here&amp;#39;s the link to my prompt: &lt;a href=&quot;https://smith.langchain.com/hub/smtabatabaie/gps&quot;&gt;https://smith.langchain.com/hub/smtabatabaie/gps&lt;/a&gt;&lt;br/&gt; And here&amp;#39;s the original prompt: &lt;a href=&quot;https://smith.langchain.com/hub/smtabatabaie/web-voyager&quot;&gt;https://smith.langchain.com/hub/smtabatabaie/web-voyager&lt;/a&gt;&lt;br/&gt; My prompt has a &amp;quot;ChatOpenAI&amp;quot; whereas the original prompt doesn&amp;#39;t have this section. And also my prompt has &amp;quot;scratchpad&amp;quot; as input whereas the original prompt doesn&amp;#39;t consider &amp;quot;scratchpad&amp;quot; as an input when I print the prompt in my python script.&lt;br/&gt; Also in my script when I pull and use the original prompt, it works without any problem. But when i pull and use my prompt, it shows me the following error about hitting the maximum context length: &lt;/p&gt; &lt;p&gt;&amp;quot;openai.BadRequestError: Error code: 400 - {&amp;#39;error&amp;#39;: {&amp;#39;message&amp;#39;: &amp;quot;This model&amp;#39;s maximum context length is 128000 tokens. However, your messages resulted in 473683 tokens. Please reduce the length of the messages.&amp;quot;, &amp;#39;type&amp;#39;: &amp;#39;invalid_request_error&amp;#39;, &amp;#39;param&amp;#39;: &amp;#39;messages&amp;#39;, &amp;#39;code&amp;#39;: &amp;#39;context_length_exceeded&amp;#39;}}&amp;quot; &lt;/p&gt; &lt;p&gt;Would really appreciate if you have any idea what&amp;#39;s causing this.&lt;br/&gt; Thanks very much.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/smtabatabaie&quot;&gt; /u/smtabatabaie &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en0h86/creating_a_prompt_in_langchain_hub/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1en0h86/creating_a_prompt_in_langchain_hub/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1en0h86</id><link href="https://www.reddit.com/r/LangChain/comments/1en0h86/creating_a_prompt_in_langchain_hub/" /><updated>2024-08-08T08:16:26+00:00</updated><published>2024-08-08T08:16:26+00:00</published><title>Creating a prompt in Langchain hub</title></entry><entry><author><name>/u/No-Opportunity8473</name><uri>https://www.reddit.com/user/No-Opportunity8473</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Yo using langflow, a no code editor built off of langchain (I know this is a langchain server, but the problem should be mirrored in langchain), currently trying to run a zero shot agent with Gemini, using a tool call agent, &lt;/p&gt; &lt;p&gt;integrating openAI works perfectly fine, but with Gemini, I get the error code in my image, any pointers in the right direction would be great,&lt;/p&gt; &lt;p&gt;Here is the 2 components &amp;amp; how they link (took other components out for simplicity)&lt;br/&gt; &lt;a href=&quot;https://www.loom.com/share/61e4cd93166445bea7af0a962500af29?sid=8c9b0cc3-195e-4fef-a6b8-922670c52f95&quot;&gt;https://www.loom.com/share/61e4cd93166445bea7af0a962500af29?sid=8c9b0cc3-195e-4fef-a6b8-922670c52f95&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Any pointers would be amazing&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No-Opportunity8473&quot;&gt; /u/No-Opportunity8473 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emvqkj/gemini_zero_shot_promptfunction_call_any_help/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emvqkj/gemini_zero_shot_promptfunction_call_any_help/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emvqkj</id><link href="https://www.reddit.com/r/LangChain/comments/1emvqkj/gemini_zero_shot_promptfunction_call_any_help/" /><updated>2024-08-08T03:25:01+00:00</updated><published>2024-08-08T03:25:01+00:00</published><title>Gemini Zero shot prompt/function call, any help?</title></entry><entry><author><name>/u/jakezegil</name><uri>https://www.reddit.com/user/jakezegil</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everybody,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been really frustrated with the developer experience of Langchain in Typescript, particularly around structured extraction from image and text and agent workflows. I have started building out a dev toolkit to solve that with some DX inspiration from dev tools like vercel and prisma: &lt;a href=&quot;https://github.com/forge-ml/forge-ml&quot;&gt;https://github.com/forge-ml/forge-ml&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I&amp;#39;d love feedback on the current product, but I&amp;#39;d also love to know what else I can incorporate - what are the big pain points people are having? &lt;/p&gt; &lt;p&gt;Some of the current things on the roadmap are, in no particular order:&lt;br/&gt; - structured extraction from video&lt;br/&gt; - structured extraction from audio&lt;br/&gt; - Anthropic/Groq support&lt;br/&gt; - Semantic Search over Documents&lt;br/&gt; - Semantic Search over Databases&lt;br/&gt; - Fine tuning&lt;br/&gt; - Workflows&lt;br/&gt; - Model routing&lt;/p&gt; &lt;p&gt;What are the biggest issues that you&amp;#39;re facing when building AI products?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jakezegil&quot;&gt; /u/jakezegil &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emfs9w/how_can_i_help_you_build_more_reliable_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emfs9w/how_can_i_help_you_build_more_reliable_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emfs9w</id><link href="https://www.reddit.com/r/LangChain/comments/1emfs9w/how_can_i_help_you_build_more_reliable_ai/" /><updated>2024-08-07T16:07:25+00:00</updated><published>2024-08-07T16:07:25+00:00</published><title>How can I help you build more reliable AI products faster?</title></entry><entry><author><name>/u/jiraiya1729</name><uri>https://www.reddit.com/user/jiraiya1729</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Other than chatbot what are the other use cases the LLM or open source hugging face models are used for? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jiraiya1729&quot;&gt; /u/jiraiya1729 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emgi8p/discussion_llm_use_cases/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emgi8p/discussion_llm_use_cases/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emgi8p</id><link href="https://www.reddit.com/r/LangChain/comments/1emgi8p/discussion_llm_use_cases/" /><updated>2024-08-07T16:35:10+00:00</updated><published>2024-08-07T16:35:10+00:00</published><title>[Discussion] LLM use cases</title></entry><entry><author><name>/u/MountainBlock</name><uri>https://www.reddit.com/user/MountainBlock</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve developed a script using Langchain and Agents that I plan to launch internally within our company. Before moving it to production, I&amp;#39;d appreciate a second pair of eyes to review the code for any potential redundancies or areas for improvement.&lt;/p&gt; &lt;p&gt;I’ve noticed that some posts sharing code here don’t always get much traction. I didn’t see any rules against sharing code for review, but I wanted to check if it&amp;#39;s appropriate to ask for feedback here. &lt;/p&gt; &lt;p&gt;If not, could you suggest any other platforms where I might get my code reviewed?&lt;/p&gt; &lt;p&gt;Thanks in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MountainBlock&quot;&gt; /u/MountainBlock &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emiqo5/where_can_i_get_my_code_reviewed/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emiqo5/where_can_i_get_my_code_reviewed/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emiqo5</id><link href="https://www.reddit.com/r/LangChain/comments/1emiqo5/where_can_i_get_my_code_reviewed/" /><updated>2024-08-07T18:01:57+00:00</updated><published>2024-08-07T18:01:57+00:00</published><title>Where can I get my code reviewed?</title></entry><entry><author><name>/u/Wise-Dog-9930</name><uri>https://www.reddit.com/user/Wise-Dog-9930</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Folks, I am really new here. I am working on a multi-agent project where each agent would look up information on a set of select predefined websites. I am hoping to use web search to do it. Is there a way for me search articles related to a specific topic on a specific website using web search?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Wise-Dog-9930&quot;&gt; /u/Wise-Dog-9930 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emdose/specialized_web_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emdose/specialized_web_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emdose</id><link href="https://www.reddit.com/r/LangChain/comments/1emdose/specialized_web_search/" /><updated>2024-08-07T14:47:07+00:00</updated><published>2024-08-07T14:47:07+00:00</published><title>Specialized Web Search</title></entry><entry><author><name>/u/ekkoogod</name><uri>https://www.reddit.com/user/ekkoogod</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i&amp;#39;ve developped a rag application using langchain with the retrieval chain that combines history retriever and documents chain, and it performs pretty good .&lt;br/&gt; i have been tasked to add summarization and some other tools , so i tought about using agent and adding tools for such tasks and still use the rag chain as a tool . &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Is there a way to use the same rag chain as a tool for the agent ?&lt;/strong&gt; &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ekkoogod&quot;&gt; /u/ekkoogod &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emd7m3/using_retrieval_chain_as_a_tool_for_an_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emd7m3/using_retrieval_chain_as_a_tool_for_an_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1emd7m3</id><link href="https://www.reddit.com/r/LangChain/comments/1emd7m3/using_retrieval_chain_as_a_tool_for_an_agent/" /><updated>2024-08-07T14:27:30+00:00</updated><published>2024-08-07T14:27:30+00:00</published><title>using retrieval_chain as a tool for an agent</title></entry><entry><author><name>/u/Suitable-Ad-8598</name><uri>https://www.reddit.com/user/Suitable-Ad-8598</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Based on some advice I got, I started using AWS Textract ($$$) for PDFs and unstructured (local/free) for all other doc types such as docx and html. &lt;/p&gt; &lt;p&gt;My textract bill is getting a bit out of hand and I was wondering if there are any better services out there that can interpret things like tables and stuff from PDFs and other docs well?&lt;/p&gt; &lt;p&gt;Quality is my number one concern but cost is also important.&lt;/p&gt; &lt;p&gt;Looking to replace textract but also wanted to check to see if unstructured is still considered the best for other doc types.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Suitable-Ad-8598&quot;&gt; /u/Suitable-Ad-8598 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elr7sr/what_is_the_best_document_loader_for_pdfs_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elr7sr/what_is_the_best_document_loader_for_pdfs_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elr7sr</id><link href="https://www.reddit.com/r/LangChain/comments/1elr7sr/what_is_the_best_document_loader_for_pdfs_and/" /><updated>2024-08-06T19:46:01+00:00</updated><published>2024-08-06T19:46:01+00:00</published><title>What is the best document loader for PDFs? And other docs in general?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1em61b0/free_llm_apis_to_know/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em61t8/free_llm_apis_to_know/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em61t8</id><link href="https://www.reddit.com/r/LangChain/comments/1em61t8/free_llm_apis_to_know/" /><updated>2024-08-07T07:55:35+00:00</updated><published>2024-08-07T07:55:35+00:00</published><title>Free LLM APIs to know</title></entry><entry><author><name>/u/BellaHi</name><uri>https://www.reddit.com/user/BellaHi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em0qmz/langchain_vs_llamaindex_choose_the_best_framework/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/xdRw2A4E1tAFHQRy07JwUiPTZWn466MaEpJKn-gWRf8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9161ceea81d99df6557d0af71471532e71f230d8&quot; alt=&quot;LangChain vs LlamaIndex: Choose the Best Framework for Your AI Applications&quot; title=&quot;LangChain vs LlamaIndex: Choose the Best Framework for Your AI Applications&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BellaHi&quot;&gt; /u/BellaHi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://myscale.com/blog/llamaindex-vs-langchain-detailed-comparison/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em0qmz/langchain_vs_llamaindex_choose_the_best_framework/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1em0qmz</id><media:thumbnail url="https://external-preview.redd.it/xdRw2A4E1tAFHQRy07JwUiPTZWn466MaEpJKn-gWRf8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9161ceea81d99df6557d0af71471532e71f230d8" /><link href="https://www.reddit.com/r/LangChain/comments/1em0qmz/langchain_vs_llamaindex_choose_the_best_framework/" /><updated>2024-08-07T02:41:36+00:00</updated><published>2024-08-07T02:41:36+00:00</published><title>LangChain vs LlamaIndex: Choose the Best Framework for Your AI Applications</title></entry><entry><author><name>/u/phan_ngt</name><uri>https://www.reddit.com/user/phan_ngt</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have very simple code &lt;strong&gt;Langserve&lt;/strong&gt; with &lt;strong&gt;langfuse_handler&lt;/strong&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;add_routes(app, normal_agent.with_config(RunnableConfig(callbacks=[langfuse_handler])), per_req_config_modifier=per_request_config_modifier, path=&amp;quot;/normal&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When I run my code: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;import asyncio from langserve import RemoteRunnable remote_runnable = RemoteRunnable(&amp;quot;http://localhost:8001/normal&amp;quot;) async def main(): async for chunk in remote_runnable.astream({&amp;#39;input&amp;#39;: &amp;#39;tell me about ronaldo&amp;#39;}): print(chunk, end=&amp;#39;|\n&amp;#39;, flush=True) asyncio.run(main()) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I want return to client my trace_id of Langfuse. Do you have any ideas to do that? I stuck here for 2 days. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phan_ngt&quot;&gt; /u/phan_ngt &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em7aik/how_to_return_langfuse_trace_id_when_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em7aik/how_to_return_langfuse_trace_id_when_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em7aik</id><link href="https://www.reddit.com/r/LangChain/comments/1em7aik/how_to_return_langfuse_trace_id_when_using/" /><updated>2024-08-07T09:20:38+00:00</updated><published>2024-08-07T09:20:38+00:00</published><title>How to return langfuse trace_id when using Langserve stream?</title></entry><entry><author><name>/u/anujtomar_17</name><uri>https://www.reddit.com/user/anujtomar_17</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emasec/how_is_artificial_intelligence_transforming_every/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/c7vrszPtN15vT-OCeI7U4uVmTYXabFtpBRSWRUYD0m8.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=be3b9e23e90b82f3f7f7b7de289007d6bb5361ca&quot; alt=&quot;How is Artificial Intelligence Transforming Every Industry?&quot; title=&quot;How is Artificial Intelligence Transforming Every Industry?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/anujtomar_17&quot;&gt; /u/anujtomar_17 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.quickwayinfosystems.com/blog/how-artificial-intelligence-transforming/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1emasec/how_is_artificial_intelligence_transforming_every/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1emasec</id><media:thumbnail url="https://external-preview.redd.it/c7vrszPtN15vT-OCeI7U4uVmTYXabFtpBRSWRUYD0m8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=be3b9e23e90b82f3f7f7b7de289007d6bb5361ca" /><link href="https://www.reddit.com/r/LangChain/comments/1emasec/how_is_artificial_intelligence_transforming_every/" /><updated>2024-08-07T12:43:20+00:00</updated><published>2024-08-07T12:43:20+00:00</published><title>How is Artificial Intelligence Transforming Every Industry?</title></entry><entry><author><name>/u/notknot0</name><uri>https://www.reddit.com/user/notknot0</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I need to build a simple chatbot for my documentation pages. I need advice on where to host it, currently I adjusted it for Supabase edge function and Supabase vector store because it&amp;#39;s free and deployed all over the world, but if I exceed the requests limit, I will have to self-host Supabase and then it&amp;#39;s just one location.&lt;/p&gt; &lt;p&gt;Does anyone already have chatbots for small documentations and can you share which vector store you use and where you deployed your code? my docs pages are served from AWS S3. If I use AWS lambda to host the edge function, I&amp;#39;m afraid of a cost increase if there will be many requests.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/notknot0&quot;&gt; /u/notknot0 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em997z/advice_on_where_to_host_langchainjs_rest_api/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em997z/advice_on_where_to_host_langchainjs_rest_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em997z</id><link href="https://www.reddit.com/r/LangChain/comments/1em997z/advice_on_where_to_host_langchainjs_rest_api/" /><updated>2024-08-07T11:24:10+00:00</updated><published>2024-08-07T11:24:10+00:00</published><title>Advice on where to host LangChain.js REST API function for Q&amp;A chatbot for my docs</title></entry><entry><author><name>/u/TimeTravellingCat</name><uri>https://www.reddit.com/user/TimeTravellingCat</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elkjcz/building_multiagent_workflows_with_open_and/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/emRxMDJpOTA1MmhkMQOeLRWbXZLLqGF7C1pE6u8v4bV4Eov2GX0h5P2dipJi.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=efb7632c3d308cdeef92241156ced31db3fcbf57&quot; alt=&quot;Building multi-agent workflows with open and closed models using an open-source low-code platform&quot; title=&quot;Building multi-agent workflows with open and closed models using an open-source low-code platform&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TimeTravellingCat&quot;&gt; /u/TimeTravellingCat &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/nzs7bi9052hd1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elkjcz/building_multiagent_workflows_with_open_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1elkjcz</id><media:thumbnail url="https://external-preview.redd.it/emRxMDJpOTA1MmhkMQOeLRWbXZLLqGF7C1pE6u8v4bV4Eov2GX0h5P2dipJi.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=efb7632c3d308cdeef92241156ced31db3fcbf57" /><link href="https://www.reddit.com/r/LangChain/comments/1elkjcz/building_multiagent_workflows_with_open_and/" /><updated>2024-08-06T15:20:54+00:00</updated><published>2024-08-06T15:20:54+00:00</published><title>Building multi-agent workflows with open and closed models using an open-source low-code platform</title></entry><entry><author><name>/u/GPT-Claude-Gemini</name><uri>https://www.reddit.com/user/GPT-Claude-Gemini</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone I want to share a Langchain-based project that I have been working on for the last few months — &lt;a href=&quot;https://www.jenova.ai/&quot;&gt;JENOVA&lt;/a&gt;, an AI (similar to ChatGPT) that integrates the best foundation models and tools into one seamless experience.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;AI is advancing too fast for most people to follow.&lt;/strong&gt; New state-of-the-art models emerge constantly, each with unique strengths and specialties. Currently:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Claude 3.5 Sonnet is the best at reasoning, math, and coding.&lt;/li&gt; &lt;li&gt;Gemini 1.5 Pro excels in business/financial analysis and language translations.&lt;/li&gt; &lt;li&gt;Llama 3.1 405B is most performative in roleplaying and creativity.&lt;/li&gt; &lt;li&gt;GPT-4o is most knowledgeable in areas such as art, entertainment, and travel.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This rapidly changing and fragmenting AI landscape is leading to the following problems for consumers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Awareness Gap:&lt;/strong&gt; Most people are unaware of the latest models and their specific strengths, and are often paying for AI (e.g. ChatGPT) that is suboptimal for their tasks.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Constant Switching:&lt;/strong&gt; Due to constant changes in SOTA models, consumers have to frequently switch their preferred AI and subscription.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;User Friction:&lt;/strong&gt; Switching AI results in significant user experience disruptions, such as losing chat histories or critical features such as web browsing.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;JENOVA is built to solve this.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;When you ask JENOVA a question, it automatically routes your query to the model that can provide the optimal answer (built on top of Langchain).&lt;/strong&gt; For example, if your first question is about coding, then Claude 3.5 Sonnet will respond. If your second question is about tourist spots in Tokyo, then GPT-4o will respond. All this happens seamlessly in the background.&lt;/p&gt; &lt;p&gt;JENOVA&amp;#39;s model ranking is continuously updated to incorporate the latest AI models and performance benchmarks, ensuring you are always using the best models for your specific needs.&lt;/p&gt; &lt;p&gt;In addition to the best AI models, JENOVA also provides you with an expanding suite of the most useful tools, starting with:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Web browsing&lt;/strong&gt; for real-time information (performs surprisingly well, nearly on par with Perplexity)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Multi-format document analysis&lt;/strong&gt; including PDF, Word, Excel, PowerPoint, and more&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Image interpretation&lt;/strong&gt; for visual tasks&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Your privacy is very important to us. Your conversations and data are never used for training, either by us or by third-party AI providers.&lt;/p&gt; &lt;p&gt;Try it out at &lt;a href=&quot;https://www.jenova.ai/&quot;&gt;&lt;strong&gt;www.jenova.ai&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; JENOVA might be running into some issues with web search/browsing right now due to very high demand.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/GPT-Claude-Gemini&quot;&gt; /u/GPT-Claude-Gemini &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ellpk9/sharing_my_project_that_was_built_on_langchain_an/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ellpk9/sharing_my_project_that_was_built_on_langchain_an/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ellpk9</id><link href="https://www.reddit.com/r/LangChain/comments/1ellpk9/sharing_my_project_that_was_built_on_langchain_an/" /><updated>2024-08-06T16:07:14+00:00</updated><published>2024-08-06T16:07:14+00:00</published><title>Sharing my project that was built on Langchain: An all-in-one AI that integrates the best foundation models (GPT, Claude, Gemini, Llama) and tools into one seamless experience.</title></entry><entry><author><name>/u/maniac_runner</name><uri>https://www.reddit.com/user/maniac_runner</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/maniac_runner&quot;&gt; /u/maniac_runner &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://openai.com/index/introducing-structured-outputs-in-the-api/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em0d5n/introducing_structured_outputs_in_the_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em0d5n</id><link href="https://www.reddit.com/r/LangChain/comments/1em0d5n/introducing_structured_outputs_in_the_api/" /><updated>2024-08-07T02:22:55+00:00</updated><published>2024-08-07T02:22:55+00:00</published><title>Introducing Structured Outputs in the API</title></entry><entry><author><name>/u/phuzul</name><uri>https://www.reddit.com/user/phuzul</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am fairly new to Langchain and wanted to seek out some advice for free methods of using LLMs to just do some basic prompting for a web application. The prompting is just providing some music artists and asking the LLM to think of potential ideas for those artists. I have a node.js backend that I am attempting to integrate Langchain.js into. &lt;/p&gt; &lt;p&gt;I first wanted to ask are there any decent models for my task that can be used with Langchain.js for free and what would a very basic code snippet look like to run it. &lt;/p&gt; &lt;p&gt;In addition, I wanted to ask if Ollama is applicable here or is that strictly for local applications?&lt;/p&gt; &lt;p&gt;Thanks !&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phuzul&quot;&gt; /u/phuzul &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em3muc/support_with_langchainjs_for_free_inference/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em3muc/support_with_langchainjs_for_free_inference/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em3muc</id><link href="https://www.reddit.com/r/LangChain/comments/1em3muc/support_with_langchainjs_for_free_inference/" /><updated>2024-08-07T05:17:36+00:00</updated><published>2024-08-07T05:17:36+00:00</published><title>Support with Langchain.js for free inference</title></entry><entry><author><name>/u/ProfessionalBig9431</name><uri>https://www.reddit.com/user/ProfessionalBig9431</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hi there i am learning about rag with knowledge graph any proper documentation from where i can get the reference any thing would be helpful &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ProfessionalBig9431&quot;&gt; /u/ProfessionalBig9431 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em3b9p/rag_and_knowledge_graph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em3b9p/rag_and_knowledge_graph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em3b9p</id><link href="https://www.reddit.com/r/LangChain/comments/1em3b9p/rag_and_knowledge_graph/" /><updated>2024-08-07T04:58:39+00:00</updated><published>2024-08-07T04:58:39+00:00</published><title>RAG and KNOWLEDGE GRAPH</title></entry><entry><author><name>/u/BigYesterday2785</name><uri>https://www.reddit.com/user/BigYesterday2785</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I wanted to ask, if I want to run local LLMs only on CPU.&lt;/p&gt; &lt;p&gt;I do not have access to GPUs and wanted to ask how much slower CPU would be, compared to GPU.&lt;/p&gt; &lt;p&gt;I would love to run a small Open Source LLM only on CPUs to read 500 pages PDFs and be able to ask it questions.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BigYesterday2785&quot;&gt; /u/BigYesterday2785 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli67w/run_local_llm_on_cpu_how_bad_would_would_it_be/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli67w/run_local_llm_on_cpu_how_bad_would_would_it_be/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eli67w</id><link href="https://www.reddit.com/r/LangChain/comments/1eli67w/run_local_llm_on_cpu_how_bad_would_would_it_be/" /><updated>2024-08-06T13:44:24+00:00</updated><published>2024-08-06T13:44:24+00:00</published><title>Run local LLM on CPU. how Bad would would it be compared to GPUs</title></entry><entry><author><name>/u/Standard-Factor-9408</name><uri>https://www.reddit.com/user/Standard-Factor-9408</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone come across an issue with chroma as a vector store where it can’t handle a large K unless it’s “warmed up”?&lt;/p&gt; &lt;p&gt;Have a db with about 30k docs in it each about a paragraph long. I need to return the top 100 or so as part of a larger ranking process. When I first load the db though if I don’t start with a k size of 5 and work my way up it consistently errors out with “cannot return the results in a contiguous 2d array. Probably ef or M is too small”. I’ve tried changing the hnsw parameters when creating the collection but nothing seems to give. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Standard-Factor-9408&quot;&gt; /u/Standard-Factor-9408 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ely226/chromadb_issues/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ely226/chromadb_issues/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ely226</id><link href="https://www.reddit.com/r/LangChain/comments/1ely226/chromadb_issues/" /><updated>2024-08-07T00:32:49+00:00</updated><published>2024-08-07T00:32:49+00:00</published><title>Chromadb issues</title></entry></feed>