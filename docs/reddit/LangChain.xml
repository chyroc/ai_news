<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-14T21:54:04+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Secret_Wave6520</name><uri>https://www.reddit.com/user/Secret_Wave6520</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;can i get an invite code for langsmith please , been waiting forever&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Secret_Wave6520&quot;&gt; /u/Secret_Wave6520 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196nq3r/can_i_get_an_invite_code_for_langsmith_please/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196nq3r/can_i_get_an_invite_code_for_langsmith_please/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_196nq3r</id><link href="https://www.reddit.com/r/LangChain/comments/196nq3r/can_i_get_an_invite_code_for_langsmith_please/" /><updated>2024-01-14T19:20:45+00:00</updated><published>2024-01-14T19:20:45+00:00</published><title>can i get an invite code for langsmith please , been waiting forever</title></entry><entry><author><name>/u/wwwy3y3</name><uri>https://www.reddit.com/user/wwwy3y3</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently working on an internal project at my company. My goal is to develop a chat-based solution that allows business users to query the data warehouse (we&amp;#39;re using BigQuery) through conversation. I‚Äôm trying to make this project more production-ready, rather than being an experiment. I‚Äôm using LangChain and followed guides in documentation &amp;amp; blogs (ex: &lt;a href=&quot;https://python.langchain.com/docs/use_cases/qa_structured/sql&quot;&gt;https://python.langchain.com/docs/use_cases/qa_structured/sql&lt;/a&gt;) to achieve the first version and I could really use some inputs:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Data Privacy and Access Control&lt;/strong&gt;: One of our top priorities is to ensure data privacy and appropriate access controls. Tagging a column like ‚Äúrevenue‚Äù to be private might work for simple scenarios, but real-life scenarios are more complex, for example, how do you let users from the marketing department see the ‚Äúemail‚Äù column of customers, while others see redacted email? What about row-level security?&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Reviewing Generated SQL Queries&lt;/strong&gt;: Our data analysts have raised concerns about the difficulty in reviewing SQL statements generated by LLMs. These queries can be complex and hard to interpret. Any suggestions for making this process more manageable and transparent? Perhaps a SQL lineage tool to show the visibility of the SQL ?&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Semantic Integration with Database Tables and Columns&lt;/strong&gt;: Lastly, I&amp;#39;m wondering about the best way to integrate semantics into our database tables and columns. Seems that feeding dbt models (including description) directly to the LLM can work at first, but is there any solution that I can let business users define these metadata themselves ? Does it mean I need to build an internal tool that allows users to update the metadata ?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Any feedback, insights, or experiences you can share regarding these challenges are appreciated.&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/wwwy3y3&quot;&gt; /u/wwwy3y3 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196lhv9/seeking_advice_for_developing_a_texttosql/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196lhv9/seeking_advice_for_developing_a_texttosql/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_196lhv9</id><link href="https://www.reddit.com/r/LangChain/comments/196lhv9/seeking_advice_for_developing_a_texttosql/" /><updated>2024-01-14T17:45:49+00:00</updated><published>2024-01-14T17:45:49+00:00</published><title>Seeking advice for developing a text-to-sql application</title></entry><entry><author><name>/u/hxh6749</name><uri>https://www.reddit.com/user/hxh6749</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;My employer is doing a Hackathon soon and the focus is on GenAI. Like most orgs, they‚Äôve created a spin off LLM for employee use running on GPT-4 that we can use in our daily tasks (and hackathon practice). There‚Äôs a document upload feature where I‚Äôve been providing context about the platform we support (microservices in FinTech) along with a small dataset of information related to successful processing of requests, time taken data, and application error log data for maybe a 15 minute sample and would them prompt it with a question like ‚ÄúCustomer XYZ reported some issues at 11:30am, was anything going on?‚Äù I‚Äôd get a pretty decent response back where it would point out an increase in failed requests and some errors logged around that same time. &lt;/p&gt; &lt;p&gt;My question is how do I expand upon this?&lt;/p&gt; &lt;p&gt;I‚Äôm still working on the DataBricks notebook that will pull this data in a consistent format based on the requested time and eventually stream this of some sort. &lt;/p&gt; &lt;p&gt;More so though, it‚Äôs the context needed to accurately answer needs applied each time I test a new snippet of data. That lead me to vector databases, HuggingFace models, LangChain, and Faiss. It all feels very overwhelming to logically connect these dots. &lt;/p&gt; &lt;p&gt;Is there an ELI5 of how this would conceptually work regarding the data generated, the context, and answering the prompt?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hxh6749&quot;&gt; /u/hxh6749 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196lcjp/a_vision/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/196lcjp/a_vision/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_196lcjp</id><link href="https://www.reddit.com/r/LangChain/comments/196lcjp/a_vision/" /><updated>2024-01-14T17:39:25+00:00</updated><published>2024-01-14T17:39:25+00:00</published><title>A Vision</title></entry><entry><author><name>/u/Fancy-Welcome-9064</name><uri>https://www.reddit.com/user/Fancy-Welcome-9064</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Sorry I am new to langchain. And I found all the examples are OpenAI. But I think the value of langchain is mainly on local llm. Otherwise, why not using GPTs? I‚Äôm very curious about it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fancy-Welcome-9064&quot;&gt; /u/Fancy-Welcome-9064 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1966yxv/why_langchain_focuses_on_openai_rather_than_local/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1966yxv/why_langchain_focuses_on_openai_rather_than_local/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1966yxv</id><link href="https://www.reddit.com/r/LangChain/comments/1966yxv/why_langchain_focuses_on_openai_rather_than_local/" /><updated>2024-01-14T04:08:01+00:00</updated><published>2024-01-14T04:08:01+00:00</published><title>Why langchain focuses on OpenAI rather than local llm?</title></entry><entry><author><name>/u/Fleischkluetensuppe</name><uri>https://www.reddit.com/user/Fleischkluetensuppe</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195qyv6/iteratively_synchronize_git_changes_with_faiss_to/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/OGk4a2JmcWtiOGNjMcdr_-oj80y4bsuac6-ehVUcxyrYyzYeAiBSfRNoFk_T.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fb92b91a18681e7728b385919e96057e49f00ad9&quot; alt=&quot;Iteratively synchronize git changes with faiss to incorporate LLMs for chat and semantic search locally&quot; title=&quot;Iteratively synchronize git changes with faiss to incorporate LLMs for chat and semantic search locally&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fleischkluetensuppe&quot;&gt; /u/Fleischkluetensuppe &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/s1l9iq2gb8cc1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195qyv6/iteratively_synchronize_git_changes_with_faiss_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_195qyv6</id><media:thumbnail url="https://external-preview.redd.it/OGk4a2JmcWtiOGNjMcdr_-oj80y4bsuac6-ehVUcxyrYyzYeAiBSfRNoFk_T.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fb92b91a18681e7728b385919e96057e49f00ad9" /><link href="https://www.reddit.com/r/LangChain/comments/195qyv6/iteratively_synchronize_git_changes_with_faiss_to/" /><updated>2024-01-13T15:52:36+00:00</updated><published>2024-01-13T15:52:36+00:00</published><title>Iteratively synchronize git changes with faiss to incorporate LLMs for chat and semantic search locally</title></entry><entry><author><name>/u/Wild-Market9571</name><uri>https://www.reddit.com/user/Wild-Market9571</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m utilizing Cohere AI for a project, and I have a text file that I want to embed. While I&amp;#39;m aware that Langchain has chunking functions, I believe Tiktoken might be more effective. However, I&amp;#39;m unsure about how Tiktoken works or if it would be suitable for Cohere.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Wild-Market9571&quot;&gt; /u/Wild-Market9571 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195yneb/optimizing_text_embedding_for_cohere_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195yneb/optimizing_text_embedding_for_cohere_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_195yneb</id><link href="https://www.reddit.com/r/LangChain/comments/195yneb/optimizing_text_embedding_for_cohere_ai/" /><updated>2024-01-13T21:26:47+00:00</updated><published>2024-01-13T21:26:47+00:00</published><title>Optimizing Text Embedding for Cohere AI</title></entry><entry><author><name>/u/Overall-Charity-4896</name><uri>https://www.reddit.com/user/Overall-Charity-4896</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks, &lt;/p&gt; &lt;p&gt;I&amp;#39;ve been pondering the process of embedding in a RAG app using various models. When examining examples, I noticed that some models (the most popular ones) include their embeddings. However, if I want to perform embedding with a different foundation model or an instructive one, what&amp;#39;s the procedure? Do I need to extract the truncated version of the LLM to create the embedding model, or is there a process I&amp;#39;m not familiar with? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Overall-Charity-4896&quot;&gt; /u/Overall-Charity-4896 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195rest/mastering_rag_app_embedding_with_custom_models/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195rest/mastering_rag_app_embedding_with_custom_models/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_195rest</id><link href="https://www.reddit.com/r/LangChain/comments/195rest/mastering_rag_app_embedding_with_custom_models/" /><updated>2024-01-13T16:11:52+00:00</updated><published>2024-01-13T16:11:52+00:00</published><title>Mastering RAG App Embedding with Custom Models</title></entry><entry><author><name>/u/iceburg51</name><uri>https://www.reddit.com/user/iceburg51</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello LLM enthusiasts! I&amp;#39;m eager to hear about the creative and innovative ways you&amp;#39;ve been using Large Language Models (LLMs) in your projects. Lang Chain, has been a game-changer in bringing these applications from the drawing board to real-world use. Have you developed something unique, solved a complex problem, or simply experimented with something fun? Let&amp;#39;s inspire each other by sharing our experiences and discussing how Lang Chain has facilitated our journey with LLMs!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/iceburg51&quot;&gt; /u/iceburg51 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1958znq/show_and_tell_what_have_you_built_with_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1958znq/show_and_tell_what_have_you_built_with_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1958znq</id><link href="https://www.reddit.com/r/LangChain/comments/1958znq/show_and_tell_what_have_you_built_with_llms/" /><updated>2024-01-12T23:19:55+00:00</updated><published>2024-01-12T23:19:55+00:00</published><title>Show and Tell: What have you built with LLMs?</title></entry><entry><author><name>/u/VarietyElderberry</name><uri>https://www.reddit.com/user/VarietyElderberry</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am surprised to see many posts like &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193oz8b/holy_f_i_have_never_seen_such_spaghetti_code_in/&quot;&gt;this one&lt;/a&gt;, or &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18eukhc/i_just_had_the_displeasure_of_implementing/&quot;&gt;this one&lt;/a&gt;, expressing negative sentiments about LangChain and in particular the agreement about the negativity in the comment section. For a community that comes together for the LangChain package and ecosystem, there seems to be a surprising amount of people that don&amp;#39;t like it. The advice given is often to not use LangChain at all.&lt;/p&gt; &lt;p&gt;Personally, I have been impressed by the developer&amp;#39;s willingness to listen to the community, and would expect this to lead to a positive mindset in the community. For example the introduction of LCEL is an attempt to improve the code quality and reduce the complexity of applications build with LangChain. However, &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18t3jn9/do_we_really_need_lcel/&quot;&gt;the community does not seem to see its value&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;While I understand some of the criticism, I don&amp;#39;t believe the amount of negativity is justified. Moreover, it seems there is little willingness for constructive feedback that could be used to improve the situation. This post is a plea to improve this mindset for the betterment of the LangChain ecosystem and the community that uses it. With LangChain having just released version 0.1, I think this is a good moment in time for this community to reflect on what it expects from LangChain going forward. Let me know what you think.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/VarietyElderberry&quot;&gt; /u/VarietyElderberry &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194u376/lets_dicsuss_this_subs_negative_feelings_towards/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194u376/lets_dicsuss_this_subs_negative_feelings_towards/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_194u376</id><link href="https://www.reddit.com/r/LangChain/comments/194u376/lets_dicsuss_this_subs_negative_feelings_towards/" /><updated>2024-01-12T12:39:18+00:00</updated><published>2024-01-12T12:39:18+00:00</published><title>Let's dicsuss this sub's negative feelings towards LangChain</title></entry><entry><author><name>/u/danipudani</name><uri>https://www.reddit.com/user/danipudani</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195392c/intro_to_langchain_full_documentation_overview/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/sVTHLyvfg970cr9MD_72wQqkiADi53dPj4mMz7rqK4w.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=362f231282720dbda6fe4de5188bd10440805d1e&quot; alt=&quot;Intro to LangChain - Full Documentation Overview&quot; title=&quot;Intro to LangChain - Full Documentation Overview&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/danipudani&quot;&gt; /u/danipudani &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/dXP841pBcJw?si=V03bfGxR0E2DVOA8&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/195392c/intro_to_langchain_full_documentation_overview/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_195392c</id><media:thumbnail url="https://external-preview.redd.it/sVTHLyvfg970cr9MD_72wQqkiADi53dPj4mMz7rqK4w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=362f231282720dbda6fe4de5188bd10440805d1e" /><link href="https://www.reddit.com/r/LangChain/comments/195392c/intro_to_langchain_full_documentation_overview/" /><updated>2024-01-12T19:19:37+00:00</updated><published>2024-01-12T19:19:37+00:00</published><title>Intro to LangChain - Full Documentation Overview</title></entry><entry><author><name>/u/MysteriousApricot991</name><uri>https://www.reddit.com/user/MysteriousApricot991</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am new to langchain. Can someone please explain to me how to use hugging face models like Microsoft phi-2 with langchain? The official documentation talks about openAI and other inference API based LLMs but how about locally running models?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MysteriousApricot991&quot;&gt; /u/MysteriousApricot991 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1954q8y/langchain_with_hugging_face_models/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1954q8y/langchain_with_hugging_face_models/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1954q8y</id><link href="https://www.reddit.com/r/LangChain/comments/1954q8y/langchain_with_hugging_face_models/" /><updated>2024-01-12T20:20:36+00:00</updated><published>2024-01-12T20:20:36+00:00</published><title>Langchain with Hugging face models</title></entry><entry><author><name>/u/qa_anaaq</name><uri>https://www.reddit.com/user/qa_anaaq</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi. I&amp;#39;m tasked with building a chatbot for work. We are an HR tech company. &lt;/p&gt; &lt;p&gt;I&amp;#39;m using Retrieval QA, trying different chunking sizes, testing both Pinecone and Supabase for vector Retrieval. &lt;/p&gt; &lt;p&gt;However, I&amp;#39;m of the opinion that our data sucks. Our API docs have like 50 words per page at most, and there are maybe 30 pages. We have a lot of support tickets, like 500, but only 20% have actual answers written out to the ticket reason. So I get maybe 20-50 words per useable ticket. Lastly, our community sourced internal documentation is fragmentation and inconsistently designed. &lt;/p&gt; &lt;p&gt;I&amp;#39;ve engineered all the text into consistent structures. The purpose is Q/A, like &amp;quot;If a user is complaining X isn&amp;#39;t working in their dashboard, what might be the cause?&amp;quot;&lt;/p&gt; &lt;p&gt;But is there anything realistic I can do with this situation when the data is so low volume and poor quality? Any technical approaches that don&amp;#39;t require a manual documentation overhaul, that is. &lt;/p&gt; &lt;p&gt;Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/qa_anaaq&quot;&gt; /u/qa_anaaq &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1957t7r/trying_to_solve_for_bad_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1957t7r/trying_to_solve_for_bad_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1957t7r</id><link href="https://www.reddit.com/r/LangChain/comments/1957t7r/trying_to_solve_for_bad_data/" /><updated>2024-01-12T22:30:31+00:00</updated><published>2024-01-12T22:30:31+00:00</published><title>Trying to solve for bad data</title></entry><entry><author><name>/u/EscapedLaughter</name><uri>https://www.reddit.com/user/EscapedLaughter</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/portkey-ai/gateway&quot;&gt;https://github.com/portkey-ai/gateway&lt;/a&gt;&lt;/p&gt; &lt;p&gt;We&amp;#39;ve been developing this open-source AI gateway that routes to hundred+ LLMs using the OpenAI SDK.&lt;/p&gt; &lt;p&gt;It is a one-line executable that starts a local proxy server - you can just put that url in the baseURL of the OpenAI SDK and call providers like Google, Azure, AWS, Anthropic, Anyscale, Together, Perplexity, Mistral, and more.&lt;/p&gt; &lt;p&gt;It&amp;#39;s designed to be highly performant ‚Äî we have been using it to route billions of tokens daily for our customers.&lt;/p&gt; &lt;p&gt;Would love to hear the community&amp;#39;s views/feedback üôè&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EscapedLaughter&quot;&gt; /u/EscapedLaughter &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194ut4u/contribute_to_opensource_ai_gateway_written_in_ts/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194ut4u/contribute_to_opensource_ai_gateway_written_in_ts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_194ut4u</id><link href="https://www.reddit.com/r/LangChain/comments/194ut4u/contribute_to_opensource_ai_gateway_written_in_ts/" /><updated>2024-01-12T13:16:05+00:00</updated><published>2024-01-12T13:16:05+00:00</published><title>Contribute to open-source AI gateway, written in TS</title></entry><entry><author><name>/u/EmilianoLP</name><uri>https://www.reddit.com/user/EmilianoLP</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I‚Äôm working on a solution for a client who needs an agent to pull data from a CSV file, which contains information about a provider‚Äôs location, services, categories, phone numbers, and addresses. Initial trials with chroma embeddings and a gpt-3.5-turbo LLM had inconsistent outcomes. However, switching to gpt-4-1106-preview and adjusting the chroma retriever kwargs ‚Äúk‚Äù from 4 to 8 enhanced document retrieval but also increased token usage. The CSV Agent was less effective, yielding poorer results than the embeddings. For context, my agent is an assistant that provides contact information for providers based on user queries. For example: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;User: &amp;quot;asado barrio san vicente&amp;quot;&lt;/li&gt; &lt;li&gt;AI: &amp;quot;Aqu√≠ tienes informaci√≥n sobre asado en el barrio San Vicente:&lt;/li&gt; &lt;li&gt;Asadero Parrillero - Tel√©fonos: 123456789, 123456788&lt;/li&gt; &lt;li&gt;ASADO LA CASA DEL COSTILLAR, Javier Rodriguez - Tel√©fonos: 123456789 - Direcci√≥n: Example 123&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Espero que esta informaci√≥n te sea √∫til. &amp;quot; &lt;/p&gt; &lt;p&gt;What should i try?&lt;br/&gt; The adjunted image is a sample of my CSV/Excel file. Any advice is would be aprecciated. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EmilianoLP&quot;&gt; /u/EmilianoLP &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194xwhi/chroma_retrievercsv_agent_giving_poor_results_any/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194xwhi/chroma_retrievercsv_agent_giving_poor_results_any/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_194xwhi</id><link href="https://www.reddit.com/r/LangChain/comments/194xwhi/chroma_retrievercsv_agent_giving_poor_results_any/" /><updated>2024-01-12T15:36:06+00:00</updated><published>2024-01-12T15:36:06+00:00</published><title>Chroma retriever/CSV Agent giving poor results, any advice on this?</title></entry><entry><author><name>/u/e-nigmaNL</name><uri>https://www.reddit.com/user/e-nigmaNL</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/e-nigmaNL&quot;&gt; /u/e-nigmaNL &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ChatGPT/comments/194u9z9/what_does_agi_mean/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194ub0z/what_does_agi_mean/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_194ub0z</id><link href="https://www.reddit.com/r/LangChain/comments/194ub0z/what_does_agi_mean/" /><updated>2024-01-12T12:50:49+00:00</updated><published>2024-01-12T12:50:49+00:00</published><title>What does AGI mean?</title></entry><entry><author><name>/u/Due-Date7835</name><uri>https://www.reddit.com/user/Due-Date7835</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Langchain enthusiasts!&lt;/p&gt; &lt;p&gt;I‚Äôve noticed a lot of chatter about the steep learning curve of Langchain. So, I thought I‚Äôd share my approach that makes it not only manageable but also pretty awesome to use.&lt;/p&gt; &lt;p&gt;üöÄ The Game-Changer: I tweaked the Langchain chatbot (open-source, yay!) by swapping out the GPT-3.5 model with the shiny new GPT-4, boasting a massive 128K context window. This upgrade means we can feed it a hefty amount of chain reference code. The result? Writing substantial code segments that require minimal tweaking!&lt;/p&gt; &lt;p&gt;üõ†Ô∏è Here‚Äôs How You Can Do It Too:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;1. Set the Stage: Clone the chat-langchain repo and set it up as per the guidelines. A piece of cake! 2. The Magic Swap: In chain.py, replace ‚ÄúGPT-3.5-turbo‚Äù with ‚Äúgpt-4-1106-preview‚Äù. Boost the number of retrieved chunks (I‚Äôm rocking search_kwargs=dict(k=20)). 3. Prompt Perfection: Modify the prompt (example below) and ensure your initial description is crystal clear. Dropping in known class names helps the bot understand your needs better. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Happy coding!&lt;/p&gt; &lt;p&gt;Here‚Äôs the prompt I‚Äôm using:&lt;/p&gt; &lt;p&gt;RESPONSE_TEMPLATE = &amp;quot;&amp;quot;&amp;quot;\ You are an expert programmer and problem-solver, tasked with answering any question \ about Langchain and generating complete working scripts using the Langchain framework. Your responses \ shall have two parts: Answer and Code.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;For the Answer:&lt;/em&gt;&lt;/strong&gt; Generate a comprehensive and informative answer of 80 words or less for the \ given question based solely on the provided search results (URL and content). You must \ only use information from the provided search results. Use an unbiased and \ journalistic tone. Combine search results together into a coherent answer. Do not \ repeat text. Cite search results using [${{number}}] notation. Only cite the most \ relevant results that answer the question accurately. Place these citations at the end \ of the sentence or paragraph that reference them - do not put them all at the end. If \ different results refer to different entities within the same name, write separate \ answers for each entity.&lt;/p&gt; &lt;p&gt;You should use bullet points in your answer for readability. Put citations where they apply \ rather than putting them all at the end.&lt;/p&gt; &lt;p&gt;If there is nothing in the context relevant to the question at hand, just say &amp;quot;Hmm, \ I&amp;#39;m not sure.&amp;quot; Don&amp;#39;t try to make up an answer.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;For the Code:&lt;/em&gt;&lt;/strong&gt; Produce complete, functional Python code that utilizes the Langchain framework to address the question or task \ presented. Ensure that the code is: 1. Readable: Write clear, understandable code. Use descriptive variable names and adhere to Python&amp;#39;s PEP 8 style \ guidelines for maximum readability. 2. Efficient: Optimize for performance. Use efficient algorithms and data structures to ensure the code runs \ effectively and conservatively uses resources. 3. Error-Handled: Incorporate error handling to manage and anticipate potential issues that might arise during \ execution. Use try-except blocks where appropriate and validate input data. 4. Tested: Include necessary assertions or print statements to demonstrate the functionality and correctness \ of the code. Ensure that the code produces expected results when executed. 5. Complete: Ensure the code can be copied directly into a Python project with no modifications needed. \ It should be self-contained, specifying all necessary imports and dependencies. 6. Langchain-Specific: Utilize the appropriate classes, functions, and methods from the Langchain \ framework. Clearly demonstrate how Langchain&amp;#39;s features and capabilities are applied to solve the \ given problem or task. 7. Context-Aware: Use the provided context effectively. Reference and utilize data, variables, or \ insights derived from the &amp;#39;context&amp;#39; section to inform the code&amp;#39;s logic and functionality. \ 8. Comment-Free Execution: Avoid using comment blocks as placeholders for code. Ensure all functional \ parts of the code are executable statements and not comments.&lt;/p&gt; &lt;p&gt;If the question or task does not provide enough information for a complete script, or if it is outside the scope of \ the Langchain framework, clearly state that a complete working script cannot be provided as requested, explain \ the reasons and provide suggestions and/or alternatives. &lt;/p&gt; &lt;p&gt;Anything between the following &lt;code&gt;context&lt;/code&gt; html blocks is retrieved from a knowledge \ bank, and is provided in addition to the conversation with the user. &amp;lt;context&amp;gt; {context} &amp;lt;context/&amp;gt;&lt;/p&gt; &lt;p&gt;Anything between the following &lt;code&gt;Code_Block&lt;/code&gt; html blocks were provided by user as integral and shall be \ treated as essential to your response. Each block of code is enclosed within a pair of markdowns triple backticks (```) &amp;lt;Code_Block&amp;gt; {Code_Block} &amp;lt;Code_Block/&amp;gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;REMEMBER:&lt;/em&gt;&lt;/strong&gt; -If there is no relevant information within the context, just say &amp;quot;Hmm, I&amp;#39;m \ not sure.&amp;quot; Don&amp;#39;t try to make up an answer. Anything between the preceding &amp;#39;context&amp;#39; \ html blocks is retrieved from a knowledge bank, not part of the conversation with the \ user. -The goal is to provide code that is ready to be integrated and used in a project, \ demonstrating the practical application and power of the Langchain framework in solving real-world problems.\ Anything between the preceding &amp;#39;Code_Block&amp;#39; html blocks were provided by user as integral and shall be \ treated as essential to your response. &amp;quot;&amp;quot;&amp;quot;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Due-Date7835&quot;&gt; /u/Due-Date7835 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1947pl5/simplifying_langchain_a_practical_guide_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1947pl5/simplifying_langchain_a_practical_guide_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1947pl5</id><link href="https://www.reddit.com/r/LangChain/comments/1947pl5/simplifying_langchain_a_practical_guide_to/" /><updated>2024-01-11T17:49:43+00:00</updated><published>2024-01-11T17:49:43+00:00</published><title>Simplifying Langchain: A Practical Guide to Supercharging with GPT-4</title></entry><entry><author><name>/u/3RiversAINexus</name><uri>https://www.reddit.com/user/3RiversAINexus</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello!&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been organizing a langchain user group meeting every other Thursday at 7pm eastern US time.&lt;/p&gt; &lt;p&gt;We get people just interested in langchain, people using langchain at work, people using langchain as a hobby. We like to discuss the langchain blog posts, interesting projects using langchain, and as a general networking event among people tuned into the AI boom. It&amp;#39;s a great opportunity to share the latest developments, what works, what doesn&amp;#39;t work, and so on.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.meetup.com/langchain-user-group/events/298217248/&quot;&gt;https://www.meetup.com/langchain-user-group/events/298217248/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/3RiversAINexus&quot;&gt; /u/3RiversAINexus &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194g33t/langchain_user_group_meeting_on_thursday_jan_18/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194g33t/langchain_user_group_meeting_on_thursday_jan_18/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_194g33t</id><link href="https://www.reddit.com/r/LangChain/comments/194g33t/langchain_user_group_meeting_on_thursday_jan_18/" /><updated>2024-01-11T23:34:21+00:00</updated><published>2024-01-11T23:34:21+00:00</published><title>Langchain User Group Meeting on Thursday Jan 18 2024</title></entry><entry><author><name>/u/abeecrombie</name><uri>https://www.reddit.com/user/abeecrombie</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I really like langchain. its not perfect, not always easy but for free open source software, I really appreciate it.&lt;/p&gt; &lt;p&gt;Chat LangChain is really cool. I am not a software developer. I am a data dude who has to code to get stuff done. Chat Langchain is super helpful to do that. &lt;/p&gt; &lt;p&gt;Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/abeecrombie&quot;&gt; /u/abeecrombie &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1943u42/chat_langchain_is_awesome/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1943u42/chat_langchain_is_awesome/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1943u42</id><link href="https://www.reddit.com/r/LangChain/comments/1943u42/chat_langchain_is_awesome/" /><updated>2024-01-11T15:07:16+00:00</updated><published>2024-01-11T15:07:16+00:00</published><title>Chat LangChain is awesome!</title></entry><entry><author><name>/u/Mephidia</name><uri>https://www.reddit.com/user/Mephidia</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;No wonder there barely exists tutorials or articles exploring complex workflows. To make anything other than a simple RAG app you need to have a PHD in langchain. Better get studying üò≠&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mephidia&quot;&gt; /u/Mephidia &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193oz8b/holy_f_i_have_never_seen_such_spaghetti_code_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193oz8b/holy_f_i_have_never_seen_such_spaghetti_code_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_193oz8b</id><link href="https://www.reddit.com/r/LangChain/comments/193oz8b/holy_f_i_have_never_seen_such_spaghetti_code_in/" /><updated>2024-01-11T01:13:21+00:00</updated><published>2024-01-11T01:13:21+00:00</published><title>Holy f*** I have never seen such spaghetti code in my life</title></entry><entry><author><name>/u/Downtown-Crab271</name><uri>https://www.reddit.com/user/Downtown-Crab271</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Suppose taking files .cs (C#) from repo, splitting into chunks and storing in vector db. Using embedding model sentence transformer model***. Kindly suggest me best vector db storage and best similarity search for same which can can give best context to pass to llm. Thanks in advance üôÇ&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Downtown-Crab271&quot;&gt; /u/Downtown-Crab271 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1948p85/which_is_best_vector_similarity_search_and_vector/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1948p85/which_is_best_vector_similarity_search_and_vector/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1948p85</id><link href="https://www.reddit.com/r/LangChain/comments/1948p85/which_is_best_vector_similarity_search_and_vector/" /><updated>2024-01-11T18:29:51+00:00</updated><published>2024-01-11T18:29:51+00:00</published><title>Which is best vector similarity search and vector db for code chunks?</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey,&lt;/p&gt; &lt;p&gt;I have a general question: I want to run LLMs locally on Laptops with 128Mb VRAM and 32GB RAM. Is this possible as my VRAM is so low? &lt;/p&gt; &lt;p&gt;So which GGUF-Version would be possible to use here:&lt;/p&gt; &lt;p&gt;- &lt;a href=&quot;https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GGUF&quot;&gt;https://huggingface.co/TheBloke/Mixtral-8x7B-v0.1-GGUF&lt;/a&gt; or here: &lt;/p&gt; &lt;p&gt;- &lt;a href=&quot;https://huggingface.co/TheBloke/em_german_mistral_v01-GGUF&quot;&gt;https://huggingface.co/TheBloke/em_german_mistral_v01-GGUF&lt;/a&gt; ? &lt;/p&gt; &lt;p&gt;At the moment I am deploying on my Mac without any problems, but it has 64GB RAM.&lt;/p&gt; &lt;p&gt;Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194434d/run_thebloke_llms_on_laptop_with_32gb_ram_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/194434d/run_thebloke_llms_on_laptop_with_32gb_ram_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_194434d</id><link href="https://www.reddit.com/r/LangChain/comments/194434d/run_thebloke_llms_on_laptop_with_32gb_ram_and/" /><updated>2024-01-11T15:18:35+00:00</updated><published>2024-01-11T15:18:35+00:00</published><title>Run TheBloke LLMs on Laptop with 32GB RAM and 128MB VRAM</title></entry><entry><author><name>/u/Trick-Asparagus-9260</name><uri>https://www.reddit.com/user/Trick-Asparagus-9260</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a rag chain using LCEL. I want to extract just the context that has been set in the chain. Below is my function: &lt;/p&gt; &lt;p&gt;def get_rag_chain(retriever, format_docs, prompt, llm): | format_docs&lt;/p&gt; &lt;p&gt;rag_chain = (&lt;/p&gt; &lt;p&gt;{&amp;quot;context&amp;quot;: retriever | format_docs, &amp;quot;question&amp;quot;: RunnablePassthrough()}&lt;/p&gt; &lt;p&gt;| prompt&lt;/p&gt; &lt;p&gt;| llm&lt;/p&gt; &lt;p&gt;| StrOutputParser()&lt;/p&gt; &lt;p&gt;)&lt;/p&gt; &lt;p&gt;return rag_chain &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Trick-Asparagus-9260&quot;&gt; /u/Trick-Asparagus-9260 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193y7ca/how_to_retrieve_the_context_from_a_chain_set/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193y7ca/how_to_retrieve_the_context_from_a_chain_set/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_193y7ca</id><link href="https://www.reddit.com/r/LangChain/comments/193y7ca/how_to_retrieve_the_context_from_a_chain_set/" /><updated>2024-01-11T10:01:53+00:00</updated><published>2024-01-11T10:01:53+00:00</published><title>How to retrieve the context from a chain set using LCEL?</title></entry><entry><author><name>/u/HappyDataGuy</name><uri>https://www.reddit.com/user/HappyDataGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am working on a project where user will ask natural language queries and this llama-index based engine will convert that natural language to sql query and execute it on my database and give answer in natural language to the user. Problem is it is only able to execute one query per question so comparison quetions are not possible to answer and also if a question does not require querying the database it will still query the database. How can I solve this. Please help me with your suggesting.&lt;br/&gt; Thanks in advance. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HappyDataGuy&quot;&gt; /u/HappyDataGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193upr6/rag_llamaindex_how_to_execute_multiple_sql/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193upr6/rag_llamaindex_how_to_execute_multiple_sql/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_193upr6</id><link href="https://www.reddit.com/r/LangChain/comments/193upr6/rag_llamaindex_how_to_execute_multiple_sql/" /><updated>2024-01-11T06:07:23+00:00</updated><published>2024-01-11T06:07:23+00:00</published><title>[RAG] [llama-index] How to execute multiple SQL queries with SQLTableRetrieverQueryEngine in NL2SQL project?</title></entry><entry><author><name>/u/ayushkarle</name><uri>https://www.reddit.com/user/ayushkarle</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Carrying out a research in RAG Models in my university. Recently found LangChain, took a few courses and I am amazed. Access to LangChain would boost my research value and give out better results. Always fun to try out new and upcoming frameworks and tools.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ayushkarle&quot;&gt; /u/ayushkarle &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193z6uz/can_i_get_an_invite_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193z6uz/can_i_get_an_invite_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_193z6uz</id><link href="https://www.reddit.com/r/LangChain/comments/193z6uz/can_i_get_an_invite_code/" /><updated>2024-01-11T11:07:17+00:00</updated><published>2024-01-11T11:07:17+00:00</published><title>Can I get an invite code?</title></entry><entry><author><name>/u/Odd-Farmer-3121</name><uri>https://www.reddit.com/user/Odd-Farmer-3121</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi! With everything around LLMs moving at such a fast pace, papers, related frameworks, libraries, toolkits, open source models and more popping up every day, I found it much harder to stay on top of everything than before. How do you stay updated and effectively navigate this space. Any recommendations for blogs, communities, channels or strategies? Thanks in advance! üòä&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Odd-Farmer-3121&quot;&gt; /u/Odd-Farmer-3121 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193ozls/keeping_up_with_the_fast_movement_in_ai_space/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193ozls/keeping_up_with_the_fast_movement_in_ai_space/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_193ozls</id><link href="https://www.reddit.com/r/LangChain/comments/193ozls/keeping_up_with_the_fast_movement_in_ai_space/" /><updated>2024-01-11T01:13:50+00:00</updated><published>2024-01-11T01:13:50+00:00</published><title>Keeping up with the fast movement in AI space</title></entry></feed>