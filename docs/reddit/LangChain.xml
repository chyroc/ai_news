<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-07-01T10:59:48+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Equivalent_Noise3560</name><uri>https://www.reddit.com/user/Equivalent_Noise3560</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dso9pj/custom_functions_with_runnablelambda_in_langchain/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/2347JJ6JbmR5WGmdxSM3iu0OnGohPD3MltcLei8lmx8.jpg?width=108&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7a4559964a97155995aa6f0c96a36eebba24728a&quot; alt=&quot;Custom Functions with RunnableLambda in LangChain JS&quot; title=&quot;Custom Functions with RunnableLambda in LangChain JS&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Made a short post about how to make Custom Functions with RunnableLambda in LangChain JS:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.js-craft.io/blog/custom-functions-runnablelambda-langchain-js/&quot;&gt;https://www.js-craft.io/blog/custom-functions-runnablelambda-langchain-js/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/9v8pcoekfv9d1.png?width=1474&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8dfa8bb8a5efb6b1873e1ee70fba90cd43f2e4ff&quot;&gt;https://preview.redd.it/9v8pcoekfv9d1.png?width=1474&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8dfa8bb8a5efb6b1873e1ee70fba90cd43f2e4ff&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Equivalent_Noise3560&quot;&gt; /u/Equivalent_Noise3560 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dso9pj/custom_functions_with_runnablelambda_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dso9pj/custom_functions_with_runnablelambda_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dso9pj</id><media:thumbnail url="https://external-preview.redd.it/2347JJ6JbmR5WGmdxSM3iu0OnGohPD3MltcLei8lmx8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a4559964a97155995aa6f0c96a36eebba24728a" /><link href="https://www.reddit.com/r/LangChain/comments/1dso9pj/custom_functions_with_runnablelambda_in_langchain/" /><updated>2024-07-01T08:52:49+00:00</updated><published>2024-07-01T08:52:49+00:00</published><title>Custom Functions with RunnableLambda in LangChain JS</title></entry><entry><author><name>/u/AffectionateChain907</name><uri>https://www.reddit.com/user/AffectionateChain907</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsmk86/decreasing_the_response_time_in_multiagent/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/Trr0hIVGArLk1jDefnLU165NUCuypW9tm7AD1E8osbM.jpg&quot; alt=&quot;Decreasing the response time in Multi-Agent Workflow of LangGraph using Ollama - Llama 3 model&quot; title=&quot;Decreasing the response time in Multi-Agent Workflow of LangGraph using Ollama - Llama 3 model&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So recently I was testing out the Multi-Agent Workflow of langchain with some budget constraints and hence I decided to use Llama 3 model from Ollama. &lt;/p&gt; &lt;p&gt;I am following the supervisor structure as shown in their tutorials. The role of the supervisor is to simply redirect the query to one particular agent and that particular agent then handles the extraction of some special attributes from the user query.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/nsib0o7btu9d1.png?width=1934&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=96b120524949e1af997b82b3df221b9824ce1d8d&quot;&gt;Multi-Agent Workflow Schema Diagram&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Now what&amp;#39;s happening is that when I run these agents (without langraph) on a individual script level for 5 user queries, the first query takes around 20 seconds to generate the response and then the subsequent 4 queries give response like within 3 seconds. &lt;/p&gt; &lt;p&gt;But when I connect the supervisor to the agents using LangGraph, and I test it for the same 5 queries, each query takes &amp;gt; 100 seconds to yield the final output. &lt;/p&gt; &lt;p&gt;My hardware specs are pretty decent i believe and should not be a hardware issue :-&lt;/p&gt; &lt;p&gt;RAM- 16GB, PROCESSOR - RYZEN 9, GPU - 4GB RTX 3050&lt;/p&gt; &lt;p&gt;Is this happening most likely due to a code level issue or something related to my ollama server settings like number of models running parallelly? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AffectionateChain907&quot;&gt; /u/AffectionateChain907 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsmk86/decreasing_the_response_time_in_multiagent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsmk86/decreasing_the_response_time_in_multiagent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dsmk86</id><media:thumbnail url="https://b.thumbs.redditmedia.com/Trr0hIVGArLk1jDefnLU165NUCuypW9tm7AD1E8osbM.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1dsmk86/decreasing_the_response_time_in_multiagent/" /><updated>2024-07-01T06:55:03+00:00</updated><published>2024-07-01T06:55:03+00:00</published><title>Decreasing the response time in Multi-Agent Workflow of LangGraph using Ollama - Llama 3 model</title></entry><entry><author><name>/u/ramkitvprk</name><uri>https://www.reddit.com/user/ramkitvprk</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi All,&lt;br/&gt; any resources or reference , I can get to convert the SAS scripts into HIve SQL using LLMs? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ramkitvprk&quot;&gt; /u/ramkitvprk &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsl8ne/sas_to_hive_sql_conversions_using_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsl8ne/sas_to_hive_sql_conversions_using_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dsl8ne</id><link href="https://www.reddit.com/r/LangChain/comments/1dsl8ne/sas_to_hive_sql_conversions_using_llm/" /><updated>2024-07-01T05:27:30+00:00</updated><published>2024-07-01T05:27:30+00:00</published><title>SAS to Hive sql conversions using LLM</title></entry><entry><author><name>/u/westernspion</name><uri>https://www.reddit.com/user/westernspion</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello there,&lt;/p&gt; &lt;p&gt;What practical applications for langchain based agents have you been having success with?&lt;/p&gt; &lt;p&gt;Of particular interests, what foundational models have you been seeing perform best as agents? What size of datasets do you have it reasoning through?&lt;/p&gt; &lt;p&gt;I’ve been building agents and chains for the past year. My lingering impression is that I won’t get agents involved in any real time chat use cases for performance reasons. I have been sticking to static lcel based chains but they are nowhere near as capable. Tried streaming events back and updating the UI with backend status but - that isn’t actually fixing anything &lt;/p&gt; &lt;p&gt;Sincerely, $corporate_employee &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/westernspion&quot;&gt; /u/westernspion &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds2f62/agents_as_a_practical_solution/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds2f62/agents_as_a_practical_solution/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds2f62</id><link href="https://www.reddit.com/r/LangChain/comments/1ds2f62/agents_as_a_practical_solution/" /><updated>2024-06-30T14:14:05+00:00</updated><published>2024-06-30T14:14:05+00:00</published><title>Agents as a practical solution</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds0vq6/building_autoanalyst_a_data_analytics_ai_agentic/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=176a74000cbddae2ae4411428019bc4d3d1ed768&quot; alt=&quot;Building “Auto-Analyst” — A data analytics AI agentic system&quot; title=&quot;Building “Auto-Analyst” — A data analytics AI agentic system&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://medium.com/firebird-technologies/building-auto-analyst-a-data-analytics-ai-agentic-system-3ac2573dcaf0&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds0vq6/building_autoanalyst_a_data_analytics_ai_agentic/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ds0vq6</id><media:thumbnail url="https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=176a74000cbddae2ae4411428019bc4d3d1ed768" /><link href="https://www.reddit.com/r/LangChain/comments/1ds0vq6/building_autoanalyst_a_data_analytics_ai_agentic/" /><updated>2024-06-30T12:56:15+00:00</updated><published>2024-06-30T12:56:15+00:00</published><title>Building “Auto-Analyst” — A data analytics AI agentic system</title></entry><entry><author><name>/u/UpvoteBeast</name><uri>https://www.reddit.com/user/UpvoteBeast</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Question is self explanatory! Im looking for a workbench or way to evaluate different LLMs. For example giving score to answers, comparing prompts, giving good answer samples, etc etc&lt;/p&gt; &lt;p&gt;If it can show me the runs, the better so i can compare.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpvoteBeast&quot;&gt; /u/UpvoteBeast &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsgbif/evaluate_different_llms_or_flows/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsgbif/evaluate_different_llms_or_flows/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dsgbif</id><link href="https://www.reddit.com/r/LangChain/comments/1dsgbif/evaluate_different_llms_or_flows/" /><updated>2024-07-01T00:50:30+00:00</updated><published>2024-07-01T00:50:30+00:00</published><title>Evaluate different LLMs or flows</title></entry><entry><author><name>/u/Electronic-Letter592</name><uri>https://www.reddit.com/user/Electronic-Letter592</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I need the to extract table content (mainly numbers) from scanned documents. Those numbers are typed, not handwritten. The position and layout of the table can slightly change. What is currently the best open source model for that?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Electronic-Letter592&quot;&gt; /u/Electronic-Letter592 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds4rnu/recommendation_for_table_extraction/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds4rnu/recommendation_for_table_extraction/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds4rnu</id><link href="https://www.reddit.com/r/LangChain/comments/1ds4rnu/recommendation_for_table_extraction/" /><updated>2024-06-30T16:01:08+00:00</updated><published>2024-06-30T16:01:08+00:00</published><title>Recommendation for table extraction</title></entry><entry><author><name>/u/Not-That-rpg</name><uri>https://www.reddit.com/user/Not-That-rpg</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Was writing some code that wanted to print the model string for a model without having a specific model. Unfortunately, &lt;code&gt;BaseChatModel&lt;/code&gt; does not have a &lt;code&gt;model&lt;/code&gt; property. Tried the set of alternatives used in my code at present, &lt;code&gt;Union[ChatOpenAI, ChatLiteLLM, ChatAnthropic]&lt;/code&gt; and &lt;code&gt;ChatOpenAI&lt;/code&gt; has no &lt;code&gt;model&lt;/code&gt; property. This kind of thing hurts langchain&amp;#39;s ability to paper over the differences between LLMs, which is its key strength.&lt;/p&gt; &lt;p&gt;I suggest a refactoring that promotes &lt;code&gt;model&lt;/code&gt; up to the &lt;code&gt;BaseChatModel&lt;/code&gt; and does something about &lt;code&gt;model&lt;/code&gt; vs. &lt;code&gt;model_name&lt;/code&gt; to make the latter both clearer in terms of its meaning (or simply an alias to the former, as it is in &lt;code&gt;ChatAnthropic&lt;/code&gt; (see below). The following in &lt;code&gt;ChatLiteLLM&lt;/code&gt; is not at all helpful:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;model_name: Optional[str] = None &amp;quot;&amp;quot;&amp;quot;Model name to use.&amp;quot;&amp;quot;&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As opposed to model name not to use?&lt;/p&gt; &lt;p&gt;&lt;code&gt;ChatAnthropic&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;model: str = Field(alias=&amp;quot;model_name&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It&amp;#39;s ok if &lt;code&gt;model_name&lt;/code&gt; is just and alias for backwards compatibility, but on &lt;code&gt;ChatLiteLLM&lt;/code&gt; the fact that it&amp;#39;s &lt;code&gt;Optional&lt;/code&gt; means that it might not be defined, which foils that purpose.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Not-That-rpg&quot;&gt; /u/Not-That-rpg &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds40ke/chat_model_class_orthogonality_suggestion/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds40ke/chat_model_class_orthogonality_suggestion/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds40ke</id><link href="https://www.reddit.com/r/LangChain/comments/1ds40ke/chat_model_class_orthogonality_suggestion/" /><updated>2024-06-30T15:26:37+00:00</updated><published>2024-06-30T15:26:37+00:00</published><title>Chat Model Class orthogonality suggestion</title></entry><entry><author><name>/u/Alarmed-Reporter-230</name><uri>https://www.reddit.com/user/Alarmed-Reporter-230</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;RunnableBranch and RunnableParallel , probably allow to lower api calls costs down, but I fail to see when they are truly needed. What&amp;#39;s your experience with them? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Alarmed-Reporter-230&quot;&gt; /u/Alarmed-Reporter-230 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds3ih5/when_to_use_runnablebranch_and_runnableparallel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds3ih5/when_to_use_runnablebranch_and_runnableparallel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds3ih5</id><link href="https://www.reddit.com/r/LangChain/comments/1ds3ih5/when_to_use_runnablebranch_and_runnableparallel/" /><updated>2024-06-30T15:04:01+00:00</updated><published>2024-06-30T15:04:01+00:00</published><title>When to use RunnableBranch and RunnableParallel</title></entry><entry><author><name>/u/RoundImpressive3543</name><uri>https://www.reddit.com/user/RoundImpressive3543</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The input is going to be unfilled form images (imagine W2) and I want to fill it with fake relevant data. The current code I have uses a JSON config file containing the location of coordinates where the fake data needs to go and I just write text on those fields with a white background. I use the faker library to generate fake data but I&amp;#39;m looking for something more accurate and relevant. Can I have some suggestions regarding what technologies I need to use to create such a form generator?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RoundImpressive3543&quot;&gt; /u/RoundImpressive3543 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds7h57/automated_document_filling_need_suggestions/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds7h57/automated_document_filling_need_suggestions/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds7h57</id><link href="https://www.reddit.com/r/LangChain/comments/1ds7h57/automated_document_filling_need_suggestions/" /><updated>2024-06-30T18:04:14+00:00</updated><published>2024-06-30T18:04:14+00:00</published><title>Automated document filling - Need Suggestions</title></entry><entry><author><name>/u/shanumas</name><uri>https://www.reddit.com/user/shanumas</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for a solution for this problem. &lt;a href=&quot;https://github.com/langchain-ai/chat-langchain/issues/339&quot;&gt;https://github.com/langchain-ai/chat-langchain/issues/339&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I checked-out chat-langchain from github. I get the error that :&lt;/p&gt; &lt;p&gt;langgraph-api-1 | ValueError: License key is not valid&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/shanumas&quot;&gt; /u/shanumas &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds1qal/langgraph_license_key_is_not_valid/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds1qal/langgraph_license_key_is_not_valid/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds1qal</id><link href="https://www.reddit.com/r/LangChain/comments/1ds1qal/langgraph_license_key_is_not_valid/" /><updated>2024-06-30T13:40:06+00:00</updated><published>2024-06-30T13:40:06+00:00</published><title>Langgraph &quot;License key is not valid&quot;</title></entry><entry><author><name>/u/DueHearing1315</name><uri>https://www.reddit.com/user/DueHearing1315</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drrn4a/visualize_where_in_the_world_your_commits_come/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/wxe3e856hm9d1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f5b62e26c83d3b2c6448c13df1c105b4fce0bc51&quot; alt=&quot;Visualize where in the world your commits come from.&quot; title=&quot;Visualize where in the world your commits come from.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DueHearing1315&quot;&gt; /u/DueHearing1315 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/wxe3e856hm9d1.png&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drrn4a/visualize_where_in_the_world_your_commits_come/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1drrn4a</id><media:thumbnail url="https://preview.redd.it/wxe3e856hm9d1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f5b62e26c83d3b2c6448c13df1c105b4fce0bc51" /><link href="https://www.reddit.com/r/LangChain/comments/1drrn4a/visualize_where_in_the_world_your_commits_come/" /><updated>2024-06-30T02:45:24+00:00</updated><published>2024-06-30T02:45:24+00:00</published><title>Visualize where in the world your commits come from.</title></entry><entry><author><name>/u/electricjimi</name><uri>https://www.reddit.com/user/electricjimi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, just a question that popped up in my mind.&lt;/p&gt; &lt;p&gt;I already developed a saas for serving agentic RAG to multiple customers/companies using LangGraph and LangServe.&lt;/p&gt; &lt;p&gt;However, I&amp;#39;m developing a new application for agentic document analysis and parsing, all without using anything langchain related.&lt;/p&gt; &lt;p&gt;For the first project, I really wanted to learn a framework that was &amp;quot;broadly&amp;quot; used, but now I want the agent to &amp;quot;just work&amp;quot; and follow the steps in the process, and &amp;quot;normal&amp;quot; if/else chains coupled with &amp;quot;clever&amp;quot; prompting seem to work without getting into any of the intricacies of Langchain/LangGraph.&lt;/p&gt; &lt;p&gt;So, what do you think are the REAL advantages of using LangGraph? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/electricjimi&quot;&gt; /u/electricjimi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drlvx1/what_are_the_advantages_of_using_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drlvx1/what_are_the_advantages_of_using_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1drlvx1</id><link href="https://www.reddit.com/r/LangChain/comments/1drlvx1/what_are_the_advantages_of_using_langgraph/" /><updated>2024-06-29T21:45:43+00:00</updated><published>2024-06-29T21:45:43+00:00</published><title>What are the advantages of using LangGraph?</title></entry><entry><author><name>/u/jeffrey-0711</name><uri>https://www.reddit.com/user/jeffrey-0711</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dr5kki/the_most_important_thing_to_build_great_rag_system/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/aSvgcxH8kl5APyCeU_-ymZnxs9eMW53nDrsjhN1wuwg.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=66b1fe8fe5c7506a06c09888d09d52b392a08019&quot; alt=&quot;The most important thing to build great RAG system&quot; title=&quot;The most important thing to build great RAG system&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The most important thing to build great RAG system is &amp;#39;building great RAG evaluation dataset&amp;#39;.&lt;/p&gt; &lt;p&gt;Why?&lt;/p&gt; &lt;p&gt;Like all other ML systems out there, there are no silver bullet in the RAG field. Some techinques can be great on some documents, but it can be terrible on the other dataset.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/4igymtmlmg9d1.png?width=2964&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a5801d1e3b401bceafe8fca97048f91d4f313cf3&quot;&gt;Experiment on the different dataset (done by me)&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The performance of BM25 was great on the financial document, but it was terrible at the college rulebook document. It is one of the example that RAG performance can be very different when the document is different.&lt;/p&gt; &lt;p&gt;So, how to find the great RAG module for &lt;strong&gt;your document&lt;/strong&gt;?&lt;/p&gt; &lt;p&gt;Of course, start making great RAG evaluation dataset. &lt;/p&gt; &lt;p&gt;I think the great RAG dataset must be realistic. It is always better to gather real user&amp;#39;s question. If you can&amp;#39;t try to mock their question.&lt;br/&gt; Plus, it have to be precise. Wrong ground truth answer or wrong retrieval ground truth is bad for the result.&lt;br/&gt; And, do not believe LLM. LLM, even gpt-4o or claude-3 opus, is quite dumb to make &amp;quot;natural and realistic&amp;quot; question from the given passages. &lt;/p&gt; &lt;p&gt;You don&amp;#39;t have to make thousands of questions. A hundred questions will be enough.&lt;/p&gt; &lt;p&gt;After making great RAG evaluation dataset, the 90% of your work is done. You can use AutoML tools like &lt;a href=&quot;https://github.com/Marker-Inc-Korea/AutoRAG/&quot;&gt;AutoRAG&lt;/a&gt; to optimize RAG using your dataset. You can get high performance RAG in a few hours. For do that, you have to make great RAG evaluation dataset with much more time.&lt;/p&gt; &lt;p&gt;Actually, I am the builder of AutoRAG and there is an youtube video that I explain about AutoRAG. Click &lt;a href=&quot;https://www.youtube.com/watch?v=b2WR9p1yS7Y&quot;&gt;here&lt;/a&gt; to watch that.&lt;/p&gt; &lt;p&gt;Thank you! I want to connect with RAG builders and feel free to leave a comment.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jeffrey-0711&quot;&gt; /u/jeffrey-0711 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dr5kki/the_most_important_thing_to_build_great_rag_system/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dr5kki/the_most_important_thing_to_build_great_rag_system/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dr5kki</id><media:thumbnail url="https://external-preview.redd.it/aSvgcxH8kl5APyCeU_-ymZnxs9eMW53nDrsjhN1wuwg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=66b1fe8fe5c7506a06c09888d09d52b392a08019" /><link href="https://www.reddit.com/r/LangChain/comments/1dr5kki/the_most_important_thing_to_build_great_rag_system/" /><updated>2024-06-29T07:16:12+00:00</updated><published>2024-06-29T07:16:12+00:00</published><title>The most important thing to build great RAG system</title></entry><entry><author><name>/u/Not-That-rpg</name><uri>https://www.reddit.com/user/Not-That-rpg</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m confused by this use case: I made a &lt;code&gt;SystemMsg&lt;/code&gt; and a &lt;code&gt;Prompt&lt;/code&gt;, then I want to put them in a pipeline. So I tried adding them, but you can&amp;#39;t add a prompt and a message. So I tried making a &lt;code&gt;PipelinePromptTemplate&lt;/code&gt;. That doesn&amp;#39;t work, either, since a &lt;code&gt;SystemMsg&lt;/code&gt; is not a &lt;code&gt;Runnable&lt;/code&gt;. &lt;/p&gt; &lt;p&gt;This seems like something that should be very easy to do, but I&amp;#39;m stumped. &lt;/p&gt; &lt;p&gt;I suppose I can just smash together the system prompt string and the Prompt string and then make a single template, but it seems wrong that we have these classes that can&amp;#39;t be composed. Seems like adding a &lt;code&gt;Message&lt;/code&gt; to a &lt;code&gt;PromptTemplate&lt;/code&gt; ought to give a &lt;code&gt;PromptTemplate&lt;/code&gt;. Am I missing something?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Not-That-rpg&quot;&gt; /u/Not-That-rpg &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drmqcy/add_a_message_to_a_prompt_or_put_a_message_in_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drmqcy/add_a_message_to_a_prompt_or_put_a_message_in_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1drmqcy</id><link href="https://www.reddit.com/r/LangChain/comments/1drmqcy/add_a_message_to_a_prompt_or_put_a_message_in_a/" /><updated>2024-06-29T22:26:42+00:00</updated><published>2024-06-29T22:26:42+00:00</published><title>Add a message to a prompt or put a message in a pipeline?</title></entry><entry><author><name>/u/MrTulufan</name><uri>https://www.reddit.com/user/MrTulufan</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone used the UnstructuredExcelLoader() class to load xlsx file?&lt;/p&gt; &lt;p&gt;I am trying to load a simple one sheet Excel file (.xlsx) using the function:&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain.document_loaders import UnstructuredExcelLoader&lt;/code&gt;&lt;br/&gt; &lt;code&gt;loader = UnstructuredExcelLoader(file, mode=&amp;#39;single&amp;#39;, sheet_name = &amp;#39;sheet1&amp;#39;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;docs = loader.load()&lt;/code&gt;&lt;/p&gt; &lt;p&gt;however I received the following message:&lt;/p&gt; &lt;p&gt;&lt;code&gt;IndexError: too many indices for array: array is 3-dimensional, but 25 were indexed&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Not sure what is wrong. Any help is appreciated!&lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MrTulufan&quot;&gt; /u/MrTulufan &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drobcc/unstructuredexcelloader_not_working/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drobcc/unstructuredexcelloader_not_working/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1drobcc</id><link href="https://www.reddit.com/r/LangChain/comments/1drobcc/unstructuredexcelloader_not_working/" /><updated>2024-06-29T23:43:34+00:00</updated><published>2024-06-29T23:43:34+00:00</published><title>UnstructuredExcelLoader() not working</title></entry><entry><author><name>/u/Ibkha</name><uri>https://www.reddit.com/user/Ibkha</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone. Sorry if this question doesn&amp;#39;t make sense. I&amp;#39;m making an application where I&amp;#39;m using a GoogleMap component in react on the front-end and LangGraph for my LLM Agent. Here&amp;#39;s the workflow I&amp;#39;m trying to achieve&lt;/p&gt; &lt;p&gt;User asks a question -&amp;gt; Depending on the question, Agent updates GoogleMap context -&amp;gt; Map changes (Depending on tool)&lt;/p&gt; &lt;p&gt;I created my GoogleMap react context and used the hook inside of the Agent tool function to update state. TS throws an error saying I shouldn&amp;#39;t be updating state from the server [ addPinpoint() is a function that updates array state on my GoogleMap component. This array is then mapped to reflect changes ] Is there a way in LangGraph to resolve something like this? Thanks in advance and apologies if this is a noob question.&lt;/p&gt; &lt;p&gt;Code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;export const pinpointTool = new DynamicStructuredTool({ name: &amp;quot;pinpointTool&amp;quot;, description: &amp;quot;A tool for placing pinpoints on the map, given a specific address, which includes Street, City, State, and Country. If you want to show a user a location, use this tool by passing in the address of the location&amp;quot;, schema: pinpointSchema, func: async ( input ) =&amp;gt; { const { lat, lng } = await fetchCoordinates(input) const { addPinpoint } = useMap(); addPinpoint(lat, lng) return &amp;quot;Pinpoints Placed&amp;quot; } }) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ibkha&quot;&gt; /u/Ibkha &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drcw11/updating_react_context_with_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drcw11/updating_react_context_with_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1drcw11</id><link href="https://www.reddit.com/r/LangChain/comments/1drcw11/updating_react_context_with_langgraph/" /><updated>2024-06-29T14:50:39+00:00</updated><published>2024-06-29T14:50:39+00:00</published><title>Updating React Context with LangGraph</title></entry><entry><author><name>/u/Pitiful_Yak_390</name><uri>https://www.reddit.com/user/Pitiful_Yak_390</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, I&amp;#39;ve just published a new post diving into AI gateways, offering a birds-eye view from 50,000 feet.&lt;/p&gt; &lt;p&gt;Check it out here: &lt;a href=&quot;https://open.substack.com/pub/siddharthsambharia/p/ai-gateways-the-missing-block-in?r=en8oy&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&amp;amp;showWelcomeOnShare=true&quot;&gt;AI Gateways: The Missing Block in the AI puzzle&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I&amp;#39;d love to hear your thoughts and any questions you might have.&lt;/p&gt; &lt;p&gt;If you&amp;#39;re interested in exploring a lightweight open-source AI Gateway connecting 100+ LLMs, consider checking out Portkey AI&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Pitiful_Yak_390&quot;&gt; /u/Pitiful_Yak_390 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dr8css/ai_gateways_the_missing_block_in_the_ai_puzzle/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dr8css/ai_gateways_the_missing_block_in_the_ai_puzzle/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dr8css</id><link href="https://www.reddit.com/r/LangChain/comments/1dr8css/ai_gateways_the_missing_block_in_the_ai_puzzle/" /><updated>2024-06-29T10:37:58+00:00</updated><published>2024-06-29T10:37:58+00:00</published><title>AI Gateways: The Missing Block in the AI puzzle</title></entry><entry><author><name>/u/NeiiSan</name><uri>https://www.reddit.com/user/NeiiSan</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking over some internet data... I&amp;#39;m curious as to the limitations the DuckDuckGo (&lt;a href=&quot;https://api.python.langchain.com/en/latest/tools/langchain%5C_community.tools.ddg%5C_search.tool.DuckDuckGoSearchRun.html&quot;&gt;https://api.python.langchain.com/en/latest/tools/langchain\_community.tools.ddg\_search.tool.DuckDuckGoSearchRun.html&lt;/a&gt;) tool has compared to Talivy, or other paid web search instruments. Anyone compared them?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/NeiiSan&quot;&gt; /u/NeiiSan &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dr04up/langchains_duckduckgo_vs_talivy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dr04up/langchains_duckduckgo_vs_talivy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dr04up</id><link href="https://www.reddit.com/r/LangChain/comments/1dr04up/langchains_duckduckgo_vs_talivy/" /><updated>2024-06-29T01:49:40+00:00</updated><published>2024-06-29T01:49:40+00:00</published><title>Langchain's DuckDuckGo vs. Talivy</title></entry><entry><author><name>/u/Fluid_Conflict1237</name><uri>https://www.reddit.com/user/Fluid_Conflict1237</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is my code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain.chains.summarize import load_summarize_chain import textwrap chain = load_summarize_chain(llm, chain_type=&amp;quot;map_reduce&amp;quot;) output_summary = chain.run(docs) wrapped_text = textwrap.fill(output_summary , width=100) print(wrapped_text) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is my error:&lt;/p&gt; &lt;p&gt;IndexError Traceback (most recent call last)&lt;br/&gt; Cell In[29], line 6&lt;br/&gt; 2 import textwrap&lt;br/&gt; 5 chain = load_summarize_chain(llm, chain_type=&amp;quot;map_reduce&amp;quot;)&lt;br/&gt; ----&amp;gt; 6 output_summary = chain.run(docs)&lt;br/&gt; 7 wrapped_text = textwrap.fill(output_summary , width=100)&lt;br/&gt; 8 print(wrapped_text)&lt;/p&gt; &lt;p&gt;File c:\Users\acer\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\_api\deprecation.py:168, in deprecated.&amp;lt;locals&amp;gt;.deprecate.&amp;lt;locals&amp;gt;.warning_emitting_wrapper(*args, **kwargs)&lt;br/&gt; 166warned = True&lt;br/&gt; 167emit_warning()&lt;br/&gt; --&amp;gt; 168 return wrapped(*args, **kwargs)&lt;/p&gt; &lt;p&gt;File c:\Users\acer\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain\chains\base.py:600, in Chain.run(self, callbacks, tags, metadata, *args, **kwargs)&lt;br/&gt; 598if len(args) != 1:&lt;br/&gt; 599raise ValueError(&amp;quot;`run` supports only one positional argument.&amp;quot;)&lt;br/&gt; --&amp;gt; 600return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[&lt;br/&gt; 601_output_key&lt;br/&gt; 602]&lt;br/&gt; 604 if kwargs and not args:&lt;br/&gt; 605return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[&lt;br/&gt; 606_output_key&lt;br/&gt; 607]&lt;/p&gt; &lt;pre&gt;&lt;code&gt;... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;219Structured output.&lt;br/&gt; 220&amp;quot;&amp;quot;&amp;quot;&lt;br/&gt; --&amp;gt; 221return self.parse(result[0].text)&lt;/p&gt; &lt;p&gt;IndexError: list index out of range&lt;/p&gt; &lt;p&gt;Edit 1 : I realized this is happening as the LLM isn&amp;#39;t returning anything and hence an empty list leading to result[0] being out of range. The tutorial I was following used OpenAI API but since it is paid , I used Google Palm. Why this wont work with Palm ??&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fluid_Conflict1237&quot;&gt; /u/Fluid_Conflict1237 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dr4hf9/getting_indexerror_when_trying_to_pass_document/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dr4hf9/getting_indexerror_when_trying_to_pass_document/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dr4hf9</id><link href="https://www.reddit.com/r/LangChain/comments/1dr4hf9/getting_indexerror_when_trying_to_pass_document/" /><updated>2024-06-29T06:03:15+00:00</updated><published>2024-06-29T06:03:15+00:00</published><title>Getting IndexError when trying to pass Document Object in LangChain for Summarizing text</title></entry><entry><author><name>/u/FlatConversation9982</name><uri>https://www.reddit.com/user/FlatConversation9982</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;My company has a large library of 200ish page documents that we frequently create for project proposals. Creating these documents is very laborious and so is searching for information in them. I was advised to turn those documents into vector embeddings, load those embeddings into embeddings index or db, then do Retrieval Augmented Generation over those documents using langchain.&lt;/p&gt; &lt;p&gt;I am curious if this process is possible to do entirely locally because of the sensitive nature of the documents and if so what tools to use? Any advice would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FlatConversation9982&quot;&gt; /u/FlatConversation9982 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dqjf6r/advice_on_rag_and_locally_running_an_llm_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dqjf6r/advice_on_rag_and_locally_running_an_llm_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dqjf6r</id><link href="https://www.reddit.com/r/LangChain/comments/1dqjf6r/advice_on_rag_and_locally_running_an_llm_for/" /><updated>2024-06-28T13:17:09+00:00</updated><published>2024-06-28T13:17:09+00:00</published><title>Advice on RAG and Locally Running an LLM for sensitive documents.</title></entry><entry><author><name>/u/harshit_nariya</name><uri>https://www.reddit.com/user/harshit_nariya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dqil3c/parrot_vs_chatgpt/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/7t4z04tlxa9d1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9b79159d0ed85865f57eb674e05e6808e49097c1&quot; alt=&quot;Parrot vs ChatGPT&quot; title=&quot;Parrot vs ChatGPT&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/harshit_nariya&quot;&gt; /u/harshit_nariya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/7t4z04tlxa9d1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dqil3c/parrot_vs_chatgpt/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dqil3c</id><media:thumbnail url="https://preview.redd.it/7t4z04tlxa9d1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b79159d0ed85865f57eb674e05e6808e49097c1" /><link href="https://www.reddit.com/r/LangChain/comments/1dqil3c/parrot_vs_chatgpt/" /><updated>2024-06-28T12:35:01+00:00</updated><published>2024-06-28T12:35:01+00:00</published><title>Parrot vs ChatGPT</title></entry><entry><author><name>/u/mr_riddler24</name><uri>https://www.reddit.com/user/mr_riddler24</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What would actually be better for answering questions to product docs (say 4,000 pages of product docs)? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mr_riddler24&quot;&gt; /u/mr_riddler24 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dqvb3h/rag_vs_open_ai_assistant_file_retrieval/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dqvb3h/rag_vs_open_ai_assistant_file_retrieval/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dqvb3h</id><link href="https://www.reddit.com/r/LangChain/comments/1dqvb3h/rag_vs_open_ai_assistant_file_retrieval/" /><updated>2024-06-28T21:51:58+00:00</updated><published>2024-06-28T21:51:58+00:00</published><title>RAG vs open ai assistant file retrieval?</title></entry><entry><author><name>/u/BustinBallsYo</name><uri>https://www.reddit.com/user/BustinBallsYo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, I’m new to LangChain. I am trying to figure out if it’s possible to use my own custom vecDB to use with LangChain (or am I stuck with something like chroma)? If so, are there any guidance on how to approach the integration with LLMs and RAG? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BustinBallsYo&quot;&gt; /u/BustinBallsYo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dqu7jv/using_custom_vecdb_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dqu7jv/using_custom_vecdb_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dqu7jv</id><link href="https://www.reddit.com/r/LangChain/comments/1dqu7jv/using_custom_vecdb_with_langchain/" /><updated>2024-06-28T21:03:16+00:00</updated><published>2024-06-28T21:03:16+00:00</published><title>Using Custom vecDB with LangChain</title></entry><entry><author><name>/u/qa_anaaq</name><uri>https://www.reddit.com/user/qa_anaaq</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m curious about how I might go about creating the chatgpt experience, which combines chat and the ability to write and execute python code. &lt;/p&gt; &lt;p&gt;I know I could do this with yne Assistants API. And I know I could do this with Langchain. &lt;/p&gt; &lt;p&gt;How could I do it with vanilla agents? Like if I used Open Interpreter as the code part, I don&amp;#39;t know how to combine it with chat abilities so that the agent &amp;quot;knows&amp;quot; to chat if it needs to chat and to use code if it needs to code (e.g. Create a chart from data). &lt;/p&gt; &lt;p&gt;Could a vanilla agent setup be used in such a way as a backend for a chat application?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/qa_anaaq&quot;&gt; /u/qa_anaaq &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dqxuhw/creating_chatgpt_experience_complete_with_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dqxuhw/creating_chatgpt_experience_complete_with_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dqxuhw</id><link href="https://www.reddit.com/r/LangChain/comments/1dqxuhw/creating_chatgpt_experience_complete_with_code/" /><updated>2024-06-28T23:50:07+00:00</updated><published>2024-06-28T23:50:07+00:00</published><title>Creating Chatgpt experience, complete with Code Interpreter</title></entry></feed>