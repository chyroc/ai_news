<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-22T07:06:29+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Adam-Schroeder</name><uri>https://www.reddit.com/user/Adam-Schroeder</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/Tm3xcm8pFutyjWhY5DD2viOOuO0c_TRKig3pFRimUEw.jpg&quot; alt=&quot;Create AI Chatbots for Websites in Python - EmbedChain Dash&quot; title=&quot;Create AI Chatbots for Websites in Python - EmbedChain Dash&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Everyone,I just created a free video tutorial showing how to build an AI Chatbots for Beginners in Python. We&amp;#39;ll use the EmbedChain (built on top of LangChain) and Dash libraries, and we&amp;#39;ll learn the core principles of training and interacting with your bot. I hope you learn a lot.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/tmOmTBEdNrE&quot;&gt;https://youtu.be/tmOmTBEdNrE&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/tq1ovgfihxdc1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b4e1593532e2f396d0397ec80161020a30d14b69&quot;&gt;https://preview.redd.it/tq1ovgfihxdc1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b4e1593532e2f396d0397ec80161020a30d14b69&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Adam-Schroeder&quot;&gt; /u/Adam-Schroeder &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19coe4m</id><media:thumbnail url="https://b.thumbs.redditmedia.com/Tm3xcm8pFutyjWhY5DD2viOOuO0c_TRKig3pFRimUEw.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/" /><updated>2024-01-22T05:33:29+00:00</updated><published>2024-01-22T05:33:29+00:00</published><title>Create AI Chatbots for Websites in Python - EmbedChain Dash</title></entry><entry><author><name>/u/LARGE_LANGUE_MODEL</name><uri>https://www.reddit.com/user/LARGE_LANGUE_MODEL</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I already have some basic knowledge about langchain and LLM. Now I want to apply it to a production environment, but I realize that basic knowledge is not enough. I want to make a news Q&amp;amp;A chatbot application using RAG and use API access tools to get real-time information about cryptocurrencies. Does anyone have a sample repo that I can refer to? Thank you very much&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LARGE_LANGUE_MODEL&quot;&gt; /u/LARGE_LANGUE_MODEL &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cgrpd/chatbot_rag_and_tool_about_crypto/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cgrpd/chatbot_rag_and_tool_about_crypto/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19cgrpd</id><link href="https://www.reddit.com/r/LangChain/comments/19cgrpd/chatbot_rag_and_tool_about_crypto/" /><updated>2024-01-21T23:11:18+00:00</updated><published>2024-01-21T23:11:18+00:00</published><title>Chatbot RAG and tool about crypto</title></entry><entry><author><name>/u/redd-dev</name><uri>https://www.reddit.com/user/redd-dev</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, what framework or tools do I use if I wanted to build an open-sourced LLM chatbot which is enterprise scalable to multiple users?&lt;/p&gt; &lt;p&gt;A framework/tool I am thinking of is Langchain. There won‚Äôt be any fine-tuning for my chatbot so I am not sure if I need to use Langchain.&lt;/p&gt; &lt;p&gt;Would there be a different suitable framework to use if I wanted to build for a small to mid sized enterprise compared to a large enterprise?&lt;/p&gt; &lt;p&gt;I am thinking of using AWS to host the LLM model. &lt;/p&gt; &lt;p&gt;Any help would really be appreciated. Many thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/redd-dev&quot;&gt; /u/redd-dev &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bzgh1/what_framework_to_use_to_build_an_opensourced_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bzgh1/what_framework_to_use_to_build_an_opensourced_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bzgh1</id><link href="https://www.reddit.com/r/LangChain/comments/19bzgh1/what_framework_to_use_to_build_an_opensourced_llm/" /><updated>2024-01-21T09:11:44+00:00</updated><published>2024-01-21T09:11:44+00:00</published><title>What framework to use to build an open-sourced LLM chatbot which is enterprise scalable to multiple users</title></entry><entry><author><name>/u/sharrajesh</name><uri>https://www.reddit.com/user/sharrajesh</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Not sure where to ask this question&lt;/p&gt; &lt;p&gt;Why: I am seeing mild success with openai assistant api on their portal platform.openai.com. However it&amp;#39;s impossible to test custom functions on their portal. DevX of that api is not straightforward. I seem to like Langchain attempts to wrap this capability. However it&amp;#39;s missing this ability to register custom functions. &lt;/p&gt; &lt;p&gt;Please guide me if there&amp;#39;s a work around?&lt;/p&gt; &lt;hr/&gt; &lt;h2&gt;Feature Request created by chat.langchain.com after I couldn&amp;#39;t get my answer on this help portal&lt;/h2&gt; &lt;p&gt;Subject: Feature Request: Custom Function Registration in Langchain Dear Langchain Team, I hope this message finds you well. I am a user of the Langchain platform and have been exploring the capabilities of the OpenAI Assistant integration. While working with the platform, I noticed that there is no explicit documentation or mention of a register_function method for registering custom functions with the OpenAI Assistant. I believe that having the ability to register custom functions would greatly enhance the flexibility and extensibility of the OpenAI Assistant. This feature would allow users to define their own functions and seamlessly integrate them into the assistant&amp;#39;s conversational flow. Specifically, I envision a method similar to register_function that would enable users to define custom functions in Python and register them with the OpenAI Assistant. These registered functions could then be invoked during the conversation, allowing for more dynamic and interactive interactions with the assistant. I kindly request that the Langchain team consider adding this feature to the platform. It would empower users to create more tailored and specialized conversational experiences with the OpenAI Assistant. Thank you for your attention to this feature request. I appreciate your dedication to continuously improving the Langchain platform and look forward to any updates or feedback regarding this request. Best regards, [Your Name]&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sharrajesh&quot;&gt; /u/sharrajesh &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19c9969/request_to_improve_integration_with_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19c9969/request_to_improve_integration_with_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19c9969</id><link href="https://www.reddit.com/r/LangChain/comments/19c9969/request_to_improve_integration_with_openai/" /><updated>2024-01-21T17:57:50+00:00</updated><published>2024-01-21T17:57:50+00:00</published><title>Request to improve integration with openai assistant api to add custom functions registered inside platform.openai.com</title></entry><entry><author><name>/u/ep3gotts</name><uri>https://www.reddit.com/user/ep3gotts</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;*Guidance Scale* Stable diffusion setting, ‚Äúprompt strength‚Äù&lt;/p&gt; &lt;p&gt;&amp;gt; Guidance Scale: controls how similar the generated image will be to the prompt. A higher guidance scale means the model will try to generate an image that follows the prompt more strictly. A lower guidance scale means the model will have more creativity.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ep3gotts&quot;&gt; /u/ep3gotts &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bz3o1/is_llm_temperature_setting_similar_to_guidance/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bz3o1/is_llm_temperature_setting_similar_to_guidance/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bz3o1</id><link href="https://www.reddit.com/r/LangChain/comments/19bz3o1/is_llm_temperature_setting_similar_to_guidance/" /><updated>2024-01-21T08:47:06+00:00</updated><published>2024-01-21T08:47:06+00:00</published><title>Is LLM &quot;temperature&quot; setting similar to &quot;Guidance scale&quot; from Stable Diffusion?</title></entry><entry><author><name>/u/Sensitive-Garden6776</name><uri>https://www.reddit.com/user/Sensitive-Garden6776</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys,&lt;/p&gt; &lt;p&gt;I am deciding to implement RAG pipeline into my code&lt;/p&gt; &lt;p&gt;between Langchain and Llama Index, what RAG capability yield better performance and what&amp;#39;s the main different?&lt;/p&gt; &lt;p&gt;Thanks a lot guys!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sensitive-Garden6776&quot;&gt; /u/Sensitive-Garden6776 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bnjnz/langchain_vs_llama_index/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bnjnz/langchain_vs_llama_index/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bnjnz</id><link href="https://www.reddit.com/r/LangChain/comments/19bnjnz/langchain_vs_llama_index/" /><updated>2024-01-20T22:18:19+00:00</updated><published>2024-01-20T22:18:19+00:00</published><title>Langchain vs Llama Index</title></entry><entry><author><name>/u/cambridgecoder415</name><uri>https://www.reddit.com/user/cambridgecoder415</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Title, is chatGPT the best llm to help with the python API?&lt;/p&gt; &lt;p&gt;üôè&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cambridgecoder415&quot;&gt; /u/cambridgecoder415 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bqj57/is_there_a_chat_to_help_with_the_langchain_api/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bqj57/is_there_a_chat_to_help_with_the_langchain_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bqj57</id><link href="https://www.reddit.com/r/LangChain/comments/19bqj57/is_there_a_chat_to_help_with_the_langchain_api/" /><updated>2024-01-21T00:34:19+00:00</updated><published>2024-01-21T00:34:19+00:00</published><title>Is there a chat to help with the langchain API?</title></entry><entry><author><name>/u/cambridgecoder415</name><uri>https://www.reddit.com/user/cambridgecoder415</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Title, is chatGPT the best llm to help with the python API?&lt;/p&gt; &lt;p&gt;üôè&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cambridgecoder415&quot;&gt; /u/cambridgecoder415 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bqj5z/is_there_a_chat_to_help_with_the_langchain_api/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bqj5z/is_there_a_chat_to_help_with_the_langchain_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bqj5z</id><link href="https://www.reddit.com/r/LangChain/comments/19bqj5z/is_there_a_chat_to_help_with_the_langchain_api/" /><updated>2024-01-21T00:34:20+00:00</updated><published>2024-01-21T00:34:20+00:00</published><title>Is there a chat to help with the langchain API?</title></entry><entry><author><name>/u/bigluzer</name><uri>https://www.reddit.com/user/bigluzer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;first time long time. love the platform.&lt;/p&gt; &lt;p&gt;we have build custom tools and agents.&lt;/p&gt; &lt;p&gt;i am trying to extend our implementation with the following&lt;/p&gt; &lt;p&gt;- custom meta-prompts - that are stored on the firm or individual level and could be used as part of a workflow&lt;/p&gt; &lt;p&gt;- Custom meta-data storage - like a list of URLs. this would allow the user to edit this list, and then a custom agent (web scraper, etc) could reference it&lt;/p&gt; &lt;p&gt;- multi-agents? our function calls can only do one thing at a time (one scrape, etc). is there a way to run multiple, in parallel, and return together?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bigluzer&quot;&gt; /u/bigluzer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bfisz/langchain_questions_advanced_use_cases/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bfisz/langchain_questions_advanced_use_cases/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bfisz</id><link href="https://www.reddit.com/r/LangChain/comments/19bfisz/langchain_questions_advanced_use_cases/" /><updated>2024-01-20T16:28:10+00:00</updated><published>2024-01-20T16:28:10+00:00</published><title>LangChain Questions - Advanced Use Cases</title></entry><entry><author><name>/u/rahabash</name><uri>https://www.reddit.com/user/rahabash</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Howdy. I have a project which initially made use of LlamaIndex and GithubRepositoryReader to locally persist a vector store containing the contents of a github code repository that I will now be looking to instead integrate into Azure AI search service.&lt;/p&gt; &lt;p&gt;Does anyone know of any resources they can point me to which demonstrates such a project (generating embeddings for a code repo, uploading the docs to azure ai search, q&amp;amp;a against said search service)&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rahabash&quot;&gt; /u/rahabash &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bn28q/integrating_azure_ai_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bn28q/integrating_azure_ai_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bn28q</id><link href="https://www.reddit.com/r/LangChain/comments/19bn28q/integrating_azure_ai_search/" /><updated>2024-01-20T21:56:54+00:00</updated><published>2024-01-20T21:56:54+00:00</published><title>Integrating Azure AI search</title></entry><entry><author><name>/u/99OG121314</name><uri>https://www.reddit.com/user/99OG121314</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have tested two retriever methods, 1) Pinecone Hybrid Search and 2) ParentDocument Retriever.&lt;/p&gt; &lt;p&gt;Generally, the ParentDocument Retriever performs a lot better but there are instances where the Hybrid search finds interesting nuggets.&lt;/p&gt; &lt;p&gt;I wanted to know, if using the ensemble retriever, I can do a combination of BM25 and ParentDocument? Has anyone tried this?&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/99OG121314&quot;&gt; /u/99OG121314 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bjuov/ensemble_retriever_with_parentdoc/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bjuov/ensemble_retriever_with_parentdoc/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bjuov</id><link href="https://www.reddit.com/r/LangChain/comments/19bjuov/ensemble_retriever_with_parentdoc/" /><updated>2024-01-20T19:36:22+00:00</updated><published>2024-01-20T19:36:22+00:00</published><title>Ensemble Retriever with ParentDoc</title></entry><entry><author><name>/u/Sim_Check</name><uri>https://www.reddit.com/user/Sim_Check</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;d like to modify the model path using GPT4AllEmbeddings and use a model I already downloading from the browser (the all-MiniLM-L6-v2-f16.gguf model, the same that GPT4AllEmbeddings downloads by default).&lt;/p&gt; &lt;p&gt;I need it to create RAG chatbot completely offline.&lt;/p&gt; &lt;p&gt;The langchain documentation chatbot suggests me to use:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;from langchain_community.embeddings &lt;strong&gt;import&lt;/strong&gt; GPT4AllEmbeddings&lt;br/&gt; model_path = &amp;quot;/path/to/your/model.bin&amp;quot;&lt;br/&gt; gpt4all_embd = GPT4AllEmbeddings(model=model_path)&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;I tried it but it does not work. It completely ignore the model path.&lt;/p&gt; &lt;p&gt;Is there something I&amp;#39;m missing?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sim_Check&quot;&gt; /u/Sim_Check &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19biswa/gpt4allembeddings_modify_model_path/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19biswa/gpt4allembeddings_modify_model_path/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19biswa</id><link href="https://www.reddit.com/r/LangChain/comments/19biswa/gpt4allembeddings_modify_model_path/" /><updated>2024-01-20T18:51:23+00:00</updated><published>2024-01-20T18:51:23+00:00</published><title>GPT4AllEmbeddings modify model path</title></entry><entry><author><name>/u/worldender999</name><uri>https://www.reddit.com/user/worldender999</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Howdy. I am an experienced software engineer working on my first ever project using an LLM. My goal is to use it to replace a rules engine for transaction categorization in an application I have. I will feed in the new transactions, list of categories, plus data on past categorized transactions, to produce the new output. All results will go through manual review prior to being accepted, which is the current behavior with the existing rules engine anyway.&lt;/p&gt; &lt;p&gt;This will be deployed to my home server which has a powerful CPU, lots of RAM, but a shit GPU. Because of this, my plan is to use a cloud LLM like ChatGPT. However I want to run the Vector database (Cassandra, chroma, etc. haven&amp;#39;t picked yet) on the server. I know the embeddings will be generated by the LLM and just stored in the Vector DB, so I don&amp;#39;t need to worry about the hardware needs for that.&lt;/p&gt; &lt;p&gt;My question is around querying the Vector DB. Are there special hardware requirements (ie, GPU-preferred operations) for running those queries? I&amp;#39;m not worried about operations that a CPU can handle well, only stuff that requires a beefier GPU.&lt;/p&gt; &lt;p&gt;Thanks in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/worldender999&quot;&gt; /u/worldender999 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bcztd/question_about_hardware_requirements_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19bcztd/question_about_hardware_requirements_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19bcztd</id><link href="https://www.reddit.com/r/LangChain/comments/19bcztd/question_about_hardware_requirements_for/" /><updated>2024-01-20T14:31:50+00:00</updated><published>2024-01-20T14:31:50+00:00</published><title>Question about hardware requirements for LangChain and vector DBs</title></entry><entry><author><name>/u/Nice-Target-9434</name><uri>https://www.reddit.com/user/Nice-Target-9434</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I am currently looking into using LLMs for a project and figured LiteLLM might be a good start to test out different models. With a bit of research I saw that langchain is basically the number one library for doing this kind of things, becauso of RAG support etc.&lt;/p&gt; &lt;p&gt;What I do not quite understand is, what is the relation between these tools? Does LangChain use LiteLLM or vice versa? Is there even a link or are these just completely seperate tools? There is also autogen, which is basically LangChain with mutiple agents developed by microsoft if I understand it correctly.&lt;/p&gt; &lt;p&gt;What I found was the mention of LangChain in LiteLLMs docs: &lt;a href=&quot;https://docs.litellm.ai/docs/langchain/&quot;&gt;https://docs.litellm.ai/docs/langchain/&lt;/a&gt; where ChatLiteLLM is imported from LangChain, does that mean there is LiteLLM integrated into LangChain?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I am quite confused here, would appreciate any input on this topic. Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Nice-Target-9434&quot;&gt; /u/Nice-Target-9434 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19b9fzw/relation_between_litellm_and_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19b9fzw/relation_between_litellm_and_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19b9fzw</id><link href="https://www.reddit.com/r/LangChain/comments/19b9fzw/relation_between_litellm_and_langchain/" /><updated>2024-01-20T11:05:18+00:00</updated><published>2024-01-20T11:05:18+00:00</published><title>Relation between LiteLLM and LangChain</title></entry><entry><author><name>/u/gargara_s_hui</name><uri>https://www.reddit.com/user/gargara_s_hui</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I build a chat bot with langchain.js and one of the tools of the bot is using a VectorDBQAChain connecred to a vector store that is basicaly one big txt file. The model I use is gpt-3.5-turbo-0613 and the chunck size of the text splitter is 1000. There are just a hundred rows of information. It works ok, but it takes too much time and sends a lot of embedings until it can answer a question correctly.&lt;/p&gt; &lt;p&gt;Now I am asked to create similar chat bot but working with a few thousand PDF&amp;#39;s and I wonder if this is even possible? I saw there is DocumentLoader, but is it needs to send embedings of all the content until it can formulate an answer it is useless. The cost will be too high and the time it takes will be enourmous. Maybe I am missing something here?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gargara_s_hui&quot;&gt; /u/gargara_s_hui &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19b40f8/multiple_pdfs_vs_single_large_file/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19b40f8/multiple_pdfs_vs_single_large_file/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19b40f8</id><link href="https://www.reddit.com/r/LangChain/comments/19b40f8/multiple_pdfs_vs_single_large_file/" /><updated>2024-01-20T05:07:14+00:00</updated><published>2024-01-20T05:07:14+00:00</published><title>Multiple PDF's vs single large file?</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am into creating an interactive chatbot that can take inputs from multiple data sources like pdf, word file, text file, excel files etc. I am using Pinecone retriever with Langchain wrapper on top of it. When I go for DirectoryLoader using glob function, I‚Äôm unable to load other file types except PDF and convert it to vector embeddings. Need a way to load rest of the documents and process it further for embeddings.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19b2ivj/is_there_any_common_loaders_in_langchain_to_load/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19b2ivj/is_there_any_common_loaders_in_langchain_to_load/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19b2ivj</id><link href="https://www.reddit.com/r/LangChain/comments/19b2ivj/is_there_any_common_loaders_in_langchain_to_load/" /><updated>2024-01-20T03:45:00+00:00</updated><published>2024-01-20T03:45:00+00:00</published><title>Is there any common loaders in langchain to load all types of documents??</title></entry><entry><author><name>/u/Money_Mycologist4939</name><uri>https://www.reddit.com/user/Money_Mycologist4939</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everybody I was wondering how would it be like a typical Dockerfile for running a langchain pipeline. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Money_Mycologist4939&quot;&gt; /u/Money_Mycologist4939 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19amgmz/how_to_dockerise_a_langchain_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19amgmz/how_to_dockerise_a_langchain_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19amgmz</id><link href="https://www.reddit.com/r/LangChain/comments/19amgmz/how_to_dockerise_a_langchain_app/" /><updated>2024-01-19T16:04:39+00:00</updated><published>2024-01-19T16:04:39+00:00</published><title>How to dockerise a Langchain app</title></entry><entry><author><name>/u/SensitiveFel</name><uri>https://www.reddit.com/user/SensitiveFel</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to realize such a scenario: Let&amp;#39;s say I have a &lt;code&gt;name&lt;/code&gt; field stored in my db, and when the user asks for bob, I may have Bob, Boe... in the db. If there is no exact match for bob, I want the bot to guide the user: do you want to query Bob or boe?&lt;/p&gt; &lt;p&gt;What I understand is that it&amp;#39;s actually how to make the bot stop to continue the query and output the result under certain circumstances during the execution, how should I implement this using langChain? Can I do it by &lt;code&gt;bind(stop=&amp;#39;xx&amp;#39;)&lt;/code&gt;?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SensitiveFel&quot;&gt; /u/SensitiveFel &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ambyh/using_agent_in_langchain_i_want_to_abort_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ambyh/using_agent_in_langchain_i_want_to_abort_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ambyh</id><link href="https://www.reddit.com/r/LangChain/comments/19ambyh/using_agent_in_langchain_i_want_to_abort_in/" /><updated>2024-01-19T15:59:21+00:00</updated><published>2024-01-19T15:59:21+00:00</published><title>Using Agent in langChain I want to abort in specific situations, how should I design it</title></entry><entry><author><name>/u/Wild-Market9571</name><uri>https://www.reddit.com/user/Wild-Market9571</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I found langchain to be overly complex for my needs, leading me to opt for coding from scratch. It seemed like langchain created vectordb per table, rather than consolidating them within one table, which wasn&amp;#39;t efficient according to my preferences.&lt;/p&gt; &lt;p&gt;Despite the complexities, I required a tool like langchain for splitting my documents into chunks. This quest took up more of my time, and I couldn&amp;#39;t fully comprehend the hype surrounding langchain as the epitome of freedom.&lt;/p&gt; &lt;p&gt;Nonetheless, I took matters into my own hands and devised my splitting technique. While it may not be the most optimal solution, it suits my requirements perfectly. I leveraged the spaCy Library and its NLP capabilities to separate my documents into sentences, providing me with the desired outcome and a sense of freedom.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Wild-Market9571&quot;&gt; /u/Wild-Market9571 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a5flh/langchain_appears_to_be_a_library_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a5flh/langchain_appears_to_be_a_library_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19a5flh</id><link href="https://www.reddit.com/r/LangChain/comments/19a5flh/langchain_appears_to_be_a_library_with/" /><updated>2024-01-19T00:19:11+00:00</updated><published>2024-01-19T00:19:11+00:00</published><title>Langchain appears to be a library with unnecessary complexities.</title></entry><entry><author><name>/u/SensitiveFel</name><uri>https://www.reddit.com/user/SensitiveFel</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;When a user asks a question, in what way can I achieve the display of similar questions. For example: the user asks for Bob&amp;#39;s age? I will give 4 related questions: who is Bob, Bob&amp;#39;s gender,.... But these questions are not random, they are given based on my profile&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SensitiveFel&quot;&gt; /u/SensitiveFel &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19an810/how_to_achieve_relevance_question_leading/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19an810/how_to_achieve_relevance_question_leading/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19an810</id><link href="https://www.reddit.com/r/LangChain/comments/19an810/how_to_achieve_relevance_question_leading/" /><updated>2024-01-19T16:35:50+00:00</updated><published>2024-01-19T16:35:50+00:00</published><title>How to achieve relevance question leading</title></entry><entry><author><name>/u/Capable_Juice98</name><uri>https://www.reddit.com/user/Capable_Juice98</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello People I&amp;#39;ve joined this community very recently, I&amp;#39;m working on a project, where I&amp;#39;m creating a QnA model on existing magazines of my college. I&amp;#39;m experimenting between different embeddings (openai, bge, gte..), vector stores (FAISS, Chroma db,...), document chunking ... Finally I have to deploy all of this into a webpage Can you suggest a way forward?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Capable_Juice98&quot;&gt; /u/Capable_Juice98 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19adx5s/deployment_of_rag_based_qna_model/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19adx5s/deployment_of_rag_based_qna_model/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19adx5s</id><link href="https://www.reddit.com/r/LangChain/comments/19adx5s/deployment_of_rag_based_qna_model/" /><updated>2024-01-19T07:54:27+00:00</updated><published>2024-01-19T07:54:27+00:00</published><title>Deployment of RAG Based QNA Model</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am using Llamacpp to load my models and streaming in the terminal works with the &lt;code&gt;StreamingStdOutCallbackHandler()&lt;/code&gt; and the parameter &lt;code&gt;streaming=True&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Now I want to enable Streaming in FastAPI responses, but didn&amp;#39;t find a solution that satisfies my requirements. Many tutorials wait until the response from the LLM is ready and then streaming it. But I want to see a &amp;quot;live&amp;quot; streaming of the tokens, otherwise it will take too long until the user gets a response (especially for longer texts).&lt;/p&gt; &lt;p&gt;So does anyone know to do this with Llamacpp and FastAPI?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;(I am NOT using any OpenAI model, I am using GGUF models locally)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19aevbz/streaming_with_llamacpp_langchain_and_fastapi/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19aevbz/streaming_with_llamacpp_langchain_and_fastapi/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19aevbz</id><link href="https://www.reddit.com/r/LangChain/comments/19aevbz/streaming_with_llamacpp_langchain_and_fastapi/" /><updated>2024-01-19T09:01:11+00:00</updated><published>2024-01-19T09:01:11+00:00</published><title>Streaming with Llamacpp, Langchain and FastAPI</title></entry><entry><author><name>/u/marcuss171</name><uri>https://www.reddit.com/user/marcuss171</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! I am developing a expense chatbot on WhatsApp but the cost per customer is very high. Each request is about 0.0884 and we are expecting each customer to do at least 100 request per month. Which would mean $8 per customer.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;We have a set of tools that is elevating the cost because it is passed as context, so my idea was to store the tools in a db, use GPT-3.5 to decide which tool to use. Pass just one tool to GPT 4 in the prompt and reduce the cost. But the costs would still be high at $0.025 per request. &lt;/p&gt; &lt;p&gt;I have two questions: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;What do you think about my solution?&lt;/li&gt; &lt;li&gt;Do you think using Llama2 would be a good idea to create a chatbot? And if so do you have any docs on how to do so.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;THanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/marcuss171&quot;&gt; /u/marcuss171 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a4pxq/cost_x_prompt_too_high_using_gpt_4/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a4pxq/cost_x_prompt_too_high_using_gpt_4/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19a4pxq</id><link href="https://www.reddit.com/r/LangChain/comments/19a4pxq/cost_x_prompt_too_high_using_gpt_4/" /><updated>2024-01-18T23:47:38+00:00</updated><published>2024-01-18T23:47:38+00:00</published><title>Cost x Prompt too high using GPT 4</title></entry><entry><author><name>/u/ubertodev</name><uri>https://www.reddit.com/user/ubertodev</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a4s0n/apichain/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/f576w3wcdadc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=26f01ce0ada53b935afb38d72436073b69803f16&quot; alt=&quot;Apichain&quot; title=&quot;Apichain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;when streaming apichain, it prepends the api url to a streaming text response. Any ideas why it would do this ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ubertodev&quot;&gt; /u/ubertodev &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/f576w3wcdadc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a4s0n/apichain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19a4s0n</id><media:thumbnail url="https://preview.redd.it/f576w3wcdadc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=26f01ce0ada53b935afb38d72436073b69803f16" /><link href="https://www.reddit.com/r/LangChain/comments/19a4s0n/apichain/" /><updated>2024-01-18T23:50:16+00:00</updated><published>2024-01-18T23:50:16+00:00</published><title>Apichain</title></entry><entry><author><name>/u/AbbreviationsPale867</name><uri>https://www.reddit.com/user/AbbreviationsPale867</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey I was using langhchain before the 0.1.0 update and I&amp;#39;m using it in a project that will go live soon, however I want to move to 0.1.0 but my custom agent completely breaks and I feel like LangSmith is my only option. Is there a way to get an invite code as I have been on the wait list for a bit.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AbbreviationsPale867&quot;&gt; /u/AbbreviationsPale867 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199nbwa/langsmith/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199nbwa/langsmith/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199nbwa</id><link href="https://www.reddit.com/r/LangChain/comments/199nbwa/langsmith/" /><updated>2024-01-18T10:42:18+00:00</updated><published>2024-01-18T10:42:18+00:00</published><title>Langsmith</title></entry></feed>