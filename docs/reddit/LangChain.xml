<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-29T22:49:46+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/d3the_h3ll0w</name><uri>https://www.reddit.com/user/d3the_h3ll0w</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae5fwi/searching_youtube_with_langchain_tools_streamlit/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/155DtY3G4XZlDaIpDtzSo7jEzWtBdwlnyoGucKjwfo4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9447ddad191458ea03eb58f9e7035a59501ef2cf&quot; alt=&quot;Searching Youtube with Langchain Tools + Streamlit&quot; title=&quot;Searching Youtube with Langchain Tools + Streamlit&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/d3the_h3ll0w&quot;&gt; /u/d3the_h3ll0w &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://jdsemrau.substack.com/p/searching-youtube-with-langchain&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae5fwi/searching_youtube_with_langchain_tools_streamlit/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ae5fwi</id><media:thumbnail url="https://external-preview.redd.it/155DtY3G4XZlDaIpDtzSo7jEzWtBdwlnyoGucKjwfo4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9447ddad191458ea03eb58f9e7035a59501ef2cf" /><link href="https://www.reddit.com/r/LangChain/comments/1ae5fwi/searching_youtube_with_langchain_tools_streamlit/" /><updated>2024-01-29T20:34:19+00:00</updated><published>2024-01-29T20:34:19+00:00</published><title>Searching Youtube with Langchain Tools + Streamlit</title></entry><entry><author><name>/u/Electronic-Letter592</name><uri>https://www.reddit.com/user/Electronic-Letter592</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to implement RAG for a 100 pages document that has a hierarchical structure of chapters, sub-chapters, etc. Therefore I chunk the document into smaller paragraphs. In many cases, a chunk within a sub-chapter makes only sense in the context of the title of the sub-chapter, e.g. (6.1 Method ABC, 6.1.1 Disadvantages).&lt;/p&gt; &lt;p&gt;I wonder what are the most common approaches in RAG to handle hierarchical structures, which are very common in longer documents?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Electronic-Letter592&quot;&gt; /u/Electronic-Letter592 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae3urf/rag_for_documents_with_chapters_and_subchapters/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae3urf/rag_for_documents_with_chapters_and_subchapters/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ae3urf</id><link href="https://www.reddit.com/r/LangChain/comments/1ae3urf/rag_for_documents_with_chapters_and_subchapters/" /><updated>2024-01-29T19:29:37+00:00</updated><published>2024-01-29T19:29:37+00:00</published><title>RAG for documents with chapters and sub-chapters</title></entry><entry><author><name>/u/CantaloupeLeading646</name><uri>https://www.reddit.com/user/CantaloupeLeading646</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;what are some good notebooks or repos that i could use to start playing around with a system that chains together multiple operations including RAG operation?&lt;/p&gt; &lt;p&gt;i want in the end to have a system that does the following:&lt;/p&gt; &lt;p&gt;input -&amp;gt; enters some LLM that outputs another text -&amp;gt; retrieve some documents and output multiple different texts -&amp;gt; for each of the outputted texts go through another LLM&lt;/p&gt; &lt;p&gt;i know it shouldn&amp;#39;t be very complicated but i have a hard time getting started and i don&amp;#39;t see anything that does that but I&amp;#39;m sure it exists. &lt;/p&gt; &lt;p&gt;specifically, i don&amp;#39;t see anywhere an example of a chain that passes the output of an LLM as the input to another LLM instance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CantaloupeLeading646&quot;&gt; /u/CantaloupeLeading646 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adxilw/good_starting_points_for_a_new_project_involving/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adxilw/good_starting_points_for_a_new_project_involving/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adxilw</id><link href="https://www.reddit.com/r/LangChain/comments/1adxilw/good_starting_points_for_a_new_project_involving/" /><updated>2024-01-29T15:10:01+00:00</updated><published>2024-01-29T15:10:01+00:00</published><title>good starting points for a new project involving chains of LLM operations</title></entry><entry><author><name>/u/kecepa5669</name><uri>https://www.reddit.com/user/kecepa5669</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Are there any research tools available to do research on the internet for free? Has anyone had any good or bad experiences with this type of task?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kecepa5669&quot;&gt; /u/kecepa5669 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae7y59/free_internet_research_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae7y59/free_internet_research_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ae7y59</id><link href="https://www.reddit.com/r/LangChain/comments/1ae7y59/free_internet_research_tools/" /><updated>2024-01-29T22:17:15+00:00</updated><published>2024-01-29T22:17:15+00:00</published><title>Free internet research tools?</title></entry><entry><author><name>/u/pr1vacyn0eb</name><uri>https://www.reddit.com/user/pr1vacyn0eb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I can write the code, but it seems all-over-the-place. Not very reusable.&lt;/p&gt; &lt;p&gt;I like my csv, but the world likes their jsons formatted in alpeca/openAI/mistral/(did I miss any?). &lt;/p&gt; &lt;p&gt;When you do the final comparison between your model&amp;#39;s output and the correct answer, you are doing this in a dataframe/csv. &lt;/p&gt; &lt;p&gt;When you run multiple rounds of prompt testings, I suppose I could flatten this each time. &lt;/p&gt; &lt;p&gt;What does langchain do for this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pr1vacyn0eb&quot;&gt; /u/pr1vacyn0eb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adx6ny/why_does_it_seem_prompt_testing_is_hard_is_it/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adx6ny/why_does_it_seem_prompt_testing_is_hard_is_it/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adx6ny</id><link href="https://www.reddit.com/r/LangChain/comments/1adx6ny/why_does_it_seem_prompt_testing_is_hard_is_it/" /><updated>2024-01-29T14:55:28+00:00</updated><published>2024-01-29T14:55:28+00:00</published><title>Why does it seem prompt testing is hard? Is it data formatting? Or the actual testing?</title></entry><entry><author><name>/u/webNoob13</name><uri>https://www.reddit.com/user/webNoob13</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have qa pairs like ```&lt;/p&gt; &lt;h1&gt;Example question-answer pairs&lt;/h1&gt; &lt;p&gt;qa_pairs = [ {&amp;quot;question&amp;quot;: &amp;quot;Who leads the rebellion in &amp;#39;Animal Farm&amp;#39;?&amp;quot;, &amp;quot;answer&amp;quot;: &amp;quot;The pigs, specially Snowball and Napoleon, leads the rebellion.&amp;quot;}, {&amp;quot;question&amp;quot;: &amp;quot;What is the main theme of &amp;#39;Animal Farm&amp;#39;?&amp;quot;, &amp;quot;answer&amp;quot;: &amp;quot;The main theme are the corruption of power.&amp;quot;}, {&amp;quot;question&amp;quot;: &amp;quot;What happens to Boxer in the novel?&amp;quot;, &amp;quot;answer&amp;quot;: &amp;quot;Boxer is send to a slaughterhouse by the pigs.&amp;quot;} ] &lt;code&gt; Then I&amp;#39;m trying to iterate them like &lt;/code&gt; def create_grading_prompt(qa_pair): return [ (&amp;quot;system&amp;quot;, &amp;quot;You are a helpful AI bot. Your name is {name}.&amp;quot;), (&amp;quot;human&amp;quot;, f&amp;quot;Question: {qa_pair[&amp;#39;question&amp;#39;]}\nAnswer: {qa_pair[&amp;#39;answer&amp;#39;]}\n\nPlease grade the grammar of the answer based on the following rubric:\n{grammar_rubric}&amp;quot;) ]&lt;/p&gt; &lt;h1&gt;Process each question-answer pair&lt;/h1&gt; &lt;p&gt;for qa&lt;em&gt;pair in qa_pairs: grammar_and_grading_chain = SequentialChain([ ChatPromptTemplate.from_messages(create_grading_prompt(qa_pair)), llm, StrOutputParser() ]) result = grammar_and_grading_chain.invoke(qa_pair) print(f&amp;quot;Question: {qa_pair[&amp;#39;question&amp;#39;]}\nAnswer: {qa_pair[&amp;#39;answer&amp;#39;]}\nGrade: {result}\n&amp;quot;) &lt;code&gt; throws &lt;/code&gt; { &amp;quot;name&amp;quot;: &amp;quot;TypeError&amp;quot;, &amp;quot;message&amp;quot;: &amp;quot;Serializable.&lt;/em&gt;&lt;em&gt;init&lt;/em&gt;_() takes 1 positional argument but 2 were given&amp;quot;, &amp;quot;stack&amp;quot;: &amp;quot;--------------------------------------------------------------------------- TypeError Traceback (most recent call last) Cell In[6], line 9 7 # Process each question-answer pair 8 for qa_pair in qa_pairs: ----&amp;gt; 9 grammar_and_grading_chain = SequentialChain([ 10 ChatPromptTemplate.from_messages(create_grading_prompt(qa_pair)), 11 llm, 12 StrOutputParser() 13 ]) 14 result = grammar_and_grading_chain.invoke(qa_pair) 15 print(f\&amp;quot;Question: {qa_pair[&amp;#39;question&amp;#39;]}\ Answer: {qa_pair[&amp;#39;answer&amp;#39;]}\ Grade: {result}\ \&amp;quot;)&lt;/p&gt; &lt;p&gt;TypeError: Serializable.&lt;strong&gt;init&lt;/strong&gt;() takes 1 positional argument but 2 were given&amp;quot; } &lt;code&gt; because my previous try was throwing this same error. My previous try &lt;/code&gt; grammar_and_grading_chain = SequentialChain([ ChatPromptTemplate(lambda qa_pair: f&amp;quot;Question: {qa_pair[&amp;#39;question&amp;#39;]}\nAnswer: {qa_pair[&amp;#39;answer&amp;#39;]}\n\nPlease grade the grammar of the answer based on the following rubric:\n{grammar_rubric}&amp;quot;), llm, StrOutputParser() ])&lt;/p&gt; &lt;h1&gt;Process each question-answer pair&lt;/h1&gt; &lt;p&gt;for qa_pair in qa_pairs: result = grammar_and_grading_chain.invoke(qa_pair) print(f&amp;quot;Question: {qa_pair[&amp;#39;question&amp;#39;]}\nAnswer: {qa_pair[&amp;#39;answer&amp;#39;]}\nGrade: {result}\n&amp;quot;) ``` I looked at documentation here: &lt;a href=&quot;https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#&quot;&gt;https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#&lt;/a&gt; and don&amp;#39;t understand what I&amp;#39;m doing wrong.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/webNoob13&quot;&gt; /u/webNoob13 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adu5e9/chatprompttemplate_keeps_telling_me_i_have_2/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adu5e9/chatprompttemplate_keeps_telling_me_i_have_2/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adu5e9</id><link href="https://www.reddit.com/r/LangChain/comments/1adu5e9/chatprompttemplate_keeps_telling_me_i_have_2/" /><updated>2024-01-29T12:27:13+00:00</updated><published>2024-01-29T12:27:13+00:00</published><title>ChatPromptTemplate keeps telling me I have 2 arguments</title></entry><entry><author><name>/u/mac_bateman</name><uri>https://www.reddit.com/user/mac_bateman</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, I&amp;#39;m trying to use these two guides from the Langchain documentation:&lt;/p&gt; &lt;p&gt;- &lt;a href=&quot;https://python.langchain.com/docs/use_cases/question_answering/citations&quot;&gt;https://python.langchain.com/docs/use_cases/question_answering/citations&lt;/a&gt;&lt;/p&gt; &lt;p&gt;- &lt;a href=&quot;https://python.langchain.com/docs/use_cases/question_answering/chat_history&quot;&gt;https://python.langchain.com/docs/use_cases/question_answering/chat_history&lt;/a&gt;&lt;/p&gt; &lt;p&gt;to create a chain that will return structured output with citations but also will accept chat_history. &lt;/p&gt; &lt;p&gt;Has anyone managed to create something similar using LCEL? &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mac_bateman&quot;&gt; /u/mac_bateman &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1advsq8/lcel_citations_chain_with_chat_history/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1advsq8/lcel_citations_chain_with_chat_history/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1advsq8</id><link href="https://www.reddit.com/r/LangChain/comments/1advsq8/lcel_citations_chain_with_chat_history/" /><updated>2024-01-29T13:52:40+00:00</updated><published>2024-01-29T13:52:40+00:00</published><title>LCEL - Citations chain with chat history</title></entry><entry><author><name>/u/RatioAltruistic9324</name><uri>https://www.reddit.com/user/RatioAltruistic9324</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everybody!&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently developing some agents on Langchain for many purpose. Some are just documents analysis or data extraction from documents, and other are more Chatbot Rag based The first category are not really agents, they are refine chain (a bit modified from the LCEL turo one) + stuff one And the second is Langchain Agents (ZeroShotPrompt)&lt;/p&gt; &lt;p&gt;Both run with GPT4&lt;/p&gt; &lt;p&gt;But here is the thing :&lt;/p&gt; &lt;p&gt;For the first category, as the pdf can goes to 5 to 20 pages, my agents take several minutes to handle them Also, I remarqued that the more I put a defined structure in the prompt to extracr information, the more it is long (can go up to 10min)&lt;/p&gt; &lt;p&gt;And for the second category, as there is a multi query retrieval Generation based on pinecone, it also take 1 min before generation.&lt;/p&gt; &lt;p&gt;I look for conceptual way to explain that. We see a lot of agent out there which are more fast &lt;/p&gt; &lt;ul&gt; &lt;li&gt;is it the framework Langchain that slow down everything?&lt;/li&gt; &lt;li&gt;is I had a local model would it be faster ?&lt;/li&gt; &lt;li&gt;is because of the Rag too complex?&lt;/li&gt; &lt;li&gt;how could I drastically shorten my prompt but keeping clear schema for data extraction?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Thanks you all for your help !&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RatioAltruistic9324&quot;&gt; /u/RatioAltruistic9324 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adqrwj/speed_up_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adqrwj/speed_up_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adqrwj</id><link href="https://www.reddit.com/r/LangChain/comments/1adqrwj/speed_up_agents/" /><updated>2024-01-29T08:47:18+00:00</updated><published>2024-01-29T08:47:18+00:00</published><title>Speed up Agents</title></entry><entry><author><name>/u/glip-glop-evil</name><uri>https://www.reddit.com/user/glip-glop-evil</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to use langchain with GPT for a search tool. The search database query has a language code (en or zh) and when the tool is used, the language code is determined from the user query.&lt;/p&gt; &lt;p&gt;How can I get langchain to run the tool twice - in all available language codes translating the user query when necessary and compare the search content and get the most appropriate one before returning an answer? &lt;/p&gt; &lt;p&gt;Does this need to be done via the prompt or a more programmatic approach?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/glip-glop-evil&quot;&gt; /u/glip-glop-evil &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adpw9c/language_switching_with_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adpw9c/language_switching_with_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adpw9c</id><link href="https://www.reddit.com/r/LangChain/comments/1adpw9c/language_switching_with_tools/" /><updated>2024-01-29T07:46:15+00:00</updated><published>2024-01-29T07:46:15+00:00</published><title>Language switching with tools</title></entry><entry><author><name>/u/ashpreetbedi</name><uri>https://www.reddit.com/user/ashpreetbedi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi reddit, I built an AI that can interact with the Hacker News API: &lt;a href=&quot;https://hn.aidev.run&quot;&gt;https://hn.aidev.run&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You can ask questions like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;What&amp;#39;s on hackernews about AI?&lt;/li&gt; &lt;li&gt;What&amp;#39;s on hackernews about iPhone?&lt;/li&gt; &lt;li&gt;What&amp;#39;s trending on hackernews?&lt;/li&gt; &lt;li&gt;What are users showing on hackernews?&lt;/li&gt; &lt;li&gt;What are users asking on hackernews?&lt;/li&gt; &lt;li&gt;Summarize this story: &lt;a href=&quot;https://news.ycombinator.com/item?id=39156778&quot;&gt;https://news.ycombinator.com/item?id=39156778&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It uses function calling to query the HN api.&lt;/p&gt; &lt;p&gt;To answer questions about a particular topic, it’ll search its knowledge base (a vector db that is periodically updated with the “top stories”) and get details about those stories from the API.&lt;/p&gt; &lt;p&gt;This is pretty barebones and I built it today in &amp;lt; 2 hours, so it probably won’t meet your high standards. If you give it a try, I’d love your feedback on how I can improve it.&lt;/p&gt; &lt;p&gt;If you’re interested, I built this using &lt;a href=&quot;https://github.com/phidatahq/phidata&quot;&gt;phidata&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thanks for reading and would love to hear what you think.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashpreetbedi&quot;&gt; /u/ashpreetbedi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adarpa/hackernews_ai_built_using_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adarpa/hackernews_ai_built_using_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adarpa</id><link href="https://www.reddit.com/r/LangChain/comments/1adarpa/hackernews_ai_built_using_function_calling/" /><updated>2024-01-28T19:28:17+00:00</updated><published>2024-01-28T19:28:17+00:00</published><title>HackerNews AI built using function calling</title></entry><entry><author><name>/u/Hungry-Connection645</name><uri>https://www.reddit.com/user/Hungry-Connection645</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, I&amp;#39;m trying to familiarize myself with the internals of the langchain python package, I noticed that langchain and langchain_core are separated and in the internal code they have similar sub packages. my question is what is the need for this separation and what is the thought process behind what should be implemented in langchain vs langchain_core. Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Hungry-Connection645&quot;&gt; /u/Hungry-Connection645 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad9x8c/why_separate_langchain_and_langchain_core_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad9x8c/why_separate_langchain_and_langchain_core_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad9x8c</id><link href="https://www.reddit.com/r/LangChain/comments/1ad9x8c/why_separate_langchain_and_langchain_core_for/" /><updated>2024-01-28T18:53:53+00:00</updated><published>2024-01-28T18:53:53+00:00</published><title>Why separate langchain and langchain_core for python package</title></entry><entry><author><name>/u/Benjamona97</name><uri>https://www.reddit.com/user/Benjamona97</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Im looking for a production level vector db, so I was thinking about plain pg + pgvector, the problem is that I can&amp;#39;t find an easy way of finding a good library to interact with it, so far I&amp;#39;m using raw queries like this (i will leave code at the bottom). I don&amp;#39;t know if this is the best way apart from chroma, weaviate, pinecone, etc etc this is going to be at production level por mi company to be used internally.&lt;br/&gt; WITH vector_matches AS (&lt;br/&gt; SELECT document_id, 1 - (embedding &amp;lt;=&amp;gt; %s) AS similarity&lt;br/&gt; FROM documents_embeddings&lt;br/&gt; WHERE 1 - (embedding &amp;lt;=&amp;gt; %s) &amp;gt; %s&lt;br/&gt; ORDER BY similarity DESC&lt;br/&gt; LIMIT %s&lt;br/&gt; )&lt;br/&gt; SELECT d.page_content, d.metadata, d.file_id, vm.similarity&lt;br/&gt; FROM documents d&lt;br/&gt; INNER JOIN vector_matches vm ON d.id = vm.document_id &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Benjamona97&quot;&gt; /u/Benjamona97 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adf3o6/looking_for_a_production_level_vector_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adf3o6/looking_for_a_production_level_vector_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adf3o6</id><link href="https://www.reddit.com/r/LangChain/comments/1adf3o6/looking_for_a_production_level_vector_db/" /><updated>2024-01-28T22:29:16+00:00</updated><published>2024-01-28T22:29:16+00:00</published><title>Looking for a production level vector db</title></entry><entry><author><name>/u/Xerxes_Artemisia</name><uri>https://www.reddit.com/user/Xerxes_Artemisia</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad2hcq/streamlit_run_apppy_blank_screen_help_vscode/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/7jx0iOSXrRqXqAo25L6_dP-LHrDNQDvR_eYBTULyOOY.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c42e7ed72cf80343b339e6911558dba6cf300b4b&quot; alt=&quot;Streamlit run app.py - blank screen help ( vscode) - OpenAI chat bot project&quot; title=&quot;Streamlit run app.py - blank screen help ( vscode) - OpenAI chat bot project&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I&amp;#39;m a newbie programmer and having mind boggling issue of my app not deploying...it is a chat bot...everything seems to be fine just the error was Inport error: Openai can&amp;#39;t be imported from langchain. I don&amp;#39;t know..have scoured the internet for the fixes, but unable to find a solution.&lt;/p&gt; &lt;p&gt;Saw a tutorial from free coding camp on YouTube and it seems to work in that tutorial. I followed step by step even checked multiple times.&lt;/p&gt; &lt;p&gt;If someone can help me find out what is wrong I will be very grateful.&lt;/p&gt; &lt;p&gt;It may be a simple thing or complex I don&amp;#39;t know as I don&amp;#39;t have a 360 degree understanding of python libraries or streamlit requirements. I followed the tutorial 100% though. I can say that.&lt;/p&gt; &lt;p&gt;I reached 1:14:00 in the video&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Xerxes_Artemisia&quot;&gt; /u/Xerxes_Artemisia &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/x0AnCE9SE4A?si=Yb1LMCiz5AJ1RE7E&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad2hcq/streamlit_run_apppy_blank_screen_help_vscode/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ad2hcq</id><media:thumbnail url="https://external-preview.redd.it/7jx0iOSXrRqXqAo25L6_dP-LHrDNQDvR_eYBTULyOOY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c42e7ed72cf80343b339e6911558dba6cf300b4b" /><link href="https://www.reddit.com/r/LangChain/comments/1ad2hcq/streamlit_run_apppy_blank_screen_help_vscode/" /><updated>2024-01-28T13:18:32+00:00</updated><published>2024-01-28T13:18:32+00:00</published><title>Streamlit run app.py - blank screen help ( vscode) - OpenAI chat bot project</title></entry><entry><author><name>/u/stoicbats_</name><uri>https://www.reddit.com/user/stoicbats_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I have converted some domain-specific name vectors into embeddings, with a dataset size of 200k words. All the embeddings were generated using OpenAI&amp;#39;s embedding model 3 (3072 dim per embedding) . Now I am planning to implement semantic search similarity. Given a domain keyword, I want to find the top 5 most similar matches. After embedding all 280k words, the size of the JSON file containing the embeddings is around 30GB.&lt;/p&gt; &lt;p&gt;I am new to this domain and evaluating the best options.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Should I use a cloud vector database like Pinecone or Typsense, or host locally on DigitalOcean?&lt;/li&gt; &lt;li&gt;If I go with a cloud option like Typsense, what configuration (RAM, etc.) would I need for 280k embeddings (30GB in size)? And how much would it likely cost?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I have been confused for the past few days and unable to find useful resources. Any help or advice you could provide would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/stoicbats_&quot;&gt; /u/stoicbats_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acxxbw/best_practices_for_semantic_search_on_200k/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acxxbw/best_practices_for_semantic_search_on_200k/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acxxbw</id><link href="https://www.reddit.com/r/LangChain/comments/1acxxbw/best_practices_for_semantic_search_on_200k/" /><updated>2024-01-28T08:19:24+00:00</updated><published>2024-01-28T08:19:24+00:00</published><title>Best Practices for Semantic Search on 200k vectors (30GB) Worth of Embeddings?</title></entry><entry><author><name>/u/worldender999</name><uri>https://www.reddit.com/user/worldender999</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building an app using LangChain to integrate with ChatGPT. I need a vector DB to store the embeddings. I want to use an on-prem option, not a cloud one. There are quite a few options I see from my searches. Wondering what folks would recommend. Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/worldender999&quot;&gt; /u/worldender999 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad52as/what_is_the_best_onprem_vector_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad52as/what_is_the_best_onprem_vector_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad52as</id><link href="https://www.reddit.com/r/LangChain/comments/1ad52as/what_is_the_best_onprem_vector_db/" /><updated>2024-01-28T15:27:08+00:00</updated><published>2024-01-28T15:27:08+00:00</published><title>What is the best on-prem vector db</title></entry><entry><author><name>/u/rkubc</name><uri>https://www.reddit.com/user/rkubc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on extracting information from PDFs containing tables using OpenAI, LangChain, and FAISS. My focus is on extracting value especially regarding specific keywords present in these documents. I&amp;#39;m looking for advice on optimal chunking strategies for these PDFs to ensure comprehensive information extraction without losing key details. Any insights or best practices would be greatly appreciated!&lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rkubc&quot;&gt; /u/rkubc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acudx2/efficient_chunking_strategies_for_pdf_information/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acudx2/efficient_chunking_strategies_for_pdf_information/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acudx2</id><link href="https://www.reddit.com/r/LangChain/comments/1acudx2/efficient_chunking_strategies_for_pdf_information/" /><updated>2024-01-28T04:40:05+00:00</updated><published>2024-01-28T04:40:05+00:00</published><title>Efficient Chunking Strategies for PDF Information Extraction with AI Tools</title></entry><entry><author><name>/u/Fr4nkWh1te</name><uri>https://www.reddit.com/user/Fr4nkWh1te</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am creating a chatbot over the data of my &lt;strong&gt;static React website&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;I fetch the page files from the file system using the &lt;a href=&quot;https://js.langchain.com/docs/modules/data_connection/document_loaders/file_directory&quot;&gt;DirectoryLoader&lt;/a&gt;. I could use a web loader but I want it to work even in local development.&lt;/p&gt; &lt;p&gt;The issue is the text splitter.&lt;/p&gt; &lt;p&gt;I couldn&amp;#39;t find a proper text splitter for JSX (React) code. But I seem to get decent results with the &lt;a href=&quot;https://js.langchain.com/docs/modules/data_connection/document_transformers/code_splitter#html&quot;&gt;HTML recursive text splitter&lt;/a&gt;, probably because JSX and HTML are so similar.&lt;/p&gt; &lt;p&gt;Before I send my documents to the HTML splitter, I &lt;strong&gt;remove all import statements and class names&lt;/strong&gt; (to get rid of the unnecessary clutter). I keep everything else (which might include some JavaScript code).&lt;/p&gt; &lt;p&gt;Is my approach fine? Is the HTML splitter suited for this use case? Is it normal that there is no text overlap in the generated documents?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fr4nkWh1te&quot;&gt; /u/Fr4nkWh1te &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad4eye/use_html_splitter_for_jsx_react_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad4eye/use_html_splitter_for_jsx_react_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad4eye</id><link href="https://www.reddit.com/r/LangChain/comments/1ad4eye/use_html_splitter_for_jsx_react_code/" /><updated>2024-01-28T14:57:12+00:00</updated><published>2024-01-28T14:57:12+00:00</published><title>Use HTML splitter for JSX (React) code?</title></entry><entry><author><name>/u/Spare_Cancel3205</name><uri>https://www.reddit.com/user/Spare_Cancel3205</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to store Langchain Documents in the qdrant database(docker). When I try storing them in the db. I am getting this error. Please help me solve this.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;UnexpectedResponse: Unexpected Response: 400 (Bad Request)&lt;/p&gt; &lt;p&gt;Raw response content:&lt;/p&gt; &lt;p&gt;b&amp;#39;{&amp;quot;status&amp;quot;:{&amp;quot;error&amp;quot;:&amp;quot;Payload error: JSON payload (46866880 bytes) is larger than allowed (limit: 33554432 bytes).&amp;quot;},&amp;quot;time&amp;quot;:0.0}&amp;#39;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Spare_Cancel3205&quot;&gt; /u/Spare_Cancel3205 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad0vvg/qdrant_db_payload_limit_exceeded_error/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad0vvg/qdrant_db_payload_limit_exceeded_error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad0vvg</id><link href="https://www.reddit.com/r/LangChain/comments/1ad0vvg/qdrant_db_payload_limit_exceeded_error/" /><updated>2024-01-28T11:42:25+00:00</updated><published>2024-01-28T11:42:25+00:00</published><title>Qdrant DB: Payload Limit Exceeded Error</title></entry><entry><author><name>/u/Traditional-Fish-517</name><uri>https://www.reddit.com/user/Traditional-Fish-517</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Nice blog article about how to build an AI therapist with LangChain: &lt;a href=&quot;https://blog.langchain.dev/mental-health-therapy-as-an-llm-state-machine/&quot;&gt;https://blog.langchain.dev/mental-health-therapy-as-an-llm-state-machine/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Traditional-Fish-517&quot;&gt; /u/Traditional-Fish-517 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acou6m/langchain_blog_on_ai_mental_health_therapy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acou6m/langchain_blog_on_ai_mental_health_therapy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acou6m</id><link href="https://www.reddit.com/r/LangChain/comments/1acou6m/langchain_blog_on_ai_mental_health_therapy/" /><updated>2024-01-27T23:57:31+00:00</updated><published>2024-01-27T23:57:31+00:00</published><title>LangChain Blog on AI mental health therapy</title></entry><entry><author><name>/u/aniketmaurya</name><uri>https://www.reddit.com/user/aniketmaurya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to rerank my retrieved documents but couldn&amp;#39;t find an example on Langchain. Ant pointers would help. (not looking for context compression)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/aniketmaurya&quot;&gt; /u/aniketmaurya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acywew/is_there_a_reranking_example_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acywew/is_there_a_reranking_example_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acywew</id><link href="https://www.reddit.com/r/LangChain/comments/1acywew/is_there_a_reranking_example_with_langchain/" /><updated>2024-01-28T09:27:00+00:00</updated><published>2024-01-28T09:27:00+00:00</published><title>Is there a reranking example with Langchain?</title></entry><entry><author><name>/u/dima11235813</name><uri>https://www.reddit.com/user/dima11235813</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I use webpilot and vox script all the time and wondering if there are examples of achieving this with LangChain.&lt;/p&gt; &lt;p&gt;I especially like both because I can provide a url and get all that info in context, which seems like even ChatGPT 4 with Bing can&amp;#39;t be relied on to do it consistently.&lt;/p&gt; &lt;p&gt;I have some examples in this article I generated.&lt;br/&gt; &lt;a href=&quot;https://www.learninternetgrow.com/real-time-search-with-llms/&quot;&gt;https://www.learninternetgrow.com/real-time-search-with-llms/&lt;/a&gt; &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dima11235813&quot;&gt; /u/dima11235813 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1achbg7/has_anyone_found_an_example_of_coupling_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1achbg7/has_anyone_found_an_example_of_coupling_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1achbg7</id><link href="https://www.reddit.com/r/LangChain/comments/1achbg7/has_anyone_found_an_example_of_coupling_langchain/" /><updated>2024-01-27T18:25:11+00:00</updated><published>2024-01-27T18:25:11+00:00</published><title>Has anyone found an example of coupling LangChain with external URL requests?</title></entry><entry><author><name>/u/cambridgecoder415</name><uri>https://www.reddit.com/user/cambridgecoder415</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;from langchain.chains import RetrievalQA from langchain.chat_models import ChatOpenAI from langchain.document_loaders import CSVLoader from langchain.vectorstores import DocArrayInMemorySearch from IPython.display import display, Markdown from langchain.llms import OpenAI file = &amp;#39;OutdoorClothingCatalog_1000.csv&amp;#39; loader = CSVLoader(file_path=file) print(loader) from langchain.indexes import VectorstoreIndexCreator index = VectorstoreIndexCreator( vectorstore_cls=DocArrayInMemorySearch ).from_loaders([loader]) query =&amp;quot;Please list all your shirts with sun protection \ in a table in markdown and summarize each one.&amp;quot; from langchain_openai import ChatOpenAI model_name = &amp;#39;gpt-3.5-turbo-instruct&amp;#39; llm_replacement_model = ChatOpenAI(temperature=0.0, model=model_name, openai_api_key=openai.api_key) response = index.query(query, llm=llm_replacement_model &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;--------------------------------------------------------------------------- ValidationError Traceback (most recent call last) Cell In[22], line 5 3 model_name = &amp;#39;gpt-3.5-turbo-instruct&amp;#39; 4 llm_replacement_model = ChatOpenAI(temperature=0.0, model=model_name, openai_api_key=openai.api_key) ----&amp;gt; 5 response = index.query(query, llm=llm_replacement_model) File ~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/langchain/indexes/vectorstore.py:46, in VectorStoreIndexWrapper.query(self, question, llm, retriever_kwargs, **kwargs) 42 retriever_kwargs = retriever_kwargs or {} 43 chain = RetrievalQA.from_chain_type( 44 llm, retriever=self.vectorstore.as_retriever(**retriever_kwargs), **kwargs 45 ) ---&amp;gt; 46 return chain.run(question) File ~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:145, in deprecated.&amp;lt;locals&amp;gt;.deprecate.&amp;lt;locals&amp;gt;.warning_emitting_wrapper(*args, **kwargs) 143 warned = True 144 emit_warning() --&amp;gt; 145 return wrapped(*args, **kwargs) File ~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/langchain/chains/base.py:538, in Chain.run(self, callbacks, tags, metadata, *args, **kwargs) 536 if len(args) != 1: 537 raise ValueError(&amp;quot;`run` supports only one positional argument.&amp;quot;) --&amp;gt; 538 return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[ 539 _output_key 540 ] ... Field required [type=missing, input_value={&amp;#39;embedding&amp;#39;: [0.00682570..., -0.02392816262769903]}, input_type=dict] For further information visit https://errors.pydantic.dev/2.5/v/missing metadata Field required [type=missing, input_value={&amp;#39;embedding&amp;#39;: [0.00682570..., -0.02392816262769903]}, input_type=dict] For further information visit https://errors.pydantic.dev/2.5/v/missing &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Help, this is from a course I&amp;#39;m taking on Deep learning&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cambridgecoder415&quot;&gt; /u/cambridgecoder415 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aceuxq/query_csv_code_not_working_help/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aceuxq/query_csv_code_not_working_help/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aceuxq</id><link href="https://www.reddit.com/r/LangChain/comments/1aceuxq/query_csv_code_not_working_help/" /><updated>2024-01-27T16:38:41+00:00</updated><published>2024-01-27T16:38:41+00:00</published><title>Query CSV code not working help!</title></entry><entry><author><name>/u/Dealwap1337</name><uri>https://www.reddit.com/user/Dealwap1337</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How can I ensure that the order of extracted documents in Langchain is maintained? I have a RAG app that allows users to query documents, but I&amp;#39;ve noticed that some numbered data is extracted in the wrong order. &lt;/p&gt; &lt;p&gt;For example, the documents may contain numbered items from 1 to 50, but when the final result is returned, the 2nd item may appear last and the 50th item may appear first. I need to maintain the same order as it appears in the original document.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Dealwap1337&quot;&gt; /u/Dealwap1337 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ac80ys/how_to_maintain_extracted_document_order/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ac80ys/how_to_maintain_extracted_document_order/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ac80ys</id><link href="https://www.reddit.com/r/LangChain/comments/1ac80ys/how_to_maintain_extracted_document_order/" /><updated>2024-01-27T10:31:31+00:00</updated><published>2024-01-27T10:31:31+00:00</published><title>How to Maintain extracted Document Order</title></entry><entry><author><name>/u/Ill_Bodybuilder3499</name><uri>https://www.reddit.com/user/Ill_Bodybuilder3499</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;JinaAi just released an Embeddingmodel with a context size of 8k. I was wondering what are the advantages of Long Context Embedding models for a Rag Use Case?&lt;/p&gt; &lt;p&gt;Happy for discussion!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ill_Bodybuilder3499&quot;&gt; /u/Ill_Bodybuilder3499 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ac7t19/what_ist_the_advantage_of_long_context_embedding/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ac7t19/what_ist_the_advantage_of_long_context_embedding/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ac7t19</id><link href="https://www.reddit.com/r/LangChain/comments/1ac7t19/what_ist_the_advantage_of_long_context_embedding/" /><updated>2024-01-27T10:16:10+00:00</updated><published>2024-01-27T10:16:10+00:00</published><title>What ist the advantage of Long Context Embedding Models for Rag</title></entry><entry><author><name>/u/Datenschieber</name><uri>https://www.reddit.com/user/Datenschieber</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am a noob experimenting with LLMs and i am looking for a reliable method for merging / combining two texts into one credible sounding merged text. Does that take a langchain based RAG or am i simply too stupid to engineer the right prompt in a mixtral or something similar? :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Datenschieber&quot;&gt; /u/Datenschieber &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acbcqn/how_do_i_merge_combine_two_texts_into_one/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acbcqn/how_do_i_merge_combine_two_texts_into_one/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acbcqn</id><link href="https://www.reddit.com/r/LangChain/comments/1acbcqn/how_do_i_merge_combine_two_texts_into_one/" /><updated>2024-01-27T13:55:58+00:00</updated><published>2024-01-27T13:55:58+00:00</published><title>How do i merge / combine two texts into one?</title></entry></feed>