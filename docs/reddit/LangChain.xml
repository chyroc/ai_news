<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-03-22T14:19:36+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Fit-Set6851</name><uri>https://www.reddit.com/user/Fit-Set6851</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;If I have 100 documents in my vector db. In the metadata t are total of 5 sources and each source have 20 documents in the vector db. &lt;/p&gt; &lt;p&gt;So now as query is given by the user I want to process relevant documents of each source separately and then combine the answers. &lt;/p&gt; &lt;p&gt;Can somebody help me on how to do this in an optimized way? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fit-Set6851&quot;&gt; /u/Fit-Set6851 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkysyf/how_to_process_each_source_in_vector_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkysyf/how_to_process_each_source_in_vector_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkysyf</id><link href="https://www.reddit.com/r/LangChain/comments/1bkysyf/how_to_process_each_source_in_vector_db/" /><updated>2024-03-22T13:07:15+00:00</updated><published>2024-03-22T13:07:15+00:00</published><title>How to process each source in Vector db individually ?</title></entry><entry><author><name>/u/heisenberg-principle</name><uri>https://www.reddit.com/user/heisenberg-principle</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Couldn&amp;#39;t find any other post on this topic but I&amp;#39;m having an issue with langchain_mistralai library. We&amp;#39;re using weaviate_client 4.5.4 which requires httpx version 0.27.0. However langchain_mistralai is not compatible with httpx versions &amp;gt; 0.26.0. Will this be fixed at some point or should I give up and find a workaround? (downgrading weaviate_client is not an option, since it has needed functionalities which can&amp;#39;t be sacrificed XD)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/heisenberg-principle&quot;&gt; /u/heisenberg-principle &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkxdyu/dependency_issues_when_adding_langchain_mistralai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkxdyu/dependency_issues_when_adding_langchain_mistralai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkxdyu</id><link href="https://www.reddit.com/r/LangChain/comments/1bkxdyu/dependency_issues_when_adding_langchain_mistralai/" /><updated>2024-03-22T11:51:14+00:00</updated><published>2024-03-22T11:51:14+00:00</published><title>Dependency issues when adding langchain_mistralai to the project dependencies</title></entry><entry><author><name>/u/Putrid_Spinach3961</name><uri>https://www.reddit.com/user/Putrid_Spinach3961</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey i am getting this error:&lt;/p&gt; &lt;p&gt;openai.NotFoundError: Error code: 404 - {&amp;#39;error&amp;#39;:{&amp;#39;code&amp;#39;:&amp;#39;404&amp;#39;, &amp;#39;message&amp;#39;: &amp;#39;Resource not found&amp;#39;}}&lt;/p&gt; &lt;p&gt;I used: From langchain_community.llms import OpenAI&lt;/p&gt; &lt;p&gt;From langchain.chains import LLMChain&lt;/p&gt; &lt;p&gt;Code: llm= OpenAI(model_name=&amp;quot;modelname&amp;quot;)&lt;/p&gt; &lt;p&gt;Output=LLMChain(prompt=prompt, llm=llm).run(&amp;#39;query&amp;#39;)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Putrid_Spinach3961&quot;&gt; /u/Putrid_Spinach3961 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkxck3/why_this_error/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkxck3/why_this_error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkxck3</id><link href="https://www.reddit.com/r/LangChain/comments/1bkxck3/why_this_error/" /><updated>2024-03-22T11:49:06+00:00</updated><published>2024-03-22T11:49:06+00:00</published><title>Why this error?</title></entry><entry><author><name>/u/s8ntinel69</name><uri>https://www.reddit.com/user/s8ntinel69</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkwdjn/why_is_my_chaininvoke_command_giving_the_full/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/tkmq7LaPtW_OrBODlSdRs4PFlx5mNx5A-oAsIBwbBhQ.jpg&quot; alt=&quot;Why is my chain.invoke({}) command giving the full model response instead of just AIMessage(content=' ')&quot; title=&quot;Why is my chain.invoke({}) command giving the full model response instead of just AIMessage(content=' ')&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using ChatVertexAI and the ChatPromptTemplate to provide the model with a system message, and a user message, both of which are stored in separate variables which return a string. &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/6raj796a7vpc1.png?width=831&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=61b9af92cc549d82da840310606772c3d3d0c51e&quot;&gt;Prompt template&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The chain uses LCEL to define the chain for the invoke command &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/1ud0215i7vpc1.png?width=847&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=604c30b0fdf719ff723c86abda5757ccd1146613&quot;&gt;The chain and invoke command&lt;/a&gt;&lt;/p&gt; &lt;p&gt;However, the output that I get includes details that I should get if the command was chain.generate() and not chain.invoke(). It should not include all of the response metadata that is being printed here. &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/vzocmpoy7vpc1.png?width=1103&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3890c438dfef3a70cb5801c820380236a7a62435&quot;&gt;https://preview.redd.it/vzocmpoy7vpc1.png?width=1103&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3890c438dfef3a70cb5801c820380236a7a62435&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Should&amp;#39;nt the output contain only AIMessage(content=&amp;#39;.........&amp;#39;) and not anything else? I Know I can use definition.content in this case, but in reality I cannot use that as this output is going to be used by langgraph for creating a reflection agent, in which I need to use the output like it is. &lt;/p&gt; &lt;p&gt;I checked all documentation and my prompt template as well the call to the LLM is exactly as it should be, but in the examples they show, the chain.invoke command should not print response metadata.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/s8ntinel69&quot;&gt; /u/s8ntinel69 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkwdjn/why_is_my_chaininvoke_command_giving_the_full/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkwdjn/why_is_my_chaininvoke_command_giving_the_full/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1bkwdjn</id><media:thumbnail url="https://b.thumbs.redditmedia.com/tkmq7LaPtW_OrBODlSdRs4PFlx5mNx5A-oAsIBwbBhQ.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1bkwdjn/why_is_my_chaininvoke_command_giving_the_full/" /><updated>2024-03-22T10:50:34+00:00</updated><published>2024-03-22T10:50:34+00:00</published><title>Why is my chain.invoke({}) command giving the full model response instead of just AIMessage(content=' ')</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What are some challenges you face after deploying your LLM based application in production? &lt;/p&gt; &lt;p&gt;My only goal is to improve the accuracy of my chatbot. It seems like everything boils down to this unless there are any other special usecases you are using the LLMs for. Basically. I try to monitor for all the responses of my chatbot and measure them objectively so I can tweak and improve the accuracy. This seems pretty basic. But, what are some of the other levers that I can pull to improve the accuracy of my RAG based chat application?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I am also building a tooling for tracing and monitoring the responses with higher cardinality compared to the ones that are in the market. Plan to open source it pretty soon.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bklgf7/daily_struggles_with_my_llm_based_chatbot_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bklgf7/daily_struggles_with_my_llm_based_chatbot_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bklgf7</id><link href="https://www.reddit.com/r/LangChain/comments/1bklgf7/daily_struggles_with_my_llm_based_chatbot_in/" /><updated>2024-03-21T23:53:39+00:00</updated><published>2024-03-21T23:53:39+00:00</published><title>Daily struggles with my LLM based chatbot in production</title></entry><entry><author><name>/u/BichonFrise_</name><uri>https://www.reddit.com/user/BichonFrise_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;[New in my AI agent journey]&lt;/p&gt; &lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;As I mentionned in the title of this post, I&amp;#39;m wondering if Langchain is the best framework to build AI agents that are able to retrieve information online. &lt;/p&gt; &lt;p&gt;I&amp;#39;ll give you one example : &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Step 1 :I would like to give my agent a list of website and ask them if this company is a B2C company or a B2B company.&lt;/li&gt; &lt;li&gt;Step 2 : Chain this agent to another : if it&amp;#39;s a B2B company find the pricing&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Is is possible to do so with Langchain ? &lt;/p&gt; &lt;p&gt;If yes, do you know where I could find a tutorial to get me started ?&lt;/p&gt; &lt;p&gt;If not what is the best framework out there ? I saw &lt;a href=&quot;https://github.com/joaomdmoura/crewai/&quot;&gt;https://github.com/joaomdmoura/crewai/&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://superagent.sh&quot;&gt;superagent.sh&lt;/a&gt; but I&amp;#39;m not sure if these are exactly what I&amp;#39;m looking for. &lt;/p&gt; &lt;p&gt;Thanks for your help ! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BichonFrise_&quot;&gt; /u/BichonFrise_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bktz0j/how_to_build_ai_agents_for_information_retrieval/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bktz0j/how_to_build_ai_agents_for_information_retrieval/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bktz0j</id><link href="https://www.reddit.com/r/LangChain/comments/1bktz0j/how_to_build_ai_agents_for_information_retrieval/" /><updated>2024-03-22T08:00:15+00:00</updated><published>2024-03-22T08:00:15+00:00</published><title>How to build AI agents for information retrieval online</title></entry><entry><author><name>/u/o3omoomin</name><uri>https://www.reddit.com/user/o3omoomin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I wrote this after looking at the Ensemble Retriever docs.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://docs.llamaindex.ai/en/stable/examples/retrievers/ensemble_retrieval/&quot;&gt;https://docs.llamaindex.ai/en/stable/examples/retrievers/ensemble_retrieval/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;And can you explain the code for the evaluation part in detail with comments? A post is happening, but I don&amp;#39;t know what it is. Below is the evaluation code&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from llama_index.core.evaluation import ( CorrectnessEvaluator, SemanticSimilarityEvaluator, RelevancyEvaluator, FaithfulnessEvaluator, PairwiseComparisonEvaluator, ) from llama_index.core.evaluation.eval_utils import ( get_responses; get_results_df; ) from llama_index.core.evaluation import BatchEvalRunner import numpy as np evaluator_c = CorrectnessEvaluator(llm=eval_llm) evaluator_s = SemanticSimilarityEvaluator() evaluator_r = RelevancyEvaluator(llm=eval_llm) evaluator_f = FaithfulnessEvaluator(llm=eval_llm) pairwise_evaluator = PairwiseComparisonEvaluator(llm=eval_llm) max_samples = 5 eval_qs = eval_dataset.questions qr_pairs = eval_dataset.qr_pairs ref_response_strs = [r for (_, r) in qr_pairs] base_query_engine = vector_indices[-1].as_query_engine(similarity_top_k=2) query_engine = RetrieverQueryEngine(retriever, node_postprocessors=[reranker]) base_pred_responses = get_responses( eval_qs[:max_samples], base_query_engine, show_progress=True ) pred_responses = get_responses( eval_qs[:max_samples], query_engine, show_progress=True ) sponse_strs = [str(p) for p in pred_responses] base_pred_response_strs = [str(p) for p in base_pred_responses] evaluator_dict = { &amp;quot;correctness&amp;quot;: evaluator_c, &amp;quot;faithfulness&amp;quot;: evaluator_f, &amp;quot;semantic_similarity&amp;quot;: evaluator_s, } batch_runner = BatchEvalRunner(evaluator_dict, workers=1, show_progress=True) eval_results = await batch_runner. evaluate_responses( queries=eval_qs[:max_samples], responses=pred_responses[:max_samples], reference=ref_response_strs[:max_samples], ) base_eval_results = await batch_runner.aevaluate_responses( queries=eval_qs[:max_samples], responses=base_pred_responses[:max_samples], reference=ref_response_strs[:max_samples], ) results_df = get_results_df( [eval_results, base_eval_results], [&amp;quot;Ensemble Retriever&amp;quot;, &amp;quot;Base Retriever&amp;quot;], [&amp;quot;correctness&amp;quot;, &amp;quot;faithfulness&amp;quot;, &amp;quot;semantic_similarity&amp;quot;], ) display(results_df) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/o3omoomin&quot;&gt; /u/o3omoomin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bktatx/please_explain_the_logic_behind_the_evaluation_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bktatx/please_explain_the_logic_behind_the_evaluation_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bktatx</id><link href="https://www.reddit.com/r/LangChain/comments/1bktatx/please_explain_the_logic_behind_the_evaluation_of/" /><updated>2024-03-22T07:09:51+00:00</updated><published>2024-03-22T07:09:51+00:00</published><title>Please explain the logic behind the evaluation of the llama index.</title></entry><entry><author><name>/u/rpatel09</name><uri>https://www.reddit.com/user/rpatel09</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking to build a RAG app on our github repositories but wanted to ask if anyone has done something like this and what chunking strategies worked and didn&amp;#39;t work. I&amp;#39;ve been looking at semantic chunking but unsure how this would work with code? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rpatel09&quot;&gt; /u/rpatel09 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkkqel/chunking_strategies_for_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkkqel/chunking_strategies_for_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkkqel</id><link href="https://www.reddit.com/r/LangChain/comments/1bkkqel/chunking_strategies_for_code/" /><updated>2024-03-21T23:21:06+00:00</updated><published>2024-03-21T23:21:06+00:00</published><title>chunking strategies for code?</title></entry><entry><author><name>/u/The-Tank-849</name><uri>https://www.reddit.com/user/The-Tank-849</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Any of you are happy and have almost perfect result either their LLM chatbots with business data? Happy to discuss&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/The-Tank-849&quot;&gt; /u/The-Tank-849 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkmo3b/chatbot_in_production/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkmo3b/chatbot_in_production/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkmo3b</id><link href="https://www.reddit.com/r/LangChain/comments/1bkmo3b/chatbot_in_production/" /><updated>2024-03-22T00:49:45+00:00</updated><published>2024-03-22T00:49:45+00:00</published><title>Chatbot in production</title></entry><entry><author><name>/u/internetcookiez</name><uri>https://www.reddit.com/user/internetcookiez</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a ChromaDB database which I can query information about a specific data, however, this data also has numerical data that I would like to transform into a SQL database, in .db form.&lt;/p&gt; &lt;p&gt;However, I want to be able to infer whether the LLM should call the vector db, and go through a ChromaDB chain for the answer, or go through an SQL chain. &lt;/p&gt; &lt;p&gt;How can I make this happen, automatically as the user asks questions? Basically, how can I create an agent that can determine which one to run?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/internetcookiez&quot;&gt; /u/internetcookiez &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkqww1/how_can_i_combine_chromadb_and_sql_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkqww1/how_can_i_combine_chromadb_and_sql_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkqww1</id><link href="https://www.reddit.com/r/LangChain/comments/1bkqww1/how_can_i_combine_chromadb_and_sql_in_langchain/" /><updated>2024-03-22T04:29:18+00:00</updated><published>2024-03-22T04:29:18+00:00</published><title>How can I combine ChromaDB and SQL in langchain?</title></entry><entry><author><name>/u/FigureClassic6675</name><uri>https://www.reddit.com/user/FigureClassic6675</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FigureClassic6675&quot;&gt; /u/FigureClassic6675 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkp8fv/how_to_create_lead_capture_chatbot_with_function/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkp8fv/how_to_create_lead_capture_chatbot_with_function/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkp8fv</id><link href="https://www.reddit.com/r/LangChain/comments/1bkp8fv/how_to_create_lead_capture_chatbot_with_function/" /><updated>2024-03-22T02:57:18+00:00</updated><published>2024-03-22T02:57:18+00:00</published><title>How to create lead capture chatbot with function calling feature</title></entry><entry><author><name>/u/zkid18</name><uri>https://www.reddit.com/user/zkid18</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks,&lt;br/&gt; I am in the process of building my first custom GPT and have some questions regarding how to work properly with multimodal data. Let me explain what I am trying to achieve.&lt;br/&gt; I am creating a helper tool that will assist me in analyzing various pricing strategies of different SaaS tools. I have a dataset of 100k SaaS companies that have been labeled in some way, so I can cluster them based on their industry, category, etc.&lt;/p&gt; &lt;p&gt;Here is what I have as an input for my GPT so far:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;I have collected screenshots of their pricing pages, which are stored in S3.&lt;/li&gt; &lt;li&gt;I have collected the HTML for the pricing pages, which is stored in MongoDB.&lt;/li&gt; &lt;li&gt;I have a table of the companies with enriched data.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I would like to build RAG on top of these documents, but I am a bit concerned about the next steps. My plan is to start with a simple one and use LlamaIndex. Here are the steps I have in mind:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Connect the data to the LlamaHub and pick the proper database. I want to keep the connection between the three mediums. and thus, I am not sure which database is best for my case. Should I use a vector database, graph database, or key-value database here?&lt;/li&gt; &lt;li&gt;Query the data and come up with evaluation metrics based on expert knowledge.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I have some questions along the way:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Should I parse the data from the screenshots and HTML structure beforehand, or can I put it into storage as it is? Will it help with the quality of RAG?&lt;/li&gt; &lt;/ol&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zkid18&quot;&gt; /u/zkid18 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkhdqe/need_advice_for_structuring_multimodal_data_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkhdqe/need_advice_for_structuring_multimodal_data_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkhdqe</id><link href="https://www.reddit.com/r/LangChain/comments/1bkhdqe/need_advice_for_structuring_multimodal_data_for/" /><updated>2024-03-21T21:02:22+00:00</updated><published>2024-03-21T21:02:22+00:00</published><title>Need advice for structuring multimodal data for RAG</title></entry><entry><author><name>/u/Obvious-Ad2752</name><uri>https://www.reddit.com/user/Obvious-Ad2752</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Does LangChain for Node.js offer the same level of functionality as its Python counterpart when it comes to functions and features? &lt;/p&gt; &lt;p&gt;If not, is there an alternative framework ?&lt;/p&gt; &lt;p&gt;Context : I am familiar with Node.js. I am looking to interact with an LLM for text extraction, NER, and coherence. I aim to take the response to create nodes, relationships, and labels in a Neo4j graph database.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Obvious-Ad2752&quot;&gt; /u/Obvious-Ad2752 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkg3bg/langchain_functionality_in_nodejs_and_python_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkg3bg/langchain_functionality_in_nodejs_and_python_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkg3bg</id><link href="https://www.reddit.com/r/LangChain/comments/1bkg3bg/langchain_functionality_in_nodejs_and_python_for/" /><updated>2024-03-21T20:09:50+00:00</updated><published>2024-03-21T20:09:50+00:00</published><title>LangChain Functionality in Node.js and Python for Text Processing</title></entry><entry><author><name>/u/BossHoggHazzard</name><uri>https://www.reddit.com/user/BossHoggHazzard</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We know 3-large has a 8191 token context window. I have text articles that are anywhere from 2500-4500 tokens each. Is there any advantage to chunking these? Or will I lose some of the context splitting articles into pieces?&lt;/p&gt; &lt;p&gt;Is it better to just get embeddings on whole articles or is it still a good idea to split them up into paragraphs? Or both? Feed it whole articles and paragraphs?&lt;/p&gt; &lt;p&gt;Thanks in advance for your insight.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BossHoggHazzard&quot;&gt; /u/BossHoggHazzard &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkh8wq/textembedding3large_chunking_question_for_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkh8wq/textembedding3large_chunking_question_for_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkh8wq</id><link href="https://www.reddit.com/r/LangChain/comments/1bkh8wq/textembedding3large_chunking_question_for_rag/" /><updated>2024-03-21T20:57:09+00:00</updated><published>2024-03-21T20:57:09+00:00</published><title>text-embedding-3-large chunking question for RAG</title></entry><entry><author><name>/u/halixness</name><uri>https://www.reddit.com/user/halixness</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi. I’m testing a variety of LLaMa2 7b and 13b (Hermes2Pro, MistralInstruct0.2, Chat, Solar10) as base for the React agent, but I can’t get outputs consistently as I’m encountering these issues:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;After providing the final answer, the LLM keeps running other actions and it gets off track with eg. Non relevant questions or even random programming code.&lt;/li&gt; &lt;li&gt;Sometimes it calls the tools incorrectly, especially if I switch to the structured chat agent (non existing arguments or swapped args between functions).&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;What I’m guessing is that I need larger models. I would appreciate someone else’s experience and takes on this. Thank you very much!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/halixness&quot;&gt; /u/halixness &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkb1kc/suggestions_on_working_agents_and_base_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkb1kc/suggestions_on_working_agents_and_base_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkb1kc</id><link href="https://www.reddit.com/r/LangChain/comments/1bkb1kc/suggestions_on_working_agents_and_base_llms/" /><updated>2024-03-21T16:44:08+00:00</updated><published>2024-03-21T16:44:08+00:00</published><title>Suggestions on working agents and base LLMs?</title></entry><entry><author><name>/u/No_Donut_5349</name><uri>https://www.reddit.com/user/No_Donut_5349</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building a software application. I want to use a LLM as the basis. I will finetune the model with about 20,000 pages of legal text. Specifically laws all around the country. I will then use the trained model to answer help companies create compliant products and services. At the moment I am unsure as to the best way to go about it. My initial thought was to use gpt 3.5 and then further train it with the 20,000 pages of text. The text will be broken down by state and federal agencies. This text will be added to as new laws and regulations are passed.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;The goal is for the model to only answer based on the data set it&amp;#39;s finetuned with. The data will be broken down by state. For example if they want information about loan requirements, they will ask the system and it will return with an outline of the requirements for loans by state. It will respond in a way that&amp;#39;s easy to understand.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;My thinking is once I have all the data collected, using Langchain to fine tune the LLM. Am I on the right path here?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No_Donut_5349&quot;&gt; /u/No_Donut_5349 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bk8t5f/need_input_on_software_project/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bk8t5f/need_input_on_software_project/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bk8t5f</id><link href="https://www.reddit.com/r/LangChain/comments/1bk8t5f/need_input_on_software_project/" /><updated>2024-03-21T15:10:34+00:00</updated><published>2024-03-21T15:10:34+00:00</published><title>Need input on Software Project</title></entry><entry><author><name>/u/guidsen15</name><uri>https://www.reddit.com/user/guidsen15</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks!&lt;/p&gt; &lt;p&gt;I have been interested in AI for some time, but now the time has come for I want to create a self-browsing agent that answers a certain question.&lt;/p&gt; &lt;p&gt;Couple of examples:&lt;/p&gt; &lt;p&gt;1️⃣ Prompt: what is the company &lt;a href=&quot;https://www.segment.com&quot;&gt;www.segment.com&lt;/a&gt; about?&lt;/p&gt; &lt;p&gt;- Should execute a Google search&lt;br/&gt; - Navigate to the about-us page&lt;br/&gt; - Read the page and return the result&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;2️⃣ Prompt: what is the difference between &lt;a href=&quot;https://www.segment.com&quot;&gt;www.segment.com&lt;/a&gt; and &lt;a href=&quot;https://www.intercom.com&quot;&gt;www.intercom.com&lt;/a&gt;?&lt;/p&gt; &lt;p&gt;- Should split this into multiple tasks, doing something similar to the workflow above.&lt;br/&gt; - Returns a detailed comparison based on the scanned pages&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;What are the best ways of implementing this? Are there any open-source frameworks that I might get inspired by?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/guidsen15&quot;&gt; /u/guidsen15 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bk4v99/best_way_to_create_an_ai_browsing_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bk4v99/best_way_to_create_an_ai_browsing_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bk4v99</id><link href="https://www.reddit.com/r/LangChain/comments/1bk4v99/best_way_to_create_an_ai_browsing_agent/" /><updated>2024-03-21T12:00:36+00:00</updated><published>2024-03-21T12:00:36+00:00</published><title>Best way to create an AI browsing agent</title></entry><entry><author><name>/u/pratikkoti04</name><uri>https://www.reddit.com/user/pratikkoti04</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to build a LLM Chatbot that can follow a particular flow the one we build in intent based chatbot frameworks. I want the llm to collect some information from user based on it fetch some data handle fallback queries and it should not deviate from the flow handling multi turn conversations.Any idea or open source framework that does this? Basically I want to use RASA stories and feed it to LLM so that it can follow a particular conversational flow. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pratikkoti04&quot;&gt; /u/pratikkoti04 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkcllq/rule_based_llm_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bkcllq/rule_based_llm_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bkcllq</id><link href="https://www.reddit.com/r/LangChain/comments/1bkcllq/rule_based_llm_chatbot/" /><updated>2024-03-21T17:47:25+00:00</updated><published>2024-03-21T17:47:25+00:00</published><title>Rule Based LLM Chatbot</title></entry><entry><author><name>/u/ninja24x7</name><uri>https://www.reddit.com/user/ninja24x7</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am implementing RAG and trying to understand what&amp;#39;s the advantage of Overlapping.&lt;br/&gt; Consider this text:&lt;br/&gt; &lt;code&gt;&amp;quot;One of the most important things I didn&amp;#39;t understand about the world when I was a child is the degree to which the returns for performance are superlinear.&amp;quot;&lt;/code&gt;&lt;br/&gt; which is chunked and overlapped as using Naive or any strategy :&lt;br/&gt; &lt;code&gt;chunk 1 : One of the most important things&lt;/code&gt;&lt;br/&gt; &lt;code&gt;Chunk 2 : things I didn&amp;#39;t understand about&lt;/code&gt;&lt;br/&gt; &lt;code&gt;chunk 3: about the world when I was a child&lt;/code&gt;&lt;br/&gt; and so on..&lt;br/&gt; As you can see there is a word overlap with the chunks.&lt;br/&gt; What advantage does LLM get when you feed overlapping &lt;code&gt;chunk2&lt;/code&gt; and &lt;code&gt;chunk3&lt;/code&gt; to execute RAG prompt against a user query. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ninja24x7&quot;&gt; /u/ninja24x7 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjxvov/what_is_the_advantage_of_overlapping_in_chunking/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjxvov/what_is_the_advantage_of_overlapping_in_chunking/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bjxvov</id><link href="https://www.reddit.com/r/LangChain/comments/1bjxvov/what_is_the_advantage_of_overlapping_in_chunking/" /><updated>2024-03-21T04:12:54+00:00</updated><published>2024-03-21T04:12:54+00:00</published><title>what is the advantage of overlapping in chunking strategy</title></entry><entry><author><name>/u/XhoniShollaj</name><uri>https://www.reddit.com/user/XhoniShollaj</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone here succesfully deployed LangChain in production? If yes, what were the main issues enountered and how did you approach them?&lt;/p&gt; &lt;p&gt;If not, what alternatives did you use or considering (e.g. Haystack etc.) ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/XhoniShollaj&quot;&gt; /u/XhoniShollaj &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjxx32/langchain_in_production_alternatives/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjxx32/langchain_in_production_alternatives/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bjxx32</id><link href="https://www.reddit.com/r/LangChain/comments/1bjxx32/langchain_in_production_alternatives/" /><updated>2024-03-21T04:15:01+00:00</updated><published>2024-03-21T04:15:01+00:00</published><title>Langchain in Production (&amp; Alternatives)</title></entry><entry><author><name>/u/redditforgets</name><uri>https://www.reddit.com/user/redditforgets</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjlldg/got_the_accuracy_of_gpt4_function_calling_from_35/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/EVm_c1rJmIBCr6_4BoHQygB8rtJ_kZYrD-LWEoWIYPQ.jpg&quot; alt=&quot;Got the accuracy of GPT4 Function Calling from 35% to 75% by tweaking function definitions.&quot; title=&quot;Got the accuracy of GPT4 Function Calling from 35% to 75% by tweaking function definitions.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;ul&gt; &lt;li&gt;Adding function definitions in the system prompt of functions (Clickup&amp;#39;s API calls).&lt;/li&gt; &lt;li&gt;Flattening the Schema of the function&lt;/li&gt; &lt;li&gt;Adding system prompts&lt;/li&gt; &lt;li&gt;Adding function definitions in system prompt&lt;/li&gt; &lt;li&gt;Adding individual parameter examples&lt;/li&gt; &lt;li&gt;Adding function examples&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Wrote a nice blog with an &lt;a href=&quot;https://blog.composio.dev/improving-function-calling-accuracy-for-agentic-integrations/&quot;&gt;Indepth explanation&lt;/a&gt; here.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/rmxgt35zfjpc1.png?width=816&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=934eddf839e17f2324c590157943a92ebbdedffa&quot;&gt;https://preview.redd.it/rmxgt35zfjpc1.png?width=816&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=934eddf839e17f2324c590157943a92ebbdedffa&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/redditforgets&quot;&gt; /u/redditforgets &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjlldg/got_the_accuracy_of_gpt4_function_calling_from_35/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjlldg/got_the_accuracy_of_gpt4_function_calling_from_35/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1bjlldg</id><media:thumbnail url="https://b.thumbs.redditmedia.com/EVm_c1rJmIBCr6_4BoHQygB8rtJ_kZYrD-LWEoWIYPQ.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1bjlldg/got_the_accuracy_of_gpt4_function_calling_from_35/" /><updated>2024-03-20T19:10:44+00:00</updated><published>2024-03-20T19:10:44+00:00</published><title>Got the accuracy of GPT4 Function Calling from 35% to 75% by tweaking function definitions.</title></entry><entry><author><name>/u/Livid-Violinist-7652</name><uri>https://www.reddit.com/user/Livid-Violinist-7652</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a word doc and an excel file whose information is interconnected? The excel file outlines the process steps and the word file has process specifics. &lt;/p&gt; &lt;p&gt;I want to build a RAG by leveraging these two files to generate a document based on some prompts. What is the best strategy to do it?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Livid-Violinist-7652&quot;&gt; /u/Livid-Violinist-7652 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bk0kyo/how_to_build_a_rag_on_structed_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bk0kyo/how_to_build_a_rag_on_structed_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bk0kyo</id><link href="https://www.reddit.com/r/LangChain/comments/1bk0kyo/how_to_build_a_rag_on_structed_data/" /><updated>2024-03-21T07:06:27+00:00</updated><published>2024-03-21T07:06:27+00:00</published><title>How to build a RAG on structed data?</title></entry><entry><author><name>/u/Yintorion</name><uri>https://www.reddit.com/user/Yintorion</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have the biography of a fictional character. It is about 160 pages long. How do I create a chatbot of this character with memory using RAG? I am using Gemini btw. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Yintorion&quot;&gt; /u/Yintorion &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bk0bo3/creating_chatbot_of_characters_using_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bk0bo3/creating_chatbot_of_characters_using_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bk0bo3</id><link href="https://www.reddit.com/r/LangChain/comments/1bk0bo3/creating_chatbot_of_characters_using_rag/" /><updated>2024-03-21T06:48:41+00:00</updated><published>2024-03-21T06:48:41+00:00</published><title>Creating chatbot of characters using RAG</title></entry><entry><author><name>/u/Zealousideal-Fall705</name><uri>https://www.reddit.com/user/Zealousideal-Fall705</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’m a Ph.D. student who recently try to switch from hugging face to langchain. It feels like huggingface organize their libraries the research way (or the PyTorch way? It just feel like I can use them the same way I use research papers’ code), but langchain is more like something developed by JavaScript engineers and designed with no research user cases. &lt;/p&gt; &lt;p&gt;For example, all the “batch inference “ requirements on GitHub are ignored. The interface for customized functions (e.g., chat history post processing) are ill-designed. &lt;/p&gt; &lt;p&gt;I chose langchain in the beginning because the LLMs hosted by langchain responds faster than my local ones. But it seems that it’s really hard to customize the functionalities for research purposes.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zealousideal-Fall705&quot;&gt; /u/Zealousideal-Fall705 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjks1c/do_researchers_like_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjks1c/do_researchers_like_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bjks1c</id><link href="https://www.reddit.com/r/LangChain/comments/1bjks1c/do_researchers_like_langchain/" /><updated>2024-03-20T18:37:14+00:00</updated><published>2024-03-20T18:37:14+00:00</published><title>Do researchers like langchain?</title></entry><entry><author><name>/u/Forward-Tip8621</name><uri>https://www.reddit.com/user/Forward-Tip8621</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, was going through the search tools available via langchain. Just wanted to check which is the best one to use? What are the key aspects to consider other than cost? If anyone who has used/compared these APIs that would be a great value add to my research &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Forward-Tip8621&quot;&gt; /u/Forward-Tip8621 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjsx89/best_search_tool_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjsx89/best_search_tool_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bjsx89</id><link href="https://www.reddit.com/r/LangChain/comments/1bjsx89/best_search_tool_in_langchain/" /><updated>2024-03-21T00:13:03+00:00</updated><published>2024-03-21T00:13:03+00:00</published><title>Best Search Tool in Langchain</title></entry></feed>