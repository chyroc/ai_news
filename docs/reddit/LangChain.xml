<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-16T10:48:45+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Trick-Asparagus-9260</name><uri>https://www.reddit.com/user/Trick-Asparagus-9260</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for ways to effectively chunk csv/excel files. In a meaningful manner. I looked into loaders but they have unstructuredCSV/Excel Loaders which are nothing but from Unstructured. Is there something in Langchain that I can use to chunk these formats meaningfully for my RAG?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Trick-Asparagus-9260&quot;&gt; /u/Trick-Asparagus-9260 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct97ix/how_to_effectively_chunk_csv_and_xlsx_files_excel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct97ix/how_to_effectively_chunk_csv_and_xlsx_files_excel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ct97ix</id><link href="https://www.reddit.com/r/LangChain/comments/1ct97ix/how_to_effectively_chunk_csv_and_xlsx_files_excel/" /><updated>2024-05-16T09:50:33+00:00</updated><published>2024-05-16T09:50:33+00:00</published><title>How to effectively chunk csv and xlsx files? Excel file can contain text/tables.</title></entry><entry><author><name>/u/Longjumping-Buddy501</name><uri>https://www.reddit.com/user/Longjumping-Buddy501</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;After having worked with Anthropic API and Gemini 1.5 Pro &amp;amp; Flash APIs. OpenAI API seems to be the only reliable API service available.&lt;br/&gt; With Anthropic - I am unable to add credits to their console, even after multiple mails to the customer support I have received no resolution. So I finally have to give up hope and just use Open AI.&lt;br/&gt; With Google Gemini - The APIs are absolutely unreliable, you are not sure when the APIs will return an answer and when they will not. I keep encountering error from the API something like: StopCandidateException: finish_reason: RECITATION&lt;br/&gt; So again no point in using Gemini, just switch to Open AI.&lt;/p&gt; &lt;p&gt;Hoping this experience will benefit the community.&lt;/p&gt; &lt;p&gt;Anyone else having these issues.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Longjumping-Buddy501&quot;&gt; /u/Longjumping-Buddy501 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrtc3/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrtc3/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csrtc3</id><link href="https://www.reddit.com/r/LangChain/comments/1csrtc3/open_ai_apis_are_the_only_reliable_apis_in/" /><updated>2024-05-15T18:21:45+00:00</updated><published>2024-05-15T18:21:45+00:00</published><title>Open AI APIs are the only reliable APIs in production</title></entry><entry><author><name>/u/Such-Maintenance9199</name><uri>https://www.reddit.com/user/Such-Maintenance9199</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i need a suggestion on a situation at work.&lt;/p&gt; &lt;p&gt;I am writing code for an application. i have 2 options, that is, either choose an existing python framework that is available in the market or write my own python code.&lt;/p&gt; &lt;p&gt;Existing framework: LangChain, LlamaIndex&lt;/p&gt; &lt;p&gt;Pros:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;used a lot outside in the market. just in case if i want to shift another company. i can easily adapt and can earn more money&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;I can create Agents (AI) with little ease as i dont have to implement everything from scratch (usually research work and strategies are implemented in this framework). implementing features becomes faster&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;as knowledge workers are more aware of this framework - hiring them and getting them to understand the code becomes easy &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Cons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt; So many abstractions in this framework and i fully dont understand it. few months back i tried to use this framework and i couldn&amp;#39;t customize it for our situation. I am worried if i use this and make some progress and later realize that it is not customizable. i will be screwed. lot of work will be wasted.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Own Code:&lt;/p&gt; &lt;p&gt;Pros:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;i can implement all the functionalities by myself. i can design code base and write everything from scratch. this skill is valued in lot of places especially in startups as you have literally implemented lot of things from scratch. this way i can get a hang over the language and my skill improves drastically&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;i get to do research and implement them with my own code.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;i can customize it for my specific scenario&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;the company will have a lot of dependency on me &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Cons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;lot of work&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;development might not be as fast paced as i would have liked it to be.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;i might get stuck and not find any solution as i am the only person available who has knowledge on this in this company.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Any suggestions are appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Such-Maintenance9199&quot;&gt; /u/Such-Maintenance9199 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cstpmx/llm_orchestration_framework_or_own_python_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cstpmx/llm_orchestration_framework_or_own_python_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cstpmx</id><link href="https://www.reddit.com/r/LangChain/comments/1cstpmx/llm_orchestration_framework_or_own_python_code/" /><updated>2024-05-15T19:38:46+00:00</updated><published>2024-05-15T19:38:46+00:00</published><title>LLM Orchestration framework or own python code, which is better?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1ct1sja/creating_proxy_server_for_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct1thu/creating_proxy_server_for_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ct1thu</id><link href="https://www.reddit.com/r/LangChain/comments/1ct1thu/creating_proxy_server_for_llms/" /><updated>2024-05-16T01:50:35+00:00</updated><published>2024-05-16T01:50:35+00:00</published><title>Creating proxy server for llms</title></entry><entry><author><name>/u/Longjumping-Buddy501</name><uri>https://www.reddit.com/user/Longjumping-Buddy501</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;After having worked with Anthropic API and Gemini 1.5 Pro &amp;amp; Flash APIs. OpenAI API seems to be the only reliable API service available.&lt;br/&gt; With Anthropic - I am unable to add credits to their console, even after multiple mails to the customer support I have received no resolution. So I finally have to give up hope and just use Open AI.&lt;br/&gt; With Google Gemini - The APIs are absolutely unreliable, you are not sure when the APIs will return an answer and when they will not. I keep encountering error from the API something like: StopCandidateException: finish_reason: RECITATION&lt;br/&gt; So again no point in using Gemini, just switch to Open AI.&lt;/p&gt; &lt;p&gt;Hoping this experience will benefit the community.&lt;/p&gt; &lt;p&gt;Anyone else having these issues.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Longjumping-Buddy501&quot;&gt; /u/Longjumping-Buddy501 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrta9/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrta9/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csrta9</id><link href="https://www.reddit.com/r/LangChain/comments/1csrta9/open_ai_apis_are_the_only_reliable_apis_in/" /><updated>2024-05-15T18:21:41+00:00</updated><published>2024-05-15T18:21:41+00:00</published><title>Open AI APIs are the only reliable APIs in production</title></entry><entry><author><name>/u/hesitantelephant</name><uri>https://www.reddit.com/user/hesitantelephant</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;TLDR: I made a platform to make it easy to switch between LLMs, find the best one for your specific needs, analyze their performance, and test different providers in production. Check it out at&lt;/strong&gt; &lt;a href=&quot;https://optimix.app/?lang&quot;&gt;&lt;strong&gt;optimix.app&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Figuring out whether or not you should switch to Llama 3, Gemini 1.5 Flash, or GPT-4o can be hard. And knowing if the prompt change you just made will be good or bad is even harder.&lt;/p&gt; &lt;p&gt;A key focus of Optimix is to make experimentation easy. You can run A/B tests and other experiments to figure out how your changes impacted your core metrics like cost, speed, and user satisfaction. You can also test and compare different models in our playground and make requests through our API.&lt;/p&gt; &lt;p&gt;It also dynamically selects the most suitable model for each request, and helps manage fallbacks for outages and rate limits. Facing an OpenAI outage? Switch to Llama 3. Need superior coding assistance? We can auto switch you to the best one.&lt;/p&gt; &lt;p&gt;I&amp;#39;d love any feedback or suggestions on the platform, and hope this can be helpful for you all with all the new models coming out!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hesitantelephant&quot;&gt; /u/hesitantelephant &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct4m4z/experiment_and_test_the_reliability_of_different/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct4m4z/experiment_and_test_the_reliability_of_different/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ct4m4z</id><link href="https://www.reddit.com/r/LangChain/comments/1ct4m4z/experiment_and_test_the_reliability_of_different/" /><updated>2024-05-16T04:23:44+00:00</updated><published>2024-05-16T04:23:44+00:00</published><title>Experiment and test the reliability of different LLMs in prod and pre-prod!</title></entry><entry><author><name>/u/dominik-reinert-dev</name><uri>https://www.reddit.com/user/dominik-reinert-dev</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am currently working on a project where I need to fill documents (CSV files) according to requirements in a big compendium (800+ pages PDF).&lt;/p&gt; &lt;p&gt;for example:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;context: &lt;ul&gt; &lt;li&gt;the PDF compendium of 800 pages with instructions and detailed legal requirements to be met when implementing infrastructure projects in IT sector&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;CSV file: &lt;ul&gt; &lt;li&gt;a checklist-style CSV file containing the short name of the subject from the PDF compendium and columns to input things to be checked and processed by a person (or in this case: AI)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th align=&quot;left&quot;&gt;Subject&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;Responsible&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;Price&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;Risks&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;A.1.1.&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;Author of this file&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;$20.000&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;If not done, we are doomed&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;ul&gt; &lt;li&gt;Prompt &lt;ul&gt; &lt;li&gt;&amp;quot;I want to add a exchange a router in Building C3.&amp;quot;&lt;/li&gt; &lt;li&gt;&amp;quot;I want to add a gitlab server to our network&amp;quot;&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In both cases, the output should be a CSV file or CSV text .&lt;/p&gt; &lt;p&gt;&lt;strong&gt;These are the models im using (and liking):&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;model: wizardlm2:7b&lt;/li&gt; &lt;li&gt;embedding model: mxbai-embed-large&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;What I have done so far&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;reading in the pdf files&lt;/li&gt; &lt;li&gt;embedding the pdf files&lt;/li&gt; &lt;li&gt;reading in the csv file&lt;/li&gt; &lt;li&gt;embedding the csv file (&amp;lt;- is this correct?)&lt;/li&gt; &lt;li&gt;created a prompt&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;```&lt;br/&gt; Fill the csv file in the context with valuable data found in the embeddings according to the question.&lt;/p&gt; &lt;p&gt;Do not guess, do not add anything. Use only the context.&lt;/p&gt; &lt;p&gt;{context}&lt;/p&gt; &lt;p&gt;Question: {input}&lt;/p&gt; &lt;p&gt;```&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What is not working. AKA: What is my question?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The output the model is giving me is unstructured and has nothing to do with the CSV file I put into the context.&lt;/p&gt; &lt;p&gt;Is there a way that I can make the AI&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Read in PDFs&lt;/li&gt; &lt;li&gt;Read in CSV&lt;/li&gt; &lt;li&gt;Listen to the prompt&lt;/li&gt; &lt;li&gt;Output a CSV file or (- like text) I gave it with data from the embedded PDFs correctly according to the needs arising from the input prompt&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dominik-reinert-dev&quot;&gt; /u/dominik-reinert-dev &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csts7q/how_can_i_use_langchainjs_to_fill_out_csv_file/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csts7q/how_can_i_use_langchainjs_to_fill_out_csv_file/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csts7q</id><link href="https://www.reddit.com/r/LangChain/comments/1csts7q/how_can_i_use_langchainjs_to_fill_out_csv_file/" /><updated>2024-05-15T19:41:42+00:00</updated><published>2024-05-15T19:41:42+00:00</published><title>How can I use LangChainJs to fill out csv file according to big context and prompt?</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csn64j/chat_with_your_sql_database_using_gpt_4o/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/rYJPoFWIRFemdSrdPxJrRIzP3PsTxlihd_RpHdFeMaU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2b498a1f2ad64e74a06e0e47a4a53ec4a119e9f9&quot; alt=&quot;Chat with your SQL database using GPT 4o &quot; title=&quot;Chat with your SQL database using GPT 4o &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://arslanshahid-1997.medium.com/chat-with-your-sql-database-using-gpt-4o-via-vanna-ai-b87e3296f8dc&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csn64j/chat_with_your_sql_database_using_gpt_4o/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1csn64j</id><media:thumbnail url="https://external-preview.redd.it/rYJPoFWIRFemdSrdPxJrRIzP3PsTxlihd_RpHdFeMaU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b498a1f2ad64e74a06e0e47a4a53ec4a119e9f9" /><link href="https://www.reddit.com/r/LangChain/comments/1csn64j/chat_with_your_sql_database_using_gpt_4o/" /><updated>2024-05-15T15:10:02+00:00</updated><published>2024-05-15T15:10:02+00:00</published><title>Chat with your SQL database using GPT 4o</title></entry><entry><author><name>/u/toubar_</name><uri>https://www.reddit.com/user/toubar_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m sorry for the trivial question, but I&amp;#39;ve been struggling with this and cannot find a solution. &lt;/p&gt; &lt;p&gt;I have a retrieval with a list of questions and answers, and I have a chain defined, but im struggling to properly handle the case in which the question being asked by the user doesn&amp;#39;t exist in my vector store (or even in a simplified system, where a 5 questions and their answers are added in the prompt - without a vectorstore and retrieval) &lt;/p&gt; &lt;p&gt;Thanks a lot in advance :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/toubar_&quot;&gt; /u/toubar_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csohun/need_trivial_help_with_rag_how_do_i/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csohun/need_trivial_help_with_rag_how_do_i/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csohun</id><link href="https://www.reddit.com/r/LangChain/comments/1csohun/need_trivial_help_with_rag_how_do_i/" /><updated>2024-05-15T16:05:30+00:00</updated><published>2024-05-15T16:05:30+00:00</published><title>Need trivial help with RAG: how do I programmatically handle the case in which the Q&amp;A Chain's retrieval found no match for the question being answered?</title></entry><entry><author><name>/u/RaGE_Syria</name><uri>https://www.reddit.com/user/RaGE_Syria</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building an app with Next.js. &lt;/p&gt; &lt;p&gt;Is it possible to have LangChain only give me the context it found from the vector store? I then want to take this context and manually insert it into another part of my app that&amp;#39;s using an llm as a part of the message history (but I don&amp;#39;t want to do this final step in LangChain)&lt;/p&gt; &lt;p&gt;So I don&amp;#39;t want LangChain to give me the final output just the context is found using the vector store and OpenAi embedding model.&lt;/p&gt; &lt;p&gt;I&amp;#39;m still learning sry if this a stupid question. &lt;/p&gt; &lt;p&gt;I&amp;#39;m having issues streaming output from LangChain to the front end and want to use something else I already have setup&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RaGE_Syria&quot;&gt; /u/RaGE_Syria &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csy9ul/can_i_use_langchain_to_only_give_me_the_context/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csy9ul/can_i_use_langchain_to_only_give_me_the_context/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csy9ul</id><link href="https://www.reddit.com/r/LangChain/comments/1csy9ul/can_i_use_langchain_to_only_give_me_the_context/" /><updated>2024-05-15T22:55:25+00:00</updated><published>2024-05-15T22:55:25+00:00</published><title>Can I use LangChain to only give me the context is found from the retrieval?</title></entry><entry><author><name>/u/iclickedca</name><uri>https://www.reddit.com/user/iclickedca</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/iclickedca&quot;&gt; /u/iclickedca &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csvh8w/any_example_of_using_llmbind_tool_i_get_not/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csvh8w/any_example_of_using_llmbind_tool_i_get_not/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csvh8w</id><link href="https://www.reddit.com/r/LangChain/comments/1csvh8w/any_example_of_using_llmbind_tool_i_get_not/" /><updated>2024-05-15T20:52:36+00:00</updated><published>2024-05-15T20:52:36+00:00</published><title>Any example of using llm.bind_tool ? i get not implemented error - want to run tools w GPT-4o</title></entry><entry><author><name>/u/Not-That-rpg</name><uri>https://www.reddit.com/user/Not-That-rpg</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I hope I do not sound like a jerk here, but ... more and more I feel that these classes are more trouble than they are worth. I&amp;#39;d welcome it if someone made a case for their existence.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the claim: we are (almost?) always better off just working with f-strings and format instead of working with these classes. Here is my rationale:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Concatenation: Most recently, I have been fighting with trying to concatenate various `Message` and `PromptTemplate` classes. Sometimes this works, sometimes it fails at runtime. This is made worse by the fact that static type-checking doesn&amp;#39;t detect this prior to runtime.&lt;/li&gt; &lt;li&gt;Type hints: the above illustrates a problem with these classes that extends beyond them and is pervasive in Langchain. There are a lot of type hints, and there are type failures, but the type hints don&amp;#39;t help. The type specifications are often so loose that type checking tools cannot warn me about errors to come. This is related to another pervasive problem:&lt;/li&gt; &lt;li&gt;The use of opaque objects and loose typing causes many problems in development with Langchain. When I try to write my own code to extend langchain behavior I often find that I have to handle many cases that have the potential to cause errors because of loose typing. For example, anything handling input going into an &lt;code&gt;LLM&lt;/code&gt; or &lt;code&gt;ChatModel&lt;/code&gt; must handle &lt;code&gt;PromptValue&lt;/code&gt;, &lt;code&gt;str&lt;/code&gt;, &lt;code&gt;Sequence&lt;/code&gt; of &lt;code&gt;MessageLikeRepresentation&lt;/code&gt; and &lt;code&gt;dict&lt;/code&gt; s with unknown sets of keys. When I process those &lt;code&gt;Sequence&lt;/code&gt;s I must then deal with &lt;code&gt;BaseMessage&lt;/code&gt;, &lt;code&gt;str&lt;/code&gt;, &lt;code&gt;Tuple[str,str]&lt;/code&gt; and &lt;code&gt;Dict[str, Any]&lt;/code&gt;. I apologize for being cranky, but these type hints seem more aimed at ensuring that type checkers never raise errors, rather than aimed at helping the programmer write correct code. The type checker is a tool, not an oracle to be worshipped.&lt;/li&gt; &lt;li&gt;&lt;code&gt;PromptTemplate&lt;/code&gt;s work extremely poorly when they must accommodate code as template-fillers. The curly braces in code confuse prompt handling no end.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Looping back to the hypothesis: If I try to assemble a prompt in stages by plugging values in over and over, the use of &lt;code&gt;PromptTemplate&lt;/code&gt; and &lt;code&gt;Message&lt;/code&gt; objects makes my life more difficult and costs me hours of debugging. My recent alternative is simply to assemble together ordinary strings, using &lt;code&gt;format&lt;/code&gt; as necessary, until the last minute before they are needed, at which time I wrap them in &lt;code&gt;PromptTemplate.from_template()&lt;/code&gt; so that they can be put in an LCEL chain expression.&lt;/p&gt; &lt;p&gt;IMO this indicates that the layers and layers of complex types and meta-classes are more trouble than they are worth. I&amp;#39;m willing -- indeed hoping! -- that someone will prove me wrong. How does my experience align with that of other langchain users?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Not-That-rpg&quot;&gt; /u/Not-That-rpg &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csmlwe/message_and_prompt_classes_are_they_helpful/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csmlwe/message_and_prompt_classes_are_they_helpful/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csmlwe</id><link href="https://www.reddit.com/r/LangChain/comments/1csmlwe/message_and_prompt_classes_are_they_helpful/" /><updated>2024-05-15T14:46:22+00:00</updated><published>2024-05-15T14:46:22+00:00</published><title>Message and Prompt Classes -- are they helpful?</title></entry><entry><author><name>/u/ggStrift</name><uri>https://www.reddit.com/user/ggStrift</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ggStrift&quot;&gt; /u/ggStrift &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://blog.meilisearch.com/langchain-semantic-search-tutorial/?utm_campaign=social&amp;amp;utm_source=reddit&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csok7u/a_stepbystep_tutorial_to_building_semantic_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csok7u</id><link href="https://www.reddit.com/r/LangChain/comments/1csok7u/a_stepbystep_tutorial_to_building_semantic_search/" /><updated>2024-05-15T16:08:13+00:00</updated><published>2024-05-15T16:08:13+00:00</published><title>A step-by-step tutorial to building semantic search with LangChain</title></entry><entry><author><name>/u/Glittering-Bear5748</name><uri>https://www.reddit.com/user/Glittering-Bear5748</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;issue: I am build RAG chat bot and my model is taking server time zone when i ask what is current date and time how fix it ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering-Bear5748&quot;&gt; /u/Glittering-Bear5748 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csobxi/llm_model_with_timezone_issue/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csobxi/llm_model_with_timezone_issue/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csobxi</id><link href="https://www.reddit.com/r/LangChain/comments/1csobxi/llm_model_with_timezone_issue/" /><updated>2024-05-15T15:59:13+00:00</updated><published>2024-05-15T15:59:13+00:00</published><title>LLM model with timezone issue</title></entry><entry><author><name>/u/deixhah</name><uri>https://www.reddit.com/user/deixhah</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I use Dall-E as a tool for my langchain agent but the quality of the images are so low compared to the images from the ChatGPT Interface.&lt;/p&gt; &lt;p&gt;Is there a way to fix this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/deixhah&quot;&gt; /u/deixhah &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csmium/dalle_api_low_quality_images/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csmium/dalle_api_low_quality_images/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csmium</id><link href="https://www.reddit.com/r/LangChain/comments/1csmium/dalle_api_low_quality_images/" /><updated>2024-05-15T14:42:54+00:00</updated><published>2024-05-15T14:42:54+00:00</published><title>Dall-E Api low quality images</title></entry><entry><author><name>/u/UpskillingDS17</name><uri>https://www.reddit.com/user/UpskillingDS17</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I have to do a POC and below are the steps or direction how to implement using Langchain and Snowflake DB and LLM —————— 1. User will enter the Transformation Logic sheet where every row will have the logic how the values inside the Source Table are mapped/modified to Target Table. 2. User will also have access to Target Table to check whether the SQL query generation using Transformation logic correctly mapped the values to Target table or not.&lt;/p&gt; &lt;p&gt;I have tried using excel sheet and a basic table in ChatGPT and I was able to accomplish upto good level. I want to know how to implement in python and is there any good LLM for such text-sql conversion. Many thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpskillingDS17&quot;&gt; /u/UpskillingDS17 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csjz1h/texttosql_conversion_for_etl_testing_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csjz1h/texttosql_conversion_for_etl_testing_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csjz1h</id><link href="https://www.reddit.com/r/LangChain/comments/1csjz1h/texttosql_conversion_for_etl_testing_using/" /><updated>2024-05-15T12:48:05+00:00</updated><published>2024-05-15T12:48:05+00:00</published><title>Text-to-SQL conversion for ETL testing using Snowflake</title></entry><entry><author><name>/u/electricjimi</name><uri>https://www.reddit.com/user/electricjimi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I spent the whole day testing Gpt4-o capabilities to do agentic RAG using a standard prompt (hwchase17/ReAct) personalized for my particular use case: basically, it&amp;#39;s the standard prompt but with a couple of High level instructions at the end, to give the agent some personality. It is unable to respect the response format about half of the time.&lt;/p&gt; &lt;p&gt;Gpt-4-turbo instead works like a charm.. almost all the time. It feels like Gpt-4o is a quantized version of Gpt-4-turbo on instruction following.&lt;/p&gt; &lt;p&gt;Am I the only one?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/electricjimi&quot;&gt; /u/electricjimi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cs3asj/gpt4o_react_agentic_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cs3asj/gpt4o_react_agentic_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cs3asj</id><link href="https://www.reddit.com/r/LangChain/comments/1cs3asj/gpt4o_react_agentic_rag/" /><updated>2024-05-14T21:10:27+00:00</updated><published>2024-05-14T21:10:27+00:00</published><title>Gpt-4o ReAct agentic RAG</title></entry><entry><author><name>/u/Glittering_Cup1104</name><uri>https://www.reddit.com/user/Glittering_Cup1104</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, I&amp;#39;ve built a pdf-chatbot using langchain and pinecone db. I&amp;#39;m further planning to integrate vercel&amp;#39;s latest generative UI feature &lt;a href=&quot;https://chat.vercel.ai/&quot;&gt;https://chat.vercel.ai/&lt;/a&gt; ( &lt;a href=&quot;https://github.com/vercel/ai-chatbot&quot;&gt;https://github.com/vercel/ai-chatbot&lt;/a&gt; ). &lt;/p&gt; &lt;p&gt;so here&amp;#39;s the flow:&lt;br/&gt; 1. User should be able to upload multiple pdf&amp;#39;s&lt;br/&gt; 2. All the pdf&amp;#39;s will be stored in pinecode vector Storage&lt;br/&gt; 3. User will be able to prompt and based on the prompt the AI will call generative UI like interactive quizes etc via react server components&lt;/p&gt; &lt;p&gt;Can anyone help me with how to integrate langchain with streamUI from vercel SDK? &lt;a href=&quot;https://sdk.vercel.ai/docs/reference/ai-sdk-rsc/stream-ui&quot;&gt;https://sdk.vercel.ai/docs/reference/ai-sdk-rsc/stream-ui&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering_Cup1104&quot;&gt; /u/Glittering_Cup1104 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csicrm/need_help_with_langchain_vercel_generative_ui/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csicrm/need_help_with_langchain_vercel_generative_ui/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csicrm</id><link href="https://www.reddit.com/r/LangChain/comments/1csicrm/need_help_with_langchain_vercel_generative_ui/" /><updated>2024-05-15T11:20:35+00:00</updated><published>2024-05-15T11:20:35+00:00</published><title>Need help with Langchain &amp; vercel generative UI integration</title></entry><entry><author><name>/u/Logical_Buyer9310</name><uri>https://www.reddit.com/user/Logical_Buyer9310</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csby28/gpt4o_phone_bot_build/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/VD3ngREa5spe2AQgfyqHMtYgqcii-mCP4ZA5eR6SDlY.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5f9e8ff42d9338455d0b4cd23e53deaff1efc950&quot; alt=&quot;GPT-4o Phone Bot Build&quot; title=&quot;GPT-4o Phone Bot Build&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Logical_Buyer9310&quot;&gt; /u/Logical_Buyer9310 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/7nv2hIbS9yo?si=cviynXX-Mr2t3sNS&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csby28/gpt4o_phone_bot_build/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1csby28</id><media:thumbnail url="https://external-preview.redd.it/VD3ngREa5spe2AQgfyqHMtYgqcii-mCP4ZA5eR6SDlY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f9e8ff42d9338455d0b4cd23e53deaff1efc950" /><link href="https://www.reddit.com/r/LangChain/comments/1csby28/gpt4o_phone_bot_build/" /><updated>2024-05-15T04:03:54+00:00</updated><published>2024-05-15T04:03:54+00:00</published><title>GPT-4o Phone Bot Build</title></entry><entry><author><name>/u/Queasy-Explorer8139</name><uri>https://www.reddit.com/user/Queasy-Explorer8139</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey r/LangChain , I published a new article where I built an observable semantic research paper application.&lt;/p&gt; &lt;p&gt;This is an extensive tutorial where I go in detail about:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Developing a RAG pipeline to process and retrieve the most relevant PDF documents from the arXiv API.&lt;/li&gt; &lt;li&gt;Developing a Chainlit driven web app with a Copilot for online paper retrieval.&lt;/li&gt; &lt;li&gt;Enhancing the app with LLM observability features from Literal AI.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;You can read the article here: &lt;a href=&quot;https://medium.com/towards-data-science/building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&quot;&gt;https://medium.com/towards-data-science/building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Code for the tutorial: &lt;a href=&quot;https://github.com/tahreemrasul/semantic_research_engine&quot;&gt;https://github.com/tahreemrasul/semantic_research_engine&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Queasy-Explorer8139&quot;&gt; /u/Queasy-Explorer8139 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crtas2/building_an_observable_arxiv_rag_chatbot_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crtas2/building_an_observable_arxiv_rag_chatbot_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crtas2</id><link href="https://www.reddit.com/r/LangChain/comments/1crtas2/building_an_observable_arxiv_rag_chatbot_with/" /><updated>2024-05-14T14:18:02+00:00</updated><published>2024-05-14T14:18:02+00:00</published><title>Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI</title></entry><entry><author><name>/u/Satsifaction</name><uri>https://www.reddit.com/user/Satsifaction</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;HI guys so i have a question. I have a postgres database that holds about information about clients. One table is a financial table, another is an incident table, the third is a client escalations table and finally the last one holds free text that is filled in the crm like notes…&lt;/p&gt; &lt;p&gt;these are all linked one way or another by cliend ID but the data within each table can sometimes be nested dictionaries…like under notes you could have a dictionary of , {date, text, from, to}&lt;/p&gt; &lt;p&gt;i want to take all of this data and create embedding on it…what i’m confised about is the best way to do it…do I?&lt;/p&gt; &lt;p&gt;Somehow connect all this data into a single flatted dataframe? if so this will be a massive dataframe with 100+ columns&lt;/p&gt; &lt;p&gt;Can i create an embedding for each table? if i do this, will the embedding model know that two tables are connected via a client identifier that is present in both or do i have to somehow force this connection? if so how?&lt;/p&gt; &lt;p&gt;Any other options?&lt;/p&gt; &lt;p&gt;Thanks in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Satsifaction&quot;&gt; /u/Satsifaction &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cs8ger/embedding_with_large_database/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cs8ger/embedding_with_large_database/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cs8ger</id><link href="https://www.reddit.com/r/LangChain/comments/1cs8ger/embedding_with_large_database/" /><updated>2024-05-15T01:03:01+00:00</updated><published>2024-05-15T01:03:01+00:00</published><title>Embedding with large database</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What challenges are you facing and what tools are you using? I am thinking about building out a developer friendly open source evaluations tool kit. Thinking of starting with a simple interface where you pass the context, input, output and expected output and run it through some basic tests - both LLM based and non LLM based and also allow the ability to write custom assertions.&lt;/p&gt; &lt;p&gt;But, am wondering if you all have any insights into what other capabilities might be useful. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crvzvd/what_are_your_current_challenges_with_evaluations/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crvzvd/what_are_your_current_challenges_with_evaluations/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crvzvd</id><link href="https://www.reddit.com/r/LangChain/comments/1crvzvd/what_are_your_current_challenges_with_evaluations/" /><updated>2024-05-14T16:12:28+00:00</updated><published>2024-05-14T16:12:28+00:00</published><title>What are your current challenges with evaluations?</title></entry><entry><author><name>/u/aviation_expert</name><uri>https://www.reddit.com/user/aviation_expert</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi there. So a problem is that if someone wants to parse, let suppose a parameter named Name1, Name2 and so on using output parse, how would that be done since once you define Name, the output parsing only returns 1 name only. So how can be the LLM flexible to add Name1,Name2 and so on based on the text inpit it recieves?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/aviation_expert&quot;&gt; /u/aviation_expert &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cs2gw2/nonflexible_output_parsing_for_json/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cs2gw2/nonflexible_output_parsing_for_json/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cs2gw2</id><link href="https://www.reddit.com/r/LangChain/comments/1cs2gw2/nonflexible_output_parsing_for_json/" /><updated>2024-05-14T20:35:44+00:00</updated><published>2024-05-14T20:35:44+00:00</published><title>Non-Flexible Output parsing for JSON</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I want to improve my RAG system and read about ColBERT and Cross-Encoders, but I don&amp;#39;t really get what is the difference here, can someone explain?&lt;/p&gt; &lt;p&gt;Also would be nice to have some experiences what worked better for your RAG. I have to rely on multilingual models (to use german language), so I picked out:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://huggingface.co/antoinelouis/colbert-xm&quot;&gt;https://huggingface.co/antoinelouis/colbert-xm&lt;/a&gt;&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://huggingface.co/cross-encoder/msmarco-MiniLM-L12-en-de-v1&quot;&gt;https://huggingface.co/cross-encoder/msmarco-MiniLM-L12-en-de-v1&lt;/a&gt;&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Which one would you prefer?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crt25e/cross_encoder_vs_colbert_in_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crt25e/cross_encoder_vs_colbert_in_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crt25e</id><link href="https://www.reddit.com/r/LangChain/comments/1crt25e/cross_encoder_vs_colbert_in_rag/" /><updated>2024-05-14T14:07:45+00:00</updated><published>2024-05-14T14:07:45+00:00</published><title>Cross Encoder vs. ColBERT in RAG</title></entry><entry><author><name>/u/Honest-Worth3677</name><uri>https://www.reddit.com/user/Honest-Worth3677</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crt1dv/how_to_solve_real_world_ai_job_in_upwork/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/5U_WiM-IhjTpuFdRzdIwoFc0QeVl4KRYxqNRoLdBBmc.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=afdf14ce4648d0beb8ee2daaedc4fd9431772003&quot; alt=&quot; How to Solve Real World AI Job in UPWORK&quot; title=&quot; How to Solve Real World AI Job in UPWORK&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Honest-Worth3677&quot;&gt; /u/Honest-Worth3677 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=xDOm_G7Cyac&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crt1dv/how_to_solve_real_world_ai_job_in_upwork/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1crt1dv</id><media:thumbnail url="https://external-preview.redd.it/5U_WiM-IhjTpuFdRzdIwoFc0QeVl4KRYxqNRoLdBBmc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=afdf14ce4648d0beb8ee2daaedc4fd9431772003" /><link href="https://www.reddit.com/r/LangChain/comments/1crt1dv/how_to_solve_real_world_ai_job_in_upwork/" /><updated>2024-05-14T14:06:55+00:00</updated><published>2024-05-14T14:06:55+00:00</published><title>How to Solve Real World AI Job in UPWORK</title></entry></feed>