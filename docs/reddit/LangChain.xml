<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2023-12-05T21:27:50+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/DannyBrownMz</name><uri>https://www.reddit.com/user/DannyBrownMz</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Anyone knows whether support for legacy langchain methods like sequential chain would still be continued(though it still is for now at least) despite the new addition LCEL? &lt;/p&gt; &lt;p&gt;Reason being that I find using Sequential chain and other types of chains used in Legacy Langchain quite easier to understand and implement than LCEL, plus it gives me better results.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DannyBrownMz&quot;&gt; /u/DannyBrownMz &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18bhzhk/support_for_legacy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18bhzhk/support_for_legacy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18bhzhk</id><link href="https://www.reddit.com/r/LangChain/comments/18bhzhk/support_for_legacy/" /><updated>2023-12-05T18:00:38+00:00</updated><published>2023-12-05T18:00:38+00:00</published><title>Support for Legacy</title></entry><entry><author><name>/u/devinbost</name><uri>https://www.reddit.com/user/devinbost</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Most of the doc loaders assume a &amp;quot;one and done&amp;quot; process. &lt;/p&gt; &lt;p&gt;Anyone have suggestions on continually adding docs like for a RAG flow? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/devinbost&quot;&gt; /u/devinbost &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18bfxjm/anyone_have_suggestions_on_continuous_doc_loading/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18bfxjm/anyone_have_suggestions_on_continuous_doc_loading/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18bfxjm</id><link href="https://www.reddit.com/r/LangChain/comments/18bfxjm/anyone_have_suggestions_on_continuous_doc_loading/" /><updated>2023-12-05T16:31:12+00:00</updated><published>2023-12-05T16:31:12+00:00</published><title>Anyone have suggestions on continuous doc loading?</title></entry><entry><author><name>/u/anonymous_anki</name><uri>https://www.reddit.com/user/anonymous_anki</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build a youtube assistant with the help of langchain and google palm api.&lt;/p&gt; &lt;p&gt;So, when I finally run my code, I am getting this error:&lt;/p&gt; &lt;pre&gt;&lt;code&gt; Traceback (most recent call last): File &amp;quot;/home/youtube_assitant/langchain_helper.py&amp;quot;, line 62, in &amp;lt;module&amp;gt; response, docs = get_response_from_query(vectordb, query) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File &amp;quot;/home/youtube_assitant/langchain_helper.py&amp;quot;, line 34, in get_response_from_query llm = google_palm(google_api_key=os.getenv(&amp;quot;GOOGLE_API_KEY&amp;quot;), temperature = 0) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TypeError: &amp;#39;module&amp;#39; object is not callable &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here is the entire code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt; from langchain.document_loaders import YoutubeLoader from langchain.text_splitter import RecursiveCharacterTextSplitter from langchain.llms import google_palm from langchain.chains import LLMChain from langchain.prompts import PromptTemplate from langchain.vectorstores import FAISS from langchain.embeddings.google_palm import GooglePalmEmbeddings import os from dotenv import load_dotenv load_dotenv() embeddngs = GooglePalmEmbeddings() video_url = &amp;quot;https://www.youtube.com/watch?v=XxOh12Uhg08&amp;quot; # create_vectordb_from_youtube_url = cvfyu def create_vectordb_from_youtube_url(video_url: str) -&amp;gt; FAISS: loader = YoutubeLoader.from_youtube_url(video_url) transcript = loader.load() text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100) docs = text_splitter.split_documents(transcript) db = FAISS.from_documents(docs, embeddngs) return db def get_response_from_query(db, query, k=4): # k is no. of docs that will be create docs = db.similarity_search(query, k = k) docs_page_content = &amp;quot; &amp;quot;.join([d.page_content for d in docs]) llm = google_palm(google_api_key=os.getenv(&amp;quot;GOOGLE_API_KEY&amp;quot;), temperature = 0) prompt = PromptTemplate( input_variables=[&amp;quot;question&amp;quot;, &amp;quot;docs&amp;quot;], template=&amp;quot;&amp;quot;&amp;quot; You are a helpful assistant that that can answer questions about youtube videos based on the video&amp;#39;s transcript. Answer the following question: {question} By searching the following video transcript: {docs} Only use the factual information from the transcript to answer the question. If you feel like you don&amp;#39;t have enough information to answer the question, say &amp;quot;I don&amp;#39;t know&amp;quot;. Your answers should be verbose and detailed. &amp;quot;&amp;quot;&amp;quot;, ) chain = LLMChain(llm=llm, prompt=prompt) response = chain.run(question=query, docs=docs_page_content) response = response.replace(&amp;quot;\n&amp;quot;,&amp;quot;&amp;quot;) return response, docs vectordb = create_vectordb_from_youtube_url(video_url) query = &amp;quot;What this video is about?&amp;quot; response, docs = get_response_from_query(vectordb, query) print(&amp;quot;Response: &amp;quot;, response) print(&amp;quot;Docs: &amp;quot;, docs) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I have try many methods but nothing workout so far. I tried to google search it too but it didn&amp;#39;t work. Can someone please tell me how to fix this?? Thank you.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/anonymous_anki&quot;&gt; /u/anonymous_anki &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18bhdim/module_object_is_not_callable_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18bhdim/module_object_is_not_callable_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18bhdim</id><link href="https://www.reddit.com/r/LangChain/comments/18bhdim/module_object_is_not_callable_in_langchain/" /><updated>2023-12-05T17:34:02+00:00</updated><published>2023-12-05T17:34:02+00:00</published><title>&quot;module&quot; object is not callable in langchain</title></entry><entry><author><name>/u/techocompany25</name><uri>https://www.reddit.com/user/techocompany25</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a very structured DB that mostly contain numerical valuex (x: 55, y:77... etc). My use case is to chat naturally with the DB. Do I really need pgvector to do similarity search when the DB mostly contains numerical values? Would actually using pgvector bring less accurate results with this type of data?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/techocompany25&quot;&gt; /u/techocompany25 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18b80wx/is_pgvector_needed_for_a_structured_db_or_the_sql/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18b80wx/is_pgvector_needed_for_a_structured_db_or_the_sql/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18b80wx</id><link href="https://www.reddit.com/r/LangChain/comments/18b80wx/is_pgvector_needed_for_a_structured_db_or_the_sql/" /><updated>2023-12-05T09:07:45+00:00</updated><published>2023-12-05T09:07:45+00:00</published><title>Is PgVector needed for a structured DB or the sql agent is enough?</title></entry><entry><author><name>/u/AlkaliMedia</name><uri>https://www.reddit.com/user/AlkaliMedia</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi there, I made an assistant using &lt;/p&gt; &lt;p&gt;OpenAIAssistantRunnable and ran invoke, the response I get is&lt;/p&gt; &lt;p&gt;&lt;code&gt;[ThreadMessage(id=&amp;#39;msg_BtVZtxShzp5AEvFgK1mwyhme&amp;#39;, assistant_id=&amp;#39;asst_8HFshA1tzFfosxA6G7kzqpCt&amp;#39;, content=[MessageContentText(text=Text(annotations=[], value=&amp;#39;THIS IS WHAT I WANT.&amp;#39;), type=&amp;#39;text&amp;#39;)], created_at=1701792953, file_ids=[], metadata={}, object=&amp;#39;thread.message&amp;#39;, role=&amp;#39;assistant&amp;#39;, run_id=&amp;#39;run_12o5LTNgEFcw18zl9wiMfwb8&amp;#39;, thread_id=&amp;#39;thread_LzQyxf4I41GaTZFqryqjfWRv&amp;#39;)]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;I cannot extract the value, whatever approach I try. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AlkaliMedia&quot;&gt; /u/AlkaliMedia &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18bg3ve/cannot_parse_assitant_response/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18bg3ve/cannot_parse_assitant_response/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18bg3ve</id><link href="https://www.reddit.com/r/LangChain/comments/18bg3ve/cannot_parse_assitant_response/" /><updated>2023-12-05T16:38:51+00:00</updated><published>2023-12-05T16:38:51+00:00</published><title>Cannot Parse Assitant Response</title></entry><entry><author><name>/u/overflow74</name><uri>https://www.reddit.com/user/overflow74</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’m trying to build a customer service chatbot for a travel agency (book flights,hotels , answers questions about visa etc..) i want to use openAi api with gpt3.5 however i’m facing a difficulty with building a conversation pipeline. is there a framework (other than langchain) that could help with this project?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/overflow74&quot;&gt; /u/overflow74 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18b9uk9/chat_bot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18b9uk9/chat_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18b9uk9</id><link href="https://www.reddit.com/r/LangChain/comments/18b9uk9/chat_bot/" /><updated>2023-12-05T11:20:32+00:00</updated><published>2023-12-05T11:20:32+00:00</published><title>Chat bot</title></entry><entry><author><name>/u/OpeningMarsupial7229</name><uri>https://www.reddit.com/user/OpeningMarsupial7229</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone I&amp;#39;m trying do an usecase where I can chat with CSV files,my CSV files is of 100k rows and 56 columns when I&amp;#39;m creating an CSV agent it is failing beacause of input token limit is exceeded and allowed limit is 4096,how do approach this problem please help&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OpeningMarsupial7229&quot;&gt; /u/OpeningMarsupial7229 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18b6qjm/large_csv_files_with_llama/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18b6qjm/large_csv_files_with_llama/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18b6qjm</id><link href="https://www.reddit.com/r/LangChain/comments/18b6qjm/large_csv_files_with_llama/" /><updated>2023-12-05T07:32:28+00:00</updated><published>2023-12-05T07:32:28+00:00</published><title>Large CSV files with llama</title></entry><entry><author><name>/u/nderstand2grow</name><uri>https://www.reddit.com/user/nderstand2grow</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve come across many LLM frameworks: Langchain, LlamaIndex, LMQL, guidance, Marvin, Instructor, etc. There&amp;#39;s a lot of overlap between them and I don&amp;#39;t know if any of them actually adds a value to LLM workflows in a way that&amp;#39;s maintainable and robust. So far, I&amp;#39;ve been able to just build my own little libraries to use in some LLM applications (no RAG), but as I consider the more recent advancements in the field (guaranteed function calling, better RAG, agents and tool use, etc.), I wonder if using one of these frameworks would be a better approach compared to building everything on my own. I appreciate your thoughts and comments on this!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nderstand2grow&quot;&gt; /u/nderstand2grow &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18anbjf/which_llm_frameworks_do_you_use_in_production_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18anbjf/which_llm_frameworks_do_you_use_in_production_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18anbjf</id><link href="https://www.reddit.com/r/LangChain/comments/18anbjf/which_llm_frameworks_do_you_use_in_production_and/" /><updated>2023-12-04T16:02:57+00:00</updated><published>2023-12-04T16:02:57+00:00</published><title>Which LLM framework(s) do you use in production and why?</title></entry><entry><author><name>/u/AgilePainting931</name><uri>https://www.reddit.com/user/AgilePainting931</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18aoewc/beacon_a_generative_ai_llmops_framework/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/KnhVw6iIV1V0y0-XCKePZUxzVUNRbxyJmi0-_DPTvaM.jpg&quot; alt=&quot;Beacon - A Generative AI LLMOps Framework&quot; title=&quot;Beacon - A Generative AI LLMOps Framework&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am doing r&amp;amp;d in generative AI. I created a framework which has following functionality:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Data connectors - provides various data connectors like local documents (pdf, word), azure Blob storage, Azure MS SQL database, AWS S3 Bucket. System will take data from said structured and non-structured databases and insert into vector database. right now, we are using chromadb as our local vector database.&lt;/li&gt; &lt;li&gt;LLM - This section allows users to choose which llm provide they want to use. We give options like azure open ai, open ai and amazon bedrock. Users needs to choose one of these providers for LLM and embedding models.&lt;/li&gt; &lt;li&gt;Chat - user can start chatting in this section as system takes data from connectors, stores in vector db using embeddings and use LLM provider to answer user&amp;#39;s question.&lt;/li&gt; &lt;li&gt;Observability: We are using langsmith and showing observability charts and monitoring charts.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I have attached screenshots of this tool.&lt;/p&gt; &lt;p&gt;Here is the link where you can sign up and start:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;http://4.151.58.132/beacon&quot;&gt;http://4.151.58.132/beacon&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Please let me know your thoughts on how should i proceed further. What new things i can do here.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/bhhbf75fpb4c1.png?width=1342&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=73924ba13cc0467f6c3b38809bf7423e57778278&quot;&gt;https://preview.redd.it/bhhbf75fpb4c1.png?width=1342&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=73924ba13cc0467f6c3b38809bf7423e57778278&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/7vqd295fpb4c1.png?width=1357&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=139a0bca58ffc2fbdfa11fa1c6c0d2a64abe8bd5&quot;&gt;https://preview.redd.it/7vqd295fpb4c1.png?width=1357&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=139a0bca58ffc2fbdfa11fa1c6c0d2a64abe8bd5&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/mf1tba5fpb4c1.png?width=1348&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6f43e03b19e7111b092b932143d599938d4c01a9&quot;&gt;https://preview.redd.it/mf1tba5fpb4c1.png?width=1348&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6f43e03b19e7111b092b932143d599938d4c01a9&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/lwz7nd5fpb4c1.png?width=1347&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e24fbd6b2383b59edad4bdc30bee6e149f2076f9&quot;&gt;https://preview.redd.it/lwz7nd5fpb4c1.png?width=1347&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e24fbd6b2383b59edad4bdc30bee6e149f2076f9&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/mii35b5fpb4c1.png?width=1356&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=da229817437a6481f0b4fda36cb6e8135dee9ac7&quot;&gt;https://preview.redd.it/mii35b5fpb4c1.png?width=1356&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=da229817437a6481f0b4fda36cb6e8135dee9ac7&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AgilePainting931&quot;&gt; /u/AgilePainting931 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18aoewc/beacon_a_generative_ai_llmops_framework/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18aoewc/beacon_a_generative_ai_llmops_framework/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18aoewc</id><media:thumbnail url="https://b.thumbs.redditmedia.com/KnhVw6iIV1V0y0-XCKePZUxzVUNRbxyJmi0-_DPTvaM.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/18aoewc/beacon_a_generative_ai_llmops_framework/" /><updated>2023-12-04T16:52:31+00:00</updated><published>2023-12-04T16:52:31+00:00</published><title>Beacon - A Generative AI LLMOps Framework</title></entry><entry><author><name>/u/jim_andr</name><uri>https://www.reddit.com/user/jim_andr</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;seems that openAI document upload is better atm than many other solutions. Do we know what they use for embeddings?By web GPT-4 i mean openAI login to chatGPT.Locally, i mean call openAI API with gpt-4 as a model and same csv as RAG. &lt;/p&gt; &lt;p&gt;dataset is containing structured data from smartphone industry, brand model, ram, sttorage, price etc. I was able to ask questions like &amp;quot;cheapest model with 256gb of storage, etc)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jim_andr&quot;&gt; /u/jim_andr &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18am1f9/i_tested_a_csv_upload_and_qa_to_web_gpt4_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18am1f9/i_tested_a_csv_upload_and_qa_to_web_gpt4_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18am1f9</id><link href="https://www.reddit.com/r/LangChain/comments/18am1f9/i_tested_a_csv_upload_and_qa_to_web_gpt4_and/" /><updated>2023-12-04T15:02:31+00:00</updated><published>2023-12-04T15:02:31+00:00</published><title>I tested a csv upload and Q&amp;A to web gpt-4 and worked like a charm. Tried to do the same locally with csv loader, chroma and langchain and results (Q&amp;A on the same dataset and GPT model - gpt4) were poor. I suspect i need to create better embeddings with chroma or any vector db. Any suggestions?</title></entry><entry><author><name>/u/devinbost</name><uri>https://www.reddit.com/user/devinbost</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;If you could have an execution framework for spinning up LangChain applications at runtime, how would you design it? One idea would be a YAML/config based approach that would use an orchestration layer to spin up Kubernetes pods. If we go that route, then the next question is determining what parts of langchain should be exposed vs what should be configurable via the config. Thoughts?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/devinbost&quot;&gt; /u/devinbost &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18alrin/execution_framework_for_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18alrin/execution_framework_for_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18alrin</id><link href="https://www.reddit.com/r/LangChain/comments/18alrin/execution_framework_for_langchain/" /><updated>2023-12-04T14:49:14+00:00</updated><published>2023-12-04T14:49:14+00:00</published><title>Execution framework for LangChain?</title></entry><entry><author><name>/u/IllustriousArt2202</name><uri>https://www.reddit.com/user/IllustriousArt2202</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How do I Replace the existing Langchain REACT Agent in the L3AGI framework with the XAgent framework? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/IllustriousArt2202&quot;&gt; /u/IllustriousArt2202 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189pkr1/integration_of_xagent_into_l3agi_framework/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189pkr1/integration_of_xagent_into_l3agi_framework/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_189pkr1</id><link href="https://www.reddit.com/r/LangChain/comments/189pkr1/integration_of_xagent_into_l3agi_framework/" /><updated>2023-12-03T08:55:02+00:00</updated><published>2023-12-03T08:55:02+00:00</published><title>Integration of XAgent into L3AGI Framework</title></entry><entry><author><name>/u/Full_Sentence_3678</name><uri>https://www.reddit.com/user/Full_Sentence_3678</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189gkp0/embodied_llms_for_robotics_code_in_comments/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/NTRocnAxdWR6eTNjMXoQB95sJhOH8DH2fTHH41Ap3Y8STa1xy0MP2uEfLJ5e.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=287b0852c7d3c729420bbef12e3dea483cd73780&quot; alt=&quot;Embodied LLMs for robotics (code in comments)&quot; title=&quot;Embodied LLMs for robotics (code in comments)&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Full_Sentence_3678&quot;&gt; /u/Full_Sentence_3678 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/jll5idt5zy3c1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189gkp0/embodied_llms_for_robotics_code_in_comments/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_189gkp0</id><media:thumbnail url="https://external-preview.redd.it/NTRocnAxdWR6eTNjMXoQB95sJhOH8DH2fTHH41Ap3Y8STa1xy0MP2uEfLJ5e.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=287b0852c7d3c729420bbef12e3dea483cd73780" /><link href="https://www.reddit.com/r/LangChain/comments/189gkp0/embodied_llms_for_robotics_code_in_comments/" /><updated>2023-12-02T23:55:10+00:00</updated><published>2023-12-02T23:55:10+00:00</published><title>Embodied LLMs for robotics (code in comments)</title></entry><entry><author><name>/u/BtownIU</name><uri>https://www.reddit.com/user/BtownIU</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi y&amp;#39;all,&lt;/p&gt; &lt;p&gt;Newbie to langchain here. Curious if there is a way to let a chain deal with different types of questions automatically. &lt;/p&gt; &lt;p&gt;Say when a prompt is something like &amp;quot;what&amp;#39;s your product XYZ?&amp;quot;, the user is usually ok with 15 seconds for a paragraph to be generated detailing the answer.&lt;/p&gt; &lt;p&gt;But a user may just want to get the links to self-help documents, like &amp;quot;give me the links to all your docs about XYZ&amp;quot;. And the speed is expected to be much faster.&lt;/p&gt; &lt;p&gt;Should I set up a chain that classifies a prompt into 2 different pipelines, where one pipeline would be something like a vector database search without RAG, the other one with RAG? Or are there tricks with LLM that can spew out structured answers much faster than unstructured textual answers? Thanks in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BtownIU&quot;&gt; /u/BtownIU &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189ml0n/how_to_handle_prompts_asking_for_links_instead_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189ml0n/how_to_handle_prompts_asking_for_links_instead_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_189ml0n</id><link href="https://www.reddit.com/r/LangChain/comments/189ml0n/how_to_handle_prompts_asking_for_links_instead_of/" /><updated>2023-12-03T05:29:46+00:00</updated><published>2023-12-03T05:29:46+00:00</published><title>How to handle prompts asking for links instead of textual answers?</title></entry><entry><author><name>/u/LeDebardeur</name><uri>https://www.reddit.com/user/LeDebardeur</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I’m using sql agent, and I want to pass custom database tables infos ( column and tables infos ) Which format can I pass those and how ?&lt;/p&gt; &lt;p&gt;Thanks in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LeDebardeur&quot;&gt; /u/LeDebardeur &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189k1lx/custom_sql_database_infos/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/189k1lx/custom_sql_database_infos/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_189k1lx</id><link href="https://www.reddit.com/r/LangChain/comments/189k1lx/custom_sql_database_infos/" /><updated>2023-12-03T03:05:55+00:00</updated><published>2023-12-03T03:05:55+00:00</published><title>Custom SQL database infos</title></entry><entry><author><name>/u/nebulum747</name><uri>https://www.reddit.com/user/nebulum747</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I was working on using gpt4all&amp;#39;s open AI-like API backend to see if I could start phasing out the actual openai API to some extent. &lt;/p&gt; &lt;p&gt;Essentially, I wanted to use Langchain&amp;#39;s ChatOpenAI(), but switch the OPENAI_BASE_URL, and put something random in for the key.&lt;/p&gt; &lt;p&gt;When I tried this with LLaMA models like mistral and snoozy, I get instant replies, but ones that aren&amp;#39;t useful. Something like this:&lt;/p&gt; &lt;p&gt;Me: hi!&lt;/p&gt; &lt;p&gt;AI: Echo: hi!&lt;/p&gt; &lt;p&gt;Me: how are you?&lt;/p&gt; &lt;p&gt;AI: Echo: how are you?&lt;/p&gt; &lt;p&gt;It just bounces the message I wrote back. Any tips on integrating in these models with OpenAI-like APIs? I&amp;#39;m trying to get it so that I can &amp;quot;plug and play&amp;quot; with models using the openai API standard (i&amp;#39;ll change the prompts, ofc)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nebulum747&quot;&gt; /u/nebulum747 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1899yhr/does_langchain_support_openaiapi_compatible/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1899yhr/does_langchain_support_openaiapi_compatible/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1899yhr</id><link href="https://www.reddit.com/r/LangChain/comments/1899yhr/does_langchain_support_openaiapi_compatible/" /><updated>2023-12-02T18:34:31+00:00</updated><published>2023-12-02T18:34:31+00:00</published><title>Does Langchain support OpenAI-API compatible agents with it's ChatOpenAI, OpenAIFunctionsAgents, etc.?</title></entry><entry><author><name>/u/nebulum747</name><uri>https://www.reddit.com/user/nebulum747</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I was working on using gpt4all&amp;#39;s open AI-like API backend to see if I could start phasing out the actual openai API to some extent. &lt;/p&gt; &lt;p&gt;Essentially, I wanted to use Langchain&amp;#39;s ChatOpenAI(), but switch the OPENAI_BASE_URL, and put something random in for the key.&lt;/p&gt; &lt;p&gt;When I tried this with LLaMA models like mistral and snoozy, I get instant replies, but ones that aren&amp;#39;t useful. Something like this:&lt;/p&gt; &lt;p&gt;Me: hi!&lt;/p&gt; &lt;p&gt;AI: Echo: hi!&lt;/p&gt; &lt;p&gt;Me: how are you?&lt;/p&gt; &lt;p&gt;AI: Echo: how are you?&lt;/p&gt; &lt;p&gt;It just bounces the message I wrote back. Any tips on integrating in these models with OpenAI-like APIs? I&amp;#39;m trying to get it so that I can &amp;quot;plug and play&amp;quot; with models using the openai API standard (i&amp;#39;ll change the prompts, ofc)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nebulum747&quot;&gt; /u/nebulum747 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1899yhe/does_langchain_support_openaiapi_compatible/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1899yhe/does_langchain_support_openaiapi_compatible/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1899yhe</id><link href="https://www.reddit.com/r/LangChain/comments/1899yhe/does_langchain_support_openaiapi_compatible/" /><updated>2023-12-02T18:34:30+00:00</updated><published>2023-12-02T18:34:30+00:00</published><title>Does Langchain support OpenAI-API compatible agents with it's ChatOpenAI, OpenAIFunctionsAgents, etc.?</title></entry><entry><author><name>/u/lucky_not_skill</name><uri>https://www.reddit.com/user/lucky_not_skill</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1892m87/strange_behavior_in_my_chatbot_when_responding_to/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/uovAEAZ2TYP2qK3ucictDfJRPTYTd-h7xdgQJ3BLB1M.jpg&quot; alt=&quot;Strange behavior in my chatbot when responding to questions.&quot; title=&quot;Strange behavior in my chatbot when responding to questions.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, is everything fine with you?&lt;/p&gt; &lt;p&gt;I&amp;#39;m building a chatbot that can answer questions about code or generate code, and I have two different chains, one for each activity. I also have a memory for my bot to maintain a good flow with the user.&lt;/p&gt; &lt;p&gt;My issue is as follows: The bot responds well to the question but continues to generate more information than necessary. Sometimes it includes part of the prompt I gave, sometimes it&amp;#39;s a completely different question, and sometimes it&amp;#39;s random things or a mix of everything.&lt;/p&gt; &lt;p&gt;This also happens in my implementation of a retrieval-based QA bot.&lt;/p&gt; &lt;p&gt;Cutting off the input when sending the response to the frontend is not a viable option because, during testing, I asked, &amp;quot;What is Flask?&amp;quot; and then it generated a question &amp;quot;What is the difference between a for loop and a while loop?&amp;quot; and answered it. Later, when I asked for a code example right after, it generated code for the for loop and while loop, unrelated to the Flask framework.&lt;/p&gt; &lt;p&gt;In the images below, it generated things related to Flask, but it doesn&amp;#39;t always happen.&lt;/p&gt; &lt;p&gt;If anyone has any tips, I would greatly appreciate it.&lt;/p&gt; &lt;p&gt;The rest of a good day.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/z3asir9ujv3c1.png?width=1252&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1f21dda137176642c1990564133d4a42e9699dc1&quot;&gt;model&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/nw21pc9ujv3c1.png?width=1399&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a06817829e714f08f3aaa8bd4604979f3a35d132&quot;&gt;prompt&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/ci897b9ujv3c1.png?width=817&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5c19b74a6246291d0abba2c96b554fd812152f10&quot;&gt;input&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/adorc49ujv3c1.png?width=1055&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fb1564775afaf11e21d8731035fca7bd01855f88&quot;&gt;1º answer&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/taa1q39ujv3c1.png?width=1889&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fd2997205a40511755df45fa981ac8b2467614b6&quot;&gt;2º answer&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/lucky_not_skill&quot;&gt; /u/lucky_not_skill &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1892m87/strange_behavior_in_my_chatbot_when_responding_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1892m87/strange_behavior_in_my_chatbot_when_responding_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1892m87</id><media:thumbnail url="https://b.thumbs.redditmedia.com/uovAEAZ2TYP2qK3ucictDfJRPTYTd-h7xdgQJ3BLB1M.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1892m87/strange_behavior_in_my_chatbot_when_responding_to/" /><updated>2023-12-02T12:21:53+00:00</updated><published>2023-12-02T12:21:53+00:00</published><title>Strange behavior in my chatbot when responding to questions.</title></entry><entry><author><name>/u/heybigeyes123</name><uri>https://www.reddit.com/user/heybigeyes123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Since its an open source wrapper, wondering what is their revenue model?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/heybigeyes123&quot;&gt; /u/heybigeyes123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188znbs/how_does_langchain_make_money/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188znbs/how_does_langchain_make_money/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_188znbs</id><link href="https://www.reddit.com/r/LangChain/comments/188znbs/how_does_langchain_make_money/" /><updated>2023-12-02T08:54:37+00:00</updated><published>2023-12-02T08:54:37+00:00</published><title>How does Langchain make money?</title></entry><entry><author><name>/u/xixixao</name><uri>https://www.reddit.com/user/xixixao</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all, here&amp;#39;s a walkthrough for building an AI chat with context retrieval using LangChain, Convex for db and vector search and Open AI for embedding and LLM: &lt;a href=&quot;https://stack.convex.dev/ai-chat-using-langchain-and-convex&quot;&gt;https://stack.convex.dev/ai-chat-using-langchain-and-convex&lt;/a&gt;&lt;br/&gt; You can clone the repo here: &lt;a href=&quot;https://github.com/get-convex/convex-ai-chat-langchain&quot;&gt;https://github.com/get-convex/convex-ai-chat-langchain&lt;/a&gt;&lt;br/&gt; And you can play with a live version of the chat in our docs: &lt;a href=&quot;https://docs.convex.dev/&quot;&gt;https://docs.convex.dev/&lt;/a&gt;&lt;br/&gt; This is all in TypeScript.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/xixixao&quot;&gt; /u/xixixao &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188nfr8/build_ai_rag_chat_using_langchain_and_convex/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188nfr8/build_ai_rag_chat_using_langchain_and_convex/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_188nfr8</id><link href="https://www.reddit.com/r/LangChain/comments/188nfr8/build_ai_rag_chat_using_langchain_and_convex/" /><updated>2023-12-01T21:49:08+00:00</updated><published>2023-12-01T21:49:08+00:00</published><title>Build AI RAG Chat using LangChain and Convex</title></entry><entry><author><name>/u/Fabianslife</name><uri>https://www.reddit.com/user/Fabianslife</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I just started out with langchains and hybrid models after having used LLM for quite some time.&lt;/p&gt; &lt;p&gt;Now I am searching for a good way to load a complex medical guideline (~500 pages) of PDF into a chroma DB. PyPDF does not really work to good, as a lot of context gets lost when only one page is returned. &lt;/p&gt; &lt;p&gt;Any idea how to approach this specific project?&lt;/p&gt; &lt;p&gt;Thank you 😊&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fabianslife&quot;&gt; /u/Fabianslife &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188fwqo/i_want_to_load_and_encode_large_medical_texts/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188fwqo/i_want_to_load_and_encode_large_medical_texts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_188fwqo</id><link href="https://www.reddit.com/r/LangChain/comments/188fwqo/i_want_to_load_and_encode_large_medical_texts/" /><updated>2023-12-01T16:23:54+00:00</updated><published>2023-12-01T16:23:54+00:00</published><title>I want to load and encode large medical texts</title></entry><entry><author><name>/u/DonGuillotine</name><uri>https://www.reddit.com/user/DonGuillotine</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been in a couple of AI hackathons but I felt they lacked a focus on the complex applications of LLMs (Large Language Models) which many of us here are passionate about.&lt;/p&gt; &lt;p&gt;I recently discovered the &amp;#39;TruEra Challenge&amp;#39; by lablab.ai, which seems like an amazing opportunity for anyone interested in pushing the boundaries of what we can do with LLMs. This hackathon focuses on building LLM application with Google&amp;#39;s Vertex AI and TruLens for Evaluation and monitoring of models with free API credits.&lt;/p&gt; &lt;p&gt;I&amp;#39;m seriously considering joining, could this be the kind of environment where we can test out some experimental LangChain ideas? Keen to hear if anyone else is thinking of participating or has any thoughts.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DonGuillotine&quot;&gt; /u/DonGuillotine &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188hd5w/i_will_be_using_langchain_for_an_ai_hackathon/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188hd5w/i_will_be_using_langchain_for_an_ai_hackathon/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_188hd5w</id><link href="https://www.reddit.com/r/LangChain/comments/188hd5w/i_will_be_using_langchain_for_an_ai_hackathon/" /><updated>2023-12-01T17:26:17+00:00</updated><published>2023-12-01T17:26:17+00:00</published><title>I will be using LangChain for an AI Hackathon Challenge!</title></entry><entry><author><name>/u/TalhaZubair147</name><uri>https://www.reddit.com/user/TalhaZubair147</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://docs.ai21.com/docs/text-segmentation-api#features&quot;&gt;https://docs.ai21.com/docs/text-segmentation-api#features&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Anyone used this ? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TalhaZubair147&quot;&gt; /u/TalhaZubair147 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18877lh/is_this_text_segmentation_api_is_the_best_way_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18877lh/is_this_text_segmentation_api_is_the_best_way_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18877lh</id><link href="https://www.reddit.com/r/LangChain/comments/18877lh/is_this_text_segmentation_api_is_the_best_way_to/" /><updated>2023-12-01T08:47:00+00:00</updated><published>2023-12-01T08:47:00+00:00</published><title>Is this Text SEgmentation API is the best way to analyze which chunk size works better for our data ?</title></entry><entry><author><name>/u/CookingATeam</name><uri>https://www.reddit.com/user/CookingATeam</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, my name is Leon. I am looking for someone who is good with these AI stuff to finish off a AI chat bot I am building. I am putting up a team for a business in the return of shares of this project. The project is done almost 70%. I want someone who could make the conversation to be taken in a flow like how I want. I can share more deets in DMs.&lt;/p&gt; &lt;p&gt;atm I am selling it for $500/monthly (I made about 12 sales on launch and had to refund it cuz of NSFW content) and use OpenAI&amp;#39;s API&amp;#39;s which kind of screwed it over. I tried creating it with pygmalion and it is okayish. The first sales I made were with people whom I know off. If anyone is interested in working with me I can give a share of 15% and building a conversation flow would be the only thing you will need. I can make more sales easily with this project and I know where and how to sell.&lt;/p&gt; &lt;p&gt;I am sorry for my bad English since I am not a native speaker. The bot will be NSFW and prefer using open source LLMs. If you think you are a good fit DM me here or on my Telegram (@ packerxyz) for a faster response :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CookingATeam&quot;&gt; /u/CookingATeam &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18827bf/building_ai_chatbots/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18827bf/building_ai_chatbots/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18827bf</id><link href="https://www.reddit.com/r/LangChain/comments/18827bf/building_ai_chatbots/" /><updated>2023-12-01T03:50:20+00:00</updated><published>2023-12-01T03:50:20+00:00</published><title>Building AI chatbots</title></entry><entry><author><name>/u/chellycd</name><uri>https://www.reddit.com/user/chellycd</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, &lt;/p&gt; &lt;p&gt;I am looking for some suggestions on how to go about implementing an LLM based tool as described below. I&amp;#39;ve been looking around but I have not come across something similar. I&amp;#39;ve been using Langchain for other use cases and it seems like it might be useful for this problem however I am not sure. &lt;/p&gt; &lt;p&gt;Here is a generic description of what I want to do:&lt;/p&gt; &lt;p&gt;I want to use an LLM to understand, explain and convert instructions from one system to another. &lt;/p&gt; &lt;p&gt;Assuming the following: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;I have an old system for which there are many different instruction sets that define various jobs in that system. &lt;/li&gt; &lt;li&gt;I have a new system that has the same capabilities as the old, but it has a different instruction set.&lt;/li&gt; &lt;li&gt;My LLM of choice knows very little about the old system, however knows a lot about the new system. &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;What I want to do is provide the LLM with knowledge about the old system. For example, PDF manuals, text descriptions of the instruction set, potential text examples of what the old instruction looks like in the new system. &lt;/p&gt; &lt;p&gt;Once the above is accomplished, I want to be able to send these job instruction sets to the LLM and ask it to convert them to the new system. &lt;/p&gt; &lt;p&gt;Using RAG seems like a potential way to do this however this isn&amp;#39;t a Q&amp;amp;A or summarization use case. &lt;/p&gt; &lt;p&gt;I want the LLM to use the extra knowledge given to it, combine with the specific conversion request and have it output the new instructions set. &lt;/p&gt; &lt;p&gt;Does it make sense to use RAG and something like the Conversational Retrieval QA for this? Would this work if I create a prompt instructing the model not to be a question and answer assistant but to use the knowledge in the context to assist in the request? What sort of retriever would make sense in this case? &lt;/p&gt; &lt;p&gt;I am considering creating a prototype to try this however I am not confidant it&amp;#39;s not going to be a waste of time. &lt;/p&gt; &lt;p&gt;Thanks in advance. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/chellycd&quot;&gt; /u/chellycd &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188141p/looking_for_advice_giving_a_llm_obscure_knowledge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/188141p/looking_for_advice_giving_a_llm_obscure_knowledge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_188141p</id><link href="https://www.reddit.com/r/LangChain/comments/188141p/looking_for_advice_giving_a_llm_obscure_knowledge/" /><updated>2023-12-01T02:55:52+00:00</updated><published>2023-12-01T02:55:52+00:00</published><title>Looking for advice: Giving a LLM obscure knowledge</title></entry></feed>