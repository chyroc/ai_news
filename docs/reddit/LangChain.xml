<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-03-20T17:47:42+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/redfuel2</name><uri>https://www.reddit.com/user/redfuel2</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m embarking on a project that requires a fresh start, and I find myself at a crossroads trying to decide on the optimal technology stack. The core objective is to enable conversations with a database using natural language, aiming for precise outcomes. This involves working with tabular data, applying filters, and conducting semantic searches.&lt;/p&gt; &lt;p&gt;Given the plethora of options out there, from graph databases and SQLCoder models to Retrieval-Augmented Generation (RAG) techniques, making a choice feels overwhelming. Each of these technologies brings something unique to the table, but I&amp;#39;m looking for a solution that balances ease of integration, scalability, and, most importantly, the ability to understand and process natural language queries effectively.&lt;/p&gt; &lt;p&gt;I would greatly appreciate your insights, experiences, or any advice you could share on this matter. Which stack or combination of technologies have you found to be the most effective for interacting with databases through natural language? Any pitfalls or success stories you could share would also be incredibly helpful as I navigate through these options.&lt;/p&gt; &lt;p&gt;Thank you in advance for your time and help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/redfuel2&quot;&gt; /u/redfuel2 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjf4xd/seeking_the_ideal_stack_for_natural_language/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjf4xd/seeking_the_ideal_stack_for_natural_language/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bjf4xd</id><link href="https://www.reddit.com/r/LangChain/comments/1bjf4xd/seeking_the_ideal_stack_for_natural_language/" /><updated>2024-03-20T14:43:52+00:00</updated><published>2024-03-20T14:43:52+00:00</published><title>Seeking the Ideal Stack for Natural Language Database Interactions</title></entry><entry><author><name>/u/HappyDataGuy</name><uri>https://www.reddit.com/user/HappyDataGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HappyDataGuy&quot;&gt; /u/HappyDataGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/LLMDevs/comments/1bjctuz/has_anyone_used_dspy_for_rag_how_does_it_compare/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjcun4/has_anyone_used_dspy_for_rag_how_does_it_compare/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bjcun4</id><link href="https://www.reddit.com/r/LangChain/comments/1bjcun4/has_anyone_used_dspy_for_rag_how_does_it_compare/" /><updated>2024-03-20T13:00:30+00:00</updated><published>2024-03-20T13:00:30+00:00</published><title>Has anyone used dspy for RAG? how does it compare to langchain/llama-index? and how does it &quot;train&quot; an LLM?</title></entry><entry><author><name>/u/VegetableAddendum888</name><uri>https://www.reddit.com/user/VegetableAddendum888</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;If any Colab notebook or github repo available then it will be helpful&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/VegetableAddendum888&quot;&gt; /u/VegetableAddendum888 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjiabv/can_anyone_suggest_a_idea_to_implement_rag_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjiabv/can_anyone_suggest_a_idea_to_implement_rag_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bjiabv</id><link href="https://www.reddit.com/r/LangChain/comments/1bjiabv/can_anyone_suggest_a_idea_to_implement_rag_with/" /><updated>2024-03-20T16:55:26+00:00</updated><published>2024-03-20T16:55:26+00:00</published><title>Can anyone suggest a idea to implement RAG with LLm.Like if the searched query not in RAG data then LLm responses to the query</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;i have built a Langchain RAG app with a local model and now want to be able to run it on a Laptop. I am using a quantized Mixtral Model (Q5_0) and for this I want to conntect 2 GeoForce RTX 4090 to my laptop. As I am a newby (and nooby) in the Hardware topic, is it even possible to connect 2 RTX 4090 to a more or less &amp;quot;normal&amp;quot; Laptop?&lt;/p&gt; &lt;p&gt;The use case would be that the customer tries the (local) application on a standalone device and if he is happy with it he buys more Hardware to host it for production.&lt;/p&gt; &lt;p&gt;At the moment I am running everything on my Macbook with 64GB RAM but I need a solution for a customer with a Windows PC.&lt;/p&gt; &lt;p&gt;One other option would be that the customer just buys a Macbook, but the 2 GeForece RTX 4090 would be a better investment I think because these could further be used for a prodcution setting.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thanks for you suggestions!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bji0np/is_it_possible_to_connect_2_geforce_rtx_4090_to_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bji0np/is_it_possible_to_connect_2_geforce_rtx_4090_to_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bji0np</id><link href="https://www.reddit.com/r/LangChain/comments/1bji0np/is_it_possible_to_connect_2_geforce_rtx_4090_to_a/" /><updated>2024-03-20T16:44:18+00:00</updated><published>2024-03-20T16:44:18+00:00</published><title>is it possible to connect 2 GeForce RTX 4090 to a Laptop?</title></entry><entry><author><name>/u/stargazer1Q84</name><uri>https://www.reddit.com/user/stargazer1Q84</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, I hope it is fine to post questions here. &lt;/p&gt; &lt;p&gt;I am just getting started with output-parsers and I&amp;#39;m impressed with their usefulness when they work properly. I have, however, run into a case where every now and then, a chain returns an error that seems to be related to the JsonOutputParser that I use, as indicated by the following (condensed) error message:&lt;/p&gt; &lt;p&gt;&lt;code&gt;JSONDecodeError&lt;/code&gt;&lt;br/&gt; &lt;code&gt;JsonOutputParser.parse_result(self, result, partial)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;156 # Parse the JSON string into a Python dictionary&lt;/code&gt;&lt;br/&gt; &lt;code&gt;--&amp;gt; 157 parsed = parser(json_str)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;159 return parsed&lt;/code&gt;&lt;br/&gt; &lt;code&gt;122 # If we got here, we ran out of characters to remove&lt;/code&gt;&lt;br/&gt; &lt;code&gt;123 # and still couldn&amp;#39;t parse the string as JSON, so return the parse error&lt;/code&gt;&lt;br/&gt; &lt;code&gt;124 # for the original string.&lt;/code&gt;&lt;br/&gt; &lt;code&gt;--&amp;gt; 125 return json.loads(s, strict=strict)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;According to &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/17hep0o/comment/k6na6nd/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button&quot;&gt;this post here&lt;/a&gt; this could be related to there not being &amp;quot;enough tokens left to fully generate my output&amp;quot;, which seems to be in line with the error message above:&lt;/p&gt; &lt;p&gt;&amp;gt;&lt;code&gt;122 # If we got here, we ran out of characters to remove&lt;/code&gt; &lt;/p&gt; &lt;p&gt;although I am not fully sure what that means or how it can be fixed. &lt;/p&gt; &lt;p&gt;Has anybody encountered this problem before and could offer some guidance? I must admit that I&amp;#39;m feeling kind of stumped, especially since the error can&amp;#39;t be reproduced reliably and only occurs every other time I run my script. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/stargazer1Q84&quot;&gt; /u/stargazer1Q84 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjdjk0/understanding_jsondecodeerror_when_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjdjk0/understanding_jsondecodeerror_when_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bjdjk0</id><link href="https://www.reddit.com/r/LangChain/comments/1bjdjk0/understanding_jsondecodeerror_when_using/" /><updated>2024-03-20T13:33:06+00:00</updated><published>2024-03-20T13:33:06+00:00</published><title>Understanding JSONDecodeError when using JsonOutputParser</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1bjbd36/multiagent_conversation_using_crewai_genai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bjbe0j/multiagent_conversation_using_crewai_genai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bjbe0j</id><link href="https://www.reddit.com/r/LangChain/comments/1bjbe0j/multiagent_conversation_using_crewai_genai/" /><updated>2024-03-20T11:40:44+00:00</updated><published>2024-03-20T11:40:44+00:00</published><title>Multi-Agent Conversation using CrewAI (GenAI)</title></entry><entry><author><name>/u/Thegunsmith98</name><uri>https://www.reddit.com/user/Thegunsmith98</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build an application that takes templates of things like a cover letter , resume , medical research document. Now based on this template I will upload another document containing information to be used to fill the template. However after the model generates a new document following the template and information , the whole alignment of the document is wrong and it doesnt bold the necessary parts. Is there any way to ensure that a model can follow the format for a template like center allignment , bolding the headers , etc. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Thegunsmith98&quot;&gt; /u/Thegunsmith98 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bj6xl3/langchain_usage_doubt_for_document_generation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bj6xl3/langchain_usage_doubt_for_document_generation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bj6xl3</id><link href="https://www.reddit.com/r/LangChain/comments/1bj6xl3/langchain_usage_doubt_for_document_generation/" /><updated>2024-03-20T06:25:51+00:00</updated><published>2024-03-20T06:25:51+00:00</published><title>Langchain Usage doubt for document generation</title></entry><entry><author><name>/u/PreparationSad1717</name><uri>https://www.reddit.com/user/PreparationSad1717</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks, If you are building with LangChain and want to turn your work into sharable chat app in minutes and in pure python, then join the waitlist &lt;a href=&quot;https://cycls.typeform.com/waitlist&quot;&gt;https://cycls.typeform.com/waitlist&lt;/a&gt; .&lt;br/&gt; We&amp;#39;re gearing up for a release in just a few weeks. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/PreparationSad1717&quot;&gt; /u/PreparationSad1717 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bj3qjq/want_to_turn_your_work_into_sharable_chat_app_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bj3qjq/want_to_turn_your_work_into_sharable_chat_app_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bj3qjq</id><link href="https://www.reddit.com/r/LangChain/comments/1bj3qjq/want_to_turn_your_work_into_sharable_chat_app_in/" /><updated>2024-03-20T03:13:12+00:00</updated><published>2024-03-20T03:13:12+00:00</published><title>Want to turn your work into sharable chat app in minutes ?</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;when thinking about RAG evaluation, everybody talks about RAGAS. It is generally nice to have a framework where you can evaluate your RAG workflows. However I tried it with an own local LLM as well as with the gpt-4-turbo model and the results really are not reliable. &lt;/p&gt; &lt;p&gt;I adapted prompts to my language (german) and with my test dataset, the answer_correctness, answer_relevancy scores are often times very low, zero or NaN, even if the answer is completely correct. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Does anyone have similar experiences? &lt;/p&gt; &lt;p&gt;With my experience, I am not feeling comfortable using ragas as results differ heavenly from run to run, so all the evaluation doesn&amp;#39;t really help me. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bijg75/why_is_everyone_using_ragas_for_rag_evaluation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bijg75/why_is_everyone_using_ragas_for_rag_evaluation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bijg75</id><link href="https://www.reddit.com/r/LangChain/comments/1bijg75/why_is_everyone_using_ragas_for_rag_evaluation/" /><updated>2024-03-19T12:49:43+00:00</updated><published>2024-03-19T12:49:43+00:00</published><title>Why is everyone using RAGAS for RAG evaluation? For me it looks very unreliable</title></entry><entry><author><name>/u/TheBroWhoLifts</name><uri>https://www.reddit.com/user/TheBroWhoLifts</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I work in education and envision a way of using RAG to help my students develop their writing. &lt;/p&gt; &lt;p&gt;My vision is to have students keep a digital portfolio of all their writing over the course of the semester or the year. I&amp;#39;d like to then use a RAG/LLM setup to provide students with feedback regarding their writing development over the course of the year. Ultimately, I&amp;#39;d like to load all of their writing into a RAG for my own analysis. I would be running this on an local LM Studio LLM for student privacy. &lt;/p&gt; &lt;p&gt;Is Langchain an appropriate tool to achieve this? Would I be able to set it up to analyze thousands of pages of student work? And can I design it so that it is a conversational interaction with a history window? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TheBroWhoLifts&quot;&gt; /u/TheBroWhoLifts &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bimg0l/high_school_teacher_here_with_a_use_case_question/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bimg0l/high_school_teacher_here_with_a_use_case_question/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bimg0l</id><link href="https://www.reddit.com/r/LangChain/comments/1bimg0l/high_school_teacher_here_with_a_use_case_question/" /><updated>2024-03-19T15:06:18+00:00</updated><published>2024-03-19T15:06:18+00:00</published><title>High school teacher here with a use case question for the educational setting.</title></entry><entry><author><name>/u/logandarknight</name><uri>https://www.reddit.com/user/logandarknight</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello! I have a question I haven’t been able to find online, and was hoping someone could explain it to me. &lt;/p&gt; &lt;p&gt;I need to build a “chatbot” where the user asks questions about history, and the agent must reply with the correct answer. Here’s the thing: The context needs to be fed from certain books, and some pdfs.&lt;/p&gt; &lt;p&gt;Why’s the best way to do this? The objective is to outperform in replying correctly to OpenAI models. Or, which model would be the best (or combination of model + RAG) to get the best result?&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/logandarknight&quot;&gt; /u/logandarknight &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1biwtil/use_case_doubt/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1biwtil/use_case_doubt/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1biwtil</id><link href="https://www.reddit.com/r/LangChain/comments/1biwtil/use_case_doubt/" /><updated>2024-03-19T22:05:22+00:00</updated><published>2024-03-19T22:05:22+00:00</published><title>Use case doubt</title></entry><entry><author><name>/u/DXVA</name><uri>https://www.reddit.com/user/DXVA</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a good way to integrate LangChain with a personal LLM RESTAPI yet?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/17v1rhv/integrating_llm_rest_api_into_a_langchain/&quot;&gt;https://www.reddit.com/r/LangChain/comments/17v1rhv/integrating_llm_rest_api_into_a_langchain/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I saw this post, but it doesn&amp;#39;t explain any of the integration with basic chains like LLMChain. There&amp;#39;re so many integrations, but nothing I see so far for interacting with your own tooling?&lt;/p&gt; &lt;p&gt;The API just has the basic response structure for a LLM, but that should just be one piece of the connection right? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DXVA&quot;&gt; /u/DXVA &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1billcu/integration_with_restapis/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1billcu/integration_with_restapis/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1billcu</id><link href="https://www.reddit.com/r/LangChain/comments/1billcu/integration_with_restapis/" /><updated>2024-03-19T14:28:38+00:00</updated><published>2024-03-19T14:28:38+00:00</published><title>Integration with RESTAPIs?</title></entry><entry><author><name>/u/heybigeyes123</name><uri>https://www.reddit.com/user/heybigeyes123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Where are you guys finding customers to sell your RAG products? What do thesr customers look like?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/heybigeyes123&quot;&gt; /u/heybigeyes123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bitjgv/rag_customers/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bitjgv/rag_customers/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bitjgv</id><link href="https://www.reddit.com/r/LangChain/comments/1bitjgv/rag_customers/" /><updated>2024-03-19T19:54:58+00:00</updated><published>2024-03-19T19:54:58+00:00</published><title>RAG customers</title></entry><entry><author><name>/u/Not-That-rpg</name><uri>https://www.reddit.com/user/Not-That-rpg</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I was just changing an existing langchain workflow from using an OpenAI model to using one from Replicate.&lt;/p&gt; &lt;p&gt;This showed the value of using &lt;code&gt;langchain&lt;/code&gt; because it pretty much Just Worked to change the LLM model constructor I had used originally, and then rerun all my code (in a Jupyter Notebook).&lt;/p&gt; &lt;p&gt;But it only &amp;quot;pretty much&amp;quot; worked: in particular, when I invoked the OpenAI models, I would get an &lt;code&gt;AIMessage&lt;/code&gt; object out of the chain. When I invoke a Replicate model, I am just getting a string.&lt;/p&gt; &lt;p&gt;I imagine that this could cause issues if trying to extend a chain past the Replicate LLM to something like an Output Parser couldn&amp;#39;t it?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Not-That-rpg&quot;&gt; /u/Not-That-rpg &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bish94/should_i_report_this_as_a_bug/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bish94/should_i_report_this_as_a_bug/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bish94</id><link href="https://www.reddit.com/r/LangChain/comments/1bish94/should_i_report_this_as_a_bug/" /><updated>2024-03-19T19:12:17+00:00</updated><published>2024-03-19T19:12:17+00:00</published><title>Should I report this as a bug?</title></entry><entry><author><name>/u/danipudani</name><uri>https://www.reddit.com/user/danipudani</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1biwioh/intro_to_langchain_full_documentation_overview/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/sVTHLyvfg970cr9MD_72wQqkiADi53dPj4mMz7rqK4w.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=362f231282720dbda6fe4de5188bd10440805d1e&quot; alt=&quot;Intro to LangChain - Full Documentation Overview&quot; title=&quot;Intro to LangChain - Full Documentation Overview&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/danipudani&quot;&gt; /u/danipudani &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/dXP841pBcJw?si=w8NWHE6uv-5vzSTq&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1biwioh/intro_to_langchain_full_documentation_overview/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1biwioh</id><media:thumbnail url="https://external-preview.redd.it/sVTHLyvfg970cr9MD_72wQqkiADi53dPj4mMz7rqK4w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=362f231282720dbda6fe4de5188bd10440805d1e" /><link href="https://www.reddit.com/r/LangChain/comments/1biwioh/intro_to_langchain_full_documentation_overview/" /><updated>2024-03-19T21:53:38+00:00</updated><published>2024-03-19T21:53:38+00:00</published><title>Intro to LangChain - Full Documentation Overview</title></entry><entry><author><name>/u/Comprehensive-Pay530</name><uri>https://www.reddit.com/user/Comprehensive-Pay530</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;So I am a lead software engineer in a SaaS startups we are exploring many use cases for implement GenAI solutions and are building most of them inhouse so we are writing a lot of prompts across various teams in product and engineering.&lt;/p&gt; &lt;p&gt;I was trying to explore some best tools for managing and testing prompts for different use cases things i am looking for : &lt;/p&gt; &lt;p&gt;Must have :&lt;br/&gt; 1. UI where PM&amp;#39;s can go and test prompts - here they should be able to test same prompt on different model and a high level overview of cost incurred across these model for the result.&lt;br/&gt; 2. SDK/api to fetch these prompts in code with versing and all for different use-cases.&lt;br/&gt; 3. Dynamic rules for A/B testing of prompts.&lt;/p&gt; &lt;p&gt;Good to have :&lt;br/&gt; Maybe if the tool helps in crafting the prompts, create nested prompts workflows (chain of prompts) , etc.&lt;/p&gt; &lt;p&gt;Basically looking for Launchdarkly type solution for prompts where you can also create dynamic rules to load different prompt feature flag them based on user persona and teams.&lt;/p&gt; &lt;p&gt;Also interested in hearing how teams are managing or doing this is there a better way or something that I am missing?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Comprehensive-Pay530&quot;&gt; /u/Comprehensive-Pay530 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bigg4l/best_prompt_testing_and_management_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bigg4l/best_prompt_testing_and_management_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bigg4l</id><link href="https://www.reddit.com/r/LangChain/comments/1bigg4l/best_prompt_testing_and_management_tools/" /><updated>2024-03-19T09:49:31+00:00</updated><published>2024-03-19T09:49:31+00:00</published><title>Best prompt testing and management tools</title></entry><entry><author><name>/u/Supersam6341</name><uri>https://www.reddit.com/user/Supersam6341</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So I am running langchain on a doc that sometimes has parts of the same answer split into 2 different sections, therefore not in the same chunk. What RAG technique can I use to handle this? I read somewhere that there is a technique where you can include the summaries of the previous chunks into the next chunk, but was not able to find it. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Supersam6341&quot;&gt; /u/Supersam6341 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bi9w3p/chunking_doesnt_have_the_full_answer/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bi9w3p/chunking_doesnt_have_the_full_answer/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bi9w3p</id><link href="https://www.reddit.com/r/LangChain/comments/1bi9w3p/chunking_doesnt_have_the_full_answer/" /><updated>2024-03-19T02:48:48+00:00</updated><published>2024-03-19T02:48:48+00:00</published><title>Chunking doesn’t have the full answer</title></entry><entry><author><name>/u/UsamaHussain99</name><uri>https://www.reddit.com/user/UsamaHussain99</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am working on a chat application in Langchain, Python. The idea is that user submits some pdf files that the chat model is trained on and then asks questions from the model regarding those documents. The embeddings are stored in Chromadb vector database. So effectively a RAG-based solution. &lt;/p&gt; &lt;p&gt;Now, both the creation and storage of embeddings are working fine and also chat is working good. However, I am storing my custom metadata to the embeddings and some ids. The code for that is given as under: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;def read_docs(pdf_file): &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;pdf_loader = PyPDFLoader(pdf_file) pdf_documents = pdf_loader.load()&lt;/p&gt; &lt;p&gt;text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200) documents = text_splitter.split_documents(pdf_documents)&lt;/p&gt; &lt;p&gt;return documents&lt;/p&gt; &lt;pre&gt;&lt;code&gt;def generate_and_store_embeddings(documents, pdf_file, user_id): client = chromadb.PersistentClient(path=&amp;quot;./trained_db&amp;quot;) collection = client.get_or_create_collection(&amp;quot;PDF_Embeddings&amp;quot;, embedding_function=embedding_functions.OpenAIEmbeddingFunction(api_key=config[&amp;quot;OPENAI_API_KEY&amp;quot;], model_name=configs.EMBEDDINGS_MODEL)) now = datetime.now() #custom metadata and ids I want to store along with the embeddings for each pdf metadata = {&amp;quot;source&amp;quot;: pdf_file.filename, &amp;quot;user&amp;quot;: str(user_id), &amp;#39;created_at&amp;#39;: now.strftime(&amp;quot;%d/%m/%Y %H:%M:%S&amp;quot;)} ids = [str(uuid.uuid4()) for _ in range(len(documents))] try: vectordb = Chroma.from_documents( documents, embedding=OpenAIEmbeddings(openai_api_key=config[&amp;quot;OPENAI_API_KEY&amp;quot;], model=configs.EMBEDDINGS_MODEL), persist_directory=&amp;#39;./trained_db&amp;#39;, collection_name = collection.name, client = client, ids = ids, collection_metadata = {item: value for (item, value) in metadata.items()} ) vectordb.persist() except Exception as err: print(f&amp;quot;An error occured: {err=}, {type(err)=}&amp;quot;) return {&amp;quot;answer&amp;quot;: &amp;quot;An error occured while generating embeddings. Please check terminal for more details.&amp;quot;} return vectordb &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now, what I want is to retrieve those ids and metadata associated with the pdf file rather than all the ids/metadata in the collection. This is so that when a user enters the pdf file to delete the embeddings of, I can retrieve the metadata and the ids of &lt;em&gt;that pdf file only&lt;/em&gt; and then delete those embeddings from the collection.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UsamaHussain99&quot;&gt; /u/UsamaHussain99 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bifpp0/how_to_retrieve_ids_and_metadata_associated_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bifpp0/how_to_retrieve_ids_and_metadata_associated_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bifpp0</id><link href="https://www.reddit.com/r/LangChain/comments/1bifpp0/how_to_retrieve_ids_and_metadata_associated_with/" /><updated>2024-03-19T08:55:23+00:00</updated><published>2024-03-19T08:55:23+00:00</published><title>How to retrieve ids and metadata associated with embeddings of a particular file and not just for the entire collection?</title></entry><entry><author><name>/u/major_grooves</name><uri>https://www.reddit.com/user/major_grooves</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Would a data store that is capable of doing entity resolution (ER; link and deduplicate all structured data regarding an entity, each in its own graph) be useful for RAG and LLMs?&lt;/p&gt; &lt;p&gt;We recently had a bunch of people contact us asking if they could use our ER solution as a &amp;quot;source of truth&amp;quot; for LLM RAG. We don&amp;#39;t know much about LLM or RAG so have been trying to get up to speed quickly, so wanted to ask the question here - if you work on RAG do you see a use case for a fuzzy search engine for structured data (which is effectively what our solution is), where the underlying data is considered a &amp;quot;source of truth&amp;quot;?&lt;/p&gt; &lt;p&gt;Probably should mention the underlying data is deduplicated and linked (and searched) using rules based on various phonetic, similarity and distance algorithms (including Cosine). We don&amp;#39;t use vectors or embeddings in our matching, although we plan to later.&lt;/p&gt; &lt;p&gt;We are just now trying to evaluate whether we should double down on the LLM/RAG space and build a LangChain connector for our solution.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/major_grooves&quot;&gt; /u/major_grooves &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bih5kc/is_there_a_need_for_entitybased_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bih5kc/is_there_a_need_for_entitybased_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bih5kc</id><link href="https://www.reddit.com/r/LangChain/comments/1bih5kc/is_there_a_need_for_entitybased_rag/" /><updated>2024-03-19T10:36:17+00:00</updated><published>2024-03-19T10:36:17+00:00</published><title>Is there a need for entity-based RAG?</title></entry><entry><author><name>/u/o3omoomin</name><uri>https://www.reddit.com/user/o3omoomin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I want to implement a chatbot. This will implement a QA chatbot. There are quite a few retrievers in the docs below. What I want is a retriever that gives very accurate answers. When I need to implement a QA chatbot, what is the most popular retriever? &lt;a href=&quot;https://docs.llamaindex.ai/en/stable/module_guides/querying/retriever/retrievers.html&quot;&gt;https://docs.llamaindex.ai/en/stable/module_guides/querying/retriever/retrievers.html&lt;/a&gt; (수정됨)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/o3omoomin&quot;&gt; /u/o3omoomin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bi8n3b/llama_index_which_retriever_has_the_most_accurate/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bi8n3b/llama_index_which_retriever_has_the_most_accurate/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bi8n3b</id><link href="https://www.reddit.com/r/LangChain/comments/1bi8n3b/llama_index_which_retriever_has_the_most_accurate/" /><updated>2024-03-19T01:48:32+00:00</updated><published>2024-03-19T01:48:32+00:00</published><title>llama index - Which retriever has the most accurate answers and best performance?</title></entry><entry><author><name>/u/Money_Mycologist4939</name><uri>https://www.reddit.com/user/Money_Mycologist4939</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I created a vector store using the AzureCosmosDBVectorSearch class as explained in the langchain tutorial. I load the docs, split them and create the index as described in the tutorial. Once created the index I initialize the vector store using the method from_string. When I run the similarity search for the first time it gives me back the list of relevant docs as intended, however once I start again the same query I get back just the first doc of that list, as if the other docs were not retrieved at all, being not present in the list. As anyone had the same issue as me??&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Money_Mycologist4939&quot;&gt; /u/Money_Mycologist4939 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bifsol/azure_cosmos_vector_store_class_does_not_work/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bifsol/azure_cosmos_vector_store_class_does_not_work/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bifsol</id><link href="https://www.reddit.com/r/LangChain/comments/1bifsol/azure_cosmos_vector_store_class_does_not_work/" /><updated>2024-03-19T09:01:15+00:00</updated><published>2024-03-19T09:01:15+00:00</published><title>Azure cosmos vector store class does not work properly</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I built a RAG app with complex pdfs and now want to find the best chunking strategy for complex pdfs. Here I wanted to discuss if (from your experience) the RecursiveCharaterSplitter from Langchain or chunking the docs by title with the UnstructuredFileLoader from Langchain worked better?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;This is how I implemented both but I am not sure which one I should use. Generally I think Unstructured should be better but when evaluating results with RAGAS, somehow the RecursiveCharacterSplitter is better.&lt;/p&gt; &lt;p&gt;&lt;code&gt;if chunking_strategy == &amp;quot;recursive&amp;quot;:&lt;/code&gt;&lt;br/&gt; &lt;code&gt;loader = DirectoryLoader(directory_path,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;glob=&amp;#39;*.pdf&amp;#39;,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;loader_cls=PyPDFLoader)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;documents = loader.load()&lt;/code&gt;&lt;br/&gt; &lt;code&gt;text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;chunk_overlap=chunk_overlap,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;#length_function = len&lt;/code&gt;&lt;br/&gt; &lt;code&gt;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;texts = text_splitter.split_documents(documents)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;if chunking_strategy == &amp;quot;unstructured&amp;quot;:&lt;/code&gt;&lt;br/&gt; &lt;code&gt;texts = []&lt;/code&gt;&lt;br/&gt; &lt;code&gt;for i in files:&lt;/code&gt;&lt;br/&gt; &lt;code&gt;loader = UnstructuredFileLoader(&lt;/code&gt;&lt;br/&gt; &lt;code&gt;i, strategy=&amp;quot;hi_res&amp;quot;, mode=&amp;quot;elements&amp;quot;, chunking_strategy=&amp;quot;by_title&amp;quot;,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;ocr_languages=&amp;quot;eng+deu&amp;quot;,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;max_characters=4000,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;new_after_n_chars=3800,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;combine_text_under_n_chars=2000&lt;/code&gt;&lt;br/&gt; &lt;code&gt;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;docs = loader.load()&lt;/code&gt;&lt;br/&gt; &lt;code&gt;texts.append(docs)&lt;/code&gt; &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bhv87c/complex_pdf_chunking_which_one_works_better_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bhv87c/complex_pdf_chunking_which_one_works_better_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bhv87c</id><link href="https://www.reddit.com/r/LangChain/comments/1bhv87c/complex_pdf_chunking_which_one_works_better_for/" /><updated>2024-03-18T16:39:38+00:00</updated><published>2024-03-18T16:39:38+00:00</published><title>Complex PDF Chunking: Which one works better for you: RecursiveCharactersplitter or Unstructured.io</title></entry><entry><author><name>/u/Traditional_Swan_326</name><uri>https://www.reddit.com/user/Traditional_Swan_326</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bi07u3/open_source_rag_observability_in_llama_index_with/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/a4OFe5GeSRfMil4Q8wrTVzhvBrDetwOfkWWAxZCI0B4.jpg&quot; alt=&quot;open source RAG observability in llama index with 2 lines of code&quot; title=&quot;open source RAG observability in llama index with 2 lines of code&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Traditional_Swan_326&quot;&gt; /u/Traditional_Swan_326 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.llamaindex.ai/blog/one-click-open-source-rag-observability-with-langfuse&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bi07u3/open_source_rag_observability_in_llama_index_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1bi07u3</id><media:thumbnail url="https://a.thumbs.redditmedia.com/a4OFe5GeSRfMil4Q8wrTVzhvBrDetwOfkWWAxZCI0B4.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1bi07u3/open_source_rag_observability_in_llama_index_with/" /><updated>2024-03-18T19:58:17+00:00</updated><published>2024-03-18T19:58:17+00:00</published><title>open source RAG observability in llama index with 2 lines of code</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, check out how I built a Multi-Agent Debate app which intakes a debate topic, creates 2 opponents, have a debate and than comes a jury who decide which party wins. Checkout the full code explanation here : &lt;a href=&quot;https://youtu.be/tEkQmem64eM?si=4nkNMKtqxFq-yuJk&quot;&gt;https://youtu.be/tEkQmem64eM?si=4nkNMKtqxFq-yuJk&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bhscn6/multiagent_debate_using_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bhscn6/multiagent_debate_using_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bhscn6</id><link href="https://www.reddit.com/r/LangChain/comments/1bhscn6/multiagent_debate_using_langgraph/" /><updated>2024-03-18T14:40:43+00:00</updated><published>2024-03-18T14:40:43+00:00</published><title>Multi-Agent Debate using LangGraph</title></entry><entry><author><name>/u/SneakyZi0</name><uri>https://www.reddit.com/user/SneakyZi0</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Greetings, i am trying to find whats the best way to tackle this problem. &lt;/p&gt; &lt;p&gt;Dont know if i should start with local LLMs (models from hugging face etc), or go with text summarization APIs which i think will have limitations due to the text technicalities and size. Or finally go with the big boys gpt-4,claudie etc. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I would love to have an up to date answer from people that have tried simmilar approaches and what would be the best cost-effective way to go about it. much appreciated. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;PS: I dont have the technical capability to go for a full custom model on my own, i am a dev but dont have huge programming experience on the AI stuff to optimize parameters on my own.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SneakyZi0&quot;&gt; /u/SneakyZi0 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bhomrn/text_summarization_of_technical_reports_more_than/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bhomrn/text_summarization_of_technical_reports_more_than/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bhomrn</id><link href="https://www.reddit.com/r/LangChain/comments/1bhomrn/text_summarization_of_technical_reports_more_than/" /><updated>2024-03-18T11:40:09+00:00</updated><published>2024-03-18T11:40:09+00:00</published><title>Text summarization of technical reports more than 30 pages</title></entry></feed>