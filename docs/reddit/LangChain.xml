<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-23T23:19:58+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/the_snow_princess</name><uri>https://www.reddit.com/user/the_snow_princess</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dp7e2/awesome_list_of_ai_agents_and_agentbuilding/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/amFtcWVvdHg1N2VjMVsrKOVaRlL6CSzyiPBSRcju48PidCE7SUNuW3Vur3do.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e62e5d6e5fecb8bb694c9fa2a2cb9a94e428c0e4&quot; alt=&quot;Awesome list of AI agents and agent-building frameworks&quot; title=&quot;Awesome list of AI agents and agent-building frameworks&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/the_snow_princess&quot;&gt; /u/the_snow_princess &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/x8gio2o9v6ec1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dp7e2/awesome_list_of_ai_agents_and_agentbuilding/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19dp7e2</id><media:thumbnail url="https://external-preview.redd.it/amFtcWVvdHg1N2VjMVsrKOVaRlL6CSzyiPBSRcju48PidCE7SUNuW3Vur3do.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e62e5d6e5fecb8bb694c9fa2a2cb9a94e428c0e4" /><link href="https://www.reddit.com/r/LangChain/comments/19dp7e2/awesome_list_of_ai_agents_and_agentbuilding/" /><updated>2024-01-23T14:07:31+00:00</updated><published>2024-01-23T14:07:31+00:00</published><title>Awesome list of AI agents and agent-building frameworks</title></entry><entry><author><name>/u/DBAdvice123</name><uri>https://www.reddit.com/user/DBAdvice123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Saw this webinar that is around building a real-time RAG app on Wikipedia with LangChain.js, Vercel, and Astra DB. Looks interesting and is set to go tomorrow: &lt;a href=&quot;https://dtsx.io/498383Z&quot;&gt;https://dtsx.io/498383Z&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DBAdvice123&quot;&gt; /u/DBAdvice123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dvjtb/wikichat/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dvjtb/wikichat/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dvjtb</id><link href="https://www.reddit.com/r/LangChain/comments/19dvjtb/wikichat/" /><updated>2024-01-23T18:43:33+00:00</updated><published>2024-01-23T18:43:33+00:00</published><title>WikiChat</title></entry><entry><author><name>/u/Revolutionary_Let833</name><uri>https://www.reddit.com/user/Revolutionary_Let833</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m creating a demo for a client - it will involve a web ui, a conversational component and some knowledge retrieval. Any insight into what is the best way to set this up? Whether for an MVP or Production grade software? &lt;/p&gt; &lt;p&gt;I really do like Langchain for its flexibility (no vendor lock-in) but am also open to Assistants API. I&amp;#39;m wondering specifically what is the best &amp;#39;front end&amp;#39; chat interface (Botpress ,Voiceflow, custom JS) and how others are setting up a seamless experience while having chatGPT like power. &lt;/p&gt; &lt;p&gt;Just looking to think about tradeoffs as I plan to design the service.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Revolutionary_Let833&quot;&gt; /u/Revolutionary_Let833 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e0853/creating_demo_conversational_ai_for_client/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e0853/creating_demo_conversational_ai_for_client/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19e0853</id><link href="https://www.reddit.com/r/LangChain/comments/19e0853/creating_demo_conversational_ai_for_client/" /><updated>2024-01-23T21:56:36+00:00</updated><published>2024-01-23T21:56:36+00:00</published><title>Creating demo conversational AI for Client</title></entry><entry><author><name>/u/Capable_Juice98</name><uri>https://www.reddit.com/user/Capable_Juice98</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Currently, my chatbot can generate answers for current questions using the context (acc to prompt). Now I want to use the conversational part i.e., the chat history part to make it more sensible. How is that possible?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Capable_Juice98&quot;&gt; /u/Capable_Juice98 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dya0n/can_we_use_conversation_history_in_rag_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dya0n/can_we_use_conversation_history_in_rag_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dya0n</id><link href="https://www.reddit.com/r/LangChain/comments/19dya0n/can_we_use_conversation_history_in_rag_chain/" /><updated>2024-01-23T20:36:17+00:00</updated><published>2024-01-23T20:36:17+00:00</published><title>Can we use Conversation History in rag chain?</title></entry><entry><author><name>/u/2BucChuck</name><uri>https://www.reddit.com/user/2BucChuck</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have had to upgrade pinecone-client and dependencies in conjunction with langchain for vectorstores. In doing so ran into a conflict with the imports for pinecone import Pinecone and langchain_community.vectorstores import Pinecone &lt;/p&gt; &lt;p&gt;where the class config appears incompatible now and errors with api_key unexpected on Pinecone client creation unless I remove the langchain import line which of course causes the vectorstore setup to fail. &lt;/p&gt; &lt;p&gt;Running the following versions: Pinecone-client 3.0.1 Langchain 0.1.3 Langchain-community 0.0.14 Langchain-core 0.1.15&lt;/p&gt; &lt;p&gt;Any input greatly appreciated - this update made current chatbot inoperable &lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/2BucChuck&quot;&gt; /u/2BucChuck &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dxzv2/updated_pinecone_client_issue_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dxzv2/updated_pinecone_client_issue_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dxzv2</id><link href="https://www.reddit.com/r/LangChain/comments/19dxzv2/updated_pinecone_client_issue_with_langchain/" /><updated>2024-01-23T20:24:40+00:00</updated><published>2024-01-23T20:24:40+00:00</published><title>Updated Pinecone client issue with Langchain vectorstore</title></entry><entry><author><name>/u/megaeren37</name><uri>https://www.reddit.com/user/megaeren37</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I&amp;#39;m using Elasticsearch to maintain a set of documents. When a user types in a query, I perform a lexical (+semantic) search and output the results. So far I&amp;#39;ve had good success with this approach. However, I now want to perform a post-retrieval re-ranking using Cohere. I&amp;#39;m curious as to how should I paginate the results, or if it&amp;#39;s even possible in the first-place?&lt;br/&gt; Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/megaeren37&quot;&gt; /u/megaeren37 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19du39n/reranking_and_pagination/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19du39n/reranking_and_pagination/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19du39n</id><link href="https://www.reddit.com/r/LangChain/comments/19du39n/reranking_and_pagination/" /><updated>2024-01-23T17:45:09+00:00</updated><published>2024-01-23T17:45:09+00:00</published><title>Re-ranking and pagination</title></entry><entry><author><name>/u/giorgiozer</name><uri>https://www.reddit.com/user/giorgiozer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on embedding some documents (lots of it) and I was debugging my code, running it to check if the AzureOpenEmbeddingAPI works, here&amp;#39;s the code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt; loader = DataFrameLoader(df, page_content_column=&amp;quot;desc_cleaned&amp;quot;) splitter = RecursiveCharacterTextSplitter( chunk_size=1000, chunk_overlap=200 ) splits = splitter.split_documents(loader.load()) vectorstore = Chroma.from_documents(documents=splits, embedding=AzureOpenAIEmbeddings(show_progress_bar=True)) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;So now I got my debugger on, and I&amp;#39;m trying to save the vector store so that I don&amp;#39;t have to sit through the whole thing again, but doing `vectorstore.persist()` does not seem to work, and it does not throw an error either.&lt;/p&gt; &lt;p&gt;Do you guys have an idea on how I could save the store locally?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/giorgiozer&quot;&gt; /u/giorgiozer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dsmf1/help_cant_save_the_chromadb_vector_store/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dsmf1/help_cant_save_the_chromadb_vector_store/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dsmf1</id><link href="https://www.reddit.com/r/LangChain/comments/19dsmf1/help_cant_save_the_chromadb_vector_store/" /><updated>2024-01-23T16:40:28+00:00</updated><published>2024-01-23T16:40:28+00:00</published><title>[HELP] Can't save the chromadb vector store</title></entry><entry><author><name>/u/Money_Mycologist4939</name><uri>https://www.reddit.com/user/Money_Mycologist4939</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How can I build a custom retrieval chatbot chain using the LCEL and not the available default langchain chains?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Money_Mycologist4939&quot;&gt; /u/Money_Mycologist4939 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19drvmj/memory_handling_in_lcel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19drvmj/memory_handling_in_lcel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19drvmj</id><link href="https://www.reddit.com/r/LangChain/comments/19drvmj/memory_handling_in_lcel/" /><updated>2024-01-23T16:09:22+00:00</updated><published>2024-01-23T16:09:22+00:00</published><title>Memory handling in LCEL.</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, &lt;/p&gt; &lt;p&gt;I wanted to find a more clean way to load my PDFs than PyPDF loader and came across &lt;a href=&quot;https://Unstructured.io&quot;&gt;Unstructured.io&lt;/a&gt; wit Langchain. I am loading my PDF like this: &lt;/p&gt; &lt;p&gt;&lt;code&gt;# UnstructuredIO Test&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain_community.document_loaders import UnstructuredFileLoader&lt;/code&gt;&lt;br/&gt; &lt;code&gt;loader = UnstructuredFileLoader(&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;my.pdf&amp;quot;, mode=&amp;quot;elements&amp;quot;&lt;/code&gt;&lt;br/&gt; &lt;code&gt;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;docs = loader.load()&lt;/code&gt;&lt;br/&gt; &lt;code&gt;docs[:5]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Now I figured out that this loads every line of the PDF into a list entry (PDF with 22 pages ended up with 580 entries). But how can I extract the text of whole pages to be able to further use it for RAG?&lt;/p&gt; &lt;p&gt;With only reading on one line each, I think context gets lost.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dk7mc/langchain_unstructuredfileloader_load_pdfs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dk7mc/langchain_unstructuredfileloader_load_pdfs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dk7mc</id><link href="https://www.reddit.com/r/LangChain/comments/19dk7mc/langchain_unstructuredfileloader_load_pdfs/" /><updated>2024-01-23T09:00:42+00:00</updated><published>2024-01-23T09:00:42+00:00</published><title>Langchain UnstructuredFileLoader: Load PDFs</title></entry><entry><author><name>/u/Aggressive_Tea9664</name><uri>https://www.reddit.com/user/Aggressive_Tea9664</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello all, May I know what is the metric used to compute similarity for QDrant Retriever, with a search_type=similarity ? Would it be cosine similarity? L2?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Aggressive_Tea9664&quot;&gt; /u/Aggressive_Tea9664 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dmjn0/qdrant_similarity_search_metric/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dmjn0/qdrant_similarity_search_metric/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dmjn0</id><link href="https://www.reddit.com/r/LangChain/comments/19dmjn0/qdrant_similarity_search_metric/" /><updated>2024-01-23T11:41:46+00:00</updated><published>2024-01-23T11:41:46+00:00</published><title>Qdrant Similarity Search Metric</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I understand that Chunking for RAG is very important for longer texts. But I was wondering why it is common that PDFs also get chunked. &lt;/p&gt; &lt;p&gt;For example, many PDF pages in my use case have less than 2000 characters. When reading in the PDF, the context over pages gets lost anyways, because PyPDFLoader for example stores every page separately. As 2000 chars isn&amp;#39;t that much and I want to get as many context as possible (so maximum 1 page), why should I consider chunking?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dip1l/rag_with_pdfs_why_chunking_and_not_using_whole/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dip1l/rag_with_pdfs_why_chunking_and_not_using_whole/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dip1l</id><link href="https://www.reddit.com/r/LangChain/comments/19dip1l/rag_with_pdfs_why_chunking_and_not_using_whole/" /><updated>2024-01-23T07:11:32+00:00</updated><published>2024-01-23T07:11:32+00:00</published><title>RAG with PDFs: Why chunking and not using whole page</title></entry><entry><author><name>/u/Appropriate_Egg6118</name><uri>https://www.reddit.com/user/Appropriate_Egg6118</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have built RAG chatbot entirely from scratch NO langchain involved. The docs are retrieved for every query, I want to Stop docs Retrieval for Greeting messenges.&lt;/p&gt; &lt;p&gt;I have tried conditional check by storing all Greeting messages in a list which worked fine But what if user enters different greeting message that&amp;#39;s not in list, what if he enters with spelling mistakes. This will definitely fail.&lt;/p&gt; &lt;p&gt;How to handle this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Appropriate_Egg6118&quot;&gt; /u/Appropriate_Egg6118 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d9d6t/how_to_stop_document_retrieval_in_a_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d9d6t/how_to_stop_document_retrieval_in_a_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19d9d6t</id><link href="https://www.reddit.com/r/LangChain/comments/19d9d6t/how_to_stop_document_retrieval_in_a_rag_chatbot/" /><updated>2024-01-22T23:08:36+00:00</updated><published>2024-01-22T23:08:36+00:00</published><title>How to Stop Document Retrieval in a RAG chatbot for Greeting input from user Like Hi, Hello, Good Morning etc</title></entry><entry><author><name>/u/altruios</name><uri>https://www.reddit.com/user/altruios</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to embed a prompt, invert the sign of each embedding, then turn that new embedding back into text.&lt;/p&gt; &lt;p&gt;I am getting stuck on getting the embedding transformed back into words...&lt;/p&gt; &lt;p&gt;how do you do that?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/altruios&quot;&gt; /u/altruios &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d3z4g/vec2word/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d3z4g/vec2word/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19d3z4g</id><link href="https://www.reddit.com/r/LangChain/comments/19d3z4g/vec2word/" /><updated>2024-01-22T19:28:13+00:00</updated><published>2024-01-22T19:28:13+00:00</published><title>vec2word</title></entry><entry><author><name>/u/WinterStatistician70</name><uri>https://www.reddit.com/user/WinterStatistician70</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am building a chatbot using Azure OpenAI API. Is there a way I can integrate the memory module of the Langchain framework into my chat application? Currently, I am using summarization to implement the short-term memory but I would like to expand the memory implications to a long-term memory and also manage the summarization using the buffer memory methods in Langchain. My conversations are currently stored in a Redis cache.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/WinterStatistician70&quot;&gt; /u/WinterStatistician70 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d72dg/llm_based_chatbots_with_memory/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d72dg/llm_based_chatbots_with_memory/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19d72dg</id><link href="https://www.reddit.com/r/LangChain/comments/19d72dg/llm_based_chatbots_with_memory/" /><updated>2024-01-22T21:34:36+00:00</updated><published>2024-01-22T21:34:36+00:00</published><title>LLM based ChatBots with Memory</title></entry><entry><author><name>/u/Accomplished_Pin_626</name><uri>https://www.reddit.com/user/Accomplished_Pin_626</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build rag solution for a user guide I have worked with chromadb and OpenAI but I want to build something robust step by step Can you suggest something for me Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Accomplished_Pin_626&quot;&gt; /u/Accomplished_Pin_626 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d11xt/create_full_rag_solution_tutorial/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d11xt/create_full_rag_solution_tutorial/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19d11xt</id><link href="https://www.reddit.com/r/LangChain/comments/19d11xt/create_full_rag_solution_tutorial/" /><updated>2024-01-22T17:29:21+00:00</updated><published>2024-01-22T17:29:21+00:00</published><title>Create full RAG solution tutorial</title></entry><entry><author><name>/u/TelephoneParty5934</name><uri>https://www.reddit.com/user/TelephoneParty5934</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently trying to build an app (python) using local llms I tried Mistral 7b instruct. I have tried few prompts asking the model to generate code snippets and functions. But now i have to test the model if it can give source code to build an app (let&amp;#39;s say a chatbot for instance). Basically the input would be a use case in natural language&lt;/p&gt; &lt;p&gt;For example: Build an end to end chatbot that can answer customer&amp;#39;s queries and help with the issues.&lt;/p&gt; &lt;p&gt;What should be my approach ? How to get this done ? Please provide suggestions since I&amp;#39;m really new to LLMs. If possible provide any tutorials or guides.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TelephoneParty5934&quot;&gt; /u/TelephoneParty5934 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d64ek/developing_an_app_using_open_source_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d64ek/developing_an_app_using_open_source_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19d64ek</id><link href="https://www.reddit.com/r/LangChain/comments/19d64ek/developing_an_app_using_open_source_llms/" /><updated>2024-01-22T20:57:04+00:00</updated><published>2024-01-22T20:57:04+00:00</published><title>Developing an app using open source LLMs</title></entry><entry><author><name>/u/danipudani</name><uri>https://www.reddit.com/user/danipudani</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d26e0/mistral_7b_from_mistralai_full_whitepaper_overview/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/FhC_y-oxVeC6HGqk8BsT7wthO6-z0HqQsR-HgQeRTXo.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6d9b98acf968232120730892defc7e42319e3130&quot; alt=&quot;Mistral 7B from Mistral.AI - FULL WHITEPAPER OVERVIEW&quot; title=&quot;Mistral 7B from Mistral.AI - FULL WHITEPAPER OVERVIEW&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/danipudani&quot;&gt; /u/danipudani &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/rSUqg5X4SAU?si=xoXyfmrDUu7idHI3&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19d26e0/mistral_7b_from_mistralai_full_whitepaper_overview/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19d26e0</id><media:thumbnail url="https://external-preview.redd.it/FhC_y-oxVeC6HGqk8BsT7wthO6-z0HqQsR-HgQeRTXo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6d9b98acf968232120730892defc7e42319e3130" /><link href="https://www.reddit.com/r/LangChain/comments/19d26e0/mistral_7b_from_mistralai_full_whitepaper_overview/" /><updated>2024-01-22T18:14:13+00:00</updated><published>2024-01-22T18:14:13+00:00</published><title>Mistral 7B from Mistral.AI - FULL WHITEPAPER OVERVIEW</title></entry><entry><author><name>/u/SensitiveFel</name><uri>https://www.reddit.com/user/SensitiveFel</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I found that using RAG to search for documents through a vector store definitely loses some of the information, such as context, because it has no way to look at your problem based on the whole document. langchain There is a concept proposed in that, which is &lt;code&gt;Parent Document Retriever&lt;/code&gt;. But even so, I think he may not be as effective as passing all the data as context to LLM,then this also derives a maximum token problem, then does it mean: the model that supports the most tokens is better at searching, something like &lt;code&gt;CLAUDE2&lt;/code&gt; vs &lt;code&gt;ChatGPT&lt;/code&gt;. It feels like the simplest and crudest is instead the most effective&lt;/p&gt; &lt;p&gt;Editï¼š Or maybe this is the way to go. &lt;a href=&quot;https://medium.com/@akriti.upadhyay/building-advanced-rag-applications-using-falkordb-langchain-diffbot-api-and-openai-083fa1b6a96c&quot;&gt;advanced-rag&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SensitiveFel&quot;&gt; /u/SensitiveFel &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cpvw6/rag_vs_full_context/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cpvw6/rag_vs_full_context/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19cpvw6</id><link href="https://www.reddit.com/r/LangChain/comments/19cpvw6/rag_vs_full_context/" /><updated>2024-01-22T07:07:05+00:00</updated><published>2024-01-22T07:07:05+00:00</published><title>RAG vs. full context</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;in a RAG application, I am using FAISS as retriever:&lt;/p&gt; &lt;p&gt;&lt;code&gt;retriever = vectorstore.as_retriever(search_kwargs={&amp;#39;k&amp;#39;: 3, &amp;#39;score_treshold&amp;#39;: 0.9}, search_type=&amp;quot;similarity&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;retriever.get_relevant_documents(&amp;quot;- I am Karl and I play soccer&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;However when changing the Score-Treshold I am still getting back the same documents. So there is no difference if I set it to 0.1 or 0.9.&lt;/p&gt; &lt;p&gt;In my understanding it should work as follows:&lt;/p&gt; &lt;p&gt;- Search the top 3 docs that have a similarity score of 0.9 or higher.&lt;/p&gt; &lt;p&gt;- If for example only one doc has a higher similarity than 0.9, only retrieve one doc.&lt;/p&gt; &lt;p&gt;- But: it is always retrieving 3 Docs, even if they are not similar&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Is this assumption correct or how can I make it work?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ctf42/faiss_as_retriever_score_treshold_not_working/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ctf42/faiss_as_retriever_score_treshold_not_working/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ctf42</id><link href="https://www.reddit.com/r/LangChain/comments/19ctf42/faiss_as_retriever_score_treshold_not_working/" /><updated>2024-01-22T11:20:30+00:00</updated><published>2024-01-22T11:20:30+00:00</published><title>FAISS as Retriever: Score Treshold not working</title></entry><entry><author><name>/u/PrimaryHeat5864</name><uri>https://www.reddit.com/user/PrimaryHeat5864</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m now working in an AI company, and we&amp;#39;re developing infra products to enhance RAG. As the product marketing, it&amp;#39;s important to hear from the community. I want to know:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;How necessary do you think the RAG project can be for your current business?&lt;/li&gt; &lt;li&gt;What are the primary challenges you face with the current implementation of RAG?&lt;/li&gt; &lt;li&gt;Which embedding model you are using nowï¼Ÿ&lt;/li&gt; &lt;li&gt;Have you considered finding a better Embedding model to get better results from RAG?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I&amp;#39;m looking forward to seeing your reply from anyone who is exploring RAG for real production. You are also welcome to share your insights via the &lt;a href=&quot;https://forms.gle/xkyBpruTC7twZxSz7&quot;&gt;survey&lt;/a&gt;, and Iâ€˜ll then contact you to discuss future collaboration opportunities. You may find more information about our product, the Jina Embeddings model in the survey form. And our Embeddings have been integrated into Langchain already. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/PrimaryHeat5864&quot;&gt; /u/PrimaryHeat5864 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19crogm/survey_about_retrieval_augmented_generation_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19crogm/survey_about_retrieval_augmented_generation_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19crogm</id><link href="https://www.reddit.com/r/LangChain/comments/19crogm/survey_about_retrieval_augmented_generation_rag/" /><updated>2024-01-22T09:16:43+00:00</updated><published>2024-01-22T09:16:43+00:00</published><title>Survey about Retrieval Augmented Generation (RAG) in Real Production</title></entry><entry><author><name>/u/Adam-Schroeder</name><uri>https://www.reddit.com/user/Adam-Schroeder</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/Tm3xcm8pFutyjWhY5DD2viOOuO0c_TRKig3pFRimUEw.jpg&quot; alt=&quot;Create AI Chatbots for Websites in Python - EmbedChain Dash&quot; title=&quot;Create AI Chatbots for Websites in Python - EmbedChain Dash&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Everyone,I just created a free video tutorial showing how to build an AI Chatbots for Beginners in Python. We&amp;#39;ll use the EmbedChain (built on top of LangChain) and Dash libraries, and we&amp;#39;ll learn the core principles of training and interacting with your bot. I hope you learn a lot.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/tmOmTBEdNrE&quot;&gt;https://youtu.be/tmOmTBEdNrE&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/tq1ovgfihxdc1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b4e1593532e2f396d0397ec80161020a30d14b69&quot;&gt;https://preview.redd.it/tq1ovgfihxdc1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b4e1593532e2f396d0397ec80161020a30d14b69&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Adam-Schroeder&quot;&gt; /u/Adam-Schroeder &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19coe4m</id><media:thumbnail url="https://b.thumbs.redditmedia.com/Tm3xcm8pFutyjWhY5DD2viOOuO0c_TRKig3pFRimUEw.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/19coe4m/create_ai_chatbots_for_websites_in_python/" /><updated>2024-01-22T05:33:29+00:00</updated><published>2024-01-22T05:33:29+00:00</published><title>Create AI Chatbots for Websites in Python - EmbedChain Dash</title></entry><entry><author><name>/u/Downtown_Repeat7455</name><uri>https://www.reddit.com/user/Downtown_Repeat7455</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cus3v/wht_chat_histrory/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/3aqbGyeHXrqzX7N29Gq7PgrtI1O-3TAwp1vfiPLX5GU.jpg&quot; alt=&quot;wht chat_histrory&quot; title=&quot;wht chat_histrory&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I know this is not related langchain. somehow i am unable to post in python group. why the hell this is showing error. chat_history I declared at 99. why its showingerror at 106 but not at 108&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/4e8lqlgolzdc1.png?width=1324&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=277c36af1e06d189b047d50ada64a7b07001ed8c&quot;&gt;https://preview.redd.it/4e8lqlgolzdc1.png?width=1324&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=277c36af1e06d189b047d50ada64a7b07001ed8c&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Downtown_Repeat7455&quot;&gt; /u/Downtown_Repeat7455 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cus3v/wht_chat_histrory/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cus3v/wht_chat_histrory/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19cus3v</id><media:thumbnail url="https://b.thumbs.redditmedia.com/3aqbGyeHXrqzX7N29Gq7PgrtI1O-3TAwp1vfiPLX5GU.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/19cus3v/wht_chat_histrory/" /><updated>2024-01-22T12:42:03+00:00</updated><published>2024-01-22T12:42:03+00:00</published><title>wht chat_histrory</title></entry><entry><author><name>/u/HelicopterNext3726</name><uri>https://www.reddit.com/user/HelicopterNext3726</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on an innovative gym app that incorporates AI for personalized workout plans and diet charts, sourced from a gym owner&amp;#39;s knowledge base.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the scoop: &lt;/p&gt; &lt;p&gt;Users can input their daily attendance, receive workout plans(from trainers), track meals, and chat with an AI bot. &lt;/p&gt; &lt;p&gt;The Ai bot should consider knowledge based and user&amp;#39;s previous history texts and their database(their workout and meal history and plan(weightloss) and their Medical condition(optional) ) and provide optimal answers according to the users queries&lt;/p&gt; &lt;p&gt;My tech arsenal I like to use includes &lt;/p&gt; &lt;p&gt;Rag, LangChain, Supabase, supabase - VectorDB, and Next.js. I&amp;#39;m eager to hear your thoughts and insights on how to make this ambitious project a reality. Any advice, suggestions, or experiences you can share would be immensely helpful! Thanks a ton! ðŸ’ªðŸ¤–&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HelicopterNext3726&quot;&gt; /u/HelicopterNext3726 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19csujt/developing_an_aipowered_gym_chat_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19csujt/developing_an_aipowered_gym_chat_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19csujt</id><link href="https://www.reddit.com/r/LangChain/comments/19csujt/developing_an_aipowered_gym_chat_app/" /><updated>2024-01-22T10:42:11+00:00</updated><published>2024-01-22T10:42:11+00:00</published><title>Developing an AI-Powered Gym chat app</title></entry><entry><author><name>/u/Zestyclose-Bid-487</name><uri>https://www.reddit.com/user/Zestyclose-Bid-487</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zestyclose-Bid-487&quot;&gt; /u/Zestyclose-Bid-487 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cs6vb/any_support_for_agent_with_ope_source_models_such/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cs6vb/any_support_for_agent_with_ope_source_models_such/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19cs6vb</id><link href="https://www.reddit.com/r/LangChain/comments/19cs6vb/any_support_for_agent_with_ope_source_models_such/" /><updated>2024-01-22T09:55:03+00:00</updated><published>2024-01-22T09:55:03+00:00</published><title>any support for Agent with ope source models such as mistral,lama 2 ?</title></entry><entry><author><name>/u/LARGE_LANGUE_MODEL</name><uri>https://www.reddit.com/user/LARGE_LANGUE_MODEL</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I already have some basic knowledge about langchain and LLM. Now I want to apply it to a production environment, but I realize that basic knowledge is not enough. I want to make a news Q&amp;amp;A chatbot application using RAG and use API access tools to get real-time information about cryptocurrencies. Does anyone have a sample repo that I can refer to? Thank you very much&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LARGE_LANGUE_MODEL&quot;&gt; /u/LARGE_LANGUE_MODEL &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cgrpd/chatbot_rag_and_tool_about_crypto/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19cgrpd/chatbot_rag_and_tool_about_crypto/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19cgrpd</id><link href="https://www.reddit.com/r/LangChain/comments/19cgrpd/chatbot_rag_and_tool_about_crypto/" /><updated>2024-01-21T23:11:18+00:00</updated><published>2024-01-21T23:11:18+00:00</published><title>Chatbot RAG and tool about crypto</title></entry></feed>