<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-03-29T03:57:46+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/dxtros</name><uri>https://www.reddit.com/user/dxtros</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, we&amp;#39;ve just published a tutorial with an adaptive retrieval technique to cut down your token use in top-k retrieval RAG:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://pathway.com/developers/showcases/adaptive-rag&quot;&gt;https://pathway.com/developers/showcases/adaptive-rag&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Simple but sure, if you want to DIY, it&amp;#39;s about 50 lines of code (your mileage will vary depending on the Vector Database you are using). Works with GPT4, works with many local LLM&amp;#39;s, works with old GPT 3.5 Turbo, does not work with the latest GPT 3.5 as OpenAI makes it hallucinate over-confidently in a recent upgrade (interesting, right?). Enjoy!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dxtros&quot;&gt; /u/dxtros &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpz9dw/tuning_rag_retriever_to_reduce_llm_token_cost_4x/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpz9dw/tuning_rag_retriever_to_reduce_llm_token_cost_4x/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpz9dw</id><link href="https://www.reddit.com/r/LangChain/comments/1bpz9dw/tuning_rag_retriever_to_reduce_llm_token_cost_4x/" /><updated>2024-03-28T16:06:16+00:00</updated><published>2024-03-28T16:06:16+00:00</published><title>Tuning RAG retriever to reduce LLM token cost (4x in benchmarks)</title></entry><entry><author><name>/u/Defiant-Sir-1199</name><uri>https://www.reddit.com/user/Defiant-Sir-1199</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all , I was trying to evaluate and compare the performance of Azure AI search index vs Chroma Db in memory index . I have heard that Chroma Db is good for high speed retrieval but relevancy of retrieved docs are not that good . &lt;/p&gt; &lt;p&gt;I was thinking that Azure AI search should easily outperform chroma DB , So I configured both Chroma DB and Azure AI search Index with same configuration ( HNSW with Cosin similarity ) . I used same embedding model text-embedding-3-small for embedding the test document ( 300 character small chunks) . Now I was a bit confused to see that , while testing with some queries both Vector Dbs( Indexes)are returning the same results . Even with k=4 nearest items , both are returning same 4 doc chunks ( relevancy scores are different though) I am now concerned that somehow I have messed up something, What do you guys think?? Am I supposed to see the same results with same config or I am doing something wrong?&lt;/p&gt; &lt;p&gt;Can you guys suggest me some good dataset for benchmarking the retrieval systems. Thanks in advance ðŸ˜ƒ&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Defiant-Sir-1199&quot;&gt; /u/Defiant-Sir-1199 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqa628/azure_ai_search_vs_chroma_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bqa628/azure_ai_search_vs_chroma_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bqa628</id><link href="https://www.reddit.com/r/LangChain/comments/1bqa628/azure_ai_search_vs_chroma_db/" /><updated>2024-03-28T23:30:33+00:00</updated><published>2024-03-28T23:30:33+00:00</published><title>Azure AI search vs Chroma Db</title></entry><entry><author><name>/u/Andaso</name><uri>https://www.reddit.com/user/Andaso</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;With the recent announcement of &amp;#39;traces&amp;#39; being charged for, does anyone know if the rest of the framework is still free to use?!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Andaso&quot;&gt; /u/Andaso &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq9knx/can_langchain_still_be_used_for_free/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq9knx/can_langchain_still_be_used_for_free/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq9knx</id><link href="https://www.reddit.com/r/LangChain/comments/1bq9knx/can_langchain_still_be_used_for_free/" /><updated>2024-03-28T23:05:19+00:00</updated><published>2024-03-28T23:05:19+00:00</published><title>Can LangChain still be used for free?!</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am just trying to understand if any of you use the &amp;quot;system&amp;quot; role for adding prompts to programmatic invocations. I know this is the support by the books way to do it. But I have also attached the prompt directly to the &amp;quot;user&amp;quot; role with similar accuracy. Wondering what the best practice is.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq5g0u/do_you_use_the_system_role_for_adding_prompts_or/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq5g0u/do_you_use_the_system_role_for_adding_prompts_or/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq5g0u</id><link href="https://www.reddit.com/r/LangChain/comments/1bq5g0u/do_you_use_the_system_role_for_adding_prompts_or/" /><updated>2024-03-28T20:15:18+00:00</updated><published>2024-03-28T20:15:18+00:00</published><title>Do you use the &quot;system&quot; role for adding prompts or just append it to the &quot;user&quot; role?</title></entry><entry><author><name>/u/Shabbinx</name><uri>https://www.reddit.com/user/Shabbinx</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I know that this question about LangChain is frequent but I just wanted to ask if there&amp;#39;s any comprehensive or practical course for learning langchain? Because the documentations on python are SO vague and do not really teach anything. I&amp;#39;ve checked YouTube courses but most of them are old and langchain has changed ever since. Plus the YouTube courses all teach the basics, they don&amp;#39;t go through various modules.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Shabbinx&quot;&gt; /u/Shabbinx &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq73n0/learning_resources/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq73n0/learning_resources/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq73n0</id><link href="https://www.reddit.com/r/LangChain/comments/1bq73n0/learning_resources/" /><updated>2024-03-28T21:21:38+00:00</updated><published>2024-03-28T21:21:38+00:00</published><title>Learning resources</title></entry><entry><author><name>/u/Fit-Set6851</name><uri>https://www.reddit.com/user/Fit-Set6851</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The typical streaming method is not working for the below chain&lt;/p&gt; &lt;p&gt;chain_main = RunnableParallel({&lt;br/&gt; &amp;quot;query&amp;quot;: RunnablePassthrough(),&lt;br/&gt; &amp;quot;context&amp;quot;: retrieval_chain,&lt;br/&gt; }) | generation_prompt | model | OpenAIFunctionsAgentOutputParser() | route&lt;/p&gt; &lt;p&gt;But streaming method works for simple chain without function calling like the one below&lt;/p&gt; &lt;p&gt;chain = RunnableParallel({&lt;br/&gt; &amp;quot;query&amp;quot;: RunnablePassthrough(),&lt;br/&gt; &amp;quot;context&amp;quot;: retrieval_chain,&lt;br/&gt; }) | generation_prompt |model | parser&lt;/p&gt; &lt;p&gt;Can someone help me on this. Thanks in advance for the help&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fit-Set6851&quot;&gt; /u/Fit-Set6851 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq881o/how_can_i_stream_output_for_my_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq881o/how_can_i_stream_output_for_my_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq881o</id><link href="https://www.reddit.com/r/LangChain/comments/1bq881o/how_can_i_stream_output_for_my_chain/" /><updated>2024-03-28T22:08:17+00:00</updated><published>2024-03-28T22:08:17+00:00</published><title>How can i stream output for my chain ?</title></entry><entry><author><name>/u/IlEstLaPapi</name><uri>https://www.reddit.com/user/IlEstLaPapi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have an application that is currently based on 3 agents using LangChain and GPT4-turbo.&lt;/p&gt; &lt;p&gt;I&amp;#39;d like to test Claude 3 in this context. However all my agents are created using the function &lt;code&gt;create_openai_tools_agent()&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Reading the documentation, it seems that the recommended Agent for Claude is the &lt;a href=&quot;https://python.langchain.com/docs/modules/agents/agent_types/xml_agent&quot;&gt;XML Agent&lt;/a&gt;. However this documentation is referring to Claude 2 instead of Claude 3. It&amp;#39;s also assuming that the model is a LLM and not a Chatbot. That seems weird. Especially given that Anthropic documentation is clear about using a Chatlike API, with &lt;a href=&quot;https://docs.anthropic.com/claude/reference/messages_post&quot;&gt;a system prompt and a list of users/assistant messages&lt;/a&gt;. Instead the XML Agent seems to only be able to &lt;a href=&quot;https://python.langchain.com/docs/modules/agents/agent_types/xml_agent#using-with-chat-history&quot;&gt;understand chathistory as a single string&lt;/a&gt;. &lt;/p&gt; &lt;p&gt;Given that LLM in general, and Claude in particular are quite sensitive to prompting format, I&amp;#39;m not really happy with the idea of having a chat history sent as a single string instead of the standard format provided by the API. Thus I&amp;#39;m hesitating about using the XML agent.&lt;/p&gt; &lt;p&gt;So I&amp;#39;m curious if any of you has any experience using the XML Agent with a chat history ? Or did you use another kind of agent ?&lt;/p&gt; &lt;p&gt;Thanks in advance !&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/IlEstLaPapi&quot;&gt; /u/IlEstLaPapi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq1rgj/how_to_implement_claude_based_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq1rgj/how_to_implement_claude_based_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq1rgj</id><link href="https://www.reddit.com/r/LangChain/comments/1bq1rgj/how_to_implement_claude_based_agents/" /><updated>2024-03-28T17:47:31+00:00</updated><published>2024-03-28T17:47:31+00:00</published><title>How to implement Claude based Agents ?</title></entry><entry><author><name>/u/ramkitvprk</name><uri>https://www.reddit.com/user/ramkitvprk</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;While trying to connect to presto db I am getting the invalid literal for int() with base 10 &lt;/p&gt; &lt;p&gt;Though I have tried all options of converting the port number to int using below&lt;/p&gt; &lt;p&gt;int(port_number)&lt;/p&gt; &lt;p&gt;int(float(port_number)&lt;/p&gt; &lt;p&gt;I am still getting the error, also needs to understand more on the from_uri method, will that only take conn_str [string ] as parameter?&lt;br/&gt; Outside the langchain I could able to connect to presto DB with dbapi.&lt;br/&gt; please help&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ramkitvprk&quot;&gt; /u/ramkitvprk &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq0r2j/getting_invalid_literal_for_int_with_base_10/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq0r2j/getting_invalid_literal_for_int_with_base_10/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq0r2j</id><link href="https://www.reddit.com/r/LangChain/comments/1bq0r2j/getting_invalid_literal_for_int_with_base_10/" /><updated>2024-03-28T17:06:51+00:00</updated><published>2024-03-28T17:06:51+00:00</published><title>Getting invalid literal for int() with base 10 while using from_uri method in the SQLDatabase</title></entry><entry><author><name>/u/Alor_3821</name><uri>https://www.reddit.com/user/Alor_3821</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I have an error with langchain and langserve that I can&amp;#39;t solve. This is my code:&lt;/p&gt; &lt;p&gt;from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import ChatPromptTemplate from langchain_core.runnables import RunnableMap, RunnablePassthrough from langchain_openai import ChatOpenAI, OpenAIEmbeddings from operator import itemgetter from langchain_community.vectorstores import Chroma from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string from langchain_core.prompts import format_document from langchain_core.runnables import RunnableParallel from langchain.retrievers.multi_vector import MultiVectorRetriever from langchain.storage import LocalFileStore from langchain.prompts.prompt import PromptTemplate from langchain.docstore.document import Document from langserve import add_routes from fastapi import FastAPI&lt;/p&gt; &lt;p&gt;vectorstore = Chroma(collection_name=&amp;quot;summaries&amp;quot;, embedding_function=OpenAIEmbeddings(), persist_directory=&amp;quot;path/to/directory/&amp;quot;)&lt;/p&gt; &lt;p&gt;store = LocalFileStore(&amp;quot;path/to/directory&amp;quot;) id_key = &amp;quot;doc_id&amp;quot;&lt;/p&gt; &lt;p&gt;retriever = MultiVectorRetriever( vectorstore=vectorstore, docstore=store, id_key=id_key, search_kwargs={&amp;#39;k&amp;#39;: 3} )&lt;/p&gt; &lt;p&gt;_template = &amp;quot;&amp;quot;&amp;quot;Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.&lt;/p&gt; &lt;p&gt;Chat History: {chat_history} Follow Up Input: {question} Standalone question:&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt; &lt;p&gt;CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)&lt;/p&gt; &lt;p&gt;template = &amp;quot;&amp;quot;&amp;quot;Answer the question based only on the following context: {context}&lt;/p&gt; &lt;p&gt;Question: {question} &amp;quot;&amp;quot;&amp;quot; ANSWER_PROMPT = ChatPromptTemplate.from_template(template)&lt;/p&gt; &lt;p&gt;DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=&amp;quot;{page_content}&amp;quot;)&lt;/p&gt; &lt;p&gt;def _combine_documents( docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=&amp;quot;\n\n&amp;quot; ): format_doc = [ ] for i in docs: single_doc = Document(page_content=i, metadata={&amp;quot;doc_name&amp;quot;: &amp;quot;doc_name&amp;quot;}) format_doc.append(single_doc) doc_strings = [format_document(doc, document_prompt) for doc in format_doc] return document_separator.join(doc_strings)&lt;/p&gt; &lt;p&gt;_inputs = RunnableParallel( standalone_question=RunnablePassthrough.assign( chat_history=lambda x: get_buffer_string(x[&amp;#39;chat_history&amp;#39;]) ) | CONDENSE_QUESTION_PROMPT | ChatOpenAI() | StrOutputParser(), )&lt;/p&gt; &lt;p&gt;_context = { &amp;quot;context&amp;quot;: itemgetter(&amp;quot;standalone_question&amp;quot;) | retriever | _combine_documents, &amp;quot;question&amp;quot;: lambda x: x[&amp;quot;standalone_question&amp;quot;], }&lt;/p&gt; &lt;p&gt;llm = ChatOpenAI()&lt;/p&gt; &lt;p&gt;conversational_qa_chain = _inputs | _context | ANSWER_PROMPT | llm&lt;/p&gt; &lt;p&gt;app = FastAPI( title=&amp;quot;LangChain Server&amp;quot;, version=&amp;quot;1.0&amp;quot;, description=&amp;quot;Spin up a simple api server using Langchain&amp;#39;s Runnable interfaces&amp;quot;)&lt;/p&gt; &lt;p&gt;add_routes(app, conversational_qa_chain)&lt;/p&gt; &lt;p&gt;if &lt;strong&gt;name&lt;/strong&gt; == &amp;quot;&lt;strong&gt;main&lt;/strong&gt;&amp;quot;: import uvicorn&lt;/p&gt; &lt;pre&gt;&lt;code&gt;uvicorn.run(app, host=&amp;quot;localhost&amp;quot;, port=8000) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When I try to use playground or I try to use request like this: &lt;/p&gt; &lt;p&gt;import requests&lt;/p&gt; &lt;p&gt;inputs = {&amp;quot;input&amp;quot;: {&amp;quot;question&amp;quot;: &amp;quot;what do you know about harrison&amp;quot;, &amp;quot;chat_history&amp;quot;: []}} response = requests.post(&amp;quot;http://localhost:8000/invoke&amp;quot;, json=inputs)&lt;/p&gt; &lt;p&gt;response.json()&lt;/p&gt; &lt;p&gt;I have this error: &lt;/p&gt; &lt;p&gt;chat_history=lambda x: get_buffer_string(x[&amp;#39;chat_history&amp;#39;]) KeyError: &amp;#39;chat_history&amp;#39;&lt;/p&gt; &lt;p&gt;Do you know a way to solve this error? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Alor_3821&quot;&gt; /u/Alor_3821 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq0t3b/conversationalretrievalchain_and_langserve/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bq0t3b/conversationalretrievalchain_and_langserve/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bq0t3b</id><link href="https://www.reddit.com/r/LangChain/comments/1bq0t3b/conversationalretrievalchain_and_langserve/" /><updated>2024-03-28T17:09:08+00:00</updated><published>2024-03-28T17:09:08+00:00</published><title>ConversationalRetrievalChain and langserve</title></entry><entry><author><name>/u/TomasPiaggio</name><uri>https://www.reddit.com/user/TomasPiaggio</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone. I&amp;#39;m Tom, CTO and Co-Founder of &lt;a href=&quot;https://getautonoma.com&quot;&gt;Autonoma AI&lt;/a&gt;. I&amp;#39;m coming with &lt;a href=&quot;https://gitgud.autonoma.app/&quot;&gt;something we cooked up this weekend&lt;/a&gt; and wanted your feedback on. &lt;a href=&quot;https://www.youtube.com/watch?v=6kfr1lqw2gg&quot;&gt;Here&amp;#39;s a video&lt;/a&gt; if you like that format better.&lt;/p&gt; &lt;p&gt;It&amp;#39;s &lt;strong&gt;free&lt;/strong&gt;, &lt;strong&gt;no account needed&lt;/strong&gt;, &lt;strong&gt;no credit card needed&lt;/strong&gt;. We just want you guys to tell us what you think.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;It&amp;#39;s very alpha, so I apologize in advance for the bugs and issues that might exist.&lt;/p&gt; &lt;p&gt;Feel free to ask about the architecture or design decisions, or whatever you want to discuss about.&lt;/p&gt; &lt;p&gt;Thank you all in advance for this as well.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;If you like the product, I&amp;#39;d like to ask you to upvote the &lt;a href=&quot;https://www.producthunt.com/posts/gitgud&quot;&gt;producthunt post&lt;/a&gt;, it&amp;#39;d really help us!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TomasPiaggio&quot;&gt; /u/TomasPiaggio &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpyx3o/ai_chain_builder_for_code_manipulation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpyx3o/ai_chain_builder_for_code_manipulation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpyx3o</id><link href="https://www.reddit.com/r/LangChain/comments/1bpyx3o/ai_chain_builder_for_code_manipulation/" /><updated>2024-03-28T15:52:24+00:00</updated><published>2024-03-28T15:52:24+00:00</published><title>AI Chain Builder for Code Manipulation</title></entry><entry><author><name>/u/eschxr</name><uri>https://www.reddit.com/user/eschxr</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/eschxr&quot;&gt; /u/eschxr &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/u_eschxr/comments/1bpyn5c/hack_opengpts_to_automate_anything/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpynej/hack_opengpts_to_automate_anything/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpynej</id><link href="https://www.reddit.com/r/LangChain/comments/1bpynej/hack_opengpts_to_automate_anything/" /><updated>2024-03-28T15:41:07+00:00</updated><published>2024-03-28T15:41:07+00:00</published><title>Hack OpenGPTs to Automate Anything</title></entry><entry><author><name>/u/TimeLead4573</name><uri>https://www.reddit.com/user/TimeLead4573</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, I&amp;#39;m following this &lt;a href=&quot;https://medium.com/@Siddharth.jh/conversational-chat-bot-using-open-source-llm-model-dolly-2-0-with-added-memory-acfacc13a69e&quot;&gt;tutorial&lt;/a&gt; and I&amp;#39;m at the step where I am testing chatting with the AI chatbot. I have created the qa_chain and I am using it similar to how it is in the tutorial but I am getting the following error after I input my question and it tries generating the answer:&lt;/p&gt; &lt;p&gt;&lt;code&gt;generated_sequence = self.model.generate(&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;^^^^^^^^^^^^^^^^^^^^&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;TypeError: transformers.generation.utils.GenerationMixin.generate() got multiple values for keyword argument &amp;#39;pad_token_id&amp;#39;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;I am wondering what this issue could be coming from? I checked the collab provided in the tutorial and I can&amp;#39;t seem to find any significant differences between my code and theirs.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TimeLead4573&quot;&gt; /u/TimeLead4573 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpxeq5/error_when_trying_to_get_answer_using_qa_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpxeq5/error_when_trying_to_get_answer_using_qa_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpxeq5</id><link href="https://www.reddit.com/r/LangChain/comments/1bpxeq5/error_when_trying_to_get_answer_using_qa_chain/" /><updated>2024-03-28T14:48:27+00:00</updated><published>2024-03-28T14:48:27+00:00</published><title>Error when trying to get answer using qa_chain</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, this tutorial explains how to use Multi-Agent framework Autogen by Microsoft using Local LLMs (and not any API) using Ollama &amp;amp; LiteLLM: &lt;a href=&quot;https://youtu.be/AdGuzjGWZms?si=FHhwzaS0RoAiDubk&quot;&gt;https://youtu.be/AdGuzjGWZms?si=FHhwzaS0RoAiDubk&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpof9x/autogen_using_local_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpof9x/autogen_using_local_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpof9x</id><link href="https://www.reddit.com/r/LangChain/comments/1bpof9x/autogen_using_local_llms/" /><updated>2024-03-28T06:07:05+00:00</updated><published>2024-03-28T06:07:05+00:00</published><title>Autogen using Local LLMs</title></entry><entry><author><name>/u/Minute_Scientist8107</name><uri>https://www.reddit.com/user/Minute_Scientist8107</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys , I have a SQL LLM already implemented using. OpenAI API. I have tried ollama models but itâ€™s taking a lot of time to process. So now I need to use llama.cpp models .. I donâ€™t know how to implement it. Please ping me .. you can take a look at the code. Thanks a lot &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Minute_Scientist8107&quot;&gt; /u/Minute_Scientist8107 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bptmed/need_help_with_my_sql_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bptmed/need_help_with_my_sql_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bptmed</id><link href="https://www.reddit.com/r/LangChain/comments/1bptmed/need_help_with_my_sql_llm/" /><updated>2024-03-28T11:49:00+00:00</updated><published>2024-03-28T11:49:00+00:00</published><title>Need help with my SQL LLM</title></entry><entry><author><name>/u/New-Contribution6302</name><uri>https://www.reddit.com/user/New-Contribution6302</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, despite having some experimentation using langchain, I still can&amp;#39;t figure out how to create a best chatbot, in the sense of its way in communication, relavancy and good RAG. I request everyone to guide me so that I could go in right direction and build one for my experience. This is a request. (PS: The RAG process should be capable of taking document chunks from PDF, video, URL&amp;#39;S, and local files too. Also guide me the type of chunking to use for various types of data)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/New-Contribution6302&quot;&gt; /u/New-Contribution6302 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpt0rl/needed_help_to_create_a_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpt0rl/needed_help_to_create_a_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpt0rl</id><link href="https://www.reddit.com/r/LangChain/comments/1bpt0rl/needed_help_to_create_a_chatbot/" /><updated>2024-03-28T11:15:18+00:00</updated><published>2024-03-28T11:15:18+00:00</published><title>Needed help to create a chatbot</title></entry><entry><author><name>/u/Distinct_Pressure_36</name><uri>https://www.reddit.com/user/Distinct_Pressure_36</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m using FAISS vector database for my work. Just curious where the database is stored. Is it stored somewhere locally or what? &lt;/p&gt; &lt;p&gt;Is it safe to pass personal information to FAISS? &lt;/p&gt; &lt;p&gt;I&amp;#39;m performing chunking and later passing this chunks into FAISS&lt;/p&gt; &lt;p&gt;Data= faiss.from_texts(texts, embeddings)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Distinct_Pressure_36&quot;&gt; /u/Distinct_Pressure_36 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpsvy8/where_does_faiss_store_my_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpsvy8/where_does_faiss_store_my_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpsvy8</id><link href="https://www.reddit.com/r/LangChain/comments/1bpsvy8/where_does_faiss_store_my_data/" /><updated>2024-03-28T11:07:16+00:00</updated><published>2024-03-28T11:07:16+00:00</published><title>Where does faiss store my data?</title></entry><entry><author><name>/u/laughsforshits</name><uri>https://www.reddit.com/user/laughsforshits</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Community, I want to run evaluation over my model responses such that it is done independently of the rag pipeline. Essentially, I have a CSV generated as an output of my RAG pipeline which contains, question, correct answer and model response. Now, I want to evaluate if the model response matches the correct answer independently of the RAG pipeline. I was looking into some of the langchain metrics like Accuracy, correctness , cot_qa but have not been able to actually get any of them working, cause all the chains require a model that generates answers for the question instead of just evaluating correct answer with model answer. I have tried prompt control, QA eval chain, or literally building a custom chain with the sole purpose of evaluation but none of that has worked. Has anyone tried this before or has any idea how it can be achieved please?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/laughsforshits&quot;&gt; /u/laughsforshits &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bprzs6/custom_evaluation_of_llm_responses/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bprzs6/custom_evaluation_of_llm_responses/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bprzs6</id><link href="https://www.reddit.com/r/LangChain/comments/1bprzs6/custom_evaluation_of_llm_responses/" /><updated>2024-03-28T10:12:49+00:00</updated><published>2024-03-28T10:12:49+00:00</published><title>Custom evaluation of LLM responses</title></entry><entry><author><name>/u/Agitated_Homework744</name><uri>https://www.reddit.com/user/Agitated_Homework744</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, I am currently building a financial RAG, the RAG alone, it performs great till it starts to derive math formulas to run, then the LLM is unable to evaluate the math expression accurately. What are the solutions to giving the LLM, the ability to Compute Math?. I have seen the LLMMathChain agent, but how do I combine it with the retrieval chain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Agitated_Homework744&quot;&gt; /u/Agitated_Homework744 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bprh9c/rag_system_math_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bprh9c/rag_system_math_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bprh9c</id><link href="https://www.reddit.com/r/LangChain/comments/1bprh9c/rag_system_math_agent/" /><updated>2024-03-28T09:40:03+00:00</updated><published>2024-03-28T09:40:03+00:00</published><title>RAG system + Math Agent</title></entry><entry><author><name>/u/jfjeschke</name><uri>https://www.reddit.com/user/jfjeschke</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Iâ€™m finishing up a system that can take transcripts of users doing their processes or Process Definition Documents, and automatically generate Langchain AI Agents chains and tools. Iâ€™ve got a couple agents ready to push to prod, but having trouble finding a place to host them. Where do people here host their agents?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jfjeschke&quot;&gt; /u/jfjeschke &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpr6nb/hosting_ai_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpr6nb/hosting_ai_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpr6nb</id><link href="https://www.reddit.com/r/LangChain/comments/1bpr6nb/hosting_ai_agents/" /><updated>2024-03-28T09:19:28+00:00</updated><published>2024-03-28T09:19:28+00:00</published><title>Hosting AI Agents?</title></entry><entry><author><name>/u/ThaiosX0195</name><uri>https://www.reddit.com/user/ThaiosX0195</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;h1&gt;Summary&lt;/h1&gt; &lt;p&gt;I am trying to run FAISS.load_local after a .save_local on a 60k pdf pickle file in order to not repeat the embedding procedure everytime for a RAG. But it is really slow and I would like to launch all the RAG workflow fastly :( Could it be due to the huge amount of data?&lt;/p&gt; &lt;p&gt;OS: Ubuntu 18.04.6 LTS (Bionic Beaver)&lt;/p&gt; &lt;p&gt;Faiss version: faiss-cpu==1.7.4&lt;/p&gt; &lt;p&gt;Installed from: pip install in conda env&lt;/p&gt; &lt;p&gt;Running on: Cluster with GPU Tesla V100-SXM2-32GB&lt;/p&gt; &lt;p&gt;Interface: Python&lt;/p&gt; &lt;h1&gt;Reproduction instructions&lt;/h1&gt; &lt;p&gt;First, I have launched these lines on a py script (ingest.py):&lt;/p&gt; &lt;p&gt;vectorstore = FAISS.from_documents(documents=chunks, embedding=embeddings,)&lt;br/&gt; vectorstore.save_local(&amp;quot;./faiss_db&amp;quot;)&lt;/p&gt; &lt;p&gt;And then on a different py script (rag.py):&lt;/p&gt; &lt;p&gt;vectorstore = FAISS.load_local(&amp;quot;./faiss_db&amp;quot;, embeddings, allow_dangerous_deserialization=True)&lt;br/&gt; retriever = vectorstore.as_retriever()&lt;/p&gt; &lt;p&gt;The log file gives me back only this:&lt;/p&gt; &lt;p&gt;&amp;quot;All keys matched successfully&amp;quot;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Can you help me, please?&lt;br/&gt; Thank you in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ThaiosX0195&quot;&gt; /u/ThaiosX0195 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpqoiz/faissload_local_is_so_slow/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpqoiz/faissload_local_is_so_slow/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpqoiz</id><link href="https://www.reddit.com/r/LangChain/comments/1bpqoiz/faissload_local_is_so_slow/" /><updated>2024-03-28T08:43:33+00:00</updated><published>2024-03-28T08:43:33+00:00</published><title>FAISS.load_local is so slow</title></entry><entry><author><name>/u/smtabatabaie</name><uri>https://www.reddit.com/user/smtabatabaie</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, I&amp;#39;m trying to create a studying tutor with LLMs and langchain. What I&amp;#39;m looking for is that the app reminds the student once in a while during the conversation if he/she has done his/her homework, and based on the answer remind him/her later or don&amp;#39;t remind her again. I&amp;#39;m looking for a clue on how to achieve such a thing.&lt;br/&gt; Thanks in advance&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/smtabatabaie&quot;&gt; /u/smtabatabaie &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpiwmt/creating_a_reminder_task_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bpiwmt/creating_a_reminder_task_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bpiwmt</id><link href="https://www.reddit.com/r/LangChain/comments/1bpiwmt/creating_a_reminder_task_in_langchain/" /><updated>2024-03-28T01:13:29+00:00</updated><published>2024-03-28T01:13:29+00:00</published><title>Creating a reminder task in langchain</title></entry><entry><author><name>/u/DocBrownMS</name><uri>https://www.reddit.com/user/DocBrownMS</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1boydvr/tds_article_visualize_your_rag_data_evaluate_your/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/Jis6fbGRMbP27jC_C49qVx52vSIaeHi98xN0x6KNVgU.jpg&quot; alt=&quot;TDS Article: Visualize your RAG Data â€” Evaluate your Retrieval-Augmented Generation System with Ragas&quot; title=&quot;TDS Article: Visualize your RAG Data â€” Evaluate your Retrieval-Augmented Generation System with Ragas&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DocBrownMS&quot;&gt; /u/DocBrownMS &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://towardsdatascience.com/visualize-your-rag-data-evaluate-your-retrieval-augmented-generation-system-with-ragas-fc2486308557&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1boydvr/tds_article_visualize_your_rag_data_evaluate_your/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1boydvr</id><media:thumbnail url="https://b.thumbs.redditmedia.com/Jis6fbGRMbP27jC_C49qVx52vSIaeHi98xN0x6KNVgU.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1boydvr/tds_article_visualize_your_rag_data_evaluate_your/" /><updated>2024-03-27T10:16:03+00:00</updated><published>2024-03-27T10:16:03+00:00</published><title>TDS Article: Visualize your RAG Data â€” Evaluate your Retrieval-Augmented Generation System with Ragas</title></entry><entry><author><name>/u/gswithai</name><uri>https://www.reddit.com/user/gswithai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;Little announcement!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;What&amp;#39;s up, everyone?! &lt;/p&gt; &lt;p&gt;I finally uploaded my first YouTube video based on one of my blog posts: &lt;a href=&quot;https://www.youtube.com/watch?v=ubsqSWfXAPI&quot;&gt;https://www.youtube.com/watch?v=ubsqSWfXAPI&lt;/a&gt; &lt;/p&gt; &lt;p&gt;It&amp;#39;s a tutorial about using LangChain&amp;#39;s Output Parsers with GPT to convert the contents of a PDF file to JSON. (&lt;a href=&quot;https://www.gettingstarted.ai/how-to-extract-metadata-from-pdf-convert-to-json-langchain/&quot;&gt;I originally wrote about this on the blog here&lt;/a&gt;). To be honest, I&amp;#39;ve been wanting to publish a video for some time now but finally went for it so I&amp;#39;m not sure what to expect.&lt;/p&gt; &lt;p&gt;I&amp;#39;m still learning about video editing, recording, and YouTube in general but &lt;strong&gt;I&amp;#39;d love to know your feedback (and comments)&lt;/strong&gt; so that I can implement it in future videos.&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gswithai&quot;&gt; /u/gswithai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bp2mao/uploaded_my_first_youtube_video_ever_and_its/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bp2mao/uploaded_my_first_youtube_video_ever_and_its/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bp2mao</id><link href="https://www.reddit.com/r/LangChain/comments/1bp2mao/uploaded_my_first_youtube_video_ever_and_its/" /><updated>2024-03-27T14:01:49+00:00</updated><published>2024-03-27T14:01:49+00:00</published><title>Uploaded my first YouTube video ever and it's about LangChain!</title></entry><entry><author><name>/u/profepcot</name><uri>https://www.reddit.com/user/profepcot</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;LangChain does a great job as a full framework for LLM-based application development, but there are so many components sometimes you just want a toolkit that is better at a particular piece. I won&amp;#39;t go down the rabbit-hole of &amp;#39;frameworks vs toolkits&amp;#39; in general, but if you&amp;#39;re looking for some of the alternatives to LangChain for pieces of the LLM-application development puzzle here&amp;#39;s a write up: &lt;a href=&quot;https://www.mirascope.io/post/langchain-alternatives&quot;&gt;https://www.mirascope.io/post/langchain-alternatives&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/profepcot&quot;&gt; /u/profepcot &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bp48si/langchain_for_a_full_framework_what_options_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bp48si/langchain_for_a_full_framework_what_options_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bp48si</id><link href="https://www.reddit.com/r/LangChain/comments/1bp48si/langchain_for_a_full_framework_what_options_for/" /><updated>2024-03-27T15:10:55+00:00</updated><published>2024-03-27T15:10:55+00:00</published><title>LangChain for a full framework - what options for more focused toolkits?</title></entry><entry><author><name>/u/Beginning_Rock_1906</name><uri>https://www.reddit.com/user/Beginning_Rock_1906</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, like the title says I would like to know whether LangGraph works well with all the Claude models? I never tested the function calling abilities of Claude and have no idea if they work well inside the LangGraph framework. Any type of illumination is greatly appreciated.&lt;/p&gt; &lt;p&gt;Thanks in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Beginning_Rock_1906&quot;&gt; /u/Beginning_Rock_1906 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bp7thq/langgraph_with_claude/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1bp7thq/langgraph_with_claude/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1bp7thq</id><link href="https://www.reddit.com/r/LangChain/comments/1bp7thq/langgraph_with_claude/" /><updated>2024-03-27T17:36:56+00:00</updated><published>2024-03-27T17:36:56+00:00</published><title>LangGraph with Claude?</title></entry></feed>