<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-04-17T16:26:57+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/GeorgiaWitness1</name><uri>https://www.reddit.com/user/GeorgiaWitness1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6afp1/creating_a_framework_like_langchain_but_just_for/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/dV99UNBkq4alhuQoO4-NhixMrfrPcCQzJGlzPXc7tFU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=88dbd4916b7a8116aae3eb8d0c87641c8eebfe52&quot; alt=&quot;Creating a framework like langchain, but just for extraction. To later be integrated with langchain&quot; title=&quot;Creating a framework like langchain, but just for extraction. To later be integrated with langchain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This post is a serious question that I have been contemplating for two months now, and I think it’s time to ask. Maybe this is not the best place to ask this question, but seems for me to be the best place, so here it is.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Motivation:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I have been working as a contractor for over a year in text extraction. My work involves extracting text from various sources, including legal documents and fintech platforms. I have observed that text extraction is just a small part of the bigger picture called LangChain. However, I don&amp;#39;t think it&amp;#39;s a major issue, just should be done in another place.&lt;/p&gt; &lt;p&gt;You can see my articles about the topic: &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://blog.gopenai.com/open-source-document-extraction-using-mistral-7b-llm-18bf437ca1d2?source=your_stories_page-------------------------------------&quot;&gt;https://blog.gopenai.com/open-source-document-extraction-using-mistral-7b-llm-18bf437ca1d2?source=your_stories_page-------------------------------------&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/python-in-plain-english/claude-3-the-king-of-data-extraction-f06ad161aabf&quot;&gt;https://medium.com/python-in-plain-english/claude-3-the-king-of-data-extraction-f06ad161aabf&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This has been the repo for me to support the articles: &lt;a href=&quot;https://github.com/enoch3712/Open-DocLLM&quot;&gt;https://github.com/enoch3712/Open-DocLLM&lt;/a&gt;&lt;/p&gt; &lt;p&gt;So, i wanted to do something specific, maybe compared to &lt;a href=&quot;https://github.com/axa-group/Parsr&quot;&gt;Parsr&lt;/a&gt;, that is an integration of several pieces like OCR+LLM, agents, and Databases, to extract data from sources. &lt;/p&gt; &lt;p&gt;Here is a possible stack:Is this worth trying? Is anyone else doing this? Since I&amp;#39;m contributing daily, it could make sense.Use-cases: &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/utwxo3whp1vc1.png?width=1841&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dd2341d76cde52b8522f9fe0e26cf2e13cca57de&quot;&gt;https://preview.redd.it/utwxo3whp1vc1.png?width=1841&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dd2341d76cde52b8522f9fe0e26cf2e13cca57de&lt;/a&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Extract data according to a document. Classifies the document as “driver license”, gets the contract and extract the data. Returns a valid JSON.&lt;/li&gt; &lt;li&gt;Extract data with validation. If field is null, calls a lambda/funcion&lt;/li&gt; &lt;li&gt;Give me a bunch of files, and extract“this content”. A bunch of files like Excels, Read all of them, and extract the data with a specific format. Would use semantic routing, an agent to decide what to do. &lt;/li&gt; &lt;li&gt;Easy loaders not only for AWS textExtract, Azure Form Recognizer, but also open source transformers like docTR. &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Eventually evolving to provide open-source, fine-tuned models to help the extraction.&lt;/p&gt; &lt;p&gt;Thank you for your time. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/GeorgiaWitness1&quot;&gt; /u/GeorgiaWitness1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6afp1/creating_a_framework_like_langchain_but_just_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6afp1/creating_a_framework_like_langchain_but_just_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c6afp1</id><media:thumbnail url="https://external-preview.redd.it/dV99UNBkq4alhuQoO4-NhixMrfrPcCQzJGlzPXc7tFU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=88dbd4916b7a8116aae3eb8d0c87641c8eebfe52" /><link href="https://www.reddit.com/r/LangChain/comments/1c6afp1/creating_a_framework_like_langchain_but_just_for/" /><updated>2024-04-17T13:52:09+00:00</updated><published>2024-04-17T13:52:09+00:00</published><title>Creating a framework like langchain, but just for extraction. To later be integrated with langchain</title></entry><entry><author><name>/u/Double_Secretary9930</name><uri>https://www.reddit.com/user/Double_Secretary9930</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, &lt;/p&gt; &lt;p&gt;Like many in this sub, I have been using Langchain to learn and to build hobby projects, especially RAG agents with self-evaluation. &lt;/p&gt; &lt;p&gt;(Btw, the &lt;a href=&quot;https://www.youtube.com/watch?v=wd7TZ4w1mSw&amp;amp;list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&amp;amp;ab_channel=LangChain&quot;&gt;RAG from scratch&lt;/a&gt; Youtube series from Lance is extremely helpful!)&lt;/p&gt; &lt;p&gt;I am making &lt;strong&gt;modest&lt;/strong&gt; progress towards a self-evaluating financial chatbot using the SEC data. Ideally, I want the chatbot to do the below but I am far from completion:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Allow you to ask questions about financial conditions, and trends across companies in the S&amp;amp;P 500 in the US.&lt;/li&gt; &lt;li&gt;It uses data directly from the official financial filings of these companies with the SEC, to &lt;strong&gt;avoid&lt;/strong&gt; &lt;strong&gt;hallucination&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;It provides &lt;strong&gt;detailed&lt;/strong&gt; &lt;strong&gt;references&lt;/strong&gt; below each answer so that you can fact-check the answer if you would like&lt;/li&gt; &lt;li&gt;The database has the last 5-10 years of financial filing data so you can ask the agent to reason about &lt;strong&gt;trends&lt;/strong&gt; &lt;strong&gt;over&lt;/strong&gt; &lt;strong&gt;time&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Before each answer is returned to you, there is another agent, whose job is to &lt;strong&gt;critique&lt;/strong&gt; the &lt;strong&gt;draft&lt;/strong&gt; answer by the LLM and propose how to improve it&lt;/li&gt; &lt;li&gt;These suggestions and the entire context are then shared with the original agent. The agent can then decide to &lt;strong&gt;formulate&lt;/strong&gt; &lt;strong&gt;different&lt;/strong&gt; &lt;strong&gt;queries&lt;/strong&gt; to &lt;strong&gt;retrieve&lt;/strong&gt; &lt;strong&gt;better&lt;/strong&gt; &lt;strong&gt;information&lt;/strong&gt; from the database or simply incorporate the suggestions into the final answer&lt;/li&gt; &lt;li&gt;This final answer is then, provided to the user.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;One of the first hurdles is to get the data from the SEC. So in case this is helpful to anyone, &lt;a href=&quot;https://github.com/chandlernguyen/financial_agent&quot;&gt;here&lt;/a&gt; is my code to download different financial filings from each company from the SEC. I purposely want to download both the .txt file and the .zip file for each 10K and 10Q because I want the metadata and the actual report. Let me know what you think?&lt;/p&gt; &lt;p&gt;(And yes, I tried to use an already integrated financial retriever with Langchain called &lt;a href=&quot;https://Kay.ai&quot;&gt;Kay.ai&lt;/a&gt; . It works but doesn&amp;#39;t meet all of my needs.)&lt;/p&gt; &lt;p&gt;P.S: I wrote a much longer blog post to share my progress and challenges so far &lt;a href=&quot;https://www.chandlernguyen.com/blog/2024/04/15/building-a-self-evaluating-financial-chatbot-a-journey-through-data-code-and-struggles/&quot;&gt;here&lt;/a&gt; in case you are at all interested. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Double_Secretary9930&quot;&gt; /u/Double_Secretary9930 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6cb1x/self_evaluating_financial_chatbot_sharing_code_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6cb1x/self_evaluating_financial_chatbot_sharing_code_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6cb1x</id><link href="https://www.reddit.com/r/LangChain/comments/1c6cb1x/self_evaluating_financial_chatbot_sharing_code_to/" /><updated>2024-04-17T15:09:35+00:00</updated><published>2024-04-17T15:09:35+00:00</published><title>Self evaluating financial chatbot: Sharing code to download financial filings from SEC</title></entry><entry><author><name>/u/rockstarflo</name><uri>https://www.reddit.com/user/rockstarflo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I just stumbled upon this:&lt;br/&gt; &lt;a href=&quot;https://r.jina.ai&quot;&gt;https://r.jina.ai&lt;/a&gt;&amp;lt;website\_url here&amp;gt;&lt;/p&gt; &lt;p&gt;You can convert URLs to Markdown. This format is then better understood by LLMs compared to HTML. I think it can be used for Agents or RAG with web searches. I use it to generate synthetic data for a specific website.&lt;br/&gt; Example usage&lt;br/&gt; &lt;a href=&quot;https://r.jina.ai/https://en.wikipedia.org/wiki/Monkey_Island&quot;&gt;https://r.jina.ai/https://en.wikipedia.org/wiki/Monkey_Island&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rockstarflo&quot;&gt; /u/rockstarflo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c691qg/reader_llmfriendly_websites/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c691qg/reader_llmfriendly_websites/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c691qg</id><link href="https://www.reddit.com/r/LangChain/comments/1c691qg/reader_llmfriendly_websites/" /><updated>2024-04-17T12:52:19+00:00</updated><published>2024-04-17T12:52:19+00:00</published><title>Reader - LLM-Friendly websites</title></entry><entry><author><name>/u/LaAlice</name><uri>https://www.reddit.com/user/LaAlice</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build an LCEL chain. However, at the n-th step, a cypher graph query gets generated. The next step in the chain should be that the query gets executed and the result gets passed on to the next step. I have a Neo4jGraph object, but I don&amp;#39;t know how to integrate it into the chain. I thought about writing a function that gets the query, executes it and returns the result, but I don&amp;#39;t know how to pass the graph to that function. Is there some element, for example a retriever, that I can use?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LaAlice&quot;&gt; /u/LaAlice &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68ye8/include_graph_query_into_lcel_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68ye8/include_graph_query_into_lcel_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c68ye8</id><link href="https://www.reddit.com/r/LangChain/comments/1c68ye8/include_graph_query_into_lcel_chain/" /><updated>2024-04-17T12:48:04+00:00</updated><published>2024-04-17T12:48:04+00:00</published><title>Include graph query into LCEL chain</title></entry><entry><author><name>/u/Ill_Bodybuilder3499</name><uri>https://www.reddit.com/user/Ill_Bodybuilder3499</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;as for my understanding with BM25 Retrieval, a score is computed. Therefore i would like to set a score threshold for my Langchain Ensemble Retriever with one Bm25 component. But I did not see a way to di this in Langchain.&lt;/p&gt; &lt;p&gt;I want to do this because otherwise the Bm25 is likely to find always something for generic questions and this might not be perfect.&lt;/p&gt; &lt;p&gt;Any thoughts on this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ill_Bodybuilder3499&quot;&gt; /u/Ill_Bodybuilder3499 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6dlyu/bm25_retriever_with_score_threshold/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6dlyu/bm25_retriever_with_score_threshold/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6dlyu</id><link href="https://www.reddit.com/r/LangChain/comments/1c6dlyu/bm25_retriever_with_score_threshold/" /><updated>2024-04-17T16:01:53+00:00</updated><published>2024-04-17T16:01:53+00:00</published><title>BM25 Retriever with Score Threshold</title></entry><entry><author><name>/u/GrizzyLizz</name><uri>https://www.reddit.com/user/GrizzyLizz</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Im still new to Langchain and making use of it (though I am proficient enough with Python). I wanted to build a chatbot application where user inputs to the AI would make use of some provided image. As per my understanding, this is what RAG is for. However, I cant find an example where an LLM application is retreiving images passed to it. Here is the workflow I want to be able to implement:&lt;/p&gt; &lt;p&gt;- User provides some prompt with an image. This image gets stored in the backend by the application. The LLM part of the application then uses this image or any previously provided images as contextual information to reply to the prompt.&lt;/p&gt; &lt;p&gt;- If the prompt requests for one of the images back for e.g. &amp;quot;Can you go through the images and get back the one which is in black and white&amp;quot;, then the application finds such an image and returns it or replies with a negative&lt;/p&gt; &lt;p&gt;Is the second part of this flow achievable using Langchain? Or would I have to do it some other way?&lt;br/&gt; Note: i dont specifically want a model which can identify black and white images but basically perform some kind of semantic search through the images. The prompt may be &amp;quot;Find all the images I provided and give back the ones with a tree in it&amp;quot;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/GrizzyLizz&quot;&gt; /u/GrizzyLizz &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c66lrw/can_an_llm_application_retrieve_imagesusing_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c66lrw/can_an_llm_application_retrieve_imagesusing_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c66lrw</id><link href="https://www.reddit.com/r/LangChain/comments/1c66lrw/can_an_llm_application_retrieve_imagesusing_rag/" /><updated>2024-04-17T10:41:13+00:00</updated><published>2024-04-17T10:41:13+00:00</published><title>Can an LLM application retrieve images(using RAG or some other technique)?</title></entry><entry><author><name>/u/sebastianstehle</name><uri>https://www.reddit.com/user/sebastianstehle</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am using langchain with typescript and I have reported a few bugs and feature requests already and none of them have been answered so far.&lt;/p&gt; &lt;p&gt;There are even issues from January where only the useless bot answered has so far: &lt;a href=&quot;https://github.com/langchain-ai/langchainjs/issues/3978&quot;&gt;https://github.com/langchain-ai/langchainjs/issues/3978&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Many people complain about the documentation, but I am really worried about this problem.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sebastianstehle&quot;&gt; /u/sebastianstehle &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6aquq/developers_seem_to_inactive_at_least_in_the_js/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c6aquq/developers_seem_to_inactive_at_least_in_the_js/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c6aquq</id><link href="https://www.reddit.com/r/LangChain/comments/1c6aquq/developers_seem_to_inactive_at_least_in_the_js/" /><updated>2024-04-17T14:05:05+00:00</updated><published>2024-04-17T14:05:05+00:00</published><title>Developers seem to inactive, at least in the JS repo</title></entry><entry><author><name>/u/cerebriumBoss</name><uri>https://www.reddit.com/user/cerebriumBoss</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68lce/creating_an_executive_assistant_using_langchain/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/iiaz5GsigQoVvtdwJm2jDbRcDCFphCRBecbfTzMEjw8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1b8f1a1d24dc2aaa9b27e6f4a84ecc64f4a97656&quot; alt=&quot;Creating an Executive Assistant using LangChain, LangSmith, Cerebrium and Cal.com&quot; title=&quot;Creating an Executive Assistant using LangChain, LangSmith, Cerebrium and Cal.com&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cerebriumBoss&quot;&gt; /u/cerebriumBoss &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.cerebrium.ai/blog/creating-an-executive-assistant-using-langchain-langsmith-cerebrium-and-cal-com&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68lce/creating_an_executive_assistant_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c68lce</id><media:thumbnail url="https://external-preview.redd.it/iiaz5GsigQoVvtdwJm2jDbRcDCFphCRBecbfTzMEjw8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1b8f1a1d24dc2aaa9b27e6f4a84ecc64f4a97656" /><link href="https://www.reddit.com/r/LangChain/comments/1c68lce/creating_an_executive_assistant_using_langchain/" /><updated>2024-04-17T12:30:10+00:00</updated><published>2024-04-17T12:30:10+00:00</published><title>Creating an Executive Assistant using LangChain, LangSmith, Cerebrium and Cal.com</title></entry><entry><author><name>/u/mutexs</name><uri>https://www.reddit.com/user/mutexs</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, guys!&lt;/p&gt; &lt;p&gt;I&amp;#39;m a newbie in LangChain and need help.&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on a Next.js project for a chatbot where I&amp;#39;m using a RetrievalQAChain. Now, I also want to make external API requests. For that, I&amp;#39;m implementing an APIChain. However, I&amp;#39;m struggling to combine both chains to return the output as a single chain.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mutexs&quot;&gt; /u/mutexs &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68juh/seeking_assistance_in_combining_two_chains/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c68juh/seeking_assistance_in_combining_two_chains/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c68juh</id><link href="https://www.reddit.com/r/LangChain/comments/1c68juh/seeking_assistance_in_combining_two_chains/" /><updated>2024-04-17T12:28:03+00:00</updated><published>2024-04-17T12:28:03+00:00</published><title>Seeking assistance in combining two chains</title></entry><entry><author><name>/u/J-Kob</name><uri>https://www.reddit.com/user/J-Kob</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks!&lt;/p&gt; &lt;p&gt;We&amp;#39;re continuing to iterate on our documentation structure to make it easier to find relevant pages. We&amp;#39;re wondering what people think of top-level &amp;quot;tutorial&amp;quot;, &amp;quot;how to guides&amp;quot;, &amp;quot;conceptual guide&amp;quot; distinctions.&lt;/p&gt; &lt;p&gt;Page content is still WIP, but we were hoping to get feedback on &lt;strong&gt;the structure&lt;/strong&gt; sooner rather than later.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve linked the build we&amp;#39;re iterating on below. Please let us know if you have any thoughts or reactions - do you think this would help you find the information you need more effectively?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://langchain-git-harrison-new-docs-langchain.vercel.app/docs/get_started/introduction&quot;&gt;https://langchain-git-harrison-new-docs-langchain.vercel.app/docs/get_started/introduction&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/J-Kob&quot;&gt; /u/J-Kob &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5l53d/feedback_wanted_langchain_documentation_structure/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5l53d/feedback_wanted_langchain_documentation_structure/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5l53d</id><link href="https://www.reddit.com/r/LangChain/comments/1c5l53d/feedback_wanted_langchain_documentation_structure/" /><updated>2024-04-16T16:57:06+00:00</updated><published>2024-04-16T16:57:06+00:00</published><title>Feedback wanted: LangChain documentation structure</title></entry><entry><author><name>/u/FartingUnicyclist</name><uri>https://www.reddit.com/user/FartingUnicyclist</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys,&lt;/p&gt; &lt;p&gt;Does anyone know how to stream the output from each of the runnable components for a LCEL implementation of a chain? Like what happens when you turn on verbose=true for an agent and it outputs all the steps it is taking. Or like how each runnables are traced in Langsmith.&lt;/p&gt; &lt;p&gt;I need to do this because the full chain takes 50 secs on average to run and this is a bad UX. Using streaming endpoint is not helpful because the final response from the chain is not alot, so I am not looking for the output streaming but streaming of the individual runnables in the LCEL.&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FartingUnicyclist&quot;&gt; /u/FartingUnicyclist &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c64rf2/streaming_individual_runnable_component_for_lcel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c64rf2/streaming_individual_runnable_component_for_lcel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c64rf2</id><link href="https://www.reddit.com/r/LangChain/comments/1c64rf2/streaming_individual_runnable_component_for_lcel/" /><updated>2024-04-17T08:37:19+00:00</updated><published>2024-04-17T08:37:19+00:00</published><title>Streaming individual runnable component for LCEL</title></entry><entry><author><name>/u/ZuckyFox</name><uri>https://www.reddit.com/user/ZuckyFox</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there any small language models available in AWS? I was searching but mostly I found llms? We need some slm like flan-t5 models that can be used for classification task.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ZuckyFox&quot;&gt; /u/ZuckyFox &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c62c2a/slm_in_aws/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c62c2a/slm_in_aws/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c62c2a</id><link href="https://www.reddit.com/r/LangChain/comments/1c62c2a/slm_in_aws/" /><updated>2024-04-17T05:53:09+00:00</updated><published>2024-04-17T05:53:09+00:00</published><title>SLM in AWS?</title></entry><entry><author><name>/u/hedonist_kid</name><uri>https://www.reddit.com/user/hedonist_kid</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello&lt;/p&gt; &lt;p&gt;So I am able to connect a live postgres database and use the sql agent with open ai to a wide variety answer questions about the database and generate sql queries as well. I wanted to know if there are any other useful agents for databases maybe something to visualize, I used llamaindex in collab with a pandas dataframe and got very good results. Also would it be worthwhile to try and build your own agent. I would also want to know if anyone has tried open source models with tje langchain sql agent. &lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hedonist_kid&quot;&gt; /u/hedonist_kid &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5vyfk/what_are_some_agents_which_can_be_used_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5vyfk/what_are_some_agents_which_can_be_used_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5vyfk</id><link href="https://www.reddit.com/r/LangChain/comments/1c5vyfk/what_are_some_agents_which_can_be_used_in/" /><updated>2024-04-17T00:21:59+00:00</updated><published>2024-04-17T00:21:59+00:00</published><title>What are some agents which can be used in addition to the sql agent for rag on db.</title></entry><entry><author><name>/u/Cool_Bhidu</name><uri>https://www.reddit.com/user/Cool_Bhidu</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Guys&lt;br/&gt; I have interview scheduled next week about Langchain. But I am not sure what will be asked? I wanted your inputs on what should I prepare. &lt;/p&gt; &lt;p&gt;My background - I have built multi-doc RAG. Technologies used - Langchain, Chroma, Streamlit, &lt;a href=&quot;https://unstrctured.io&quot;&gt;unstrctured.io&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Please any help is appreciated &lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Cool_Bhidu&quot;&gt; /u/Cool_Bhidu &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5r9qj/langchain_interview_what_things_to_prepare/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5r9qj/langchain_interview_what_things_to_prepare/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5r9qj</id><link href="https://www.reddit.com/r/LangChain/comments/1c5r9qj/langchain_interview_what_things_to_prepare/" /><updated>2024-04-16T21:03:01+00:00</updated><published>2024-04-16T21:03:01+00:00</published><title>Langchain Interview. What things to prepare</title></entry><entry><author><name>/u/Temporary-Size7310</name><uri>https://www.reddit.com/user/Temporary-Size7310</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, I must use old langchain method to generate an output:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;agent_executor = initialize_agent( tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, max_execution_time=4, early_stopping_method=&amp;quot;generate&amp;quot;, verbose=False, handle_parsing_errors=True, memory=memory, ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;early_stopping_method works well using &amp;quot;generate&amp;quot; at the 4th iteration. &lt;/p&gt; &lt;p&gt;If I use new method:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;agent = create_react_agent(llm, tools, prompt) agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False, handle_parsing_errors=True, early_stopping_method=&amp;quot;generate&amp;quot;, max_iterations=4) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It&amp;#39;s like &amp;quot;generate&amp;quot; is not implemented:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;quot;/python3.11/site-packages/langchain/agents/agent.py&amp;quot;, line 127, in return_stopped_response raise ValueError( ValueError: Got unsupported early_stopping_method `generate` &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If I use &amp;quot;force&amp;quot; with and without max_iterations:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Agent stopped due to iteration limit or time limit. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The main issue is i&amp;#39;m using date_time variable, so value change every second for others tools it works like a charm.&lt;/p&gt; &lt;p&gt;Has anyone solved this issue ? Or maybe myearly stopping method is outdated&lt;br/&gt; Thank you in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Temporary-Size7310&quot;&gt; /u/Temporary-Size7310 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5ljzo/early_stopping_method_generate/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5ljzo/early_stopping_method_generate/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5ljzo</id><link href="https://www.reddit.com/r/LangChain/comments/1c5ljzo/early_stopping_method_generate/" /><updated>2024-04-16T17:13:24+00:00</updated><published>2024-04-16T17:13:24+00:00</published><title>Early stopping method : generate</title></entry><entry><author><name>/u/TheGreatZorbo</name><uri>https://www.reddit.com/user/TheGreatZorbo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let&amp;#39;s say I have a service I want to access inside a tool. Or I want to pass in a session ID or some session based state that I don&amp;#39;t want to pass via the agent. &lt;/p&gt; &lt;p&gt;I could obviously declare some things globally, but that isn&amp;#39;t appropriate for everything. &lt;/p&gt; &lt;p&gt;My first thought was wrapping tools in a class that contains their dependencies. I&amp;#39;ve tried different variants of this, but seem to hit all kinds of issues. The documentation contains trivial use cases where we&amp;#39;re passing basic types around, nothing more complex.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;What are people doing for tools which have more complex dependencies? How are they injecting those into tools, in a langchain supported way, without making everything global?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TheGreatZorbo&quot;&gt; /u/TheGreatZorbo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5slrj/whats_the_best_way_to_pass_dependencies_into/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5slrj/whats_the_best_way_to_pass_dependencies_into/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5slrj</id><link href="https://www.reddit.com/r/LangChain/comments/1c5slrj/whats_the_best_way_to_pass_dependencies_into/" /><updated>2024-04-16T21:57:12+00:00</updated><published>2024-04-16T21:57:12+00:00</published><title>what's the best way to pass dependencies into langchain tools?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Check out this demo on how I developed a Multi-Agent system to first generate an Interview panel given job role and than these interviewers interview the candidate one by one (sequentially) , give feedback and eventually all the feedbacks are combined to select the candidate. Find the code explanations &amp;amp; demo for automated interview for Junior Product Manager here : &lt;a href=&quot;https://youtu.be/or36qevjxGE?si=cM1LMhe5J_hnpyFO&quot;&gt;https://youtu.be/or36qevjxGE?si=cM1LMhe5J_hnpyFO&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5csx7/multiagent_interview_panel_using_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5csx7/multiagent_interview_panel_using_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5csx7</id><link href="https://www.reddit.com/r/LangChain/comments/1c5csx7/multiagent_interview_panel_using_langgraph/" /><updated>2024-04-16T10:33:21+00:00</updated><published>2024-04-16T10:33:21+00:00</published><title>Multi-Agent Interview Panel using LangGraph</title></entry><entry><author><name>/u/Equivalent-West-9389</name><uri>https://www.reddit.com/user/Equivalent-West-9389</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am trying to develop an application that requires function calling and responding in everyday language based on the context of user input. I see in langchain we have &lt;a href=&quot;https://js.langchain.com/docs/integrations/chat/ollama&quot;&gt;Ollama&lt;/a&gt; and &lt;a href=&quot;https://js.langchain.com/docs/integrations/chat/ollama_functions&quot;&gt;Ollama functions&lt;/a&gt;; I would like to use the Ollama Function first to check if the user needs to execute any function, then if not respond with regular Ollama, and if it does, get the function data and pass it into Ollama and response usually.&lt;/p&gt; &lt;p&gt;How is this possible?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Equivalent-West-9389&quot;&gt; /u/Equivalent-West-9389 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5n0aw/use_2_llm_1_for_function_calling_and_1_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5n0aw/use_2_llm_1_for_function_calling_and_1_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5n0aw</id><link href="https://www.reddit.com/r/LangChain/comments/1c5n0aw/use_2_llm_1_for_function_calling_and_1_for/" /><updated>2024-04-16T18:10:50+00:00</updated><published>2024-04-16T18:10:50+00:00</published><title>Use 2 LLM, 1 for function calling and 1 for Contextual Response.</title></entry><entry><author><name>/u/ArcuisAlezanzo</name><uri>https://www.reddit.com/user/ArcuisAlezanzo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Im trying building RAG LLM app for support analyst,my primary data is excel sheet with more than 6000 incidents(rows) with columns [Descrietion, Pesolution, Work notes]. Description column explains Incident Description Resolution column explains resolution provided to that Incident Work Notes column steps taken to solve incident.&lt;/p&gt; &lt;p&gt;User provides the new incident as prompt to the APP, expected functionality need to search similar incidents from data , then use that similar incident to generate approx resolution.&lt;/p&gt; &lt;p&gt;Resources available uses uses Azure ai search (for vector search) GPT 4&lt;/p&gt; &lt;p&gt;Should I clean data like, 1. Like removing special characters 2. Lowercase the all letters letters 3.lemmatization 4. Removing stop words like a , an &lt;/p&gt; &lt;p&gt;My major doubt if I embed the description of each incident as one document , does similarity search , take top k documents &lt;/p&gt; &lt;p&gt;What will K be? Will k be higher number or smaller number &lt;/p&gt; &lt;p&gt;Or any idea other cluster similar incidents ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ArcuisAlezanzo&quot;&gt; /u/ArcuisAlezanzo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5mrr1/need_architecture_help/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5mrr1/need_architecture_help/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5mrr1</id><link href="https://www.reddit.com/r/LangChain/comments/1c5mrr1/need_architecture_help/" /><updated>2024-04-16T18:01:37+00:00</updated><published>2024-04-16T18:01:37+00:00</published><title>Need architecture Help</title></entry><entry><author><name>/u/supreet02</name><uri>https://www.reddit.com/user/supreet02</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5l21i/rag_masterclass_practical_insights_from_exmeta/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/3NBtlITDQBL0okCx94aFnDP-6XwWLkbg5yC1f_F7G7U.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=da003574c667de720e0dfa6d36a9cdc3e5e00a96&quot; alt=&quot;RAG Masterclass: Practical Insights from Ex-Meta Pioneers on April 18th&quot; title=&quot;RAG Masterclass: Practical Insights from Ex-Meta Pioneers on April 18th&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/supreet02&quot;&gt; /u/supreet02 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://lu.ma/cognita-rag&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5l21i/rag_masterclass_practical_insights_from_exmeta/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c5l21i</id><media:thumbnail url="https://external-preview.redd.it/3NBtlITDQBL0okCx94aFnDP-6XwWLkbg5yC1f_F7G7U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=da003574c667de720e0dfa6d36a9cdc3e5e00a96" /><link href="https://www.reddit.com/r/LangChain/comments/1c5l21i/rag_masterclass_practical_insights_from_exmeta/" /><updated>2024-04-16T16:53:40+00:00</updated><published>2024-04-16T16:53:40+00:00</published><title>RAG Masterclass: Practical Insights from Ex-Meta Pioneers on April 18th</title></entry><entry><author><name>/u/LaAlice</name><uri>https://www.reddit.com/user/LaAlice</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Edit: This was solved by updating the langchain python package&lt;/p&gt; &lt;p&gt;This is my first time using langchain for QA on a csv file. My steps were CSVLoader --&amp;gt; RecursiveCharacterTextSplitter --&amp;gt; Chroma Vectorstore When I searched for a keyword on the vectorstore with vectorstore.search(&amp;quot;keyword&amp;quot;, search-type=&amp;quot;similarity&amp;quot;), a few documents were found. However, then I tried using a retriever with retriever=vectorstore.as_retriever(search_type=&amp;quot;similarity&amp;quot;). If I search for the same keyword I used before with retriever.invoke(&amp;quot;keyword&amp;quot;), I get the error AttributeError: &amp;#39;NoneType&amp;#39; object has no attribute &amp;#39;get&amp;#39; But I don&amp;#39;t understand why, as it worked directly on the vectorstore.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LaAlice&quot;&gt; /u/LaAlice &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5hzvh/retriever_gives_an_error/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5hzvh/retriever_gives_an_error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5hzvh</id><link href="https://www.reddit.com/r/LangChain/comments/1c5hzvh/retriever_gives_an_error/" /><updated>2024-04-16T14:49:39+00:00</updated><published>2024-04-16T14:49:39+00:00</published><title>Retriever gives an error</title></entry><entry><author><name>/u/Sensitive_Let_4239</name><uri>https://www.reddit.com/user/Sensitive_Let_4239</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, im new to all of this but i have retreived contact info from paper with a OCR into a .txt file but due to the OCR being inaccurate its all unorganised and stuff. Is it possbile to use Langchain to organise this data and make it more accurate (the &amp;quot;i&amp;quot; is often replaced with &amp;quot;l&amp;quot;) in a csv?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sensitive_Let_4239&quot;&gt; /u/Sensitive_Let_4239 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5e0ok/can_you_organize_data_into_a_csv_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c5e0ok/can_you_organize_data_into_a_csv_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c5e0ok</id><link href="https://www.reddit.com/r/LangChain/comments/1c5e0ok/can_you_organize_data_into_a_csv_with_langchain/" /><updated>2024-04-16T11:44:59+00:00</updated><published>2024-04-16T11:44:59+00:00</published><title>Can you organize data into a csv with langchain?</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am experimenting with different chunking techniques like RecursiveCharacterSplitter or &lt;a href=&quot;https://Unstructured.IO&quot;&gt;Unstructured.IO&lt;/a&gt; chunking with &amp;quot;by_title&amp;quot;. Theoretically I think the second option to chunk by title will be the most promising one.&lt;/p&gt; &lt;p&gt;But I would be interested of your experiences? The PDFs I am using are all complex and many come with a completely different structure, so manually checking for every PDF is no choice. &lt;/p&gt; &lt;p&gt;Happy to discuss with your experiences!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4nizz/your_experience_best_chunking_technique_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4nizz/your_experience_best_chunking_technique_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c4nizz</id><link href="https://www.reddit.com/r/LangChain/comments/1c4nizz/your_experience_best_chunking_technique_for/" /><updated>2024-04-15T14:24:47+00:00</updated><published>2024-04-15T14:24:47+00:00</published><title>Your Experience: Best Chunking Technique for complex PDFs</title></entry><entry><author><name>/u/jaagoBohutHuaIntezar</name><uri>https://www.reddit.com/user/jaagoBohutHuaIntezar</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Anyone has any recommendation for course/book/tutorial, free or paid? I have a decent idea about deep learning concepts. But, my current job is in backend with python, so naturally looking to expand my skillset! Thanks. &lt;/p&gt; &lt;p&gt;I just want enough to get a custom chatbot with guardrails up and running on my system. I tried with ollama but am stuck at generating embedding for my dataset &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jaagoBohutHuaIntezar&quot;&gt; /u/jaagoBohutHuaIntezar &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4s19w/coursesbooks_to_get_into_generative_ai_genai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4s19w/coursesbooks_to_get_into_generative_ai_genai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c4s19w</id><link href="https://www.reddit.com/r/LangChain/comments/1c4s19w/coursesbooks_to_get_into_generative_ai_genai/" /><updated>2024-04-15T17:29:08+00:00</updated><published>2024-04-15T17:29:08+00:00</published><title>Courses/books to get into Generative AI (GenAI)? Looking to get familiar with tools like Langchain, vector databases, LLM APIs etc.</title></entry><entry><author><name>/u/benizzy1</name><uri>https://www.reddit.com/user/benizzy1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/dagworks-inc/burr&quot;&gt;https://github.com/dagworks-inc/burr&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; We created Burr to make it easier to build and debug AI applications that carry state/make complex decisions. It is similar in concept to Langgraph, and works with any framework you want (Langchain, etc...). It comes with OS telemetry. We&amp;#39;re looking for users, contributors, and feedback.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The problem(s):&lt;/strong&gt; A lot of tools in the LLM space (DSPY, superagents, etc...) end up burying what you actually want to see behind a layer of complexity and prompt manipulation. While making applications that make decisions naturally requires complexity, we wanted to make it easier to logically model, view telemetry, manage state, etc... while not imposing any restrictions on what you can do or how to interact with LLM APIs. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;We built Burr&lt;/strong&gt; to solve these problems. With Burr, you represent your application as a state machine of python functions/objects and specify transitions/state manipulation between them. We designed it with the following capabilities in mind:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Manage application memory: Burr&amp;#39;s state abstraction allows you to prune memory/feed it to your LLM (in whatever way you want)&lt;/li&gt; &lt;li&gt;Persist/reload state: Burr allows you to load from any point in an application&amp;#39;s run so you can debug/restart from failure&lt;/li&gt; &lt;li&gt;Monitor application decisions: Burr comes with a telemetry UI that you can use to debug your app in real-time&lt;/li&gt; &lt;li&gt;Integrate with your favorite tooling: Burr is just stitching together python primitives -- classes + functions, so you can write whatever you want. Use langchain and dive into the OpenAI/other APIs when you need.&lt;/li&gt; &lt;li&gt;Gather eval data: Burr has logging capabilities to ensure you capture data for fine-tuning/eval&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;It is meant to be a lightweight python library (zero dependencies), with a host of plugins. You can get started by running: &lt;code&gt;pip install &amp;quot;burr[start]&amp;quot; &amp;amp;&amp;amp; burr&lt;/code&gt; -- this will start the telemetry server with a few demos (click on &lt;em&gt;demos&lt;/em&gt; to play with a chatbot + watch telemetry at the same time).&lt;/p&gt; &lt;p&gt;Then, check out the following resources:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;a href=&quot;https://burr.dagworks.io/getting_started/&quot;&gt;Burr&amp;#39;s documentation/getting started&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/DAGWorks-Inc/burr/tree/main/examples/multi-agent-collaboration/lcel&quot;&gt;Multi-agent-collaboration example using LCEL&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/DAGWorks-Inc/burr/tree/main/examples/web-server&quot;&gt;Fairly complex control-flow example that uses AI + human feedback to draft an email&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;We&amp;#39;re really excited&lt;/strong&gt; about the initial reception and are hoping to get more feedback/OS users/contributors -- feel free to DM me or comment here if you have any questions, and happy developing!&lt;/p&gt; &lt;p&gt;PS -- the name &lt;em&gt;Burr&lt;/em&gt; is a play on the project we OSed called &lt;a href=&quot;https://github.com/dagworks-inc/hamilton&quot;&gt;Hamilton&lt;/a&gt; that you may be familiar with. They actually work nicely together!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/benizzy1&quot;&gt; /u/benizzy1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4ssou/burr_an_os_framework_for_building_and_debugging/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c4ssou/burr_an_os_framework_for_building_and_debugging/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c4ssou</id><link href="https://www.reddit.com/r/LangChain/comments/1c4ssou/burr_an_os_framework_for_building_and_debugging/" /><updated>2024-04-15T17:59:26+00:00</updated><published>2024-04-15T17:59:26+00:00</published><title>Burr: an OS framework for building and debugging AI apps faster (manage memory, persist state, monitor decisions, use your own code, gather eval data)</title></entry></feed>