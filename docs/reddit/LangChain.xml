<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-14T16:20:40+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Queasy-Explorer8139</name><uri>https://www.reddit.com/user/Queasy-Explorer8139</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey r/LangChain , I published a new article where I built an observable semantic research paper application.&lt;/p&gt; &lt;p&gt;This is an extensive tutorial where I go in detail about:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Developing a RAG pipeline to process and retrieve the most relevant PDF documents from the arXiv API.&lt;/li&gt; &lt;li&gt;Developing a Chainlit driven web app with a Copilot for online paper retrieval.&lt;/li&gt; &lt;li&gt;Enhancing the app with LLM observability features from Literal AI.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;You can read the article here: &lt;a href=&quot;https://medium.com/towards-data-science/building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&quot;&gt;https://medium.com/towards-data-science/building-an-observable-arxiv-rag-chatbot-with-langchain-chainlit-and-literal-ai-9c345fcd1cd8&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Code for the tutorial: &lt;a href=&quot;https://github.com/tahreemrasul/semantic_research_engine&quot;&gt;https://github.com/tahreemrasul/semantic_research_engine&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Queasy-Explorer8139&quot;&gt; /u/Queasy-Explorer8139 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crtas2/building_an_observable_arxiv_rag_chatbot_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crtas2/building_an_observable_arxiv_rag_chatbot_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crtas2</id><link href="https://www.reddit.com/r/LangChain/comments/1crtas2/building_an_observable_arxiv_rag_chatbot_with/" /><updated>2024-05-14T14:18:02+00:00</updated><published>2024-05-14T14:18:02+00:00</published><title>Building an Observable arXiv RAG Chatbot with LangChain, Chainlit, and Literal AI</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1cruwel/gpt4o_by_openai_features_to_know/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crv0lf/gpt4o_by_openai_features_to_know/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crv0lf</id><link href="https://www.reddit.com/r/LangChain/comments/1crv0lf/gpt4o_by_openai_features_to_know/" /><updated>2024-05-14T15:31:24+00:00</updated><published>2024-05-14T15:31:24+00:00</published><title>GPT-4o by OpenAI, features to know</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I want to improve my RAG system and read about ColBERT and Cross-Encoders, but I don&amp;#39;t really get what is the difference here, can someone explain?&lt;/p&gt; &lt;p&gt;Also would be nice to have some experiences what worked better for your RAG. I have to rely on multilingual models (to use german language), so I picked out:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://huggingface.co/antoinelouis/colbert-xm&quot;&gt;https://huggingface.co/antoinelouis/colbert-xm&lt;/a&gt;&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://huggingface.co/cross-encoder/msmarco-MiniLM-L12-en-de-v1&quot;&gt;https://huggingface.co/cross-encoder/msmarco-MiniLM-L12-en-de-v1&lt;/a&gt;&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Which one would you prefer?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crt25e/cross_encoder_vs_colbert_in_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crt25e/cross_encoder_vs_colbert_in_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crt25e</id><link href="https://www.reddit.com/r/LangChain/comments/1crt25e/cross_encoder_vs_colbert_in_rag/" /><updated>2024-05-14T14:07:45+00:00</updated><published>2024-05-14T14:07:45+00:00</published><title>Cross Encoder vs. ColBERT in RAG</title></entry><entry><author><name>/u/damn_sirius</name><uri>https://www.reddit.com/user/damn_sirius</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Wanted to share something a colleague and Iâ€™ve been recently working on!&lt;/p&gt; &lt;p&gt;Monitoring Snowflake costs, debugging, trying to optimise credit usage, etc. were tedious tasks that were soaking up a lot of engineering bandwidth continuously at our workplace.&lt;/p&gt; &lt;p&gt;We decided to build an AI Agent for this using Langchain, Snowflake Cortex and Open AI!&lt;/p&gt; &lt;p&gt;Check out this quick demo where I ask the agent about my Snowflake spending. There are multiple agents working behind the scenes, using OpenAI and Cortex to find the best answersâ€”and the coolest part? The data visualisations are all chosen by the AI based on what you need.&lt;/p&gt; &lt;p&gt;Demo link: &lt;a href=&quot;https://www.loom.com/share/b14cb082ba6843298501985f122ffb97?sid=b4cf26d8-77f7-4a63-bab9-c8e6e9f47064&quot;&gt;https://www.loom.com/share/b14cb082ba6843298501985f122ffb97?sid=b4cf26d8-77f7-4a63-bab9-c8e6e9f47064&lt;/a&gt;&lt;/p&gt; &lt;p&gt;It can currently&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Monitor costs&lt;/li&gt; &lt;li&gt;Forecast costs&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Weâ€™re looking to add abilities like alerting on anomalies and optimising queries to it too!&lt;/p&gt; &lt;p&gt;Itâ€™s not perfect yet (sometimes it messes up ðŸ˜…), but weâ€™re working on improving it! If youâ€™ve got thoughts on this or know other tasks that could be added to this, let me know.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/damn_sirius&quot;&gt; /u/damn_sirius &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crq7k1/building_a_snowflake_cost_monitoring_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crq7k1/building_a_snowflake_cost_monitoring_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crq7k1</id><link href="https://www.reddit.com/r/LangChain/comments/1crq7k1/building_a_snowflake_cost_monitoring_and/" /><updated>2024-05-14T11:50:54+00:00</updated><published>2024-05-14T11:50:54+00:00</published><title>Building a Snowflake Cost Monitoring and Optimiser tool using Langchain, Snowflake Cortex and Open AI</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What challenges are you facing and what tools are you using? I am thinking about building out a developer friendly open source evaluations tool kit. Thinking of starting with a simple interface where you pass the context, input, output and expected output and run it through some basic tests - both LLM based and non LLM based and also allow the ability to write custom assertions.&lt;/p&gt; &lt;p&gt;But, am wondering if you all have any insights into what other capabilities might be useful. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crvzvd/what_are_your_current_challenges_with_evaluations/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crvzvd/what_are_your_current_challenges_with_evaluations/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crvzvd</id><link href="https://www.reddit.com/r/LangChain/comments/1crvzvd/what_are_your_current_challenges_with_evaluations/" /><updated>2024-05-14T16:12:28+00:00</updated><published>2024-05-14T16:12:28+00:00</published><title>What are your current challenges with evaluations?</title></entry><entry><author><name>/u/Honest-Worth3677</name><uri>https://www.reddit.com/user/Honest-Worth3677</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crt1dv/how_to_solve_real_world_ai_job_in_upwork/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/5U_WiM-IhjTpuFdRzdIwoFc0QeVl4KRYxqNRoLdBBmc.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=afdf14ce4648d0beb8ee2daaedc4fd9431772003&quot; alt=&quot; How to Solve Real World AI Job in UPWORK&quot; title=&quot; How to Solve Real World AI Job in UPWORK&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Honest-Worth3677&quot;&gt; /u/Honest-Worth3677 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=xDOm_G7Cyac&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crt1dv/how_to_solve_real_world_ai_job_in_upwork/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1crt1dv</id><media:thumbnail url="https://external-preview.redd.it/5U_WiM-IhjTpuFdRzdIwoFc0QeVl4KRYxqNRoLdBBmc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=afdf14ce4648d0beb8ee2daaedc4fd9431772003" /><link href="https://www.reddit.com/r/LangChain/comments/1crt1dv/how_to_solve_real_world_ai_job_in_upwork/" /><updated>2024-05-14T14:06:55+00:00</updated><published>2024-05-14T14:06:55+00:00</published><title>How to Solve Real World AI Job in UPWORK</title></entry><entry><author><name>/u/MoronSlayer42</name><uri>https://www.reddit.com/user/MoronSlayer42</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In a RAG application with any vector databases connected. How can I deal with ambiguity in the user query? What kind of tool/ prompt can I define so that my agent asks the user for further questions when a query is not very clear or not enough information is given to give a solid correct answer. I have a 4 tools with a ReAct agent ( &lt;code&gt;create_ReAct_agent&lt;/code&gt; ), one for using the vector databases as a retriever, one for handling irrelevant queries, one for handling generic user greetings and one for handling ambiguity. The other tools work well but the tool for ambiguity looks like it&amp;#39;s never used as the agent always retrieves docs even if the context is relevant yet ambiguous.&lt;/p&gt; &lt;p&gt;One good product that can handle this is Perplexity which prompts the user for further clarification when an ambiguous question is asked.&lt;/p&gt; &lt;p&gt;I want to handle ambiguous nature related to my documents in the vector store without the LLM assuming anything on its own. As an example, if I am creating a medical chatbot that can help people know about different health insurances, doctors in their areas and which insurances those hospitals/doctors accept and user asks &amp;quot;Which doctor should I visit?&amp;quot;. The agent should ideally be asking the user what problems they&amp;#39;re facing or any other relevant information to give a proper answer, rather than just saying here are 10 most important kinds of doctors you have to visit.....&lt;/p&gt; &lt;p&gt;It should ask about patient&amp;#39;s age, medical issues, medical history, the more clearer it can be on what the user really wants the better answer or can generate rather than giving some generic response based on the documents in the vector store.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MoronSlayer42&quot;&gt; /u/MoronSlayer42 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crl0bk/handling_ambiguity_inagents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crl0bk/handling_ambiguity_inagents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crl0bk</id><link href="https://www.reddit.com/r/LangChain/comments/1crl0bk/handling_ambiguity_inagents/" /><updated>2024-05-14T05:56:06+00:00</updated><published>2024-05-14T05:56:06+00:00</published><title>Handling ambiguity inAgents</title></entry><entry><author><name>/u/furyacer</name><uri>https://www.reddit.com/user/furyacer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building a RAG chatbot that gives you the contextual information on the documents uploaded into the database connected to the chatbot. Now, I&amp;#39;m trying to implement a feature wherein the user can use a hash(#) to instruct the bot to point to a specific document within a db and ask questions about that specific doc. Please help me on how to implement that feature (adding hash to the bot and having bot recognize the hash and automatically reference the document that follows hash) in my project. &lt;/p&gt; &lt;p&gt;For example, if the user types &amp;#39;What is the order value of #orderdetails&amp;#39;, the chatbot has to refer to the document &amp;#39;orderdetails&amp;#39; stored in the db and has to extract the order value and display it to the user.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/furyacer&quot;&gt; /u/furyacer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cro1oc/need_help_with_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cro1oc/need_help_with_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cro1oc</id><link href="https://www.reddit.com/r/LangChain/comments/1cro1oc/need_help_with_rag_chatbot/" /><updated>2024-05-14T09:34:39+00:00</updated><published>2024-05-14T09:34:39+00:00</published><title>Need help with RAG chatbot</title></entry><entry><author><name>/u/ottoboob</name><uri>https://www.reddit.com/user/ottoboob</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a question regarding matching company names to their respective sectors using descriptions.&lt;/p&gt; &lt;p&gt;I have two files, each with two columns:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;File 1: Company Name &amp;amp; Description&lt;/li&gt; &lt;li&gt;File 2: Company Sector/Class &amp;amp; Description&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The goal is to match the company names to the correct sectors based on the descriptions.&lt;/p&gt; &lt;p&gt;If it were just one company, I would embed all the descriptions, perform a similarity search to pick the top 5 matches, and then use an LLM call to finalize the matching.&lt;/p&gt; &lt;p&gt;However, how would you proceed if you needed to do this in bulk? Assume that latency and cost are not issues, and you want to process everything in a batch fashion.&lt;/p&gt; &lt;p&gt;Any insights or suggestions on the best approach to handle this bulk processing would be greatly appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ottoboob&quot;&gt; /u/ottoboob &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crpsmq/bulk_matching/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crpsmq/bulk_matching/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crpsmq</id><link href="https://www.reddit.com/r/LangChain/comments/1crpsmq/bulk_matching/" /><updated>2024-05-14T11:26:52+00:00</updated><published>2024-05-14T11:26:52+00:00</published><title>bulk matching</title></entry><entry><author><name>/u/liquidus08</name><uri>https://www.reddit.com/user/liquidus08</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve created a (RAG) system that returns relevant documents. I am now looking to enhance the user experience by displaying images associated with these documents using their documents IDS.&lt;/p&gt; &lt;p&gt;So my system is: doc retrieval, get document ids, load relevant images using IDs, display images.&lt;/p&gt; &lt;p&gt;Anyone knows how this can be done? I understand multimodal is an option but I don&amp;#39;t want to search across images. Just want to display images using document ids of returned docs&lt;/p&gt; &lt;p&gt;In my case, the retrieved documents are sent to the LLM to synthesize the answer directly. I need to figure out a way to inject response into the LLM output.&lt;/p&gt; &lt;p&gt;&lt;code&gt;conversation = ConversationalRetrievalChain.from_llm(llm,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;chain_type=&amp;quot;stuff&amp;quot;,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;retriever=retriever,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;condense_question_prompt=main_prompt,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;return_source_documents=True,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;combine_docs_chain_kwargs=dict(prompt=combine_docs_custom_prompt),&lt;/code&gt;&lt;br/&gt; &lt;code&gt;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;For example, this is the current response I am getting&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Based on your query, these are the relevant products&lt;/p&gt; &lt;p&gt;Product 1&lt;/p&gt; &lt;p&gt;Product 2&lt;/p&gt; &lt;p&gt;Product 3&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;I want to change it to this&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Based on your query, these are the relevant products&lt;/p&gt; &lt;p&gt;Product 1&lt;br/&gt; &amp;lt;images of product 1&amp;gt;&lt;/p&gt; &lt;p&gt;Product 2&lt;br/&gt; &amp;lt;images of product 2&amp;gt;&lt;/p&gt; &lt;p&gt;Product 3&lt;br/&gt; &amp;lt;images of product 3&amp;gt;&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;This is what I am trying to achieve. Anyone has experience solving this problem?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/liquidus08&quot;&gt; /u/liquidus08 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crkgp0/displaying_images_using_document_ids_in_a_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crkgp0/displaying_images_using_document_ids_in_a_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crkgp0</id><link href="https://www.reddit.com/r/LangChain/comments/1crkgp0/displaying_images_using_document_ids_in_a_rag/" /><updated>2024-05-14T05:20:50+00:00</updated><published>2024-05-14T05:20:50+00:00</published><title>Displaying Images using document IDs in a RAG System</title></entry><entry><author><name>/u/Ethan045627</name><uri>https://www.reddit.com/user/Ethan045627</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have created a custom LLMSingleActionAgent but once the agent completes the observation the AgentExecutor chain finished. This results in errors, because my parser waits for &amp;quot;Final Answer&amp;quot; for the user.&lt;/p&gt; &lt;p&gt;&lt;code&gt;def create_agent(&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;llm,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;handlers,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;max_iterations: int = 1,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;early_stopping_method: str = &amp;quot;force&amp;quot;,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;):&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;output_parser = CustomOutputParser()&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;python_tool = PythonAstREPLTool(callbacks=handlers)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tools = [python_tool]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tool_names = [tool.name for tool in tools]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;prompt = CustomPromptTemplate(&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;template=template,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tools=tools,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;input_variables=[&amp;quot;system_prompt&amp;quot;, &amp;quot;input&amp;quot;, &amp;quot;intermediate_steps&amp;quot;]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;llm_chain = LLMChain(llm=llm, prompt=prompt, callbacks=handlers)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;agent = LLMSingleActionAgent(&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;llm_chain=llm_chain,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;output_parser=output_parser,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;stop=[&amp;quot;\nObservation:&amp;quot;],&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;allowed_tools=tool_names&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;return AgentExecutor.from_agent_and_tools(&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;agent=agent,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tools=tools,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;verbose=True,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;max_iterations=max_iterations,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;callbacks=handlers,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;early_stopping_method=early_stopping_method&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ethan045627&quot;&gt; /u/Ethan045627 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crn71i/agentexecutor_chain_finished_after_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crn71i/agentexecutor_chain_finished_after_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crn71i</id><link href="https://www.reddit.com/r/LangChain/comments/1crn71i/agentexecutor_chain_finished_after_the/" /><updated>2024-05-14T08:32:51+00:00</updated><published>2024-05-14T08:32:51+00:00</published><title>AgentExecutor chain finished after the Observation, but before the llm giving Final Answer</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;DSPy is a breakthrough Generative AI package that helps in automatic prompt tuning. How is it different from LangChain? Find in this video &lt;a href=&quot;https://youtu.be/3QbiUEWpO0E?si=4oOXx6olUv-7Bdr9&quot;&gt;https://youtu.be/3QbiUEWpO0E?si=4oOXx6olUv-7Bdr9&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cril3q/langchain_vs_dspy_key_differences_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cril3q/langchain_vs_dspy_key_differences_explained/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cril3q</id><link href="https://www.reddit.com/r/LangChain/comments/1cril3q/langchain_vs_dspy_key_differences_explained/" /><updated>2024-05-14T03:30:13+00:00</updated><published>2024-05-14T03:30:13+00:00</published><title>LangChain vs DSPy Key differences explained</title></entry><entry><author><name>/u/help-me-grow</name><uri>https://www.reddit.com/user/help-me-grow</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crduue/11_ways_to_mix_and_match_tools_to_build_ai_agents/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/e_NtZPkFf4DlJeare7KHf4ZF14L0R5M6XskpL_ZZFG0.jpg&quot; alt=&quot;11 Ways to Mix and Match Tools to Build AI Agents&quot; title=&quot;11 Ways to Mix and Match Tools to Build AI Agents&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/help-me-grow&quot;&gt; /u/help-me-grow &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/ytang07/ai_agents_cookbooks&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crduue/11_ways_to_mix_and_match_tools_to_build_ai_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1crduue</id><media:thumbnail url="https://a.thumbs.redditmedia.com/e_NtZPkFf4DlJeare7KHf4ZF14L0R5M6XskpL_ZZFG0.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1crduue/11_ways_to_mix_and_match_tools_to_build_ai_agents/" /><updated>2024-05-13T23:32:35+00:00</updated><published>2024-05-13T23:32:35+00:00</published><title>11 Ways to Mix and Match Tools to Build AI Agents</title></entry><entry><author><name>/u/Ethan045627</name><uri>https://www.reddit.com/user/Ethan045627</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crln5u/agentexecutor_with_max_iterations1_finishes_the/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/dXfXaaP5s2Jg9eR4WRwOuAuRYWDH6RzpMOR2IScKSgw.jpg&quot; alt=&quot;AgentExecutor with max_iterations=1 finishes the chain before code execution resulting in observation not getting logged&quot; title=&quot;AgentExecutor with max_iterations=1 finishes the chain before code execution resulting in observation not getting logged&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have created a single base agent with Python tool, but setting max_iterations=1 finishes the chain before function output.&lt;/p&gt; &lt;p&gt;Can anyone help me debug this?&lt;/p&gt; &lt;p&gt;Image: Left pane shows the log file, where as the right pane is the terminal.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/ppqq3h1o7c0d1.png?width=1369&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=545b81e02c317642006c6c1e9459516c5baf1cf2&quot;&gt;https://preview.redd.it/ppqq3h1o7c0d1.png?width=1369&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=545b81e02c317642006c6c1e9459516c5baf1cf2&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ethan045627&quot;&gt; /u/Ethan045627 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crln5u/agentexecutor_with_max_iterations1_finishes_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crln5u/agentexecutor_with_max_iterations1_finishes_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1crln5u</id><media:thumbnail url="https://b.thumbs.redditmedia.com/dXfXaaP5s2Jg9eR4WRwOuAuRYWDH6RzpMOR2IScKSgw.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1crln5u/agentexecutor_with_max_iterations1_finishes_the/" /><updated>2024-05-14T06:39:31+00:00</updated><published>2024-05-14T06:39:31+00:00</published><title>AgentExecutor with max_iterations=1 finishes the chain before code execution resulting in observation not getting logged</title></entry><entry><author><name>/u/aryanmadhavverma</name><uri>https://www.reddit.com/user/aryanmadhavverma</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqzjq0/experimenting_with_langchain_langgraph_and/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/s5LwlsknW0tpECrvQHNAcOTUzwaZmriSp4A7dv2TGGk.jpg&quot; alt=&quot;Experimenting with Langchain, Langgraph, and Snowflake to Build a Product Copilot POC&quot; title=&quot;Experimenting with Langchain, Langgraph, and Snowflake to Build a Product Copilot POC&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In a recent hackweek, a colleague and I decided to explore the integration of natural language processing and data visualization by building a prototype agent that interfaces directly with Snowflake. Our goal was to create a tool that could automatically interpret intent, fetch relevant data, and generate visual insights, starting with trends and funnels.&lt;/p&gt; &lt;p&gt;Hereâ€™s what weâ€™ve implemented so far:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Trend visualization&lt;/li&gt; &lt;li&gt;Funnel analysis&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Looking ahead, weâ€™re excited to expand the tool&amp;#39;s capabilities to include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Retention reports&lt;/li&gt; &lt;li&gt;User cohort analysis&lt;/li&gt; &lt;li&gt;Metric alerts&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This project is very much a work-in-progress, and we&amp;#39;re keen on refining and enhancing its functionalities. We want this tool to be a helpful assistant for product managers who rely on Snowflake for data insights.&lt;/p&gt; &lt;p&gt;For a closer look, check out the video demo we posted on our LinkedIn. &lt;a href=&quot;https://www.linkedin.com/posts/shubhankarsrivastava_analytics-agents-in-snowflake-product-activity-7194598110440955904-wi51?utm_source=share&amp;amp;utm_medium=member_desktop&quot;&gt;Here&amp;#39;s the link to our LinkedIn post with the video demo.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Attached is an image showing how we structured the architecture of our agent. Iâ€™m eager to hear any feedback or ideas from this community!&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/c2kj0psg670d1.png?width=795&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=13f65407c9cd4f8295a5c9c7826451c51492446e&quot;&gt;https://preview.redd.it/c2kj0psg670d1.png?width=795&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=13f65407c9cd4f8295a5c9c7826451c51492446e&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/aryanmadhavverma&quot;&gt; /u/aryanmadhavverma &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqzjq0/experimenting_with_langchain_langgraph_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqzjq0/experimenting_with_langchain_langgraph_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cqzjq0</id><media:thumbnail url="https://b.thumbs.redditmedia.com/s5LwlsknW0tpECrvQHNAcOTUzwaZmriSp4A7dv2TGGk.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1cqzjq0/experimenting_with_langchain_langgraph_and/" /><updated>2024-05-13T13:39:11+00:00</updated><published>2024-05-13T13:39:11+00:00</published><title>Experimenting with Langchain, Langgraph, and Snowflake to Build a Product Copilot POC</title></entry><entry><author><name>/u/emersounds</name><uri>https://www.reddit.com/user/emersounds</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on a project using Google Cloud and I&amp;#39;m exploring two approaches to create an agent:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Option 1: Reasoning Engine with Langchain&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This approach involves using Langchain&amp;#39;s Reasoning Engine with my own tools connected through a REST API. I envision a frontend built with Next.js that communicates with a FastAPI backend using WebSockets. The backend would then query the Reasoning Engine using the Vertex AI SDK, which would reason with my Langchain Agent.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Option 2: Langchain &amp;amp; Langserve on Google Cloud Run&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Alternatively, I could create a standalone agent entirely in Langserve. This agent would handle memory, tools, and queries to the Gemini API for completion. Communication with the frontend would likely involve a REST API (but I&amp;#39;m open to suggestions).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;My Dilemma:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;I&amp;#39;m unsure which approach is better suited for my needs.&lt;/li&gt; &lt;li&gt;My REST API is private and deployed on AWS.&lt;/li&gt; &lt;li&gt;I&amp;#39;m open to recommendations on building an agent with Google Cloud, particularly regarding WebSockets (mandatory or optional) and overall architecture.&lt;/li&gt; &lt;li&gt;Does Langserve even support WebSockets?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Any insights or suggestions from the community would be greatly appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/emersounds&quot;&gt; /u/emersounds &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crezed/building_an_agent_with_google_cloud_langserve_on/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1crezed/building_an_agent_with_google_cloud_langserve_on/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1crezed</id><link href="https://www.reddit.com/r/LangChain/comments/1crezed/building_an_agent_with_google_cloud_langserve_on/" /><updated>2024-05-14T00:26:56+00:00</updated><published>2024-05-14T00:26:56+00:00</published><title>Building an Agent with Google Cloud (Langserve on GC Run vs. Vertex AI Reasoning Engine)</title></entry><entry><author><name>/u/CantaloupeLeading646</name><uri>https://www.reddit.com/user/CantaloupeLeading646</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hi,&lt;/p&gt; &lt;p&gt;i&amp;#39;m struggling to find an answer to this question - &lt;/p&gt; &lt;p&gt;i&amp;#39;m writing a small application that utilizes RAG with a mistral model, the main script looks something like this: &lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.document_loaders import TextLoader&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain_community.document_loaders import PyPDFLoader&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain_mistralai.chat_models import ChatMistralAI&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain_mistralai.embeddings import MistralAIEmbeddings&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain_community.vectorstores import FAISS&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain.text_splitter import RecursiveCharacterTextSplitter&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain.chains.combine_documents import create_stuff_documents_chain&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain_core.prompts import ChatPromptTemplate&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain.chains import create_retrieval_chain&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain.storage import LocalFileStore&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain.embeddings import CacheBackedEmbeddings&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from time import time&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from dotenv import load_dotenv&lt;/code&gt;&lt;br/&gt; &lt;code&gt;import os&lt;/code&gt; &lt;/p&gt; &lt;p&gt;&lt;code&gt;if __name__ == &amp;quot;__main__&amp;quot;:&lt;/code&gt;&lt;br/&gt; &lt;code&gt;load_dotenv()&lt;/code&gt;&lt;br/&gt; &lt;code&gt;api_key = os.getenv(&amp;quot;MISTRAL_KEY&amp;quot;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;loader = PyPDFLoader(&amp;quot;paper1.pdf&amp;quot;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;text_splitter = RecursiveCharacterTextSplitter(chunk_size = 2000, chunk_overlap = 300)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;docs = loader.load_and_split()&lt;/code&gt;&lt;br/&gt; &lt;code&gt;# Split text into chunks&lt;/code&gt;&lt;br/&gt; &lt;code&gt;documents = text_splitter.split_documents(docs)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;# Define the embedding model&lt;/code&gt;&lt;br/&gt; &lt;code&gt;embeddings = MistralAIEmbeddings(model=&amp;quot;mistral-embed&amp;quot;, mistral_api_key=api_key)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;store = LocalFileStore(&amp;quot;./cache/&amp;quot;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;cached_embedder = CacheBackedEmbeddings.from_bytes_store(&lt;/code&gt;&lt;br/&gt; &lt;code&gt;embeddings, store, namespace=embeddings.model&lt;/code&gt;&lt;br/&gt; &lt;code&gt;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;# Create the vector store&lt;/code&gt;&lt;br/&gt; &lt;code&gt;initial_time = time()&lt;/code&gt;&lt;br/&gt; &lt;code&gt;vector = FAISS.from_documents(documents, cached_embedder)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;# Define a retriever interface&lt;/code&gt;&lt;br/&gt; &lt;code&gt;retriever = vector.as_retriever()&lt;/code&gt;&lt;br/&gt; &lt;code&gt;# Define LLM&lt;/code&gt;&lt;br/&gt; &lt;code&gt;model = ChatMistralAI(mistral_api_key=api_key)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;# Define prompt template&lt;/code&gt;&lt;br/&gt; &lt;code&gt;prompt = ChatPromptTemplate.from_template(&amp;quot;&amp;quot;&amp;quot;Answer the following question based only on the provided context:&lt;/code&gt; &lt;/p&gt; &lt;p&gt;&lt;code&gt;&amp;lt;context&amp;gt;&lt;/code&gt;&lt;br/&gt; &lt;code&gt;{context}&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;lt;/context&amp;gt;&lt;/code&gt; &lt;/p&gt; &lt;p&gt;&lt;code&gt;Question: {input}&amp;quot;&amp;quot;&amp;quot;)&lt;/code&gt; &lt;/p&gt; &lt;p&gt;&lt;code&gt;# Create a retrieval chain to answer questions&lt;/code&gt;&lt;br/&gt; &lt;code&gt;document_chain = create_stuff_documents_chain(model, prompt)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;retrieval_chain = create_retrieval_chain(retriever, document_chain)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;response = retrieval_chain.invoke({&amp;quot;input&amp;quot;: &amp;quot;What were the two main things the author worked on before college?&amp;quot;})&lt;/code&gt;&lt;br/&gt; &lt;code&gt;print(response[&amp;quot;answer&amp;quot;])&lt;/code&gt;&lt;/p&gt; &lt;p&gt;is there any function i can run from a main script to track my usage in dollars?&lt;br/&gt; everytime the script runs it will print out how many dollars i have left or something like that. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CantaloupeLeading646&quot;&gt; /u/CantaloupeLeading646 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cr5usv/tracking_token_usage_programatically_in_python/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cr5usv/tracking_token_usage_programatically_in_python/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cr5usv</id><link href="https://www.reddit.com/r/LangChain/comments/1cr5usv/tracking_token_usage_programatically_in_python/" /><updated>2024-05-13T18:01:32+00:00</updated><published>2024-05-13T18:01:32+00:00</published><title>tracking token usage programatically in python</title></entry><entry><author><name>/u/jiggerjog</name><uri>https://www.reddit.com/user/jiggerjog</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi y&amp;#39;all! I&amp;#39;m trying to get some feedback from those using langchain with OpenAI APIs. What areas are you guys seeing the most difficulty with? I would love to hear about your experience! Feel free to mention more details in the comments section about your specific usecase&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.reddit.com/poll/1cravwx&quot;&gt;View Poll&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jiggerjog&quot;&gt; /u/jiggerjog &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cravwx/what_is_the_hardest_part_of_integrating_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cravwx/what_is_the_hardest_part_of_integrating_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cravwx</id><link href="https://www.reddit.com/r/LangChain/comments/1cravwx/what_is_the_hardest_part_of_integrating_langchain/" /><updated>2024-05-13T21:23:33+00:00</updated><published>2024-05-13T21:23:33+00:00</published><title>what is the hardest part of integrating langchain with openai?</title></entry><entry><author><name>/u/echopurpose</name><uri>https://www.reddit.com/user/echopurpose</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to understand custom tools and agents. &lt;/p&gt; &lt;p&gt;I tried to make a simple example, with three tools to choose from. Then I ask it for money. Mostly it fails in one of a few ways:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;It identifies &amp;#39;get_money&amp;#39; as the function to call, but then it says it is not valid and tries to call it again&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;It just loops calling &amp;#39;get_money&amp;#39; over and over again&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;It calls &amp;#39;get_money&amp;#39; but then decides it needs to do something with the money and that &amp;#39;get_bricks&amp;#39; seems like a good things to do. &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I&amp;#39;m using llama3 as my LLM.&lt;/p&gt; &lt;p&gt;Can you give me any pointers? Code snippet and example of looping behavior below.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;@tool def get_bricks(query: str) -&amp;gt; str: &amp;quot;&amp;quot;&amp;quot;Returns bricks&amp;quot;&amp;quot;&amp;quot; return &amp;quot;bricks&amp;quot; @tool def get_money(query: str) -&amp;gt; int: &amp;quot;&amp;quot;&amp;quot;Returns money.&amp;quot;&amp;quot;&amp;quot; return &amp;quot;money&amp;quot; @tool def get_word_length(word: str) -&amp;gt; int: &amp;quot;&amp;quot;&amp;quot;Returns the length of a word.&amp;quot;&amp;quot;&amp;quot; return len(word) tools = [get_word_length, get_money, get_bricks] prompt = hub.pull(&amp;quot;hwchase17/react&amp;quot;) agent = create_react_agent(llm, tools, prompt) agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) agent_executor.invoke( { &amp;quot;input&amp;quot;: &amp;quot;Can you get me some money?&amp;quot; } ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Which results in something like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python minimal_tool_bot.py &amp;gt; Entering new AgentExecutor chain... I&amp;#39;d be happy to help! Thought: Hmm, it looks like I need to take an action to get the money. Let me think... Action: get_money Action Input: None (since get_money doesn&amp;#39;t require any inputmoneyI&amp;#39;m glad you asked! Thought: Now that I have the money, let&amp;#39;s see how we can use it. Action: None (for now) The money seems like a nice chunk of change! Let&amp;#39;s think about what to do next... Thought: What should we do with this money? Action: get_bricks Action Input: None (since get_bricks doesn&amp;#39;t require any inputNone (for now) The money seems like a nice chunk of change! Let&amp;#39;s think about what to do next... Thought: What should we do with this money? Action: get_bricks is not a valid tool, try one of [get_word_length, get_money, get_bricks].Let&amp;#39;s continue! Thought: Oops, it looks like I made a mistake! Action: get_word_length Action Input: None (since get_word_length doesn&amp;#39;t require any input53Question: Can you get me some money? Thought: I&amp;#39;d be happy to help! Thought: Hmm, it looks like I need to take an action to get the money. Let me think... Action: get_money Action Input: None (since get_money doesn&amp;#39;t require any inputmoneyI&amp;#39;ll continue from where you left off. Question: What does the length of &amp;quot;Can you get me some money?&amp;quot; mean? Thought: I think I can use this information to help answer my original question... Action: get_word_length &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/echopurpose&quot;&gt; /u/echopurpose &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cr3lav/unexpected_and_erroneous_results_when_trying_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cr3lav/unexpected_and_erroneous_results_when_trying_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cr3lav</id><link href="https://www.reddit.com/r/LangChain/comments/1cr3lav/unexpected_and_erroneous_results_when_trying_to/" /><updated>2024-05-13T16:29:36+00:00</updated><published>2024-05-13T16:29:36+00:00</published><title>Unexpected and erroneous results when trying to use a react agent with minimal tools</title></entry><entry><author><name>/u/Glittering-Bear5748</name><uri>https://www.reddit.com/user/Glittering-Bear5748</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i have multiple collection(tables like employee,hr,deptartment) of user data and i want build RAG chat bot with citation and prompt using langchain&lt;br/&gt; can you please provide detail steps to perform it don&amp;#39;t provide reference documents&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering-Bear5748&quot;&gt; /u/Glittering-Bear5748 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cr4z66/rag_using_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cr4z66/rag_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cr4z66</id><link href="https://www.reddit.com/r/LangChain/comments/1cr4z66/rag_using_langchain/" /><updated>2024-05-13T17:26:00+00:00</updated><published>2024-05-13T17:26:00+00:00</published><title>RAG using Langchain</title></entry><entry><author><name>/u/UnhappyAd2901</name><uri>https://www.reddit.com/user/UnhappyAd2901</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I try to write a assistant prompt to llama 3 but it doesn&amp;#39;t recognize the tool at all, does any one can give me an example to it. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UnhappyAd2901&quot;&gt; /u/UnhappyAd2901 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cr48vz/llama3_assistant_prompt/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cr48vz/llama3_assistant_prompt/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cr48vz</id><link href="https://www.reddit.com/r/LangChain/comments/1cr48vz/llama3_assistant_prompt/" /><updated>2024-05-13T16:56:47+00:00</updated><published>2024-05-13T16:56:47+00:00</published><title>Llama3 Assistant Prompt</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been tinkering with DSPy and thought I will share my 2 cents here for anyone who is planning to explore it:&lt;/p&gt; &lt;p&gt;The core idea behind DSPy are two things:&lt;/p&gt; &lt;ol&gt; &lt;li&gt; â Separate programming from prompting&lt;/li&gt; &lt;li&gt; â incorporate some of the best practice prompting techniques under the hood and expose it as a â€œsignatureâ€&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Imagine working on a RAG. Today, the typical approach is to write some retrieval and pass the results to a language model for natural language generation. But, after the first pass, you realize itâ€™s not perfect and you need to iterate and improve it. Typically, there are 2 levers to pull:&lt;/p&gt; &lt;ol&gt; &lt;li&gt; â Document Chunking, insertion and Retrieval strategy&lt;/li&gt; &lt;li&gt; â Language model settings and prompt engineering&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Now, you try a few things, maybe document the performance in a google sheet, iterate and arrive at an ideal set of variables that gives max accuracy.&lt;/p&gt; &lt;p&gt;Now, letâ€™s say after a month, model upgrades, and all of a sudden the accuracy of your RAG regresses. Again you are back to square one, cos you donâ€™t know what to optimize now - retrieval or model? You see what the problem is with this approach? This is a very open ended, monolithic, brittle and unstructured way to optimize and build language model based applications.&lt;/p&gt; &lt;p&gt;This is precisely the problem DSPy is trying to solve. Whatever you can achieve with DSPy can be achieved with native prompt engineering and program composition techniques but it is purely dependent on the programmers skill. But DSPy provides native constructs which anyone can learn and use for trying different techniques in a systematic manner.&lt;/p&gt; &lt;p&gt;DSPy the concept:&lt;/p&gt; &lt;p&gt;Separate prompting from programming and signatures&lt;/p&gt; &lt;p&gt;DSPy does not do any magic with the language model. It just uses a bunch of prompt templates behind the scenes and exposes them as signatures. Ex: when you write a signature like â€˜context, question -&amp;gt; answerâ€™, DSPy adds a typical RAG prompt before it makes the call to the LLM. But DSPy also gives you nice features like module settings, assertion based backtracking and automatic prompt optimization.&lt;/p&gt; &lt;p&gt;Basically, you can do something like this with DSPy,&lt;/p&gt; &lt;p&gt;â€œGiven a context and question, answer the following question. Make sure the answer is only â€œyesâ€ or â€œnoâ€â€. If the language model responds with anything else, traditionally we prompt engineer our way to fix it. In DSPy, you can assert the answer for â€œyesâ€ or â€œnoâ€ and if the assertion fails, DSPy will backtrack automatically, update the prompt to say something like, â€œthis is not a correct answer- {previous_answer} and always only respond with a â€œyesâ€ or â€œnoâ€â€ and makes another language model call which improves the LLMs response because of this newly optimized prompt. In addition, you can also incorporate things like multi hops in your retrieval where you can do something like â€œretrieve -&amp;gt; generate queries and then retrieve again using the generated queriesâ€ for n times and build up a larger context to answer the original question.&lt;/p&gt; &lt;p&gt;Obviously, this can also be done using usual prompt engineering and programming techniques, but the framework exposes native easy to use settings and constructs to do these things more naturally. DSPy as a concept really shines when you are composing a pipeline of language model calls where prompt engineering the entire pipeline or even module wise can lead to a brittle Pipeline.&lt;/p&gt; &lt;p&gt;DSPy the Framework:&lt;/p&gt; &lt;p&gt;Now coming to the framework which is built in python, I think the framework as it stands today is&lt;/p&gt; &lt;ol&gt; &lt;li&gt; â Not production ready&lt;/li&gt; &lt;li&gt; â Buggy and poorly implemented&lt;/li&gt; &lt;li&gt; â Lacks proper documentation&lt;/li&gt; &lt;li&gt; â Poorly designed&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;To me it felt like a rushed implementation with little thought for design thinking, testing and programming principles. The framework code is very hard to understand with a lot of meta programming and data structure parsing and construction going behind the scenes that are scary to run in production.&lt;/p&gt; &lt;p&gt;This is a huge deterrent for anyone trying to learn and use this framework. But, I am sure the creators are thinking about all this and are working to reengineer the framework. Thereâ€™s also a typescript implementation of this framework that is fairly less popular but has a much better and cleaner design and codebase:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/dosco/llm-client/&quot;&gt;https://github.com/dosco/llm-client/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;My final thought about this framework is, itâ€™s a promising concept, but it does not change anything about what we already know about LLMs. Also, hiding prompts as templates does not mean prompt engineering is going away, someone still needs to â€œengineerâ€ the prompts the framework uses and imo the framework should expose these templates and give control back to the developers that way, the vision of separate programming and prompting co exists with giving control not only to program but also to prompt.&lt;/p&gt; &lt;p&gt;Finally, I was able to understand all this by running DSPy programs and visualizing the LLM calls and what prompts itâ€™s adding using my open source tool - &lt;a href=&quot;https://github.com/Scale3-Labs/langtrace&quot;&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt; . Do check it out and let me know if you have any feedback.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqexk6/thoughts_on_dspy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqexk6/thoughts_on_dspy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cqexk6</id><link href="https://www.reddit.com/r/LangChain/comments/1cqexk6/thoughts_on_dspy/" /><updated>2024-05-12T18:50:23+00:00</updated><published>2024-05-12T18:50:23+00:00</published><title>Thoughts on DSPy</title></entry><entry><author><name>/u/giobirkelund</name><uri>https://www.reddit.com/user/giobirkelund</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;When sending confidential, and highly sensitive data in rag search, I believe everything needs to be encrypted, so that even me, as the database operator, doesn&amp;#39;t have access to the data.&lt;/p&gt; &lt;p&gt;This must be a common use-case, as any company doing rag search on sensitive data has this problem. So I wonder, does anyone know how to do RAG search for sensitive data? &lt;/p&gt; &lt;p&gt;I would imagine you need to encrypt the embeddings, but how do you do the cosine similarity search on encrypted data? Seems like a tricky problem. I&amp;#39;m currently using mongodb atlas vector store, but they don&amp;#39;t offer search on encrypted data.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/giobirkelund&quot;&gt; /u/giobirkelund &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqr72f/rag_search_on_sensitive_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqr72f/rag_search_on_sensitive_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cqr72f</id><link href="https://www.reddit.com/r/LangChain/comments/1cqr72f/rag_search_on_sensitive_data/" /><updated>2024-05-13T04:56:26+00:00</updated><published>2024-05-13T04:56:26+00:00</published><title>RAG Search on sensitive data?</title></entry><entry><author><name>/u/snonsense</name><uri>https://www.reddit.com/user/snonsense</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been working on a solution for incident management for our internal team recently, and I wanted to share my ideas with all of you to gather your thoughts and suggestions. Here&amp;#39;s what I have in mind:&lt;/p&gt; &lt;p&gt;Incident Viewing: Our system will allow viewing all recorded incidents, along with their current statuses, qualifications, and unique IDs for easy tracking.&lt;/p&gt; &lt;p&gt;Incident Modification: the LLM will have the ability to modify existing incidents by changing priority, assigned team, or even the description for better accuracy.&lt;/p&gt; &lt;p&gt;User Communication: A commenting feature will be integrated so that we can exchange information directly with the concerned users, adding transparency and facilitating swift issue resolution&lt;/p&gt; &lt;p&gt;Any suggestions on how to do that with or without langchain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/snonsense&quot;&gt; /u/snonsense &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqzelj/langchain_for_classification/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqzelj/langchain_for_classification/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cqzelj</id><link href="https://www.reddit.com/r/LangChain/comments/1cqzelj/langchain_for_classification/" /><updated>2024-05-13T13:32:34+00:00</updated><published>2024-05-13T13:32:34+00:00</published><title>Langchain for classification ?</title></entry><entry><author><name>/u/EngineeringFree313</name><uri>https://www.reddit.com/user/EngineeringFree313</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I am trying to build customer support chat-bot with the goal of answering questions related to some training center courses. I have pdf document per each course containing all the information like course content, tools, price etc..&lt;br/&gt; If I load all documents into one index on a vector db, the returned chunks from db using similarity search given user&amp;#39;s query will probably related to other courses. for example, if the customer asks for a price of some course, All price chunks of all courses will be similar and a price of different course will probably be the answer which is wrong.&lt;br/&gt; So What is the standard way to solve this problem and target the right document only relevant to a specific course regardless all other courses documents.&lt;br/&gt; Also, I might in some cases need to retrieve data from multiple documents or all documents in case of a general question from the user like &amp;quot;List all courses&amp;quot; for example. In this case, I need all courses documents to answer this question.&lt;/p&gt; &lt;p&gt;I am building my project using langchain and gpt-3.5.&lt;/p&gt; &lt;p&gt;Thanks in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EngineeringFree313&quot;&gt; /u/EngineeringFree313 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqu5di/customer_support_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cqu5di/customer_support_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cqu5di</id><link href="https://www.reddit.com/r/LangChain/comments/1cqu5di/customer_support_rag_chatbot/" /><updated>2024-05-13T08:17:52+00:00</updated><published>2024-05-13T08:17:52+00:00</published><title>Customer Support RAG Chat-bot</title></entry></feed>