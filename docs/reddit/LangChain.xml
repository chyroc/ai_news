<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-07-24T22:03:13+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This demo talks about how to use Llama 3.1 with LangChain to build Generative AI applications: &lt;a href=&quot;https://youtu.be/LW64o3YgbE8?si=1nCi7Htoc-gH2zJ6&quot;&gt;https://youtu.be/LW64o3YgbE8?si=1nCi7Htoc-gH2zJ6&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eay7kz/llama_31_using_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eay7kz/llama_31_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eay7kz</id><link href="https://www.reddit.com/r/LangChain/comments/1eay7kz/llama_31_using_langchain/" /><updated>2024-07-24T10:37:35+00:00</updated><published>2024-07-24T10:37:35+00:00</published><title>Llama 3.1 using LangChain</title></entry><entry><author><name>/u/Repulsive-Bedroom883</name><uri>https://www.reddit.com/user/Repulsive-Bedroom883</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ebbuh5/your_free_personal_ai_companion_for_emotional/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/bTI2dzFocG4xamVkMYa7p5lcXDU-LbZnAe0Q65tAbY338Q3KoRvi2UTB2pMK.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b1c8f58cce53724a03a5347f3c99314dfc8a1888&quot; alt=&quot;Your Free Personal AI Companion for Emotional Support&quot; title=&quot;Your Free Personal AI Companion for Emotional Support&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Excited to share my AI Companion project—a supportive, empathetic companion available via call, now enhanced with guided sleep sessions, meditation exercises, and mental health tools. It respects privacy, keeps no personal data, and aims to make mental health support accessible to all. Your feedback shapes its evolution—let&amp;#39;s make companionship and well-being tools more accessible!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Repulsive-Bedroom883&quot;&gt; /u/Repulsive-Bedroom883 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/ka68j1xn1jed1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ebbuh5/your_free_personal_ai_companion_for_emotional/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ebbuh5</id><media:thumbnail url="https://external-preview.redd.it/bTI2dzFocG4xamVkMYa7p5lcXDU-LbZnAe0Q65tAbY338Q3KoRvi2UTB2pMK.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b1c8f58cce53724a03a5347f3c99314dfc8a1888" /><link href="https://www.reddit.com/r/LangChain/comments/1ebbuh5/your_free_personal_ai_companion_for_emotional/" /><updated>2024-07-24T20:34:15+00:00</updated><published>2024-07-24T20:34:15+00:00</published><title>Your Free Personal AI Companion for Emotional Support</title></entry><entry><author><name>/u/Time-Artist-6900</name><uri>https://www.reddit.com/user/Time-Artist-6900</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi I want to do metadata filtering first and then retrieve the document&lt;br/&gt; Code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;langchain_chroma = Chroma( client=self.persistent_client, collection_name=self.COLLECTION_NAME, embedding_function=self.embedding_function # Use the variable containing the collection name ) retriever = langchain_chroma.as_retriever(search_type=&amp;quot;similarity&amp;quot;,search_kwargs={&amp;#39;k&amp;#39;: 1, &amp;#39;filter&amp;#39;: cond}) query = &amp;quot;What is patient family Medical history in reverse cronological order?&amp;quot; res = retriever.get_relevant_documents(query) res &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is not returning scores, Whereas If use , &lt;/p&gt; &lt;pre&gt;&lt;code&gt;res = langchain_chroma.similarity_search_with_score(query) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;then i am getting score as well but how to do metadata filtering here?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Time-Artist-6900&quot;&gt; /u/Time-Artist-6900 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eb5r0v/how_to_return_similarity_scores_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eb5r0v/how_to_return_similarity_scores_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eb5r0v</id><link href="https://www.reddit.com/r/LangChain/comments/1eb5r0v/how_to_return_similarity_scores_using/" /><updated>2024-07-24T16:27:36+00:00</updated><published>2024-07-24T16:27:36+00:00</published><title>How to return similarity scores using retriever.get_relevant_documents(query)</title></entry><entry><author><name>/u/MagentaSpark</name><uri>https://www.reddit.com/user/MagentaSpark</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;At the time of posting,&lt;/p&gt; &lt;p&gt;LangChain repository&amp;#39;s &lt;code&gt;master&lt;/code&gt; branch is&lt;/p&gt; &lt;p&gt;&lt;code&gt; Cloning into &amp;#39;langchain&amp;#39;... remote: Enumerating objects: 137116, done. remote: Counting objects: 100% (5275/5275), done. remote: Compressing objects: 100% (481/481), done. remote: Total 137116 (delta 5003), reused 4829 (delta 4794), pack-reused 131841 Receiving objects: 100% (137116/137116), 224.32 MiB | 4.70 MiB/s, done. Resolving deltas: 100% (101282/101282), done. Updating files: 100% (7595/7595), done. &lt;/code&gt;&lt;/p&gt; &lt;p&gt;and LangGraph repository&amp;#39;s &lt;code&gt;main&lt;/code&gt; branch is&lt;/p&gt; &lt;p&gt;&lt;code&gt; Cloning into &amp;#39;langgraph&amp;#39;... remote: Enumerating objects: 10436, done. remote: Counting objects: 100% (1815/1815), done. remote: Compressing objects: 100% (1015/1015), done. remote: Total 10436 (delta 1090), reused 1371 (delta 774), pack-reused 8621 Receiving objects: 100% (10436/10436), 327.76 MiB | 3.13 MiB/s, done. Resolving deltas: 100% (6828/6828), done. &lt;/code&gt;&lt;/p&gt; &lt;p&gt;For comparision, this is React&amp;#39;s &lt;code&gt;main&lt;/code&gt; brach is&lt;/p&gt; &lt;p&gt;&lt;code&gt; Cloning into &amp;#39;react&amp;#39;... remote: Enumerating objects: 326918, done. remote: Counting objects: 100% (813/813), done. remote: Compressing objects: 100% (324/324), done. remote: Total 326918 (delta 470), reused 718 (delta 422), pack-reused 326105 Receiving objects: 100% (326918/326918), 532.16 MiB | 5.97 MiB/s, done. Resolving deltas: 100% (232896/232896), done. &lt;/code&gt; and it doesn&amp;#39;t even have rich text files like .ipynb.&lt;/p&gt; &lt;p&gt;There are couple of observations. 1. Maintaining an open-source repository with Jupyter Notebooks is not for easy, I think. Any updates to libraries used need notebooks to rerun and reflect latest outputs. Even if there is no change in output, the git diff changes drastically. I have heard about nbdime but have no idea about it. 2. LangGraph repo is bigger in size than LangChain after decompressing. ``` du -sh langgraph 475M langgraph&lt;/p&gt; &lt;p&gt;du -sh langchain 459M langchain``` This size by du depends on multiple factors, block size being on of them.&lt;/p&gt; &lt;p&gt;What did you find interesting? Do share more insights and fun facts about the projects!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MagentaSpark&quot;&gt; /u/MagentaSpark &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eb19ri/langchain_vs_langgraph_git/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eb19ri/langchain_vs_langgraph_git/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eb19ri</id><link href="https://www.reddit.com/r/LangChain/comments/1eb19ri/langchain_vs_langgraph_git/" /><updated>2024-07-24T13:18:20+00:00</updated><published>2024-07-24T13:18:20+00:00</published><title>LangChain VS LangGraph: Git</title></entry><entry><author><name>/u/BigYesterday2785</name><uri>https://www.reddit.com/user/BigYesterday2785</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i am using in memory vector database where I get scoring of responses. &lt;/p&gt; &lt;p&gt;Now i want to implement reranking to get the most accurate responses. &lt;/p&gt; &lt;p&gt;What would be the easiest way to implmement this in Java Langchain. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BigYesterday2785&quot;&gt; /u/BigYesterday2785 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eawsb6/easiest_way_to_implement_reranking_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eawsb6/easiest_way_to_implement_reranking_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eawsb6</id><link href="https://www.reddit.com/r/LangChain/comments/1eawsb6/easiest_way_to_implement_reranking_in_langchain/" /><updated>2024-07-24T09:06:28+00:00</updated><published>2024-07-24T09:06:28+00:00</published><title>Easiest way to implement reranking in Langchain and Java</title></entry><entry><author><name>/u/New-Contribution6302</name><uri>https://www.reddit.com/user/New-Contribution6302</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all. I am an LLM enthusiast trying to use GGUF version of Llama 3.1 for summarisation task. &lt;/p&gt; &lt;p&gt;I am using Q4_K_M model from this repo: MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF Link: &lt;a href=&quot;https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF&quot;&gt;https://huggingface.co/MaziyarPanahi/Meta-Llama-3.1-8B-Instruct-GGUF&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I used the following code to load the model: ``` from langchain_community.llms import LlamaCpp from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler&lt;/p&gt; &lt;p&gt;callback_manager = CallbackManager([StreamingStdOutCallbackHandler()]) n_gpu_layers = -1&lt;br/&gt; n_batch = 2048 &lt;/p&gt; &lt;h1&gt;Make sure the model path is correct for your system!&lt;/h1&gt; &lt;p&gt;llm = LlamaCpp( model_path=&amp;quot;./Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf&amp;quot;, n_gpu_layers=n_gpu_layers, n_ctx = 32768, rope_freq_scale=0.25, temperature = 0, n_batch=n_batch, callback_manager=callback_manager, verbose=True, # Verbose is required to pass to the callback manager ) ```&lt;/p&gt; &lt;p&gt;When I pass long inputs to this model and instruct it to summarise it, it just blabbers with random and repitive texts/numbers.&lt;/p&gt; &lt;p&gt;How do I resolve this. Requesting for guidance.&lt;/p&gt; &lt;p&gt;(PS: Tried Rope_freq_scale with values 0.125, 0.25, 1, 4, 8. But they were not so good, even comparing to the above results)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/New-Contribution6302&quot;&gt; /u/New-Contribution6302 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eayrtc/request_for_guidance/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eayrtc/request_for_guidance/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eayrtc</id><link href="https://www.reddit.com/r/LangChain/comments/1eayrtc/request_for_guidance/" /><updated>2024-07-24T11:09:56+00:00</updated><published>2024-07-24T11:09:56+00:00</published><title>Request for Guidance</title></entry><entry><author><name>/u/thevaliantfox04</name><uri>https://www.reddit.com/user/thevaliantfox04</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I am starting to use LangChain and have a question, for which I did not find a response in the documentation.&lt;/p&gt; &lt;p&gt;From my understanding, each LLM is trained with a different &lt;em&gt;chat format&lt;/em&gt; to separate AI and user messages. For instance, I am currently developing with Phi3 which uses the following format for AI messages: &lt;code&gt;&amp;lt;|assistant|&amp;gt;Assistant Message&amp;lt;|end|&amp;gt;&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;How can I pass some parameters to tell LangChain to use this format? Above all, is this handled by the &lt;code&gt;LLM&lt;/code&gt; class or by the &lt;code&gt;Message&lt;/code&gt; class?&lt;/p&gt; &lt;p&gt;I make an example to make my point clearer. When I use the following code&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, &amp;quot;Behave like this...&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;), ] ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;How can I tell LangChain to insert &lt;code&gt;&amp;lt;|user|&amp;gt;&lt;/code&gt; at the beginning of the user message? I do not see any parameter to pass to the &lt;code&gt;HumanMessage&lt;/code&gt; object. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thevaliantfox04&quot;&gt; /u/thevaliantfox04 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eav643/how_to_customize_the_chat_format_langchain_uses/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eav643/how_to_customize_the_chat_format_langchain_uses/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eav643</id><link href="https://www.reddit.com/r/LangChain/comments/1eav643/how_to_customize_the_chat_format_langchain_uses/" /><updated>2024-07-24T07:15:45+00:00</updated><published>2024-07-24T07:15:45+00:00</published><title>How to customize the Chat Format LangChain uses for my specific LLM?</title></entry><entry><author><name>/u/SpaceKey6285</name><uri>https://www.reddit.com/user/SpaceKey6285</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Does anyone have best practices to share on implementing long term memory for agents? E.g., personalization based on chat history. Based on the memgpt paper it seems best practices would be to have a secondary agent that can read/write long term context into a database, like a Redis cache. Curious if anyone has tuned a model for this? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SpaceKey6285&quot;&gt; /u/SpaceKey6285 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eat8c4/long_term_memory_for_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eat8c4/long_term_memory_for_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eat8c4</id><link href="https://www.reddit.com/r/LangChain/comments/1eat8c4/long_term_memory_for_agents/" /><updated>2024-07-24T05:10:31+00:00</updated><published>2024-07-24T05:10:31+00:00</published><title>Long term memory for agents?</title></entry><entry><author><name>/u/Senior_Union_393</name><uri>https://www.reddit.com/user/Senior_Union_393</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to make a planning agent using langgraph in which we can revert back to the planner node using conditions from other agent nodes . I am stuck on the reverting back function.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Senior_Union_393&quot;&gt; /u/Senior_Union_393 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eazoaz/reverting_back_to_planning_node_based_on_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eazoaz/reverting_back_to_planning_node_based_on_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eazoaz</id><link href="https://www.reddit.com/r/LangChain/comments/1eazoaz/reverting_back_to_planning_node_based_on_a/" /><updated>2024-07-24T12:00:29+00:00</updated><published>2024-07-24T12:00:29+00:00</published><title>Reverting back to planning node based on a condition</title></entry><entry><author><name>/u/gwen_from_nile</name><uri>https://www.reddit.com/user/gwen_from_nile</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am rather new to the AI space (my background is data infrastructure), so I am documenting my journey as I&amp;#39;m learning. This time I built an AI Code Assistant that uses RAG to answer questions about different repositories.&lt;/p&gt; &lt;p&gt;I blogged everything I learned while building this - Schema design, use of LangChain (tbh, not sure it was a good choice...), choice of models, streaming chat UX...&lt;/p&gt; &lt;p&gt;You can see the app here: &lt;a href=&quot;https://code-assist-nile.vercel.app&quot;&gt;https://code-assist-nile.vercel.app&lt;/a&gt;&lt;br/&gt; And the blog: &lt;a href=&quot;https://www.thenile.dev/blog/building_code_assistant&quot;&gt;https://www.thenile.dev/blog/building_code_assistant&lt;/a&gt;&lt;br/&gt; The code is here: &lt;a href=&quot;https://github.com/niledatabase/niledatabase/tree/main/examples/ai/code_assist/&quot;&gt;https://github.com/niledatabase/niledatabase/tree/main/examples/ai/code_assist/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gwen_from_nile&quot;&gt; /u/gwen_from_nile &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eadv0e/i_build_a_ragbased_multitenant_ai_code_assistant/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eadv0e/i_build_a_ragbased_multitenant_ai_code_assistant/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eadv0e</id><link href="https://www.reddit.com/r/LangChain/comments/1eadv0e/i_build_a_ragbased_multitenant_ai_code_assistant/" /><updated>2024-07-23T17:35:24+00:00</updated><published>2024-07-23T17:35:24+00:00</published><title>I build a RAG-based multi-tenant AI Code Assistant with OpenAI, LangChain, Postgres and PG Vector</title></entry><entry><author><name>/u/Acanthocephala_Salt</name><uri>https://www.reddit.com/user/Acanthocephala_Salt</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eageaq/exciting_news_from_meta_llama_31_is_here/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/4gnJFgu6Xo73DTSmQcJ5IIl2IzPp6vj2y5cONfUo6q4.jpg&quot; alt=&quot;Exciting News from Meta [Llama 3.1 is Here]&quot; title=&quot;Exciting News from Meta [Llama 3.1 is Here]&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Meta has just released its latest LLM model, Llama 3.1, marking a significant step in accessible artificial intelligence. Here are the key points from the announcement:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;405B version.&lt;/strong&gt; There is a new Llama 3.1 405B version. That’s right &lt;em&gt;405 Billion parameters.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Expanded context length&lt;/strong&gt;: Now all llama 3.1 models offer a context length of &lt;strong&gt;128K tokens&lt;/strong&gt;, 16 times its previous 8K context length from Llama 3. This allows for more advanced use cases, such as long-form text summarization, multilingual conversational agents, and coding assistants&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Model evaluations&lt;/strong&gt;: The model evaluations released by Meta are as follows:&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/zjcxaf93jbed1.png?width=3201&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31191792e788799899102d882d3170acc34ea19b&quot;&gt;Llama 405B&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/h1x4jcy6jbed1.png?width=3201&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4fb34e2d110345a34e1715d16be8951d0edc637b&quot;&gt;Llama 8B&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;4. API Coming Soon:&lt;/strong&gt; Users will be able to access and utilize Llama 3.1 models through &lt;a href=&quot;http://awanllm.com/&quot;&gt;awanllm.com&lt;/a&gt; soon. Stay tuned for updates in this post!&lt;/p&gt; &lt;p&gt;Source: &lt;a href=&quot;https://ai.meta.com/blog/meta-llama-3-1/&quot;&gt;https://ai.meta.com/blog/meta-llama-3-1/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Acanthocephala_Salt&quot;&gt; /u/Acanthocephala_Salt &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eageaq/exciting_news_from_meta_llama_31_is_here/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eageaq/exciting_news_from_meta_llama_31_is_here/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1eageaq</id><media:thumbnail url="https://a.thumbs.redditmedia.com/4gnJFgu6Xo73DTSmQcJ5IIl2IzPp6vj2y5cONfUo6q4.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1eageaq/exciting_news_from_meta_llama_31_is_here/" /><updated>2024-07-23T19:17:49+00:00</updated><published>2024-07-23T19:17:49+00:00</published><title>Exciting News from Meta [Llama 3.1 is Here]</title></entry><entry><author><name>/u/NasserAAA</name><uri>https://www.reddit.com/user/NasserAAA</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What are your thoughts on using MongoDB as vectorstore for your apps.&lt;/p&gt; &lt;p&gt;I was working on prototype locally for the most of its time but right now we are moving to hosting on streamlit, what are your recommendations for vectorstores.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/NasserAAA&quot;&gt; /u/NasserAAA &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaffzv/mongodb_as_vectorstore/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaffzv/mongodb_as_vectorstore/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eaffzv</id><link href="https://www.reddit.com/r/LangChain/comments/1eaffzv/mongodb_as_vectorstore/" /><updated>2024-07-23T18:39:44+00:00</updated><published>2024-07-23T18:39:44+00:00</published><title>MongoDB as vectorstore</title></entry><entry><author><name>/u/DifficultArugula8304</name><uri>https://www.reddit.com/user/DifficultArugula8304</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to give my client the option to construct new agents and create flows for input and output like vectorizing input and parsing output and storing it in a database. Is there any opensource tool with a UI that can do this? The language it&amp;#39;s written in doesn&amp;#39;t really matter, all options are welcome.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DifficultArugula8304&quot;&gt; /u/DifficultArugula8304 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaedlh/looking_for_an_opensource_framework_to_manage/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaedlh/looking_for_an_opensource_framework_to_manage/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eaedlh</id><link href="https://www.reddit.com/r/LangChain/comments/1eaedlh/looking_for_an_opensource_framework_to_manage/" /><updated>2024-07-23T17:56:20+00:00</updated><published>2024-07-23T17:56:20+00:00</published><title>Looking for an opensource framework to manage agents</title></entry><entry><author><name>/u/srvking</name><uri>https://www.reddit.com/user/srvking</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Guys,&lt;/p&gt; &lt;p&gt;Has anybody used Qdrant in the cloud, especially Azure and has gone live and in production? We are trying to insert 884 points with a production grade cluster in azure eastus and it takes about 6-8 seconds and that too with gRPC. Http takes even longer.&lt;/p&gt; &lt;p&gt;We are absolutely sure that this is the time taken by Qdrant Remote Client provided by their official package because we have enabled all the logging and can pin-point which operation takes time.&lt;/p&gt; &lt;p&gt;We created a support ticket with the Qdrant team as well, but have been ghosted by them. &lt;/p&gt; &lt;p&gt;Wondering if Qdrant is right choice and if it is, how do people insert points faster? We do have metadata and chunk text in the point. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/srvking&quot;&gt; /u/srvking &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaabwv/is_qdrant_cloud_production_ready/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaabwv/is_qdrant_cloud_production_ready/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eaabwv</id><link href="https://www.reddit.com/r/LangChain/comments/1eaabwv/is_qdrant_cloud_production_ready/" /><updated>2024-07-23T15:14:06+00:00</updated><published>2024-07-23T15:14:06+00:00</published><title>Is Qdrant cloud Production Ready?</title></entry><entry><author><name>/u/Expensive-Rub3117</name><uri>https://www.reddit.com/user/Expensive-Rub3117</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea7g23/multiagentdataanalysis_aidriven_data_analysis/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/1JX3PzIaTRXFic9OMARqVvTPnyE1x5FcNLG2jrAgYEU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=eca0d0f2c1e87731dab2321618072174b07b7430&quot; alt=&quot;Multi-agent-DataAnalysis AI-Driven Data Analysis System&quot; title=&quot;Multi-agent-DataAnalysis AI-Driven Data Analysis System&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;h1&gt;# Advanced AI-Driven Data Analysis System: A LangGraph Implementation&lt;/h1&gt; &lt;h2&gt;Project Overview&lt;/h2&gt; &lt;p&gt;I&amp;#39;ve developed a sophisticated data analysis system that leverages the power of LangGraph, showcasing its capabilities in integrating various AI architectures and methodologies. This system is designed to serve as a comprehensive example of how LangGraph can be used to streamline complex data analysis tasks by orchestrating multiple AI agents and architectural patterns.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/lntq41fap9ed1.jpg?width=610&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7b2f31c450c495ebe2eb3d5a1e75522223ae1267&quot;&gt;https://preview.redd.it/lntq41fap9ed1.jpg?width=610&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7b2f31c450c495ebe2eb3d5a1e75522223ae1267&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Key Features&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;**LangGraph-Powered Architecture**: The system demonstrates LangGraph&amp;#39;s flexibility by incorporating:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Supervisor agents for overseeing the analysis process&lt;/li&gt; &lt;li&gt;Chain-of-thought reasoning for complex problem-solving&lt;/li&gt; &lt;li&gt;Critic agents for quality assurance and error checking&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;**Innovative Note Taker Agent**: A standout feature that highlights LangGraph&amp;#39;s extensibility:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Continuously records the current state of the project&lt;/li&gt; &lt;li&gt;Provides a more efficient alternative to transmitting complete historical information&lt;/li&gt; &lt;li&gt;Enhances the system&amp;#39;s ability to maintain context and continuity across different analysis stages&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;**Adaptive Workflow**: Showcases LangGraph&amp;#39;s dynamic routing capabilities, adjusting the analysis approach based on the data and task at hand.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Why It&amp;#39;s a Valuable LangGraph Example&lt;/h2&gt; &lt;p&gt;This implementation serves as an excellent case study for LangGraph users by demonstrating:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Integration of diverse AI agent types within a unified framework&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Efficient state management using the innovative Note Taker agent&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Real-world application of LangGraph in complex data analysis scenarios&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Contribution to LangGraph&lt;/h2&gt; &lt;p&gt;I am eager to contribute this project as an example in the official LangGraph repository. My goals are to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;Provide a comprehensive, real-world example of LangGraph&amp;#39;s capabilities&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Help other developers understand advanced LangGraph implementations&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Contribute to the growth and adoption of LangGraph in the AI community&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Project Repository&lt;/h2&gt; &lt;p&gt;For a deeper dive into the codebase, architecture, and implementation details, please visit the project&amp;#39;s GitHub repository:&lt;/p&gt; &lt;p&gt;[AI-Driven Data Analysis System on GitHub](&lt;a href=&quot;https://github.com/starpig1129/Multi-agent-DataAnalysis&quot;&gt;https://github.com/starpig1129/Multi-agent-DataAnalysis&lt;/a&gt;)&lt;/p&gt; &lt;p&gt;I welcome feedback and collaboration to refine this example for potential inclusion in the LangGraph documentation or example collection.&lt;/p&gt; &lt;h2&gt;Next Steps&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;I am open to adapting the project to better align with LangGraph&amp;#39;s documentation standards.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;I would appreciate guidance on the best way to submit this as a potential official example.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;I&amp;#39;m eager to collaborate with the LangGraph community to enhance this example and make it as valuable as possible for other users.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Feel free to explore the repository, and I look forward to any feedback or suggestions for improving this as a LangGraph example!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Expensive-Rub3117&quot;&gt; /u/Expensive-Rub3117 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea7g23/multiagentdataanalysis_aidriven_data_analysis/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea7g23/multiagentdataanalysis_aidriven_data_analysis/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ea7g23</id><media:thumbnail url="https://external-preview.redd.it/1JX3PzIaTRXFic9OMARqVvTPnyE1x5FcNLG2jrAgYEU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eca0d0f2c1e87731dab2321618072174b07b7430" /><link href="https://www.reddit.com/r/LangChain/comments/1ea7g23/multiagentdataanalysis_aidriven_data_analysis/" /><updated>2024-07-23T13:09:57+00:00</updated><published>2024-07-23T13:09:57+00:00</published><title>Multi-agent-DataAnalysis AI-Driven Data Analysis System</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1ead2of/how_to_use_llama_31_in_local_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ead6zf/how_to_use_llama_31_codes_explained/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ead6zf</id><link href="https://www.reddit.com/r/LangChain/comments/1ead6zf/how_to_use_llama_31_codes_explained/" /><updated>2024-07-23T17:08:15+00:00</updated><published>2024-07-23T17:08:15+00:00</published><title>How to use Llama 3.1? Codes explained</title></entry><entry><author><name>/u/jscraft</name><uri>https://www.reddit.com/user/jscraft</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Made this 2 part tutorial about Tool Calling in LangChain.js&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Part 1️: &lt;a href=&quot;https://www.js-craft.io/blog/tool-calling-langchain-js/&quot;&gt;https://www.js-craft.io/blog/tool-calling-langchain-js/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 2: &lt;a href=&quot;https://www.js-craft.io/blog/tool-calling-langchain-js-toolmessage-schemas/&quot;&gt;https://www.js-craft.io/blog/tool-calling-langchain-js-toolmessage-schemas/&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Hope you will find it useful and any feedback is welcomed!&lt;/p&gt; &lt;p&gt;PS: I think it was one of the most time-consuming tutorials to make, as things here are not quite intuitive. At least for me :) &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jscraft&quot;&gt; /u/jscraft &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea79dp/tool_calling_tutorial_for_langchainjs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea79dp/tool_calling_tutorial_for_langchainjs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea79dp</id><link href="https://www.reddit.com/r/LangChain/comments/1ea79dp/tool_calling_tutorial_for_langchainjs/" /><updated>2024-07-23T13:01:21+00:00</updated><published>2024-07-23T13:01:21+00:00</published><title>Tool Calling tutorial for LangChain.js</title></entry><entry><author><name>/u/Direct-Station9581</name><uri>https://www.reddit.com/user/Direct-Station9581</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;from langgraph_state import GraphState from langgraph.graph import END, StateGraph from langgraph.checkpoint.memory import MemorySaver from nodes import build_strategy, human_feedback, decision_node, rag_node, database_search, web_search_node, sql_search_node, state_printer from edges import rag_database_websearch_sqlseqrch, strategy_decision workflow = StateGraph(GraphState) workflow.add_node(&amp;quot;build_strategy&amp;quot;, build_strategy) workflow.add_node(&amp;quot;human_feedback&amp;quot;, human_feedback) workflow.add_node(&amp;quot;decision_node&amp;quot;, decision_node) workflow.add_node(&amp;quot;rag_node&amp;quot;, rag_node) workflow.add_node(&amp;quot;database_search&amp;quot;, database_search) workflow.add_node(&amp;quot;web_search_node&amp;quot;, web_search_node) workflow.add_node(&amp;quot;sql_search_node&amp;quot;, sql_search_node) workflow.add_node(&amp;quot;state_printer&amp;quot;, state_printer) workflow.set_entry_point(&amp;quot;build_strategy&amp;quot;) workflow.add_edge(&amp;quot;build_strategy&amp;quot;, &amp;quot;human_feedback&amp;quot;) workflow.add_conditional_edges( &amp;quot;human_feedback&amp;quot;, strategy_decision, { &amp;quot;yes&amp;quot;: &amp;quot;decision_node&amp;quot;, &amp;quot;no&amp;quot;: &amp;quot;build_strategy&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;decision_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;rag_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;database_search&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;web_search_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;sql_search_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_edge(&amp;quot;state_printer&amp;quot;, END) memory = MemorySaver() app = workflow.compile(checkpointer=memory, interrupt_before=[&amp;quot;human_feedback&amp;quot;]) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I have created a graph with human feedback using langgraph. After &lt;strong&gt;strategy node&lt;/strong&gt; is executed. It should interrupt before &lt;strong&gt;human_feedback node&lt;/strong&gt; and ask from the user that if the strategy made by the agent is correct or wrong in case if it is correct it will proceed to the next nodes and if not then it will go to strategy node again.&lt;/p&gt; &lt;p&gt;For my first condition in case it is correct it is working fine. But when it is wrong the strategy node executes but donot go to the next nodes and the program terminates.&lt;/p&gt; &lt;p&gt;This is the issue if anyone can help. Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Direct-Station9581&quot;&gt; /u/Direct-Station9581 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea3p2i/human_in_the_loop_in_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea3p2i/human_in_the_loop_in_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea3p2i</id><link href="https://www.reddit.com/r/LangChain/comments/1ea3p2i/human_in_the_loop_in_langgraph/" /><updated>2024-07-23T09:40:10+00:00</updated><published>2024-07-23T09:40:10+00:00</published><title>Human In The Loop In Langgraph</title></entry><entry><author><name>/u/emersoftware</name><uri>https://www.reddit.com/user/emersoftware</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I want to force function calling with Gemini. Does anyone know how to do this?&lt;/p&gt; &lt;p&gt;I have checked the documentation for Vertex AI and Langchain but couldn&amp;#39;t find any information. In the Vertex AI docs, I found a parameter that could be passed, but I don&amp;#39;t know how to pass it using Langchain. I am using &lt;code&gt;ChatVertexAI().bind_tools()&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Regards!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/emersoftware&quot;&gt; /u/emersoftware &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ead44f/forced_function_calling_in_vertex_ai_gemini/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ead44f/forced_function_calling_in_vertex_ai_gemini/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ead44f</id><link href="https://www.reddit.com/r/LangChain/comments/1ead44f/forced_function_calling_in_vertex_ai_gemini/" /><updated>2024-07-23T17:05:05+00:00</updated><published>2024-07-23T17:05:05+00:00</published><title>Forced function calling in vertex ai gemini??</title></entry><entry><author><name>/u/thumbsdrivesmecrazy</name><uri>https://www.reddit.com/user/thumbsdrivesmecrazy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The article discusses various strategies and techniques for implementing RAG to large-scale code repositories, as well as potential benefits and limitations of the approach as well as show how RAG can improve developer productivity and code quality in large software projects: &lt;a href=&quot;https://www.codium.ai/blog/rag-for-large-scale-code-repos/&quot;&gt;RAG with 10K Code Repos&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thumbsdrivesmecrazy&quot;&gt; /u/thumbsdrivesmecrazy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea4nhz/applying_rag_to_largescale_code_repositories_guide/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea4nhz/applying_rag_to_largescale_code_repositories_guide/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea4nhz</id><link href="https://www.reddit.com/r/LangChain/comments/1ea4nhz/applying_rag_to_largescale_code_repositories_guide/" /><updated>2024-07-23T10:40:54+00:00</updated><published>2024-07-23T10:40:54+00:00</published><title>Applying RAG to Large-Scale Code Repositories - Guide</title></entry><entry><author><name>/u/Plane_Past129</name><uri>https://www.reddit.com/user/Plane_Past129</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can we apply RAG to JSON files. Currently we are using unstructured for parsing different types of file types. But, it doesn&amp;#39;t have integration with json file. Can anyone experienced this before?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Plane_Past129&quot;&gt; /u/Plane_Past129 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea5lco/rag_for_json/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea5lco/rag_for_json/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea5lco</id><link href="https://www.reddit.com/r/LangChain/comments/1ea5lco/rag_for_json/" /><updated>2024-07-23T11:35:09+00:00</updated><published>2024-07-23T11:35:09+00:00</published><title>RAG for JSON</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;GraphRAG has been the talk of the town since Microsoft released the viral gitrepo on GraphRAG, which uses Knowledge Graphs for the RAG framework to talk to external resources compared to vector DBs as in the case of standard RAG. The below YouTube playlist covers the following tutorials to get started on GraphRAG&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;What is GraphRAG?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;How GraphRAG works?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;GraphRAG using LangChain&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;GraphRAG for CSV data&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;GraphRAG for JSON&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Knowledge Graphs using LangChain&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;RAG vs GraphRAG&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLnH2pfPCPZsIaT48BT9zmLmkhYa_R1PhN&quot;&gt;https://www.youtube.com/playlist?list=PLnH2pfPCPZsIaT48BT9zmLmkhYa_R1PhN&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9wc8q/graphrag_tutorials_using_langchain_for_beginners/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9wc8q/graphrag_tutorials_using_langchain_for_beginners/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9wc8q</id><link href="https://www.reddit.com/r/LangChain/comments/1e9wc8q/graphrag_tutorials_using_langchain_for_beginners/" /><updated>2024-07-23T02:11:52+00:00</updated><published>2024-07-23T02:11:52+00:00</published><title>GraphRAG tutorials (using LangChain) for beginners</title></entry><entry><author><name>/u/ha1lyeah</name><uri>https://www.reddit.com/user/ha1lyeah</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, Need help in finding a docker image containing both Ollama and langchain to ease the creation/development of use cases. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ha1lyeah&quot;&gt; /u/ha1lyeah &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea4ccw/docker_image_with_ollama_and_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea4ccw/docker_image_with_ollama_and_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea4ccw</id><link href="https://www.reddit.com/r/LangChain/comments/1ea4ccw/docker_image_with_ollama_and_langchain/" /><updated>2024-07-23T10:21:37+00:00</updated><published>2024-07-23T10:21:37+00:00</published><title>Docker image with Ollama and langchain</title></entry><entry><author><name>/u/nshefeek</name><uri>https://www.reddit.com/user/nshefeek</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all,&lt;/p&gt; &lt;p&gt;This is my first take on something that is related to LLM and RAG systems. I&amp;#39;ve been working on a Retrieval-Augmented Generation (RAG) based question answering system which generate answers to the queries from uploaded documents, and I&amp;#39;d love to get your feedback, suggestions, and ideas for improvements. The system uses FastAPI, LangChain and Streamlit for a minimal UI.&lt;/p&gt; &lt;p&gt;Key features of the system:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Document upload and processing&lt;/li&gt; &lt;li&gt;Directory processing for batch document addition&lt;/li&gt; &lt;li&gt;FAISS vector store for efficient document retrieval&lt;/li&gt; &lt;li&gt;GPT4All for generating embeddings and answering questions&lt;/li&gt; &lt;li&gt;Asynchronous operations for improved performance&lt;/li&gt; &lt;li&gt;WebSocket support for real-time question answering&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;GitHub Repository: &lt;a href=&quot;https://github.com/nshefeek/docGPT.git&quot;&gt;docGPT&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Some specific areas I&amp;#39;m looking for feedback on:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Code quality and best practices.&lt;/li&gt; &lt;li&gt;Usage of LangChain.&lt;/li&gt; &lt;li&gt;The approach to improve query response timing.&lt;/li&gt; &lt;li&gt;A better approach to splitting the documents in such a way that the embeddings generated maintains a metadata that can be used to trace back to the original source doument.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Current state of the project:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Able to upload a PDF, TXT or CSV document.&lt;/li&gt; &lt;li&gt;Able to upload a directory of PDF documents. But since Streamlit has no widget for folder upload, the folder path has to be input as text.&lt;/li&gt; &lt;li&gt;Queries return somewhat relevant answers, but the returned metadata can&amp;#39;t be used to backtrack to the exact source location (like the paragraph from which the answer was inferred etc.).&lt;/li&gt; &lt;li&gt;Query times vary between 120-180 seconds.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Thank you in advance for your time and expertise. I&amp;#39;m looking forward to your insights and suggestions to help improve this project!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nshefeek&quot;&gt; /u/nshefeek &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9j3cq/built_a_rag_system_for_internal_documents_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9j3cq/built_a_rag_system_for_internal_documents_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9j3cq</id><link href="https://www.reddit.com/r/LangChain/comments/1e9j3cq/built_a_rag_system_for_internal_documents_using/" /><updated>2024-07-22T16:50:25+00:00</updated><published>2024-07-22T16:50:25+00:00</published><title>Built a RAG system for internal documents using LangChain, FastAPI, and a frontend with Streamlit. What could have been done better?</title></entry><entry><author><name>/u/kingai404</name><uri>https://www.reddit.com/user/kingai404</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone! I’m excited to share a new project: an Investment Research Project leveraging CrewAI and Composio to conduct investment research, analyze data, and provide investment recommendations.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Objectives&lt;/strong&gt;&lt;br/&gt; This project sets up a system of agents to streamline investment research and analysis, ultimately generating insightful investment recommendations.&lt;br/&gt; Implementation Details&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Tools Used&lt;/strong&gt;&lt;br/&gt; Composio, CrewAI, SERP, Python&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Setup&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Navigate to the project directory.&lt;/li&gt; &lt;li&gt;Run the setup file.&lt;/li&gt; &lt;li&gt;Fill in the &lt;code&gt;.env&lt;/code&gt; file with your secrets.&lt;/li&gt; &lt;li&gt;Run the Python script.&lt;/li&gt; &lt;li&gt;Alternatively, run the IPython Notebook &lt;code&gt;investment_analyst.ipynb&lt;/code&gt; in Jupyter for an interactive experience.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;br/&gt; The system will populate your Notion page with comprehensive investment data and analysis.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Repo&lt;/strong&gt;: &lt;a href=&quot;https://git.new/Invest&quot;&gt;GitHub Repository&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Feel free to explore the project, give it a star if you find it useful, and let me know your thoughts or suggestions for improvements!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kingai404&quot;&gt; /u/kingai404 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9ys5f/make_your_own_intelligent_investment_analyst_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9ys5f/make_your_own_intelligent_investment_analyst_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9ys5f</id><link href="https://www.reddit.com/r/LangChain/comments/1e9ys5f/make_your_own_intelligent_investment_analyst_agent/" /><updated>2024-07-23T04:20:03+00:00</updated><published>2024-07-23T04:20:03+00:00</published><title>Make your own Intelligent Investment Analyst Agent</title></entry></feed>