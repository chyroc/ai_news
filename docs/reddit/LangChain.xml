<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-08-07T08:44:01+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Suitable-Ad-8598</name><uri>https://www.reddit.com/user/Suitable-Ad-8598</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Based on some advice I got, I started using AWS Textract ($$$) for PDFs and unstructured (local/free) for all other doc types such as docx and html. &lt;/p&gt; &lt;p&gt;My textract bill is getting a bit out of hand and I was wondering if there are any better services out there that can interpret things like tables and stuff from PDFs and other docs well?&lt;/p&gt; &lt;p&gt;Quality is my number one concern but cost is also important.&lt;/p&gt; &lt;p&gt;Looking to replace textract but also wanted to check to see if unstructured is still considered the best for other doc types.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Suitable-Ad-8598&quot;&gt; /u/Suitable-Ad-8598 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elr7sr/what_is_the_best_document_loader_for_pdfs_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elr7sr/what_is_the_best_document_loader_for_pdfs_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elr7sr</id><link href="https://www.reddit.com/r/LangChain/comments/1elr7sr/what_is_the_best_document_loader_for_pdfs_and/" /><updated>2024-08-06T19:46:01+00:00</updated><published>2024-08-06T19:46:01+00:00</published><title>What is the best document loader for PDFs? And other docs in general?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1em61b0/free_llm_apis_to_know/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em61t8/free_llm_apis_to_know/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em61t8</id><link href="https://www.reddit.com/r/LangChain/comments/1em61t8/free_llm_apis_to_know/" /><updated>2024-08-07T07:55:35+00:00</updated><published>2024-08-07T07:55:35+00:00</published><title>Free LLM APIs to know</title></entry><entry><author><name>/u/BellaHi</name><uri>https://www.reddit.com/user/BellaHi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em0qmz/langchain_vs_llamaindex_choose_the_best_framework/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/xdRw2A4E1tAFHQRy07JwUiPTZWn466MaEpJKn-gWRf8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9161ceea81d99df6557d0af71471532e71f230d8&quot; alt=&quot;LangChain vs LlamaIndex: Choose the Best Framework for Your AI Applications&quot; title=&quot;LangChain vs LlamaIndex: Choose the Best Framework for Your AI Applications&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BellaHi&quot;&gt; /u/BellaHi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://myscale.com/blog/llamaindex-vs-langchain-detailed-comparison/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em0qmz/langchain_vs_llamaindex_choose_the_best_framework/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1em0qmz</id><media:thumbnail url="https://external-preview.redd.it/xdRw2A4E1tAFHQRy07JwUiPTZWn466MaEpJKn-gWRf8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9161ceea81d99df6557d0af71471532e71f230d8" /><link href="https://www.reddit.com/r/LangChain/comments/1em0qmz/langchain_vs_llamaindex_choose_the_best_framework/" /><updated>2024-08-07T02:41:36+00:00</updated><published>2024-08-07T02:41:36+00:00</published><title>LangChain vs LlamaIndex: Choose the Best Framework for Your AI Applications</title></entry><entry><author><name>/u/GPT-Claude-Gemini</name><uri>https://www.reddit.com/user/GPT-Claude-Gemini</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone I want to share a Langchain-based project that I have been working on for the last few months — &lt;a href=&quot;https://www.jenova.ai/&quot;&gt;JENOVA&lt;/a&gt;, an AI (similar to ChatGPT) that integrates the best foundation models and tools into one seamless experience.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;AI is advancing too fast for most people to follow.&lt;/strong&gt; New state-of-the-art models emerge constantly, each with unique strengths and specialties. Currently:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Claude 3.5 Sonnet is the best at reasoning, math, and coding.&lt;/li&gt; &lt;li&gt;Gemini 1.5 Pro excels in business/financial analysis and language translations.&lt;/li&gt; &lt;li&gt;Llama 3.1 405B is most performative in roleplaying and creativity.&lt;/li&gt; &lt;li&gt;GPT-4o is most knowledgeable in areas such as art, entertainment, and travel.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This rapidly changing and fragmenting AI landscape is leading to the following problems for consumers:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Awareness Gap:&lt;/strong&gt; Most people are unaware of the latest models and their specific strengths, and are often paying for AI (e.g. ChatGPT) that is suboptimal for their tasks.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Constant Switching:&lt;/strong&gt; Due to constant changes in SOTA models, consumers have to frequently switch their preferred AI and subscription.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;User Friction:&lt;/strong&gt; Switching AI results in significant user experience disruptions, such as losing chat histories or critical features such as web browsing.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;JENOVA is built to solve this.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;When you ask JENOVA a question, it automatically routes your query to the model that can provide the optimal answer (built on top of Langchain).&lt;/strong&gt; For example, if your first question is about coding, then Claude 3.5 Sonnet will respond. If your second question is about tourist spots in Tokyo, then GPT-4o will respond. All this happens seamlessly in the background.&lt;/p&gt; &lt;p&gt;JENOVA&amp;#39;s model ranking is continuously updated to incorporate the latest AI models and performance benchmarks, ensuring you are always using the best models for your specific needs.&lt;/p&gt; &lt;p&gt;In addition to the best AI models, JENOVA also provides you with an expanding suite of the most useful tools, starting with:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Web browsing&lt;/strong&gt; for real-time information (performs surprisingly well, nearly on par with Perplexity)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Multi-format document analysis&lt;/strong&gt; including PDF, Word, Excel, PowerPoint, and more&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Image interpretation&lt;/strong&gt; for visual tasks&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Your privacy is very important to us. Your conversations and data are never used for training, either by us or by third-party AI providers.&lt;/p&gt; &lt;p&gt;Try it out at &lt;a href=&quot;https://www.jenova.ai/&quot;&gt;&lt;strong&gt;www.jenova.ai&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; JENOVA might be running into some issues with web search/browsing right now due to very high demand.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/GPT-Claude-Gemini&quot;&gt; /u/GPT-Claude-Gemini &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ellpk9/sharing_my_project_that_was_built_on_langchain_an/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ellpk9/sharing_my_project_that_was_built_on_langchain_an/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ellpk9</id><link href="https://www.reddit.com/r/LangChain/comments/1ellpk9/sharing_my_project_that_was_built_on_langchain_an/" /><updated>2024-08-06T16:07:14+00:00</updated><published>2024-08-06T16:07:14+00:00</published><title>Sharing my project that was built on Langchain: An all-in-one AI that integrates the best foundation models (GPT, Claude, Gemini, Llama) and tools into one seamless experience.</title></entry><entry><author><name>/u/ProfessionalBig9431</name><uri>https://www.reddit.com/user/ProfessionalBig9431</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hi there i am learning about rag with knowledge graph any proper documentation from where i can get the reference any thing would be helpful &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ProfessionalBig9431&quot;&gt; /u/ProfessionalBig9431 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em3b9p/rag_and_knowledge_graph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em3b9p/rag_and_knowledge_graph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em3b9p</id><link href="https://www.reddit.com/r/LangChain/comments/1em3b9p/rag_and_knowledge_graph/" /><updated>2024-08-07T04:58:39+00:00</updated><published>2024-08-07T04:58:39+00:00</published><title>RAG and KNOWLEDGE GRAPH</title></entry><entry><author><name>/u/abhinavkimothi</name><uri>https://www.reddit.com/user/abhinavkimothi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em6m7e/embeddings_the_blueprint_of_contextual_ai/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/QKVGsXwodAGF0k5YNnyDIcsDJJeG9DZ2QpyUcA904NE.jpg&quot; alt=&quot;Embeddings : The blueprint of Contextual AI&quot; title=&quot;Embeddings : The blueprint of Contextual AI&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/abhinavkimothi&quot;&gt; /u/abhinavkimothi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/gallery/1em6m7e&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em6m7e/embeddings_the_blueprint_of_contextual_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1em6m7e</id><media:thumbnail url="https://b.thumbs.redditmedia.com/QKVGsXwodAGF0k5YNnyDIcsDJJeG9DZ2QpyUcA904NE.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1em6m7e/embeddings_the_blueprint_of_contextual_ai/" /><updated>2024-08-07T08:34:09+00:00</updated><published>2024-08-07T08:34:09+00:00</published><title>Embeddings : The blueprint of Contextual AI</title></entry><entry><author><name>/u/TimeTravellingCat</name><uri>https://www.reddit.com/user/TimeTravellingCat</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elkjcz/building_multiagent_workflows_with_open_and/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/emRxMDJpOTA1MmhkMQOeLRWbXZLLqGF7C1pE6u8v4bV4Eov2GX0h5P2dipJi.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=efb7632c3d308cdeef92241156ced31db3fcbf57&quot; alt=&quot;Building multi-agent workflows with open and closed models using an open-source low-code platform&quot; title=&quot;Building multi-agent workflows with open and closed models using an open-source low-code platform&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TimeTravellingCat&quot;&gt; /u/TimeTravellingCat &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/nzs7bi9052hd1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elkjcz/building_multiagent_workflows_with_open_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1elkjcz</id><media:thumbnail url="https://external-preview.redd.it/emRxMDJpOTA1MmhkMQOeLRWbXZLLqGF7C1pE6u8v4bV4Eov2GX0h5P2dipJi.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=efb7632c3d308cdeef92241156ced31db3fcbf57" /><link href="https://www.reddit.com/r/LangChain/comments/1elkjcz/building_multiagent_workflows_with_open_and/" /><updated>2024-08-06T15:20:54+00:00</updated><published>2024-08-06T15:20:54+00:00</published><title>Building multi-agent workflows with open and closed models using an open-source low-code platform</title></entry><entry><author><name>/u/maniac_runner</name><uri>https://www.reddit.com/user/maniac_runner</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/maniac_runner&quot;&gt; /u/maniac_runner &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://openai.com/index/introducing-structured-outputs-in-the-api/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em0d5n/introducing_structured_outputs_in_the_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em0d5n</id><link href="https://www.reddit.com/r/LangChain/comments/1em0d5n/introducing_structured_outputs_in_the_api/" /><updated>2024-08-07T02:22:55+00:00</updated><published>2024-08-07T02:22:55+00:00</published><title>Introducing Structured Outputs in the API</title></entry><entry><author><name>/u/phuzul</name><uri>https://www.reddit.com/user/phuzul</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am fairly new to Langchain and wanted to seek out some advice for free methods of using LLMs to just do some basic prompting for a web application. The prompting is just providing some music artists and asking the LLM to think of potential ideas for those artists. I have a node.js backend that I am attempting to integrate Langchain.js into. &lt;/p&gt; &lt;p&gt;I first wanted to ask are there any decent models for my task that can be used with Langchain.js for free and what would a very basic code snippet look like to run it. &lt;/p&gt; &lt;p&gt;In addition, I wanted to ask if Ollama is applicable here or is that strictly for local applications?&lt;/p&gt; &lt;p&gt;Thanks !&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phuzul&quot;&gt; /u/phuzul &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em3muc/support_with_langchainjs_for_free_inference/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1em3muc/support_with_langchainjs_for_free_inference/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1em3muc</id><link href="https://www.reddit.com/r/LangChain/comments/1em3muc/support_with_langchainjs_for_free_inference/" /><updated>2024-08-07T05:17:36+00:00</updated><published>2024-08-07T05:17:36+00:00</published><title>Support with Langchain.js for free inference</title></entry><entry><author><name>/u/Standard-Factor-9408</name><uri>https://www.reddit.com/user/Standard-Factor-9408</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone come across an issue with chroma as a vector store where it can’t handle a large K unless it’s “warmed up”?&lt;/p&gt; &lt;p&gt;Have a db with about 30k docs in it each about a paragraph long. I need to return the top 100 or so as part of a larger ranking process. When I first load the db though if I don’t start with a k size of 5 and work my way up it consistently errors out with “cannot return the results in a contiguous 2d array. Probably ef or M is too small”. I’ve tried changing the hnsw parameters when creating the collection but nothing seems to give. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Standard-Factor-9408&quot;&gt; /u/Standard-Factor-9408 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ely226/chromadb_issues/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ely226/chromadb_issues/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ely226</id><link href="https://www.reddit.com/r/LangChain/comments/1ely226/chromadb_issues/" /><updated>2024-08-07T00:32:49+00:00</updated><published>2024-08-07T00:32:49+00:00</published><title>Chromadb issues</title></entry><entry><author><name>/u/moonbunR</name><uri>https://www.reddit.com/user/moonbunR</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elcgt3/customer_review_analysis_ai_agent/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/pZgg5gsUcAK_aEdnnGnjE5DIsQs1HHdDTNiAo1mfyf8.jpg&quot; alt=&quot;Customer review analysis Ai Agent&quot; title=&quot;Customer review analysis Ai Agent&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://preview.redd.it/bb6kdv6oh0hd1.jpg?width=974&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=078ba4f7babb1c827c9cb413fa236fc9d1cd5c2f&quot;&gt;https://preview.redd.it/bb6kdv6oh0hd1.jpg?width=974&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=078ba4f7babb1c827c9cb413fa236fc9d1cd5c2f&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This &lt;a href=&quot;https://app.smythos.com/builder?templateId=customer-review-analysis-lxxqii7231.smyth&quot;&gt;~agent~&lt;/a&gt; uses sentiment analysis and an LLM to automatically review and give responses to customer reviews. When the agent receives the customer review, it is first taken through sentiment analysis to understand the sentiment of the feedback. Together with the sentiment for context, the review is sent to the LLM which crafts an appropriate response for the review.&lt;/p&gt; &lt;p&gt;Personally, I think the secret lies in the prompting of the LLM, in my case I set up the LLM to do 3 things mainly, &lt;/p&gt; &lt;ol&gt; &lt;li&gt;Empathize with the customer&lt;/li&gt; &lt;li&gt;Offer a solution&lt;/li&gt; &lt;li&gt;Provide additional information&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;These three gave me some pretty decent results, you can try your own or just use these on the template, but I still think that with more robust prompting, the agent can produce more natural and efficient responses that can help out your brand in a huge way. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/moonbunR&quot;&gt; /u/moonbunR &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elcgt3/customer_review_analysis_ai_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elcgt3/customer_review_analysis_ai_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1elcgt3</id><media:thumbnail url="https://a.thumbs.redditmedia.com/pZgg5gsUcAK_aEdnnGnjE5DIsQs1HHdDTNiAo1mfyf8.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1elcgt3/customer_review_analysis_ai_agent/" /><updated>2024-08-06T08:28:24+00:00</updated><published>2024-08-06T08:28:24+00:00</published><title>Customer review analysis Ai Agent</title></entry><entry><author><name>/u/BigYesterday2785</name><uri>https://www.reddit.com/user/BigYesterday2785</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I wanted to ask, if I want to run local LLMs only on CPU.&lt;/p&gt; &lt;p&gt;I do not have access to GPUs and wanted to ask how much slower CPU would be, compared to GPU.&lt;/p&gt; &lt;p&gt;I would love to run a small Open Source LLM only on CPUs to read 500 pages PDFs and be able to ask it questions.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BigYesterday2785&quot;&gt; /u/BigYesterday2785 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli67w/run_local_llm_on_cpu_how_bad_would_would_it_be/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli67w/run_local_llm_on_cpu_how_bad_would_would_it_be/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eli67w</id><link href="https://www.reddit.com/r/LangChain/comments/1eli67w/run_local_llm_on_cpu_how_bad_would_would_it_be/" /><updated>2024-08-06T13:44:24+00:00</updated><published>2024-08-06T13:44:24+00:00</published><title>Run local LLM on CPU. how Bad would would it be compared to GPUs</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1eli3xb/ragflow_ui_for_rag_framework/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli4qr/ragflow_ui_for_rag_framework/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eli4qr</id><link href="https://www.reddit.com/r/LangChain/comments/1eli4qr/ragflow_ui_for_rag_framework/" /><updated>2024-08-06T13:42:38+00:00</updated><published>2024-08-06T13:42:38+00:00</published><title>RAGflow : UI for RAG framework</title></entry><entry><author><name>/u/Relevant_Ebb_3633</name><uri>https://www.reddit.com/user/Relevant_Ebb_3633</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, I&amp;#39;m looking for a low-code platform to implement RAG in business processes. I&amp;#39;ve tested tools like Dify, RAGflow, Flowise, and langflow, but none of them seem to be well-optimized for RAG. Does anyone know of any low-code platforms that offer better RAG parameter optimization? Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Relevant_Ebb_3633&quot;&gt; /u/Relevant_Ebb_3633 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elarmg/looking_for_lowcode_tools_for_building_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elarmg/looking_for_lowcode_tools_for_building_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elarmg</id><link href="https://www.reddit.com/r/LangChain/comments/1elarmg/looking_for_lowcode_tools_for_building_and/" /><updated>2024-08-06T06:34:58+00:00</updated><published>2024-08-06T06:34:58+00:00</published><title>Looking for low-code tools for building and optimizing RAG</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1el7jc9/langchain_in_your_pocket_completes_6_months/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/aEiKKct7MORRNB8Sihet1ABmGQk9Ug9_q_P-0jOItBQ.jpg&quot; alt=&quot;LangChain in your Pocket completes 6 months !!&quot; title=&quot;LangChain in your Pocket completes 6 months !!&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m glad to share that my debut book, &lt;strong&gt;&amp;quot;LangChain in your Pocket: Beginner&amp;#39;s Guide to Building Generative AI Applications using LLMs&lt;/strong&gt;&amp;quot; completed 6 months last week and what a dream run it has been.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The book has been &lt;strong&gt;republished by Packt.&lt;/strong&gt; And is now available with all major publishers including O&amp;#39;Reilly.&lt;/li&gt; &lt;li&gt;So far, the book has sold over &lt;strong&gt;500 copies&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;It is the &lt;strong&gt;highest-rated book on LangChain&lt;/strong&gt; on Amazon (Amazon.in: 4.7; Amazon.com: 4.3 ).&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The best part is that the book hasn&amp;#39;t received a bad review regarding the content from anyone, making this even more special for me&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;&lt;em&gt;A big thanks to the community for all the support.&lt;/em&gt;&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/7wtmrl2nnygd1.png?width=901&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=da3d9b2ea43d771ee738bcbb611c6331a36ef580&quot;&gt;https://preview.redd.it/7wtmrl2nnygd1.png?width=901&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=da3d9b2ea43d771ee738bcbb611c6331a36ef580&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1el7jc9/langchain_in_your_pocket_completes_6_months/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1el7jc9/langchain_in_your_pocket_completes_6_months/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1el7jc9</id><media:thumbnail url="https://b.thumbs.redditmedia.com/aEiKKct7MORRNB8Sihet1ABmGQk9Ug9_q_P-0jOItBQ.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1el7jc9/langchain_in_your_pocket_completes_6_months/" /><updated>2024-08-06T03:24:06+00:00</updated><published>2024-08-06T03:24:06+00:00</published><title>LangChain in your Pocket completes 6 months !!</title></entry><entry><author><name>/u/Sad-Anywhere-2204</name><uri>https://www.reddit.com/user/Sad-Anywhere-2204</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on a ReAct agent(created with langchain.agents.create_react_agent) and we are creating an evaluation and monitoring tool for it to analyze and understand agent behavior, performance, latency, bottlenecks, etc. We have already some metrics, but I&amp;#39;m looking for the best practices or recommended techniques to calculate:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Number of LLM calls: given the agent will do it&amp;#39;s reasoning/acting cycle doing LLM calls internally we want to measure the number of calls.&lt;/li&gt; &lt;li&gt;Duration per LLM call: we also want to measure the duration per call.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;One of the goals is to understand where to focus when doing improvements, for example: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;improving tools descriptions, inputs etc to reduce the number of LLM calls.&lt;/li&gt; &lt;li&gt;Performing model optimization and endpoint tuning to reduce latency per call.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; due to internal constraints we are not using langsmith and preferably the solution should be independent of the model used(given we will evaluate different models and we want the metrics for all of them).&lt;/p&gt; &lt;p&gt;Any other suggested metrics are appreciated.&lt;/p&gt; &lt;p&gt;The question is: &lt;strong&gt;what is the recommended way to achieve this?&lt;/strong&gt; (I have in mind thing like callbacks like the &lt;strong&gt;on_llm_end&lt;/strong&gt; and adding a counter but not sure if this is the recommended way or maybe there is something out of the box).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sad-Anywhere-2204&quot;&gt; /u/Sad-Anywhere-2204 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elpms2/how_to_track_number_of_llm_calls_in_a_react_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elpms2/how_to_track_number_of_llm_calls_in_a_react_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elpms2</id><link href="https://www.reddit.com/r/LangChain/comments/1elpms2/how_to_track_number_of_llm_calls_in_a_react_agent/" /><updated>2024-08-06T18:42:34+00:00</updated><published>2024-08-06T18:42:34+00:00</published><title>How to track number of LLM calls in a ReAct agent</title></entry><entry><author><name>/u/franckeinstein24</name><uri>https://www.reddit.com/user/franckeinstein24</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elmowa/large_language_models_productivity_and_profits/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/0Gpr0l9wOWJpMWNIC8nus2jHb5fhiP1sqUtyjaWdipU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f97adc2c91917c889a6db9abbf2946942cc53166&quot; alt=&quot;Large Language Models, Productivity, and Profits&quot; title=&quot;Large Language Models, Productivity, and Profits&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/franckeinstein24&quot;&gt; /u/franckeinstein24 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.lycee.ai/blog/large-language-models-productivity-and-profits&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elmowa/large_language_models_productivity_and_profits/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1elmowa</id><media:thumbnail url="https://external-preview.redd.it/0Gpr0l9wOWJpMWNIC8nus2jHb5fhiP1sqUtyjaWdipU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f97adc2c91917c889a6db9abbf2946942cc53166" /><link href="https://www.reddit.com/r/LangChain/comments/1elmowa/large_language_models_productivity_and_profits/" /><updated>2024-08-06T16:46:01+00:00</updated><published>2024-08-06T16:46:01+00:00</published><title>Large Language Models, Productivity, and Profits</title></entry><entry><author><name>/u/skipvdm</name><uri>https://www.reddit.com/user/skipvdm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Guys,&lt;/p&gt; &lt;p&gt;I am working on an issue and can&amp;#39;t seem to figure it out. I want to retrieve all the embeddings that are stored in a Azure AI Search instance.&lt;/p&gt; &lt;p&gt;At this moment i&amp;#39;m trying it like this:&lt;/p&gt; &lt;p&gt;&lt;code&gt;# Create a SearchClient instance&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;endpoint = SEARCH_ENDPOINT&lt;/code&gt;&lt;br/&gt; &lt;code&gt;search_client = SearchClient(endpoint=endpoint, index_name=index_name, credential=AzureKeyCredential(api_key))&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;# Formulate a search request&lt;/code&gt;&lt;br/&gt; &lt;code&gt;search_text = &amp;quot;*&amp;quot;&lt;/code&gt;&lt;br/&gt; &lt;code&gt;select_fields = &amp;quot;*&amp;quot;&lt;/code&gt; &lt;/p&gt; &lt;p&gt;&lt;code&gt;# Execute the search&lt;/code&gt;&lt;br/&gt; &lt;code&gt;results = search_client.search(search_text, select=select_fields)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;print(results)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;However, this return me the following:&lt;/p&gt; &lt;p&gt;{&amp;#39;content&amp;#39;: &amp;#39;RANDOM CONTENT&amp;#39;,&lt;br/&gt; &amp;#39;metadata&amp;#39;:&lt;br/&gt; &amp;#39;{&amp;quot;source&amp;quot;: &amp;quot;DOC SOURCE,&lt;br/&gt; &amp;quot;page&amp;quot;: 0,&lt;br/&gt; &amp;quot;start_index&amp;quot;: 4}&amp;#39;,&lt;br/&gt; &amp;#39;id&amp;#39;: &amp;#39;OTQ4MTUwOWYtNTFiNC00NTViLWE0MzQtNTJlYjQxZDJiMmI0&amp;#39;,&lt;br/&gt; &amp;#39;@search.score&amp;#39;: 1.0, &amp;#39;@search.reranker_score&amp;#39;: None,&lt;br/&gt; &amp;#39;@search.highlights&amp;#39;: None,&lt;br/&gt; &amp;#39;@search.captions&amp;#39;: None}&lt;/p&gt; &lt;p&gt;However not the embeddings. Can anybody help me?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/skipvdm&quot;&gt; /u/skipvdm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elllb7/retrieving_all_embeddings_from_an_azure_ai_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elllb7/retrieving_all_embeddings_from_an_azure_ai_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elllb7</id><link href="https://www.reddit.com/r/LangChain/comments/1elllb7/retrieving_all_embeddings_from_an_azure_ai_search/" /><updated>2024-08-06T16:02:37+00:00</updated><published>2024-08-06T16:02:37+00:00</published><title>Retrieving all embeddings from an Azure Ai Search instance</title></entry><entry><author><name>/u/Mental-Ad-7783</name><uri>https://www.reddit.com/user/Mental-Ad-7783</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build an application that analyses all my transcripts and answer user question based on the context by performing similarity search. I am loading all my transcripts into vector database(in my case milvus) and storing them as embeddings, along with the metadata of the transcripts. I am using rag retrieval process to get the answer, but I didn&amp;#39;t get the expected output on most cases. Any better way of doing this, any suggestions on choosing the appropriate embeddings and dimensions.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mental-Ad-7783&quot;&gt; /u/Mental-Ad-7783 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elldx1/extracting_insights_from_conversational/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elldx1/extracting_insights_from_conversational/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elldx1</id><link href="https://www.reddit.com/r/LangChain/comments/1elldx1/extracting_insights_from_conversational/" /><updated>2024-08-06T15:54:39+00:00</updated><published>2024-08-06T15:54:39+00:00</published><title>Extracting insights from conversational transcripts</title></entry><entry><author><name>/u/Just_Guide7361</name><uri>https://www.reddit.com/user/Just_Guide7361</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am currently building a Q&amp;amp;A interface with Streamlit and Langchain. Our initial vector database was in Pinecone. We have documents about the same topic, but different industries. Pure embedding search is not optimal, as it will match the same concepts across industries. So, we build a simple selector option where users pick their industry, and then ask the question. In pinecone each industry had their own namespace, we then simply filter on this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings, namespace=namespace) retriever = vectorstore.as_retriever(search_type=&amp;quot;similarity&amp;quot;, search_kwargs={&amp;quot;k&amp;quot;: 3}) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Hybrid search with pinecone is not as convenient as with Weaviate, and since we noticed beter performance with hybrid search we are switching to Weaviate. The downside is that filters are not so clear for the Weaviate retriever. &lt;/p&gt; &lt;pre&gt;&lt;code&gt;retriever = WeaviateHybridSearchRetriever( client=client, index_name=WEAVIATE_INDEX_NAME, text_key=&amp;quot;page_content&amp;quot;, k=5, alpha=0.75, attributes=[&amp;quot;file_name&amp;quot;, &amp;quot;industry], create_schema_if_missing=False, ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Our Langchain Chain looks similar to this ( &lt;a href=&quot;https://github.com/langchain-ai/langchain/blob/master/templates/hybrid-search-weaviate/hybrid_search_weaviate/chain.py&quot;&gt;https://github.com/langchain-ai/langchain/blob/master/templates/hybrid-search-weaviate/hybrid_search_weaviate/chain.py&lt;/a&gt; ):&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# RAG prompt template = &amp;quot;&amp;quot;&amp;quot;Answer the question based only on the following context: {context} Question: {question} &amp;quot;&amp;quot;&amp;quot; prompt = ChatPromptTemplate.from_template(template) # RAG model = ChatOpenAI() chain = ( RunnableParallel({&amp;quot;context&amp;quot;: retriever, &amp;quot;question&amp;quot;: RunnablePassthrough()}) | prompt | model | StrOutputParser() ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The docs do show this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;retriever.invoke( &amp;quot;AI integration in society&amp;quot;, where_filter={ &amp;quot;path&amp;quot;: [&amp;quot;author&amp;quot;], &amp;quot;operator&amp;quot;: &amp;quot;Equal&amp;quot;, &amp;quot;valueString&amp;quot;: &amp;quot;Prof. Jonathan K. Sterling&amp;quot;, }, ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;a href=&quot;https://python.langchain.com/v0.2/docs/integrations/retrievers/weaviate-hybrid/&quot;&gt;https://python.langchain.com/v0.2/docs/integrations/retrievers/weaviate-hybrid/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Does anyone know how/where to add the &lt;code&gt;where_filter&lt;/code&gt; parameter for Weaviate hybrid search in the Chain?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/langchain-ai/langchain/blob/master/templates/hybrid-search-weaviate/hybrid_search_weaviate/chain.py&quot;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Just_Guide7361&quot;&gt; /u/Just_Guide7361 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elk3g2/weaviatehybridsearchretriever_with_filters/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elk3g2/weaviatehybridsearchretriever_with_filters/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elk3g2</id><link href="https://www.reddit.com/r/LangChain/comments/1elk3g2/weaviatehybridsearchretriever_with_filters/" /><updated>2024-08-06T15:03:27+00:00</updated><published>2024-08-06T15:03:27+00:00</published><title>WeaviateHybridSearchRetriever with filters?</title></entry><entry><author><name>/u/Danidre</name><uri>https://www.reddit.com/user/Danidre</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been keeping my eye on the LangGraph documentation, there was one titled &amp;quot;Help Desk RAG&amp;quot; or &amp;quot;Make a Help Desk Agent with RAG&amp;quot; or something. This was back when the documentation also showed a &amp;quot;Design Patterns&amp;quot; category for the graphs.&lt;/p&gt; &lt;p&gt;I&amp;#39;m finally ready to start the tutorial but it has all but vanished. I only see about 6 other RAG based links. All of which are long, and with names that don&amp;#39;t really indicate the differences. (Corrective RAG, Self-RAG, Agentic RAG...)&lt;/p&gt; &lt;p&gt;I may end up spending the time diving into them all eventually, but would anyone know which one specifically used to be the &amp;quot;Help Desk RAG&amp;quot;?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Danidre&quot;&gt; /u/Danidre &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elilnx/help_desk_rag_documentation_new_link_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elilnx/help_desk_rag_documentation_new_link_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elilnx</id><link href="https://www.reddit.com/r/LangChain/comments/1elilnx/help_desk_rag_documentation_new_link_langgraph/" /><updated>2024-08-06T14:02:40+00:00</updated><published>2024-08-06T14:02:40+00:00</published><title>Help Desk RAG Documentation New Link? [LangGraph]</title></entry><entry><author><name>/u/Jen1888Mik</name><uri>https://www.reddit.com/user/Jen1888Mik</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;My application logic is - i give some text from database, and using this context generated answer.But if i ask something but its dont exist in context - LLm still answer me. Why?.Here my code &lt;/p&gt; &lt;pre&gt;&lt;code&gt;const prompt = await pull&amp;lt;ChatPromptTemplate&amp;gt;(&amp;quot;rlm/rag-prompt&amp;quot;); const ragChain = await createStuffDocumentsChain({ llm, prompt:prompt, outputParser: parcer, }); const stream = await ragChain.stream({ question:question, context: [ new Document({ pageContent: text as string, }), ], }); &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jen1888Mik&quot;&gt; /u/Jen1888Mik &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli48o/llm_answer_to_the_question_context_for_answer_did/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli48o/llm_answer_to_the_question_context_for_answer_did/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eli48o</id><link href="https://www.reddit.com/r/LangChain/comments/1eli48o/llm_answer_to_the_question_context_for_answer_did/" /><updated>2024-08-06T13:42:00+00:00</updated><published>2024-08-06T13:42:00+00:00</published><title>LLM answer to the question - context for answer did not even provide</title></entry><entry><author><name>/u/Sorre33</name><uri>https://www.reddit.com/user/Sorre33</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been building an SQLagent-based chatbot, testing and prototyping with langserve. I&amp;#39;ve obtained pretty good results and the interaction with the database and query production tasks work surprisingly well. Now, I&amp;#39;m about to upgrade to multi-agent to include some RAG functionalities and being able to produce more comprehensive answers and to help users integrate information from docs etc. For that I will probably using langgraph.&lt;/p&gt; &lt;p&gt;Up to this point, I&amp;#39;ve been using the langchain SQLAgent, which works pretty well considering that it handles all in one the sql dialect, the prompt construction and the tools.&lt;/p&gt; &lt;p&gt;Yesterday though, starting to design the langgraph upgrade, I found out that the new langchain docs now suggest to build SQLagents from scratch using langgraph, through &amp;quot;create_react_agent&amp;quot; and including the sql toolkit, which to me looks like a less intuitive way compared to SQLAgent, adding extra steps to the process and messing up the old prompt building approach (the react_agent takes in input only llm, tools and messages_modifier, which is a simple SystemMessage, and the db is passed to the SQLDatabaseToolkit. To me this is way less intuitive than just having an sql_agent that takes llm, db and an actual full prompt template).&lt;/p&gt; &lt;p&gt;Is there a reason for this? Why did they change the documentations and tutorials from create_sql_agent to this new approach? Is it worth it to make the change if I&amp;#39;m going to overall switch to a langgraph-based design or will I be ok integrating the &amp;quot;old&amp;quot; SQLAgent?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sorre33&quot;&gt; /u/Sorre33 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eldqp7/create_sql_agent_vs_create_react_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eldqp7/create_sql_agent_vs_create_react_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eldqp7</id><link href="https://www.reddit.com/r/LangChain/comments/1eldqp7/create_sql_agent_vs_create_react_agent/" /><updated>2024-08-06T09:55:22+00:00</updated><published>2024-08-06T09:55:22+00:00</published><title>create_sql_agent VS create_react_agent</title></entry><entry><author><name>/u/Common-Comedian7128</name><uri>https://www.reddit.com/user/Common-Comedian7128</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt; I have an ambitious idea about using agents for long-horizon text-only storytelling but have limited technical knowledge. I hope more experienced individuals can offer input on feasibility and potential challenges.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Project Overview:&lt;/strong&gt; My goal is to create very detailed, long form AI roleplaying software where users aren&amp;#39;t just reading a novel, they are the protagonist. In my experience, AI can produce passable prose (Claude 3.5), but it struggles with story progression and planning, often resulting in circular narratives. To address this, I plan to use agents to create a detailed plot outline based on a user-supplied premise. The AI will narrate, and the user will act as the protagonist. Every time the protagonist acts, the AI will follow a series of escalating questions to assess and rewrite the outline as needed to keep the story cohesive:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Does this fit with the next planned beat? If yes, the writer AI continues; if not,&lt;/li&gt; &lt;li&gt;Does this fit with the scene? If yes, rewrite the beat; if not,&lt;/li&gt; &lt;li&gt;Does this fit with the chapter outline? If yes, rewrite the scene and beat; if not,&lt;/li&gt; &lt;li&gt;Does this fit with the arc?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;This way, the story always has an outline to stay on track but can pivot as needed based on the protagonist&amp;#39;s actions.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Assumptions:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Using a series of repeating agents, AI can generate and refine variations of a user-supplied premise into hyper-specific instructions. AI-written content often lacks specificity, which I plan to address through careful prompting and QA agents.&lt;/li&gt; &lt;li&gt;I can break up the long horizon task of impromptu novel writing (AI roleplaying) into discrete chunks I can hand off to specific agents that will only see their little section of the walled garden. This feels risky because different sections might need to know about each other to be cohesive and it could be hard to predict what that shared knowledge pool might need to be without making it so large the cost and wait time balloon beyond toleration.&lt;/li&gt; &lt;li&gt;That this won’t run afoul of the bitter lesson - where I have to get so granular I stray into deterministic logic which is inherently limiting and better solved with waiting for GPT-4.5.&lt;/li&gt; &lt;li&gt;I can get the response time from user input to the next beat written to a tolerable experience. I plan to make what I can run concurrently and use a bag of tricks to lessen the perceived waiting time.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The plot outline to keep things on track is table stakes for me. My real goal is far more ambitious (and far-fetched) about making the characters come alive:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Give all / many of the characters encountered their own AI which fully fleshes out their backstory, goals, personality, outlook, relationships with other AI characters, and gives them agency to pursue those minor/major goals as the book unfolds. The events other characters set in motion will be experienced by the protagonist whether it’s breaking and entering or being crabby in a conversation because they get hangry and it’s lunch time.&lt;/li&gt; &lt;li&gt;Create true repercussions for actions the protagonist or other characters take. If the protagonist as a student is rude, the AI controlling the teacher will assign detention, the unpleasantness determined by the AI of the teacher administering the detention &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I know a tiny amount of code (enough to hard code Towers of Hanoi in terminal) and with AI’s help, have Open Router hooked up to a local python program in VS Code where it writes to a local document. I plan to create tons of little documents the agents will write/read to. In my day job I work at a startup as a UX designer, have lots of senior engineering FAANG friends and have played extensively with AI, particularly with storytelling including programs like Sudowrite and Novelcrafter. &lt;/p&gt; &lt;p&gt;I haven’t yet messed with agents. What do you predict will be the hardest parts of this project and what are the odds of success? I suspect the programming will be simple, the prompting will be finicky, the lag challenging and the cost fairly high even with GPT-4o mini. Even if I succeed, the output will probably be average until GPT-4.5 comes along.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Common-Comedian7128&quot;&gt; /u/Common-Comedian7128 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli34m/beginner_advice_on_extremely_ambitious_agentbased/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli34m/beginner_advice_on_extremely_ambitious_agentbased/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eli34m</id><link href="https://www.reddit.com/r/LangChain/comments/1eli34m/beginner_advice_on_extremely_ambitious_agentbased/" /><updated>2024-08-06T13:40:43+00:00</updated><published>2024-08-06T13:40:43+00:00</published><title>Beginner: Advice on Extremely Ambitious Agent-Based Long-Horizon Storytelling</title></entry><entry><author><name>/u/Plane_Past129</name><uri>https://www.reddit.com/user/Plane_Past129</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I know it&amp;#39;s not right place to ask, but I need some suggestions from people who have worked with automation thing. My manager assigned me a task to fetch all the data from a website. I know to write a simple web scraper. But, first we have to log into their website. So, they suggested me to do automating website. I tried to write selenium in python. But, this has to be hosted on server and the data from the website should be accessed via an API call. Every time I run selenium code, It opens an instance of browser and performing automation. Is there any other way to handle this without opening a browser? I think this should be hosted on EC2 instance?? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Plane_Past129&quot;&gt; /u/Plane_Past129 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eldor2/automation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eldor2/automation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eldor2</id><link href="https://www.reddit.com/r/LangChain/comments/1eldor2/automation/" /><updated>2024-08-06T09:51:56+00:00</updated><published>2024-08-06T09:51:56+00:00</published><title>Automation??</title></entry></feed>