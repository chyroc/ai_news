<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-08-06T14:33:23+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/moonbunR</name><uri>https://www.reddit.com/user/moonbunR</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elcgt3/customer_review_analysis_ai_agent/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/pZgg5gsUcAK_aEdnnGnjE5DIsQs1HHdDTNiAo1mfyf8.jpg&quot; alt=&quot;Customer review analysis Ai Agent&quot; title=&quot;Customer review analysis Ai Agent&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://preview.redd.it/bb6kdv6oh0hd1.jpg?width=974&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=078ba4f7babb1c827c9cb413fa236fc9d1cd5c2f&quot;&gt;https://preview.redd.it/bb6kdv6oh0hd1.jpg?width=974&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=078ba4f7babb1c827c9cb413fa236fc9d1cd5c2f&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This &lt;a href=&quot;https://app.smythos.com/builder?templateId=customer-review-analysis-lxxqii7231.smyth&quot;&gt;~agent~&lt;/a&gt; uses sentiment analysis and an LLM to automatically review and give responses to customer reviews. When the agent receives the customer review, it is first taken through sentiment analysis to understand the sentiment of the feedback. Together with the sentiment for context, the review is sent to the LLM which crafts an appropriate response for the review.&lt;/p&gt; &lt;p&gt;Personally, I think the secret lies in the prompting of the LLM, in my case I set up the LLM to do 3 things mainly, &lt;/p&gt; &lt;ol&gt; &lt;li&gt;Empathize with the customer&lt;/li&gt; &lt;li&gt;Offer a solution&lt;/li&gt; &lt;li&gt;Provide additional information&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;These three gave me some pretty decent results, you can try your own or just use these on the template, but I still think that with more robust prompting, the agent can produce more natural and efficient responses that can help out your brand in a huge way. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/moonbunR&quot;&gt; /u/moonbunR &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elcgt3/customer_review_analysis_ai_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elcgt3/customer_review_analysis_ai_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1elcgt3</id><media:thumbnail url="https://a.thumbs.redditmedia.com/pZgg5gsUcAK_aEdnnGnjE5DIsQs1HHdDTNiAo1mfyf8.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1elcgt3/customer_review_analysis_ai_agent/" /><updated>2024-08-06T08:28:24+00:00</updated><published>2024-08-06T08:28:24+00:00</published><title>Customer review analysis Ai Agent</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1eli3xb/ragflow_ui_for_rag_framework/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli4qr/ragflow_ui_for_rag_framework/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eli4qr</id><link href="https://www.reddit.com/r/LangChain/comments/1eli4qr/ragflow_ui_for_rag_framework/" /><updated>2024-08-06T13:42:38+00:00</updated><published>2024-08-06T13:42:38+00:00</published><title>RAGflow : UI for RAG framework</title></entry><entry><author><name>/u/Relevant_Ebb_3633</name><uri>https://www.reddit.com/user/Relevant_Ebb_3633</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, I&amp;#39;m looking for a low-code platform to implement RAG in business processes. I&amp;#39;ve tested tools like Dify, RAGflow, Flowise, and langflow, but none of them seem to be well-optimized for RAG. Does anyone know of any low-code platforms that offer better RAG parameter optimization? Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Relevant_Ebb_3633&quot;&gt; /u/Relevant_Ebb_3633 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elarmg/looking_for_lowcode_tools_for_building_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elarmg/looking_for_lowcode_tools_for_building_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elarmg</id><link href="https://www.reddit.com/r/LangChain/comments/1elarmg/looking_for_lowcode_tools_for_building_and/" /><updated>2024-08-06T06:34:58+00:00</updated><published>2024-08-06T06:34:58+00:00</published><title>Looking for low-code tools for building and optimizing RAG</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1el7jc9/langchain_in_your_pocket_completes_6_months/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/aEiKKct7MORRNB8Sihet1ABmGQk9Ug9_q_P-0jOItBQ.jpg&quot; alt=&quot;LangChain in your Pocket completes 6 months !!&quot; title=&quot;LangChain in your Pocket completes 6 months !!&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m glad to share that my debut book, &lt;strong&gt;&amp;quot;LangChain in your Pocket: Beginner&amp;#39;s Guide to Building Generative AI Applications using LLMs&lt;/strong&gt;&amp;quot; completed 6 months last week and what a dream run it has been.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The book has been &lt;strong&gt;republished by Packt.&lt;/strong&gt; And is now available with all major publishers including O&amp;#39;Reilly.&lt;/li&gt; &lt;li&gt;So far, the book has sold over &lt;strong&gt;500 copies&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;It is the &lt;strong&gt;highest-rated book on LangChain&lt;/strong&gt; on Amazon (Amazon.in: 4.7; Amazon.com: 4.3 ).&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The best part is that the book hasn&amp;#39;t received a bad review regarding the content from anyone, making this even more special for me&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;&lt;em&gt;A big thanks to the community for all the support.&lt;/em&gt;&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/7wtmrl2nnygd1.png?width=901&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=da3d9b2ea43d771ee738bcbb611c6331a36ef580&quot;&gt;https://preview.redd.it/7wtmrl2nnygd1.png?width=901&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=da3d9b2ea43d771ee738bcbb611c6331a36ef580&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1el7jc9/langchain_in_your_pocket_completes_6_months/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1el7jc9/langchain_in_your_pocket_completes_6_months/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1el7jc9</id><media:thumbnail url="https://b.thumbs.redditmedia.com/aEiKKct7MORRNB8Sihet1ABmGQk9Ug9_q_P-0jOItBQ.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1el7jc9/langchain_in_your_pocket_completes_6_months/" /><updated>2024-08-06T03:24:06+00:00</updated><published>2024-08-06T03:24:06+00:00</published><title>LangChain in your Pocket completes 6 months !!</title></entry><entry><author><name>/u/Danidre</name><uri>https://www.reddit.com/user/Danidre</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been keeping my eye on the LangGraph documentation, there was one titled &amp;quot;Help Desk RAG&amp;quot; or &amp;quot;Make a Help Desk Agent with RAG&amp;quot; or something. This was back when the documentation also showed a &amp;quot;Design Patterns&amp;quot; category for the graphs.&lt;/p&gt; &lt;p&gt;I&amp;#39;m finally ready to start the tutorial but it has all but vanished. I only see about 6 other RAG based links. All of which are long, and with names that don&amp;#39;t really indicate the differences. (Corrective RAG, Self-RAG, Agentic RAG...)&lt;/p&gt; &lt;p&gt;I may end up spending the time diving into them all eventually, but would anyone know which one specifically used to be the &amp;quot;Help Desk RAG&amp;quot;?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Danidre&quot;&gt; /u/Danidre &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elilnx/help_desk_rag_documentation_new_link_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elilnx/help_desk_rag_documentation_new_link_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elilnx</id><link href="https://www.reddit.com/r/LangChain/comments/1elilnx/help_desk_rag_documentation_new_link_langgraph/" /><updated>2024-08-06T14:02:40+00:00</updated><published>2024-08-06T14:02:40+00:00</published><title>Help Desk RAG Documentation New Link? [LangGraph]</title></entry><entry><author><name>/u/BigYesterday2785</name><uri>https://www.reddit.com/user/BigYesterday2785</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I wanted to ask, if I want to run local LLMs only on CPU.&lt;/p&gt; &lt;p&gt;I do not have access to GPUs and wanted to ask how much slower CPU would be, compared to GPU.&lt;/p&gt; &lt;p&gt;I would love to run a small Open Source LLM only on CPUs to read 500 pages PDFs and be able to ask it questions.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BigYesterday2785&quot;&gt; /u/BigYesterday2785 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli67w/run_local_llm_on_cpu_how_bad_would_would_it_be/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli67w/run_local_llm_on_cpu_how_bad_would_would_it_be/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eli67w</id><link href="https://www.reddit.com/r/LangChain/comments/1eli67w/run_local_llm_on_cpu_how_bad_would_would_it_be/" /><updated>2024-08-06T13:44:24+00:00</updated><published>2024-08-06T13:44:24+00:00</published><title>Run local LLM on CPU. how Bad would would it be compared to GPUs</title></entry><entry><author><name>/u/Jen1888Mik</name><uri>https://www.reddit.com/user/Jen1888Mik</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;My application logic is - i give some text from database, and using this context generated answer.But if i ask something but its dont exist in context - LLm still answer me. Why?.Here my code &lt;/p&gt; &lt;pre&gt;&lt;code&gt;const prompt = await pull&amp;lt;ChatPromptTemplate&amp;gt;(&amp;quot;rlm/rag-prompt&amp;quot;); const ragChain = await createStuffDocumentsChain({ llm, prompt:prompt, outputParser: parcer, }); const stream = await ragChain.stream({ question:question, context: [ new Document({ pageContent: text as string, }), ], }); &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jen1888Mik&quot;&gt; /u/Jen1888Mik &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli48o/llm_answer_to_the_question_context_for_answer_did/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli48o/llm_answer_to_the_question_context_for_answer_did/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eli48o</id><link href="https://www.reddit.com/r/LangChain/comments/1eli48o/llm_answer_to_the_question_context_for_answer_did/" /><updated>2024-08-06T13:42:00+00:00</updated><published>2024-08-06T13:42:00+00:00</published><title>LLM answer to the question - context for answer did not even provide</title></entry><entry><author><name>/u/Sorre33</name><uri>https://www.reddit.com/user/Sorre33</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been building an SQLagent-based chatbot, testing and prototyping with langserve. I&amp;#39;ve obtained pretty good results and the interaction with the database and query production tasks work surprisingly well. Now, I&amp;#39;m about to upgrade to multi-agent to include some RAG functionalities and being able to produce more comprehensive answers and to help users integrate information from docs etc. For that I will probably using langgraph.&lt;/p&gt; &lt;p&gt;Up to this point, I&amp;#39;ve been using the langchain SQLAgent, which works pretty well considering that it handles all in one the sql dialect, the prompt construction and the tools.&lt;/p&gt; &lt;p&gt;Yesterday though, starting to design the langgraph upgrade, I found out that the new langchain docs now suggest to build SQLagents from scratch using langgraph, through &amp;quot;create_react_agent&amp;quot; and including the sql toolkit, which to me looks like a less intuitive way compared to SQLAgent, adding extra steps to the process and messing up the old prompt building approach (the react_agent takes in input only llm, tools and messages_modifier, which is a simple SystemMessage, and the db is passed to the SQLDatabaseToolkit. To me this is way less intuitive than just having an sql_agent that takes llm, db and an actual full prompt template).&lt;/p&gt; &lt;p&gt;Is there a reason for this? Why did they change the documentations and tutorials from create_sql_agent to this new approach? Is it worth it to make the change if I&amp;#39;m going to overall switch to a langgraph-based design or will I be ok integrating the &amp;quot;old&amp;quot; SQLAgent?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sorre33&quot;&gt; /u/Sorre33 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eldqp7/create_sql_agent_vs_create_react_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eldqp7/create_sql_agent_vs_create_react_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eldqp7</id><link href="https://www.reddit.com/r/LangChain/comments/1eldqp7/create_sql_agent_vs_create_react_agent/" /><updated>2024-08-06T09:55:22+00:00</updated><published>2024-08-06T09:55:22+00:00</published><title>create_sql_agent VS create_react_agent</title></entry><entry><author><name>/u/Common-Comedian7128</name><uri>https://www.reddit.com/user/Common-Comedian7128</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt; I have an ambitious idea about using agents for long-horizon text-only storytelling but have limited technical knowledge. I hope more experienced individuals can offer input on feasibility and potential challenges.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Project Overview:&lt;/strong&gt; My goal is to create very detailed, long form AI roleplaying software where users aren&amp;#39;t just reading a novel, they are the protagonist. In my experience, AI can produce passable prose (Claude 3.5), but it struggles with story progression and planning, often resulting in circular narratives. To address this, I plan to use agents to create a detailed plot outline based on a user-supplied premise. The AI will narrate, and the user will act as the protagonist. Every time the protagonist acts, the AI will follow a series of escalating questions to assess and rewrite the outline as needed to keep the story cohesive:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Does this fit with the next planned beat? If yes, the writer AI continues; if not,&lt;/li&gt; &lt;li&gt;Does this fit with the scene? If yes, rewrite the beat; if not,&lt;/li&gt; &lt;li&gt;Does this fit with the chapter outline? If yes, rewrite the scene and beat; if not,&lt;/li&gt; &lt;li&gt;Does this fit with the arc?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;This way, the story always has an outline to stay on track but can pivot as needed based on the protagonist&amp;#39;s actions.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Assumptions:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Using a series of repeating agents, AI can generate and refine variations of a user-supplied premise into hyper-specific instructions. AI-written content often lacks specificity, which I plan to address through careful prompting and QA agents.&lt;/li&gt; &lt;li&gt;I can break up the long horizon task of impromptu novel writing (AI roleplaying) into discrete chunks I can hand off to specific agents that will only see their little section of the walled garden. This feels risky because different sections might need to know about each other to be cohesive and it could be hard to predict what that shared knowledge pool might need to be without making it so large the cost and wait time balloon beyond toleration.&lt;/li&gt; &lt;li&gt;That this won’t run afoul of the bitter lesson - where I have to get so granular I stray into deterministic logic which is inherently limiting and better solved with waiting for GPT-4.5.&lt;/li&gt; &lt;li&gt;I can get the response time from user input to the next beat written to a tolerable experience. I plan to make what I can run concurrently and use a bag of tricks to lessen the perceived waiting time.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;The plot outline to keep things on track is table stakes for me. My real goal is far more ambitious (and far-fetched) about making the characters come alive:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Give all / many of the characters encountered their own AI which fully fleshes out their backstory, goals, personality, outlook, relationships with other AI characters, and gives them agency to pursue those minor/major goals as the book unfolds. The events other characters set in motion will be experienced by the protagonist whether it’s breaking and entering or being crabby in a conversation because they get hangry and it’s lunch time.&lt;/li&gt; &lt;li&gt;Create true repercussions for actions the protagonist or other characters take. If the protagonist as a student is rude, the AI controlling the teacher will assign detention, the unpleasantness determined by the AI of the teacher administering the detention &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I know a tiny amount of code (enough to hard code Towers of Hanoi in terminal) and with AI’s help, have Open Router hooked up to a local python program in VS Code where it writes to a local document. I plan to create tons of little documents the agents will write/read to. In my day job I work at a startup as a UX designer, have lots of senior engineering FAANG friends and have played extensively with AI, particularly with storytelling including programs like Sudowrite and Novelcrafter. &lt;/p&gt; &lt;p&gt;I haven’t yet messed with agents. What do you predict will be the hardest parts of this project and what are the odds of success? I suspect the programming will be simple, the prompting will be finicky, the lag challenging and the cost fairly high even with GPT-4o mini. Even if I succeed, the output will probably be average until GPT-4.5 comes along.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Common-Comedian7128&quot;&gt; /u/Common-Comedian7128 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli34m/beginner_advice_on_extremely_ambitious_agentbased/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eli34m/beginner_advice_on_extremely_ambitious_agentbased/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eli34m</id><link href="https://www.reddit.com/r/LangChain/comments/1eli34m/beginner_advice_on_extremely_ambitious_agentbased/" /><updated>2024-08-06T13:40:43+00:00</updated><published>2024-08-06T13:40:43+00:00</published><title>Beginner: Advice on Extremely Ambitious Agent-Based Long-Horizon Storytelling</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elgkz4/adding_memory_agent_interaction_into_the/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/8KOjNt_QWxAuMrglcZz6T7GEcc4UE4-ife3v361FEU8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=16a76ae363963d0e6b15bf595f936a6ebf7fbf63&quot; alt=&quot;Adding Memory &amp;amp; Agent interaction into the “Auto-Analyst”&quot; title=&quot;Adding Memory &amp;amp; Agent interaction into the “Auto-Analyst”&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://medium.com/firebird-technologies/adding-memory-agent-interaction-into-the-auto-analyst-01aa7a2d3614&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elgkz4/adding_memory_agent_interaction_into_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1elgkz4</id><media:thumbnail url="https://external-preview.redd.it/8KOjNt_QWxAuMrglcZz6T7GEcc4UE4-ife3v361FEU8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=16a76ae363963d0e6b15bf595f936a6ebf7fbf63" /><link href="https://www.reddit.com/r/LangChain/comments/1elgkz4/adding_memory_agent_interaction_into_the/" /><updated>2024-08-06T12:34:07+00:00</updated><published>2024-08-06T12:34:07+00:00</published><title>Adding Memory &amp; Agent interaction into the “Auto-Analyst”</title></entry><entry><author><name>/u/Anmsacx</name><uri>https://www.reddit.com/user/Anmsacx</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elbugn/deprecated_pydantic_library_is_not_working_for/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/kMbJRyrHEP98eWpF7LHLPGKz9G9rRkwt3r7gJy4W-0A.jpg&quot; alt=&quot;Deprecated pydantic library is not working for RAG pipeline development&quot; title=&quot;Deprecated pydantic library is not working for RAG pipeline development&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am new to langflow and langchain. Running the new ollama- llama3.1 locally on my machine. The error is in the main.py file of pydantic and states that the existing json, fields and other such are deprecated. As a result, i am unable to run the model for my task. Please help😿&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Anmsacx&quot;&gt; /u/Anmsacx &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/gallery/1elbugn&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elbugn/deprecated_pydantic_library_is_not_working_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1elbugn</id><media:thumbnail url="https://b.thumbs.redditmedia.com/kMbJRyrHEP98eWpF7LHLPGKz9G9rRkwt3r7gJy4W-0A.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1elbugn/deprecated_pydantic_library_is_not_working_for/" /><updated>2024-08-06T07:45:48+00:00</updated><published>2024-08-06T07:45:48+00:00</published><title>Deprecated pydantic library is not working for RAG pipeline development</title></entry><entry><author><name>/u/Plane_Past129</name><uri>https://www.reddit.com/user/Plane_Past129</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I know it&amp;#39;s not right place to ask, but I need some suggestions from people who have worked with automation thing. My manager assigned me a task to fetch all the data from a website. I know to write a simple web scraper. But, first we have to log into their website. So, they suggested me to do automating website. I tried to write selenium in python. But, this has to be hosted on server and the data from the website should be accessed via an API call. Every time I run selenium code, It opens an instance of browser and performing automation. Is there any other way to handle this without opening a browser? I think this should be hosted on EC2 instance?? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Plane_Past129&quot;&gt; /u/Plane_Past129 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eldor2/automation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eldor2/automation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eldor2</id><link href="https://www.reddit.com/r/LangChain/comments/1eldor2/automation/" /><updated>2024-08-06T09:51:56+00:00</updated><published>2024-08-06T09:51:56+00:00</published><title>Automation??</title></entry><entry><author><name>/u/Exotic_Show3271</name><uri>https://www.reddit.com/user/Exotic_Show3271</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hi guys, I want to do the retrieval part in my rag without a limit on the K. so it can answer such questions, how many times X appears for example. what is the best approach? I tried increasing the k to the total number of documents but it gave me a lot of irrelevant documents. and the vectorstore.as_retriver() always return 4 docs only&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Exotic_Show3271&quot;&gt; /u/Exotic_Show3271 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eld8ep/increase_number_of_retrieved_docs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eld8ep/increase_number_of_retrieved_docs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eld8ep</id><link href="https://www.reddit.com/r/LangChain/comments/1eld8ep/increase_number_of_retrieved_docs/" /><updated>2024-08-06T09:21:10+00:00</updated><published>2024-08-06T09:21:10+00:00</published><title>increase number of retrieved docs</title></entry><entry><author><name>/u/CharmingViolinist962</name><uri>https://www.reddit.com/user/CharmingViolinist962</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;index_name = f&amp;quot;vs_spn_chatrules&amp;quot;&lt;/p&gt; &lt;p&gt;search_client = SearchClient(&lt;br/&gt; endpoint=service_endpoint,&lt;br/&gt; index_name=index_name,&lt;br/&gt; credential=cognitive_search_credential,&lt;br/&gt; )&lt;/p&gt; &lt;h1&gt;Creating an Azure AI Search Vector Store&lt;/h1&gt; &lt;p&gt;vector_store = AzureAISearchVectorStore(&lt;br/&gt; search_or_index_client=index_client,&lt;br/&gt; filterable_metadata_field_keys=metadata_fields,&lt;br/&gt; index_name=index_name,&lt;br/&gt; index_management=IndexManagement.CREATE_IF_NOT_EXISTS,&lt;br/&gt; id_field_key=&amp;quot;id&amp;quot;,&lt;br/&gt; chunk_field_key=&amp;quot;chunk&amp;quot;, #content&lt;br/&gt; embedding_field_key=&amp;quot;embedding&amp;quot;, #content_vector&lt;br/&gt; embedding_dimensionality=1536,&lt;br/&gt; metadata_string_field_key=&amp;quot;metadata&amp;quot;,&lt;br/&gt; doc_id_field_key=&amp;quot;doc_id&amp;quot;,&lt;br/&gt; language_analyzer=&amp;quot;en.lucene&amp;quot;,&lt;br/&gt; vector_algorithm_type=&amp;quot;exhaustiveKnn&amp;quot;, #HNSW focuses on approximate methods for efficiency, KNN ensures exactness through exhaustive searches.&lt;br/&gt; )&lt;/p&gt; &lt;p&gt;Settings.llm = llm&lt;br/&gt; Settings.embed_model = embed_model&lt;/p&gt; &lt;p&gt;storage_context = StorageContext.from_defaults(vector_store=vector_store)&lt;/p&gt; &lt;h1&gt;VectorStoreIndex.from_documents&lt;/h1&gt; &lt;p&gt;index = VectorStoreIndex.from_documents(&lt;br/&gt; all_docs, storage_context=storage_context&lt;br/&gt; )&lt;/p&gt; &lt;p&gt;all_docs is a list of documents with document metadata and documents&lt;/p&gt; &lt;p&gt;while im trying to create index its gives error&lt;/p&gt; &lt;p&gt;HttpResponseError: () The request is invalid. Details: An unexpected &amp;#39;StartArray&amp;#39; node was found when reading from the JSON reader. A &amp;#39;PrimitiveValue&amp;#39; node was expected.&lt;br/&gt; Code:&lt;br/&gt; Message: The request is invalid. Details: An unexpected &amp;#39;StartArray&amp;#39; node was found when reading from the JSON reader. A &amp;#39;PrimitiveValue&amp;#39; node was expected.&lt;/p&gt; &lt;p&gt;anyone faced this&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CharmingViolinist962&quot;&gt; /u/CharmingViolinist962 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elbo4f/issue_while_trying_to_create_index_with_error_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1elbo4f/issue_while_trying_to_create_index_with_error_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1elbo4f</id><link href="https://www.reddit.com/r/LangChain/comments/1elbo4f/issue_while_trying_to_create_index_with_error_the/" /><updated>2024-08-06T07:34:15+00:00</updated><published>2024-08-06T07:34:15+00:00</published><title>Issue while trying to create index with error The request is invalid. Details: An unexpected 'StartArray' node was found when reading from the JSON reader. A 'PrimitiveValue' node was expected.</title></entry><entry><author><name>/u/anujtomar_17</name><uri>https://www.reddit.com/user/anujtomar_17</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1el9edu/javascript_revolution_nodejs_in_backend/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/4VCwe6CcHO5MeC--bZyzxCK5GSWjgRY8cnCRF7SgID8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=804d791203a8e670b391f9a21caab8e2e265d88e&quot; alt=&quot;JavaScript Revolution: Node.js in Back-End Development&quot; title=&quot;JavaScript Revolution: Node.js in Back-End Development&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/anujtomar_17&quot;&gt; /u/anujtomar_17 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.quickwayinfosystems.com/blog/javascript-revolution-nodejs-backend-development/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1el9edu/javascript_revolution_nodejs_in_backend/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1el9edu</id><media:thumbnail url="https://external-preview.redd.it/4VCwe6CcHO5MeC--bZyzxCK5GSWjgRY8cnCRF7SgID8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=804d791203a8e670b391f9a21caab8e2e265d88e" /><link href="https://www.reddit.com/r/LangChain/comments/1el9edu/javascript_revolution_nodejs_in_backend/" /><updated>2024-08-06T05:08:28+00:00</updated><published>2024-08-06T05:08:28+00:00</published><title>JavaScript Revolution: Node.js in Back-End Development</title></entry><entry><author><name>/u/MeltingHippos</name><uri>https://www.reddit.com/user/MeltingHippos</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Post by an AI researcher describing how their team made a modification to OpenAI’s Whisper model architecture that results in a 1.5x increase in speed with comparable accuracy. The improvement is achieved using a multi-head attention mechanism (hence Medusa). The post gives an overview of Whisper&amp;#39;s architecture and a detailed explanation of the method used to achieve the increase in speed:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/@sgl.yael/whisper-medusa-using-multiple-decoding-heads-to-achieve-1-5x-speedup-7344348ef89b&quot;&gt;https://medium.com/@sgl.yael/whisper-medusa-using-multiple-decoding-heads-to-achieve-1-5x-speedup-7344348ef89b&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MeltingHippos&quot;&gt; /u/MeltingHippos &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eks2cm/whispermedusa_uses_multiple_decoding_heads_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eks2cm/whispermedusa_uses_multiple_decoding_heads_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eks2cm</id><link href="https://www.reddit.com/r/LangChain/comments/1eks2cm/whispermedusa_uses_multiple_decoding_heads_for/" /><updated>2024-08-05T16:22:51+00:00</updated><published>2024-08-05T16:22:51+00:00</published><title>Whisper-Medusa: uses multiple decoding heads for 1.5X speedup</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;LangFlow is an extension of LangChain which provides GUI options to build Generative AI applications using LLMs with drag and drop options. Checkout how to install and use it in this tutorial : &lt;a href=&quot;https://youtu.be/LpxeE_eTGOU&quot;&gt;https://youtu.be/LpxeE_eTGOU&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eknnho/langflow_ui_for_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eknnho/langflow_ui_for_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eknnho</id><link href="https://www.reddit.com/r/LangChain/comments/1eknnho/langflow_ui_for_langchain/" /><updated>2024-08-05T13:22:29+00:00</updated><published>2024-08-05T13:22:29+00:00</published><title>LangFlow : UI for LangChain</title></entry><entry><author><name>/u/tisi3000</name><uri>https://www.reddit.com/user/tisi3000</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ekr1de/langgraph_fanout_ui/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/mgH19MDRIzUoIy6LkDG_eHazz8u3kwXBx1KVuKNm3uc.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=92049c27bd138737e4722f1c39707b435d1ed0d5&quot; alt=&quot;LangGraph fan-out UI&quot; title=&quot;LangGraph fan-out UI&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So LangGraph can execute nodes in parallel via fan-out. For example: Select topics -&amp;gt; research each -&amp;gt; ...&lt;br/&gt; What&amp;#39;s a good way to visualize this in a UI? Can be tricky in a 1-dimensional, linear chat interface, but also generally if there are multiple steps running in parallel.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://reddit.com/link/1ekr1de/video/3z2zywmt7vgd1/player&quot;&gt;fan-out in gotoHuman&lt;/a&gt;&lt;/p&gt; &lt;p&gt;We are using these tabs for now, but maybe people have come up with smarter solutions already?!&lt;br/&gt; (Code is &lt;a href=&quot;https://github.com/gotohuman/gth-demo-fanout-content-creator&quot;&gt;here&lt;/a&gt;) &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/tisi3000&quot;&gt; /u/tisi3000 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ekr1de/langgraph_fanout_ui/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ekr1de/langgraph_fanout_ui/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ekr1de</id><media:thumbnail url="https://external-preview.redd.it/mgH19MDRIzUoIy6LkDG_eHazz8u3kwXBx1KVuKNm3uc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=92049c27bd138737e4722f1c39707b435d1ed0d5" /><link href="https://www.reddit.com/r/LangChain/comments/1ekr1de/langgraph_fanout_ui/" /><updated>2024-08-05T15:41:44+00:00</updated><published>2024-08-05T15:41:44+00:00</published><title>LangGraph fan-out UI</title></entry><entry><author><name>/u/gabbom_XCII</name><uri>https://www.reddit.com/user/gabbom_XCII</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’m building an application made of 3 agents:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Router Agent;&lt;/li&gt; &lt;li&gt;Agent A&lt;/li&gt; &lt;li&gt;Agent B&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The router agent receives the initial user prompt and based on context it routes to one of the Agents.&lt;/p&gt; &lt;p&gt;When defining my LangGraph workflow I’m using a in-memory SqliteSaver. And also setting the thread_id when running my workflow.&lt;/p&gt; &lt;p&gt;But I’m not sure how LangGraph uses this chat history. Does it sends all agents history to all agent calls or it just sends the agent’s specific history to each agent? I’m experiencing some kind of “amnesia” in between interactions.&lt;/p&gt; &lt;p&gt;Am I missing something in my prompt building? Like including a {history} along with my {input} and {context} ? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gabbom_XCII&quot;&gt; /u/gabbom_XCII &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ekn1rt/langgraph_orchestrating_langchain_agents_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ekn1rt/langgraph_orchestrating_langchain_agents_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ekn1rt</id><link href="https://www.reddit.com/r/LangChain/comments/1ekn1rt/langgraph_orchestrating_langchain_agents_with/" /><updated>2024-08-05T12:54:58+00:00</updated><published>2024-08-05T12:54:58+00:00</published><title>LangGraph orchestrating LangChain agents with chat history.</title></entry><entry><author><name>/u/python_dev10</name><uri>https://www.reddit.com/user/python_dev10</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m using LangChain in my LLM to execute SQL query based on the input, now the issue is it doesn&amp;#39;t handing well in the generic response like for Hi, How are you or something like this. Now how can we configure langchain to handle these?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/python_dev10&quot;&gt; /u/python_dev10 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eknw12/how_can_we_configure_langchain_to_handle_both_sql/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eknw12/how_can_we_configure_langchain_to_handle_both_sql/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eknw12</id><link href="https://www.reddit.com/r/LangChain/comments/1eknw12/how_can_we_configure_langchain_to_handle_both_sql/" /><updated>2024-08-05T13:32:59+00:00</updated><published>2024-08-05T13:32:59+00:00</published><title>how can we configure langchain to handle both SQL and Generic response?</title></entry><entry><author><name>/u/Jen1888Mik</name><uri>https://www.reddit.com/user/Jen1888Mik</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I build my own RAG application but have a trouble, Logic my app is - user push button and load some document(text), after this i generate embeddings using this document and write its to database,i use Convex. And i want get this embedding from this document on database and add to llm to generate answer. But i dont find any example how do this, find only example how use ConvexVectoreStore and transform it to retriver - but in my case its dont work(i have several reason). I need just use embedding from document and pass to context and i dont know how and langchain document/discord dont give me answer. Chat bot in langchain site recomend me create CustomRetriever class - but why doc dont have answer, Pls help me&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jen1888Mik&quot;&gt; /u/Jen1888Mik &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ekql8w/how_to_pass_data_from_database_to_langchain_like/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ekql8w/how_to_pass_data_from_database_to_langchain_like/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ekql8w</id><link href="https://www.reddit.com/r/LangChain/comments/1ekql8w/how_to_pass_data_from_database_to_langchain_like/" /><updated>2024-08-05T15:23:36+00:00</updated><published>2024-08-05T15:23:36+00:00</published><title>How to pass data from database to Langchain like context/source</title></entry><entry><author><name>/u/CharmingViolinist962</name><uri>https://www.reddit.com/user/CharmingViolinist962</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;HI all,&lt;/p&gt; &lt;p&gt;Im developing a rag based chatbot for a client who mostly has pdf based docs with few text files also.&lt;br/&gt; pdf documents are mostly tabular with 3 columns &lt;/p&gt; &lt;p&gt;currently used unstructured and pdfreader to build a chatbot but the responses are mostly wrong and the chat bot hallucinating a lot&lt;br/&gt; also we want to give the source file in output as reference&lt;br/&gt; the file that is highlighted as source doesnt have any content of the response given by the chatbot and both are wrong &lt;/p&gt; &lt;p&gt;llamaindex is used for this with gpt 3.5&lt;/p&gt; &lt;p&gt;any guidance will be extremely helpful&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CharmingViolinist962&quot;&gt; /u/CharmingViolinist962 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ek14so/rag_application_for_enterprise_not_so_accurate/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ek14so/rag_application_for_enterprise_not_so_accurate/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ek14so</id><link href="https://www.reddit.com/r/LangChain/comments/1ek14so/rag_application_for_enterprise_not_so_accurate/" /><updated>2024-08-04T17:45:58+00:00</updated><published>2024-08-04T17:45:58+00:00</published><title>RAG application for enterprise not so accurate</title></entry><entry><author><name>/u/Gokul123654</name><uri>https://www.reddit.com/user/Gokul123654</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on a project to build a conversational agent that answers user questions based on their data. I&amp;#39;m considering using LangChain for this purpose. Can anyone advise on whether I should use version 0.1 or 0.2? What are the key differences between these versions, and which one is more suitable for developing a robust and efficient conversational agent? Any insights or experiences with these versions would be greatly appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Gokul123654&quot;&gt; /u/Gokul123654 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ekg6wx/which_langchain_version_is_best_for_building_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ekg6wx/which_langchain_version_is_best_for_building_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ekg6wx</id><link href="https://www.reddit.com/r/LangChain/comments/1ekg6wx/which_langchain_version_is_best_for_building_a/" /><updated>2024-08-05T05:40:36+00:00</updated><published>2024-08-05T05:40:36+00:00</published><title>Which LangChain Version is Best for Building a Conversational Agent: v0.1 or v0.2?</title></entry><entry><author><name>/u/trj_flash75</name><uri>https://www.reddit.com/user/trj_flash75</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eki1uc/langchain_evaluation_with_beyondllm/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/NCWse2LVrgbybcHe08WIFejNzgGWIhz4-lgkuZU1PpM.jpg&quot; alt=&quot;Langchain Evaluation with BeyondLLM&quot; title=&quot;Langchain Evaluation with BeyondLLM&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone! Just came across a new feature of Beyond LLM that can evaluate Langchain RAG pipelines! It provides context relevancy, answer relevancy, and groundedness. Check out the code snippet I’m sharing—perfect for testing your RAG pipelines! For more info, be sure to check it out on GitHub &lt;a href=&quot;https://github.com/aiplanethub/beyondllm/blob/main/cookbook/evaluate_langchain_rag_pipeline_beyondllm.ipynb&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/0brgw72kvsgd1.png?width=3972&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=729dddb314e224278cf388129b1fd577b008e790&quot;&gt;https://preview.redd.it/0brgw72kvsgd1.png?width=3972&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=729dddb314e224278cf388129b1fd577b008e790&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/trj_flash75&quot;&gt; /u/trj_flash75 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eki1uc/langchain_evaluation_with_beyondllm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eki1uc/langchain_evaluation_with_beyondllm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1eki1uc</id><media:thumbnail url="https://b.thumbs.redditmedia.com/NCWse2LVrgbybcHe08WIFejNzgGWIhz4-lgkuZU1PpM.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1eki1uc/langchain_evaluation_with_beyondllm/" /><updated>2024-08-05T07:45:52+00:00</updated><published>2024-08-05T07:45:52+00:00</published><title>Langchain Evaluation with BeyondLLM</title></entry><entry><author><name>/u/DevJonPizza</name><uri>https://www.reddit.com/user/DevJonPizza</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DevJonPizza&quot;&gt; /u/DevJonPizza &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://prompthippo.net/docs/ab-test-custom-langserve&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eklevi/ab_test_prompts_on_a_custom_langserve_instance/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eklevi</id><link href="https://www.reddit.com/r/LangChain/comments/1eklevi/ab_test_prompts_on_a_custom_langserve_instance/" /><updated>2024-08-05T11:29:39+00:00</updated><published>2024-08-05T11:29:39+00:00</published><title>AB Test Prompts on a Custom LangServe 🦜 Instance</title></entry></feed>