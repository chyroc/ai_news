<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-02-25T16:01:02+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/wilyx11</name><uri>https://www.reddit.com/user/wilyx11</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been using ada for a while now with a Faiss store and it has been doing well. &lt;/p&gt; &lt;p&gt;Today I tried text-embedding-3-large today and the scores are weird. &lt;/p&gt; &lt;p&gt;The correct match with ada gets a score of ~0.2 (0 being the best match and 1 being the worst match) The correct match with text-embedding-3-large gets a score of ~0.5 &lt;/p&gt; &lt;p&gt;The full ordering from score 0-1 seems to be better than ada. But the there is a shift towards a score of 1. &lt;/p&gt; &lt;p&gt;Has anyone experienced that? Or has any explanation? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/wilyx11&quot;&gt; /u/wilyx11 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azr70c/openai_embedding_v3_weird_scores/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azr70c/openai_embedding_v3_weird_scores/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1azr70c</id><link href="https://www.reddit.com/r/LangChain/comments/1azr70c/openai_embedding_v3_weird_scores/" /><updated>2024-02-25T15:56:46+00:00</updated><published>2024-02-25T15:56:46+00:00</published><title>OpenAi embedding v3 weird scores</title></entry><entry><author><name>/u/brayboy12</name><uri>https://www.reddit.com/user/brayboy12</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Iâ€™m a software quality engineer and Iâ€™ve been tasked with exploring ai use cases for my team. The only thing I could think was test plan generation by storing our existing test plans in a db and information about products(PRD, public docs etc.) and somehow getting the llm to return a test plan draft based on this. Would this even be feasible and worth exploring? What other use cases you think could be beneficial to a quality engineering team? Iâ€™m an AI noob btw with interest in building on top of llm&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/brayboy12&quot;&gt; /u/brayboy12 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azoinv/langchain_use_cases/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azoinv/langchain_use_cases/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1azoinv</id><link href="https://www.reddit.com/r/LangChain/comments/1azoinv/langchain_use_cases/" /><updated>2024-02-25T13:57:35+00:00</updated><published>2024-02-25T13:57:35+00:00</published><title>Langchain use cases</title></entry><entry><author><name>/u/Medium_Alternative50</name><uri>https://www.reddit.com/user/Medium_Alternative50</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a question regarding generating synthetic data, in the docs synthetic data generation guide is only using OpenAI and when I&amp;#39;m trying to use other model It&amp;#39;s just giving me some error is that possible to use other local models for synthetic data generation &lt;a href=&quot;https://python.langchain.com/docs/use_cases/data_generation&quot;&gt;https://python.langchain.com/docs/use_cases/data_generation&lt;/a&gt; &lt;/p&gt; &lt;p&gt;my code &lt;code&gt;py synthetic_data_generator = create_openai_data_generator( output_schema=MedicalBilling, llm=Ollama(model=&amp;quot;llama2&amp;quot;), prompt=few_shot_prompt_template ) &lt;/code&gt;&lt;/p&gt; &lt;p&gt;error &lt;code&gt; ValueError: Ollama call failed with status code 400. Details: invalid options: functions, function_call &lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Medium_Alternative50&quot;&gt; /u/Medium_Alternative50 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azi86f/synthetic_data_generation_using_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azi86f/synthetic_data_generation_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1azi86f</id><link href="https://www.reddit.com/r/LangChain/comments/1azi86f/synthetic_data_generation_using_langchain/" /><updated>2024-02-25T07:36:37+00:00</updated><published>2024-02-25T07:36:37+00:00</published><title>Synthetic data generation using langchain</title></entry><entry><author><name>/u/CoolAppointment7961</name><uri>https://www.reddit.com/user/CoolAppointment7961</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to add a human message status into the mongodb database that tells if the message has been replayed to or not, how can I do that in langchain with this function? &lt;/p&gt; &lt;pre&gt;&lt;code&gt;message_history = MongoDBChatMessageHistory( connection_string=connection_string, session_id=f&amp;quot;{phone_number}&amp;quot; ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CoolAppointment7961&quot;&gt; /u/CoolAppointment7961 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azhuxd/how_can_i_add_more_fields_into_a_mongodb_database/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azhuxd/how_can_i_add_more_fields_into_a_mongodb_database/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1azhuxd</id><link href="https://www.reddit.com/r/LangChain/comments/1azhuxd/how_can_i_add_more_fields_into_a_mongodb_database/" /><updated>2024-02-25T07:12:46+00:00</updated><published>2024-02-25T07:12:46+00:00</published><title>how can I add more fields into a mongoDB database from langchain?</title></entry><entry><author><name>/u/novel_market_21</name><uri>https://www.reddit.com/user/novel_market_21</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I am a Data Scientist by trade and have been working with Langchain specifically for about 2 months now. I enjoy coding both inside and outside of work.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I&amp;#39;m not looking for any help with work. &lt;/p&gt; &lt;p&gt;I want a non-academic tutor who I meet with once or twice a month via Zoom and I can use it like office hours. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;If you would be interested in exploring random passion projects and ideas with me please send a DM and we can discuss rates and hours there. I&amp;#39;m flexible haha.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;P.S. I&amp;#39;d love recommendations on how I can accomplish finding someone like this as well if anyone has thoughts.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/novel_market_21&quot;&gt; /u/novel_market_21 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az5do0/looking_to_hire_a_teacher_to_meet_twice_a_month/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az5do0/looking_to_hire_a_teacher_to_meet_twice_a_month/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1az5do0</id><link href="https://www.reddit.com/r/LangChain/comments/1az5do0/looking_to_hire_a_teacher_to_meet_twice_a_month/" /><updated>2024-02-24T21:06:03+00:00</updated><published>2024-02-24T21:06:03+00:00</published><title>Looking to Hire a Teacher to Meet Twice a Month</title></entry><entry><author><name>/u/function-devs</name><uri>https://www.reddit.com/user/function-devs</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How to set up a &lt;a href=&quot;https://semaphoreci.com/blog/llms-performance-testing&quot;&gt;CI/CD workflow using Langchain Evaluators and Pytest&lt;/a&gt; in measuring LLM performance with Langchain evaluators, &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/function-devs&quot;&gt; /u/function-devs &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azb96b/working_with_langchain_evaluators/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azb96b/working_with_langchain_evaluators/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1azb96b</id><link href="https://www.reddit.com/r/LangChain/comments/1azb96b/working_with_langchain_evaluators/" /><updated>2024-02-25T01:17:09+00:00</updated><published>2024-02-25T01:17:09+00:00</published><title>Working with Langchain evaluators</title></entry><entry><author><name>/u/insane-defaults</name><uri>https://www.reddit.com/user/insane-defaults</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have written a RAG-system which uses around a 100 meeting notes from various dates. While ingesting the data I attach the date as metadata (using llamaindex) to each document. &lt;/p&gt; &lt;p&gt;My problem is that the model is invariably confused about when the latest meeting was held/meeting note is from and will even contradict itself in the same chat session.&lt;/p&gt; &lt;p&gt;I would greatly appreciate any suggestions as to how I can fix this! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/insane-defaults&quot;&gt; /u/insane-defaults &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az7uay/making_gpt4_understand_dates_via_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az7uay/making_gpt4_understand_dates_via_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1az7uay</id><link href="https://www.reddit.com/r/LangChain/comments/1az7uay/making_gpt4_understand_dates_via_rag/" /><updated>2024-02-24T22:47:23+00:00</updated><published>2024-02-24T22:47:23+00:00</published><title>Making gpt-4 understand dates via RAG</title></entry><entry><author><name>/u/Calm_Pea_2428</name><uri>https://www.reddit.com/user/Calm_Pea_2428</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a Json data and I want to optimize my retrieval process down to 50ms, how can we do this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm_Pea_2428&quot;&gt; /u/Calm_Pea_2428 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azfbj0/query_optimization/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1azfbj0/query_optimization/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1azfbj0</id><link href="https://www.reddit.com/r/LangChain/comments/1azfbj0/query_optimization/" /><updated>2024-02-25T04:44:23+00:00</updated><published>2024-02-25T04:44:23+00:00</published><title>Query optimization</title></entry><entry><author><name>/u/Any_Slide_424</name><uri>https://www.reddit.com/user/Any_Slide_424</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been developing a chatbot for a niche market. But I was wondering what&amp;#39;s the best method to Monitize an AI conversational chatbot. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Any_Slide_424&quot;&gt; /u/Any_Slide_424 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aze52v/whats_the_best_way_to_monitize_ai_chatbot_webapp/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aze52v/whats_the_best_way_to_monitize_ai_chatbot_webapp/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aze52v</id><link href="https://www.reddit.com/r/LangChain/comments/1aze52v/whats_the_best_way_to_monitize_ai_chatbot_webapp/" /><updated>2024-02-25T03:40:42+00:00</updated><published>2024-02-25T03:40:42+00:00</published><title>What's the best way to Monitize AI chatbot (webapp)</title></entry><entry><author><name>/u/MrWiseOwl</name><uri>https://www.reddit.com/user/MrWiseOwl</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Iâ€™ve been trying to follow a few different tutorials but I keep getting stuck. &lt;/p&gt; &lt;p&gt;Problem: currently, itâ€™s time consuming and labor intensive to find historic data in the various reports that I have. Our staff changes seasonally so reports and data get filed away and forgotten about until someone stumbles upon it or active goes looking for â€˜that study on x 5 years agoâ€™&lt;/p&gt; &lt;p&gt;Need: I have about 20 years of environmental reports in PDF I want to load into a vector DB then put a chatbot on top of it for my co-workers to query for past results. &lt;/p&gt; &lt;p&gt;Iâ€™ve gotten to the point of where OpenAI embeddings are working but storing them and querying them is where I get lost. I overthink and keep trying different platforms (chroma, pinecone, faiss) that sets me back. &lt;/p&gt; &lt;p&gt;I followed a tutorial to use streamlit and pinecone and OpenAI and it kind of works but lacks substance on the retrieval. I then look at the scaling costs of pinecone and itâ€™s more than I need but canâ€™t figure out another VDB to learn from. &lt;/p&gt; &lt;p&gt;Any books, websites, libraries are great appreciated! Iâ€™d even pay if there is a paid version of a course to take. &lt;/p&gt; &lt;p&gt;Thank you&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MrWiseOwl&quot;&gt; /u/MrWiseOwl &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az3nu8/help_tutorial_needed/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az3nu8/help_tutorial_needed/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1az3nu8</id><link href="https://www.reddit.com/r/LangChain/comments/1az3nu8/help_tutorial_needed/" /><updated>2024-02-24T19:55:36+00:00</updated><published>2024-02-24T19:55:36+00:00</published><title>Help - tutorial needed</title></entry><entry><author><name>/u/drunkmute</name><uri>https://www.reddit.com/user/drunkmute</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, so I&amp;#39;ve been creating an agent that went from a SQL to Python/CSV agent (I kept getting errors from the db so gave up on that). I have gotten to this final product where I get a specific response schema back and I&amp;#39;d like to use it to provide an answer, along with an embedded plot that is related to said answer. I have tested it, and it seems to work but the only thing is that my output does not want to return the schema. First, below is the code for the streamlit app:&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain_openai import OpenAI from langchain_experimental.agents.agent_toolkits import create_python_agent, create_csv_agent # tools that will be used for sql agent to reason for from langchain_experimental.tools.python.tool import PythonREPLTool from langchain.agents.agent_types import AgentType # for agent type assignment from langchain.agents.react.agent import create_react_agent from langchain.agents import (AgentExecutor, Tool) # agent executor to execute agent Tool, to make tool out of agent, ConversationalAgent to create template # from langchain.memory import ConversationBufferMemory # chat memory for agentfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain.prompts import PromptTemplate from langchain.output_parsers import ResponseSchema, StructuredOutputParser from langchain_community.callbacks import StreamlitCallbackHandler from langchain.globals import set_verbose, set_debug from langchain_community.llms import Ollama from langchain_google_vertexai import VertexAI import google.auth from dotenv import load_dotenv import os import streamlit as st ##### Setup ##### # Load the environment variables load_dotenv() # google authorization CREDENTIALS, PROJECT_ID = google.auth.default() # set langchain to verbose, debug true set_verbose(True) set_debug(False) ##### LLM ##### @st.cache_resource def model_init(model_type = &amp;#39;gemini&amp;#39;): # To use Ollama you must first install the model of choice, then provide its name as a parameter if(model_type == &amp;quot;ollama&amp;quot;): model = Ollama( model=&amp;quot;mistral:latest&amp;quot;, # Provide your ollama model name here temperature = 0.0, streaming=True ) # Initializing Gemini elif model_type == &amp;quot;gemini&amp;quot;: model = VertexAI( model_name = &amp;quot;gemini-pro&amp;quot;, max_output_tokens = &amp;quot;2500&amp;quot;, temperature = 0.05, top_p = 0.8, top_k = 40, verbose = True, streaming=True, project=PROJECT_ID, credentials=CREDENTIALS ) elif model_type == &amp;quot;openai&amp;quot;: model = OpenAI(temperature = 0.05, verbose = True, api_key=os.getenv(&amp;quot;OPENAI_API_KEY&amp;quot;) streaming=True) elif model_type == &amp;quot;codellama&amp;quot;: model = VertexAI( model_name = &amp;quot;codellama-70b&amp;quot;, max_output_tokens = &amp;quot;2500&amp;quot;, temperature = 0.05, top_p = 0.8, top_k = 40, verbose = True, streaming=True, project=PROJECT_ID, credentials=CREDENTIALS ) return model ##### SQL Database ##### # @st.cache_resource # def db_init(file): # # Connect to the SQLite database # connection = sqlite3.connect(&amp;quot;data.db&amp;quot;) # # create dataframe from data # df = pd.read_csv(file) # # Convert DataFrame to a SQLite table # df.to_sql(&amp;quot;data&amp;quot;, connection, if_exists=&amp;#39;replace&amp;#39;) # # connect to local database # db = SQLDatabase.from_uri(&amp;#39;sqlite:///data.db&amp;#39;) # return db ##### Agent ##### @st.cache_resource def agent_init( _llm, data_description, file): python_agent = create_python_agent(llm=_llm, tool=PythonREPLTool(), verbose=True) csv_agent = create_csv_agent(llm=_llm, path=file,) # Create the whole list of tools tools=[ Tool( name=&amp;quot;PythonAgent&amp;quot;, func=python_agent.invoke, description=&amp;quot;Useful to plot data&amp;quot;, ), Tool( name=&amp;quot;CSVAgent&amp;quot;, func=csv_agent.invoke, description=&amp;quot;Useful to manipulate csv files as dataframes&amp;quot;, ), ] response_schemas = [ ResponseSchema(name=&amp;quot;Final Answer&amp;quot;, description=&amp;quot;Answer to the user&amp;#39;s query.&amp;quot;), ResponseSchema( name=&amp;quot;plot&amp;quot;, description=&amp;quot;Python code for the pandas plot, if applicable.&amp;quot;, ), ] output_parser = StructuredOutputParser.from_response_schemas(response_schemas) ##### Agent Creation ##### prompt_template = PromptTemplate.from_template( &amp;quot;&amp;quot;&amp;quot;We are statistically analyzing a dataset for a user by giving them natural language answers to their data analysis questions. Below is a description of the dataset: &amp;quot;&amp;quot;&amp;quot; + data_description + &amp;quot;&amp;quot;&amp;quot; Please answer the user&amp;#39;s request utilizing the tools below: {tools} The names of the tools are: {tool_names} Then, format the Final Answer as follows: {format_instructions} Do not transform the format above. It is your way of thinking through the problem. If there is no need to answer the question, or it is irrelevant to your job, please make your final answer something similar to: &amp;quot;Please ask a relevant query.&amp;quot; Begin! Question: {input} Thought: {agent_scratchpad}&amp;quot;&amp;quot;&amp;quot;, partial_variables={&amp;quot;format_instructions&amp;quot;:output_parser.get_format_instructions()}, ) # create zero shot agent (react agent) agent = create_react_agent( llm=_llm, tools=tools, prompt=prompt_template, ) # Initiate memory which allows for storing and extracting messages # memory = ConversationBufferMemory(memory_key=&amp;quot;chat_history&amp;quot;, input_key=&amp;quot;input&amp;quot;, output_key=&amp;#39;output&amp;#39;) ##### Agent Chain ##### # Create an AgentExecutor which enables verbose mode and handling parsing errors agent_chain = AgentExecutor.from_agent_and_tools( agent=agent, tools=tools, handle_parsing_errors=True, # memory=memory ) return agent_chain ##### Streamlit Code ##### # Set the webpage title st.set_page_config( page_title=&amp;quot;Dataset Q&amp;amp;A&amp;quot;, page_icon=&amp;quot;ðŸ“Š&amp;quot;, ) run = False with st.sidebar: # get params for functions model_name = st.selectbox(&amp;quot;Select model&amp;quot;, [&amp;quot;gemini&amp;quot;, &amp;quot;ollama&amp;quot;, &amp;quot;openai&amp;quot;, &amp;quot;codellama&amp;quot;]) st.session_state[&amp;quot;file&amp;quot;] = st.file_uploader(&amp;quot;Upload a csv file&amp;quot;, type=[&amp;quot;csv&amp;quot;]) st.session_state[&amp;quot;description&amp;quot;] = st.text_area(&amp;quot;Description&amp;quot;) st.markdown(&amp;quot;Dataset descirption should include a general description (e.g., the purpose of the data, what it is used for, etc.)&amp;quot;) # initialize model, db, agent on run if st.button(label=&amp;quot;Run&amp;quot;, help=&amp;quot;This will initialize the model, database, and agent. It will also reset the chat interface.&amp;quot;): st.session_state[&amp;quot;run&amp;quot;] = True # Create a header element st.header(&amp;quot;Dataset Q&amp;amp;A&amp;quot;) st.markdown(&amp;quot;**PLEASE RUN SIDEBAR FIRST BEFORE RUNNING CHAT INTERFACE**&amp;quot;) if &amp;quot;run&amp;quot; in st.session_state and st.session_state[&amp;quot;run&amp;quot;] == True: with st.spinner(&amp;quot;ðŸš€ Loading model...&amp;quot;): st.session_state[&amp;quot;llm&amp;quot;] = model_init(model_name) with st.spinner(&amp;quot;ðŸ¦¾ Loading agent...&amp;quot;): st.session_state[&amp;quot;agent_chain&amp;quot;] = agent_init(st.session_state[&amp;quot;llm&amp;quot;], st.session_state[&amp;quot;description&amp;quot;], st.session_state[&amp;quot;file&amp;quot;]) if &amp;quot;messages&amp;quot; in st.session_state: st.session_state.messages = [ {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;Welcome to the Data QA bot! Ask whatever questions you&amp;#39;d like!&amp;quot;} ] #### Create a chat interface #### # We store the conversation in the session state. # This will be used to render the chat conversation. # We initialize it with the first message we want to be greeted with. ## Session States ## if &amp;quot;messages&amp;quot; not in st.session_state: st.session_state.messages = [ {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;Welcome to the Data QA bot! Ask whatever questions you&amp;#39;d like!&amp;quot;} ] # We loop through each message in the session state and render it as # a chat message. for message in st.session_state.messages: with st.chat_message(message[&amp;quot;role&amp;quot;]): st.markdown(message[&amp;quot;content&amp;quot;]) ## Chat Code ## # We take questions/instructions from the chat input to pass to the LLM if user_input := st.chat_input(&amp;quot;Question&amp;quot;, key=&amp;quot;input&amp;quot;): st.chat_message(&amp;quot;user&amp;quot;).write(user_input) # Add our input to the session state st.session_state.messages.append( {&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: user_input} ) # Add the response to the chat window with st.chat_message(&amp;quot;assistant&amp;quot;): st_callback = StreamlitCallbackHandler(st.container()) # visualize thinking process # invoke chain with necessary input variables response = st.session_state[&amp;quot;agent_chain&amp;quot;].invoke({&amp;quot;input&amp;quot; : user_input}) # Add the response to messages session state st.session_state.messages.append( {&amp;quot;role&amp;quot;: &amp;quot;assistant&amp;quot;, &amp;quot;content&amp;quot;: response[&amp;quot;output&amp;quot;]}) st.write_stream(response[&amp;quot;output&amp;quot;]) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, here is the output (what is below, but repeated multiple times:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;```Invalid Format: Missing &amp;#39;Action:&amp;#39; after &amp;#39;Thought:```json { &amp;quot;Final Answer&amp;quot;: &amp;quot;The top selling item is &amp;#39;Computer&amp;#39;, with 22548 units sold.&amp;quot;, &amp;quot;plot&amp;quot;: &amp;quot;```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the CSV file into a DataFrame\ndf = pd.read_csv(&amp;#39;sales_data.csv&amp;#39;)\n\n# Group the data by item and sum the sales\ndf = df.groupby(&amp;#39;Item&amp;#39;).sum()\n\n# Sort the data by sales in descending order\ndf = df.sort_values(&amp;#39;Sales&amp;#39;, ascending=False)\n\n# Get the top selling item\ntop_selling_item = df.iloc[0][&amp;#39;Item&amp;#39;]\n\n# Print the top selling item\nprint(f&amp;#39;The top selling item is {top_selling_item}.&amp;#39;)\n\n# Plot the top selling item\ndf.plot.bar(x=&amp;#39;Item&amp;#39;, y=&amp;#39;Sales&amp;#39;)\nplt.title(&amp;#39;Top Selling Item&amp;#39;)\nplt.xlabel(&amp;#39;Item&amp;#39;)\nplt.ylabel(&amp;#39;Sales&amp;#39;)\nplt.show()\n```&amp;quot; } ```Invalid Format: Missing &amp;#39;Action:&amp;#39; after &amp;#39;Thought:```json { &amp;quot;Final Answer&amp;quot;: &amp;quot;The top selling item is &amp;#39;Computer&amp;#39;, with 22548 units sold.&amp;quot;, &amp;quot;plot&amp;quot;: &amp;quot;```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the CSV file into a DataFrame\ndf = pd.read_csv(&amp;#39;sales_data.csv&amp;#39;)\n\n# Group the data by item and sum the sales\ndf = df.groupby(&amp;#39;Item&amp;#39;).sum()\n\n# Sort the data by sales in descending order\ndf = df.sort_values(&amp;#39;Sales&amp;#39;, ascending=False)\n\n# Get the top selling item\ntop_selling_item = df.iloc[0][&amp;#39;Item&amp;#39;]\n\n# Print the top selling item\nprint(f&amp;#39;The top selling item is {top_selling_item}.&amp;#39;)\n\n# Plot the top selling item\ndf.plot.bar(x=&amp;#39;Item&amp;#39;, y=&amp;#39;Sales&amp;#39;)\nplt.title(&amp;#39;Top Selling Item&amp;#39;)\nplt.xlabel(&amp;#39;Item&amp;#39;)\nplt.ylabel(&amp;#39;Sales&amp;#39;)\nplt.show()\n```&amp;quot; } ```Invalid Format: Missing &amp;#39;Action:&amp;#39; after &amp;#39;Thought:```json { &amp;quot;Final Answer&amp;quot;: &amp;quot;The top selling item is &amp;#39;Computer&amp;#39;, with 22548 units sold.&amp;quot;, &amp;quot;plot&amp;quot;: &amp;quot;```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the CSV file into a DataFrame\ndf = pd.read_csv(&amp;#39;sales_data.csv&amp;#39;)\n\n# Group the data by item and sum the sales\ndf = df.groupby(&amp;#39;Item&amp;#39;).sum()\n\n# Sort the data by sales in descending order\ndf = df.sort_values(&amp;#39;Sales&amp;#39;, ascending=False)\n\n# Get the top selling item\ntop_selling_item = df.iloc[0][&amp;#39;Item&amp;#39;]\n\n# Print the top selling item\nprint(f&amp;#39;The top selling item is {top_selling_item}.&amp;#39;)\n\n# Plot the top selling item\ndf.plot.bar(x=&amp;#39;Item&amp;#39;, y=&amp;#39;Sales&amp;#39;)\nplt.title(&amp;#39;Top Selling Item&amp;#39;)\nplt.xlabel(&amp;#39;Item&amp;#39;)\nplt.ylabel(&amp;#39;Sales&amp;#39;)\nplt.show()\n```&amp;quot; } ```Invalid Format: Missing &amp;#39;Action:&amp;#39; after &amp;#39;Thought: &amp;gt; Finished chain. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Any help/feedback is much appreciated! I really wanna get good at Lang Chain but have spent a lot of time troubleshooting errors. Hopefully this is the last! (doubt it)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/drunkmute&quot;&gt; /u/drunkmute &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az69hi/response_schema_pythoncsv_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az69hi/response_schema_pythoncsv_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1az69hi</id><link href="https://www.reddit.com/r/LangChain/comments/1az69hi/response_schema_pythoncsv_agent/" /><updated>2024-02-24T21:42:05+00:00</updated><published>2024-02-24T21:42:05+00:00</published><title>Response Schema Python/CSV Agent</title></entry><entry><author><name>/u/Malcherion</name><uri>https://www.reddit.com/user/Malcherion</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I am in the process of doing my master&amp;#39;s thesis and will focus on multi-agent systems for software testing. I have decided to use LangGraph as my framework of choice and I am in the process of learning it.&lt;/p&gt; &lt;p&gt;I have been toying around with LangChain and it&amp;#39;s been working great. However, one of the things that I cannot seem to figure out, is how to have the model only give me the output, without the input being a part of it.&lt;/p&gt; &lt;p&gt;Code example below:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;llm_hf = HuggingFaceHub(repo_id=&amp;quot;mistralai/Mistral-7B-Instruct-v0.2&amp;quot;, model_kwargs={&amp;quot;temperature&amp;quot;: 0.9}) duck_specialist_template = &amp;quot;&amp;quot;&amp;quot; I want you to act as a specialist in ducks, covering aspects from their biology to conservation. Your role involves providing expert insights into different duck species, including their habitats, behaviors, and the challenges they face in their natural environments. Additionally, you&amp;#39;re tasked with advising on conservation strategies to protect these species and their habitats from threats such as habitat loss, pollution, and climate change. For any inquiry about ducks, offer a comprehensive overview that includes species identification, habitat preferences, dietary habits, migratory patterns, and conservation status. Moreover, suggest practical conservation measures that can be implemented to support the health and sustainability of duck populations. Can you provide funny name suggestions on a duck that looks like {duck_description}? &amp;quot;&amp;quot;&amp;quot; tiny = &amp;quot;a small, energetic duck with bright blue feathers and a penchant for doing somersaults in the water. Its quack is surprisingly deep for its size&amp;quot; prompt_template = PromptTemplate( input_variables=[&amp;quot;duck_description&amp;quot;], template=duck_specialist_template, ) chain = LLMChain(llm=llm_hf, prompt=prompt_template) print(chain.run(duck_description=tiny)) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now, when I run this it gives me the following output:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;I want you to act as a specialist in ducks, covering aspects from their biology to conservation.&lt;br/&gt; Your role involves providing expert insights into different duck species, including their habitats, behaviors, and the challenges they face in their natural environments. Additionally, you&amp;#39;re tasked with advising on conservation strategies to protect these species and their habitats from threats such as habitat loss, pollution, and climate change.&lt;br/&gt; For any inquiry about ducks, offer a comprehensive overview that includes species identification, habitat preferences, dietary habits, migratory patterns, and conservation status. Moreover, suggest practical conservation measures that can be implemented to support the health and sustainability of duck populations.&lt;br/&gt; Can you provide funny name suggestions on a duck that looks like a small, energetic duck with bright blue feathers and a penchant for doing somersaults in the water. Its quack is surprisingly deep for its size?&lt;br/&gt; Absolutely! Based on the description you&amp;#39;ve given, I would suggest the name &amp;quot;Flippy the Feisty Blue Bunter.&amp;quot; This name captures the duck&amp;#39;s small size, energetic nature, bright blue feathers, and acrobatic behavior in the water (somersaults), while the &amp;quot;feisty&amp;quot; part adds a fun and lively character to its name. The term &amp;quot;bunter&amp;quot; is a playful way to refer to the duck&amp;#39;s&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Here the prompt is part of the output, which in turn cuts off the models response. I have been trying to find out a way to fix this, but prompting does not seem to work and I could not find anything that works. I am just concerned that if I start chaining, then it will reach the output limit before it can respond to future prompts, making the chain obsolete and the task complete unsolvable.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Malcherion&quot;&gt; /u/Malcherion &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayszzh/how_to_remove_the_prompt_and_prompt_template_from/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayszzh/how_to_remove_the_prompt_and_prompt_template_from/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ayszzh</id><link href="https://www.reddit.com/r/LangChain/comments/1ayszzh/how_to_remove_the_prompt_and_prompt_template_from/" /><updated>2024-02-24T12:05:45+00:00</updated><published>2024-02-24T12:05:45+00:00</published><title>How to remove the prompt and prompt template from the response when invoking a chain?</title></entry><entry><author><name>/u/zkid18</name><uri>https://www.reddit.com/user/zkid18</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks,&lt;br/&gt; Playing around with the pet project that asks for subjects discussed in a video and asks for the time code.&lt;br/&gt; I found that the in-house loader is limited for the task at hand. It does not provide the necessary start code unlike the &amp;#39;youtube-transcript-api&amp;#39; library. &lt;/p&gt; &lt;p&gt;Has anyone worked on something similar? What would be the best way to do that?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zkid18&quot;&gt; /u/zkid18 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az2t9r/youtube_loader_with_timecodes/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az2t9r/youtube_loader_with_timecodes/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1az2t9r</id><link href="https://www.reddit.com/r/LangChain/comments/1az2t9r/youtube_loader_with_timecodes/" /><updated>2024-02-24T19:19:21+00:00</updated><published>2024-02-24T19:19:21+00:00</published><title>Youtube loader with timecodes</title></entry><entry><author><name>/u/Sweaty-Minimum5423</name><uri>https://www.reddit.com/user/Sweaty-Minimum5423</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone tried using the following method?&lt;/p&gt; &lt;p&gt;I have a use case where I need to pull out a product recommendation. I use open AI assistant to help me do the job. But I do not use the built-in retrieval from the openAI. Instead I build a retrieval tool which is essentially a retrieval chain (load and chunk the data myself, using vector store and use retriever) But the problem is I find that OpenAI assistant sometimes answer customer questions without using the tool.&lt;/p&gt; &lt;p&gt;Like for example, it will use its own knowledge to answer customer inquiries instead of looking up the database. Is there a way I can improve it? Something like assigning another agent to the flow downstream to check if the first response is generated by the default brain of assistant API or based on the retrieval tool? Iâ€™m just brainstorming..&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sweaty-Minimum5423&quot;&gt; /u/Sweaty-Minimum5423 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az27pt/rag_with_openai_assistant_api/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az27pt/rag_with_openai_assistant_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1az27pt</id><link href="https://www.reddit.com/r/LangChain/comments/1az27pt/rag_with_openai_assistant_api/" /><updated>2024-02-24T18:55:13+00:00</updated><published>2024-02-24T18:55:13+00:00</published><title>RAG with OpenAI assistant API</title></entry><entry><author><name>/u/nonsonoio0</name><uri>https://www.reddit.com/user/nonsonoio0</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, Is there any FlowiseAI alternative in python? Or Is there any way to export the flows created in FlowiseAI to python code?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nonsonoio0&quot;&gt; /u/nonsonoio0 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az0uae/flowiseai_python_alternative/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1az0uae/flowiseai_python_alternative/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1az0uae</id><link href="https://www.reddit.com/r/LangChain/comments/1az0uae/flowiseai_python_alternative/" /><updated>2024-02-24T17:59:28+00:00</updated><published>2024-02-24T17:59:28+00:00</published><title>FlowiseAI python alternative</title></entry><entry><author><name>/u/New-Sugar-2438</name><uri>https://www.reddit.com/user/New-Sugar-2438</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been trying to use Langhain, especially the new custom composed LCEL chains in combination with the legacy constitutional chains that allow me to do guardrails. &lt;/p&gt; &lt;p&gt;But because constitutional chains are not in the new format of LCEL, I couldn&amp;#39;t figure out a way to make it work. Legacy constitutional chain accepts only another legacy chain as an input. So I can&amp;#39;t put them together. &lt;/p&gt; &lt;p&gt;Help will be appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/New-Sugar-2438&quot;&gt; /u/New-Sugar-2438 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayv0uz/lcel_along_with_legacy_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayv0uz/lcel_along_with_legacy_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ayv0uz</id><link href="https://www.reddit.com/r/LangChain/comments/1ayv0uz/lcel_along_with_legacy_chain/" /><updated>2024-02-24T13:52:30+00:00</updated><published>2024-02-24T13:52:30+00:00</published><title>LCEL along with legacy chain</title></entry><entry><author><name>/u/gswithai</name><uri>https://www.reddit.com/user/gswithai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks! Currently working on a Micro SaaS and ended up needing to convert a PDF to JSON. Given that I&amp;#39;ve been playing around with LangChain for a while now and writing about it, I ended up using the Output Parsers to achieve this.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.gettingstarted.ai/how-to-extract-metadata-from-pdf-convert-to-json-langchain/&quot;&gt;I wrote about this on my blog&lt;/a&gt; and it works like magic... âœ¨ In fact, it&amp;#39;s not just PDF you could convert. Any type of unstructured data potentially works.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s what I covered in the post:&lt;/p&gt; &lt;p&gt;âœ… Key concepts and explanations&lt;/p&gt; &lt;p&gt;âœ… LangChain Output Parsers&lt;/p&gt; &lt;p&gt;âœ… OpenAI Functions&lt;/p&gt; &lt;p&gt;âœ… Working source code&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.gettingstarted.ai/how-to-extract-metadata-from-pdf-convert-to-json-langchain/&quot;&gt;https://www.gettingstarted.ai/how-to-extract-metadata-from-pdf-convert-to-json-langchain/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Would love to know your thoughts and if you find this helpful.&lt;/p&gt; &lt;p&gt;Cheers!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gswithai&quot;&gt; /u/gswithai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ay6vx4/extracting_metadata_from_a_pdf_and_converting_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ay6vx4/extracting_metadata_from_a_pdf_and_converting_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ay6vx4</id><link href="https://www.reddit.com/r/LangChain/comments/1ay6vx4/extracting_metadata_from_a_pdf_and_converting_to/" /><updated>2024-02-23T17:51:11+00:00</updated><published>2024-02-23T17:51:11+00:00</published><title>Extracting metadata from a PDF and converting to JSON using LangChain and GPT</title></entry><entry><author><name>/u/ashishtele</name><uri>https://www.reddit.com/user/ashishtele</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am looking for some good resources for RAG evaluation.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashishtele&quot;&gt; /u/ashishtele &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayfdhs/rag_evaluation_framework/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayfdhs/rag_evaluation_framework/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ayfdhs</id><link href="https://www.reddit.com/r/LangChain/comments/1ayfdhs/rag_evaluation_framework/" /><updated>2024-02-23T23:34:50+00:00</updated><published>2024-02-23T23:34:50+00:00</published><title>RAG evaluation framework</title></entry><entry><author><name>/u/hackmoretalkless</name><uri>https://www.reddit.com/user/hackmoretalkless</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So I was planning to build a chatbot with langchain. But I can&amp;#39;t use open Ai or any gpt api keys coz of privacy. Is there any other work around for this ? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hackmoretalkless&quot;&gt; /u/hackmoretalkless &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayipqy/without_open_ai_or_gemini_api_key/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayipqy/without_open_ai_or_gemini_api_key/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ayipqy</id><link href="https://www.reddit.com/r/LangChain/comments/1ayipqy/without_open_ai_or_gemini_api_key/" /><updated>2024-02-24T02:04:50+00:00</updated><published>2024-02-24T02:04:50+00:00</published><title>Without open AI or Gemini api key</title></entry><entry><author><name>/u/Inevitable-Judge2642</name><uri>https://www.reddit.com/user/Inevitable-Judge2642</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayo64e/lets_talk_with_a_genai_french_cook/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/_BzgMxPbCTIYC7l5UYqnYDtpcbt9vTtQtmOCdizKjLM.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6e9e43638e6084b076c68b0882abe5c8cf894ee1&quot; alt=&quot;Let's talk with a GenAI French cook&quot; title=&quot;Let's talk with a GenAI French cook&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Inevitable-Judge2642&quot;&gt; /u/Inevitable-Judge2642 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://k33g.hashnode.dev/lets-talk-with-a-genai-french-cook&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayo64e/lets_talk_with_a_genai_french_cook/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ayo64e</id><media:thumbnail url="https://external-preview.redd.it/_BzgMxPbCTIYC7l5UYqnYDtpcbt9vTtQtmOCdizKjLM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6e9e43638e6084b076c68b0882abe5c8cf894ee1" /><link href="https://www.reddit.com/r/LangChain/comments/1ayo64e/lets_talk_with_a_genai_french_cook/" /><updated>2024-02-24T06:53:17+00:00</updated><published>2024-02-24T06:53:17+00:00</published><title>Let's talk with a GenAI French cook</title></entry><entry><author><name>/u/Admirable_penguin</name><uri>https://www.reddit.com/user/Admirable_penguin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So Iâ€™m trying to get a specific chunk of data and it does retrieve it perfectly but it seems to apply the lower matched chunks as well. Is there a way to just use the very top ranked chunked document? It seems to be out of order if contextually if we apply all the chunks in a response &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Admirable_penguin&quot;&gt; /u/Admirable_penguin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayl2mb/cohere_rerank_contextual_compression_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayl2mb/cohere_rerank_contextual_compression_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ayl2mb</id><link href="https://www.reddit.com/r/LangChain/comments/1ayl2mb/cohere_rerank_contextual_compression_and/" /><updated>2024-02-24T04:02:02+00:00</updated><published>2024-02-24T04:02:02+00:00</published><title>Cohere rerank, contextual compression and ContextReorder, can I just use the top document?</title></entry><entry><author><name>/u/baragua</name><uri>https://www.reddit.com/user/baragua</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, hoping to get some insights about where to focus my studies over the next couple of months.&lt;/p&gt; &lt;p&gt;Part of my work is copywriting, and I think it would be behoove me to leverage generative AI tools in order to keep myself relevant as this tech becomes more commonplace in my domain. I&amp;#39;ve been skilling up on Python over the last several months as a hobby and also to boost the other aspect of my work, which is consulting. Apart from programming fundamentals, I&amp;#39;ve been focusing on ML/NLP. The specific use case for my consulting work is sentiment analysis, so the focus lately has been on learning to use Hugging Face and diving into data acquisition.&lt;/p&gt; &lt;p&gt;I have a LangChain tutorial earmarked to tackle next, as it seems like a good tool to generate synthetic datasets for training/fine-tuning models for sentiment analysis specific to my domain. I have the impression that it could also be quite useful for my copywriting work, but I&amp;#39;m less clear exactly how. Is that the case? Are there any other tools that would be useful for someone in my position? Any guidance along these lines would be hugely appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/baragua&quot;&gt; /u/baragua &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aykmn5/good_tool_for_copywriting/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aykmn5/good_tool_for_copywriting/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aykmn5</id><link href="https://www.reddit.com/r/LangChain/comments/1aykmn5/good_tool_for_copywriting/" /><updated>2024-02-24T03:39:15+00:00</updated><published>2024-02-24T03:39:15+00:00</published><title>Good tool for copywriting?</title></entry><entry><author><name>/u/Andy-VertaAI</name><uri>https://www.reddit.com/user/Andy-VertaAI</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello folks - I feel guilty for posting here but I really can&amp;#39;t find a better place. Thank you to anyone who can help me or point me in the right direction.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;: I&amp;#39;m so desperate for user interviews I&amp;#39;m willing to debase myself for 30 minutes of your time.&lt;br/&gt; I am trying to find people to talk to who have shipped or are close to shipping a feature that integrates with a 3rd party LLM. I have questions about LLM evaluation because we&amp;#39;re building product around that, somewhat tangential to langsmith. I need to expand way beyond my personal network. &lt;/p&gt; &lt;p&gt;I have tried searching forums, posting in slack groups, attending in person events in SF, swiping right on every ML engineer, user interview recruiting sites but I&amp;#39;m coming up with a lot of people who are still dabbling with the tech but haven&amp;#39;t hit real development yet. Most of the folks I&amp;#39;ve talked to just haven&amp;#39;t gotten to any real &amp;quot;LLM evaluation&amp;quot; needs yet. &lt;/p&gt; &lt;p&gt;Langchain&amp;#39;s series A announcement said they have 80k users, so surely there are some people here that fit my mold?&lt;/p&gt; &lt;p&gt;I am &lt;strong&gt;desperate&lt;/strong&gt; to pick your brain for 30 minutes about your &amp;quot;genai stack&amp;quot; and how you figure out if a LLM-integrated solution is behaving well on your data for your users. &lt;/p&gt; &lt;p&gt;I would gladly send you a thank you milk bar pie, buy you a bougie coffee shop gift card, take you on a date (34/F/SF) or yell at your boss for you or for a few moments of your time. &lt;/p&gt; &lt;p&gt;Please DM me if we can chat sometime in the next week or two. Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Andy-VertaAI&quot;&gt; /u/Andy-VertaAI &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayaf7p/langsmith_for_evaluation_or_something_else/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ayaf7p/langsmith_for_evaluation_or_something_else/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ayaf7p</id><link href="https://www.reddit.com/r/LangChain/comments/1ayaf7p/langsmith_for_evaluation_or_something_else/" /><updated>2024-02-23T20:13:08+00:00</updated><published>2024-02-23T20:13:08+00:00</published><title>LangSmith for evaluation or something else?</title></entry><entry><author><name>/u/UpvoteBeast</name><uri>https://www.reddit.com/user/UpvoteBeast</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1axyhz7/serverless_qa_ai_bot_with_langchain/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/wik-KoJXfKAvimeyS_d75KUu2w-F8t2OmjnmtmV-WKQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d9cab695fa2150263a97a54175bda9419321f6de&quot; alt=&quot;Serverless Q&amp;amp;A AI Bot with Langchain&quot; title=&quot;Serverless Q&amp;amp;A AI Bot with Langchain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpvoteBeast&quot;&gt; /u/UpvoteBeast &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://app.daily.dev/posts/eKFo0hJk4&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1axyhz7/serverless_qa_ai_bot_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1axyhz7</id><media:thumbnail url="https://external-preview.redd.it/wik-KoJXfKAvimeyS_d75KUu2w-F8t2OmjnmtmV-WKQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d9cab695fa2150263a97a54175bda9419321f6de" /><link href="https://www.reddit.com/r/LangChain/comments/1axyhz7/serverless_qa_ai_bot_with_langchain/" /><updated>2024-02-23T11:44:18+00:00</updated><published>2024-02-23T11:44:18+00:00</published><title>Serverless Q&amp;A AI Bot with Langchain</title></entry><entry><author><name>/u/DonutMysterious</name><uri>https://www.reddit.com/user/DonutMysterious</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, I have to admit that I struggle to keep up with the LLM Ecosystem around LangChain and wanted to ask if you have any recommended packages that people like me might not know about. I would be especially interested in packages you use to build advanced RAG applications and packages you use in Production for task xyz.&lt;/p&gt; &lt;p&gt;I start with a few:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Langfuse&lt;/strong&gt;: LangSmith alternative to monitor LLM Applications in production. MIT License - great!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Semantic-Text-Splitter&lt;/strong&gt;: Allows you to split documents by contextual parts of them, rather by a fixed document size.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Ragas&lt;/strong&gt;: Framework for evaluating RAG Pipelines. Not dived into it yet, but looks promising.&lt;/p&gt; &lt;p&gt;Please add your favorite packages. Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DonutMysterious&quot;&gt; /u/DonutMysterious &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ay1c6a/ecosystem_around_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ay1c6a/ecosystem_around_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ay1c6a</id><link href="https://www.reddit.com/r/LangChain/comments/1ay1c6a/ecosystem_around_langchain/" /><updated>2024-02-23T14:09:32+00:00</updated><published>2024-02-23T14:09:32+00:00</published><title>Ecosystem around LangChain</title></entry></feed>