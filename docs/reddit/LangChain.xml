<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-06-11T04:53:08+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/rtrex12</name><uri>https://www.reddit.com/user/rtrex12</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;For context my vector db research started today from 0 knowledge and I feel absolutely unqualified to be making this decision but here we are.&lt;/p&gt; &lt;p&gt;I have narrowed the search down to Milvus, Qdrant and potentially Weaviate.&lt;/p&gt; &lt;p&gt;I am scoping out a project for a client where we need to store up to 100 million pages. The application is scientific so retrieval precision is a top priority as is search time latency and cost.&lt;/p&gt; &lt;p&gt;It seems:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Milvus seems the most established and easiest to setup. also itis fast but takes up a lot of memory so can get quite expensive.&lt;/li&gt; &lt;li&gt;Qdrant is fast and quite a bit cheaper than Milvus but lacks dynamic sharding &lt;/li&gt; &lt;li&gt;I have seen two conflicting reports one saying Weaviate is incredibly quick with a benchmark of 0.12s for a particular query which took Milvus 0.9s to perform the same and then another where it says it is slow. and it is the cheapest.&lt;/li&gt; &lt;li&gt;PG-vector is not as performant as the dedicated vector stores but are tried and tested part of the ecosystem and anecdotally great to work with &lt;/li&gt; &lt;li&gt;Chroma is not the best for accurate retrieval and I haven&amp;#39;t heard many recommending it as the best except for its usability and ease of integration. &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rtrex12&quot;&gt; /u/rtrex12 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcyc6i/what_vector_db_should_i_choose_for_100m_pages_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcyc6i/what_vector_db_should_i_choose_for_100m_pages_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcyc6i</id><link href="https://www.reddit.com/r/LangChain/comments/1dcyc6i/what_vector_db_should_i_choose_for_100m_pages_of/" /><updated>2024-06-10T22:18:54+00:00</updated><published>2024-06-10T22:18:54+00:00</published><title>What vector db should I choose for 100m pages of text?</title></entry><entry><author><name>/u/conjuncti</name><uri>https://www.reddit.com/user/conjuncti</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;People of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt;, &lt;/p&gt; &lt;p&gt;Like many of you (&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1am3fz8/how_to_recover_document_structure_and_plain_text/&quot;&gt;1&lt;/a&gt;) (&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cn0z11/extract_tables_from_pdf_for_rag/&quot;&gt;2&lt;/a&gt;) (&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/17c7g9b/anyone_worked_on_reading_pdf_with_tables/&quot;&gt;3&lt;/a&gt;), I have been searching for a reasonable way to extract precious tables from pdfs for RAG for quite some time. Despite this seemingly simple problem, I&amp;#39;ve been surprised at just how unsolved this problem is. Despite a ton of options (see below), surprisingly few of them &amp;quot;just work&amp;quot;. Some users have even suggested paid APIs like Mathpix and Adobe Extract.&lt;/p&gt; &lt;p&gt;In an effort to consolidate all the options out there, I&amp;#39;ve made a guide for many existing pdf table extraction options, with links to quickstarts, Colab Notebooks, and github repos. I&amp;#39;ve written &lt;a href=&quot;https://drive.google.com/drive/u/0/folders/114bWRj5H4aE-BA5UKH9S5ol8LC6vhqfR&quot;&gt;colab notebooks&lt;/a&gt; that let you extract tables using methods like pdfplumber, pymupdf, nougat, open-parse, deepdoctection, surya, and unstructured. To be as objective as possible, I&amp;#39;ve also compared the options with the same 3 papers: &lt;a href=&quot;https://arxiv.org/abs/2110.00061&quot;&gt;PubTables-1M (tatr)&lt;/a&gt;, the classic &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;Attention&lt;/a&gt; paper, and a &lt;a href=&quot;http://ccc.chem.pitt.edu/wipf/Web/NMR_Impurities.pdf&quot;&gt;very challenging nmr table&lt;/a&gt;.&lt;/p&gt; &lt;h1&gt;gmft release&lt;/h1&gt; &lt;p&gt;On top of this, I&amp;#39;m thrilled to announce &lt;a href=&quot;https://github.com/conjuncts/gmft&quot;&gt;gmft&lt;/a&gt; (&lt;strong&gt;g&lt;/strong&gt;ive &lt;strong&gt;m&lt;/strong&gt;e the &lt;strong&gt;f&lt;/strong&gt;ormatted &lt;strong&gt;t&lt;/strong&gt;ables), a deep table recognition relying on Microsoft&amp;#39;s TATR. Partially written out of exasperation, it is about an &lt;em&gt;order of magnitude faster&lt;/em&gt; than most deep competitors like nougat, open-parse, unstructured and deepdoctection. It runs on &lt;strong&gt;cpu&lt;/strong&gt; (!) at around 1.381 s/page; it additionally takes ~0.945s for each table converted to df. The reason why it&amp;#39;s so fast is that gmft does not rerun OCR. In many cases, the existing OCR is already good or even better than tesseract or other OCR software, so there is no need for expensive OCR. But gmft still allows for OCR downstream by outputting an image of the cropped table.&lt;/p&gt; &lt;p&gt;I also think gmft&amp;#39;s quality is unparalleled, especially in terms of value alignment to row/column header! It&amp;#39;s easiest to see the results (&lt;a href=&quot;https://colab.research.google.com/drive/1fEqsTdKcO5RNPV_b2v9cB4Y5We9Kv-hR&quot;&gt;colab&lt;/a&gt;) (&lt;a href=&quot;https://github.com/conjuncts/gmft/blob/main/notebooks/bulk_extract.ipynb&quot;&gt;github&lt;/a&gt;) for yourself. I invite the reader to explore all the notebooks to survey your own use cases and compare see each option&amp;#39;s strengths and weaknesses.&lt;/p&gt; &lt;p&gt;Some weaknesses of gmft include no rotated table support (yet), false positives when rotated, and a current lack of support for multi-indexes (multiple row headers). However, gmft&amp;#39;s major strength is alignment. Because of the underlying algorithm, values are usually correctly aligned to their row or column header, even when there are other issues with TATR. This is in contrast with other options like unstructured, open-parse, which may fail first on alignment. Anecdotally, I&amp;#39;ve personally extracted ~4000 pdfs with gmft on cpu, and (barring occassional header issues) the quality is excellent. Again, take a look at &lt;a href=&quot;https://colab.research.google.com/drive/1fEqsTdKcO5RNPV_b2&quot;&gt;this notebook&lt;/a&gt; for the table quality.&lt;/p&gt; &lt;h1&gt;Comparison&lt;/h1&gt; &lt;p&gt;All the quickstarts that I have made/modified are in &lt;a href=&quot;https://drive.google.com/drive/u/0/folders/114bWRj5H4aE-BA5UKH9S5ol8LC6vhqfR&quot;&gt;this google drive folder&lt;/a&gt;; the installations should all work with google colab.&lt;/p&gt; &lt;p&gt;The most up-to-date table of all comparisons is &lt;a href=&quot;https://docs.google.com/spreadsheets/d/12IhxHZbYF71dPl32PQpF_6pg9e9S8f9W4sTHt-B0KTg/edit#gid=0&quot;&gt;here&lt;/a&gt;; my calculations for throughput is &lt;a href=&quot;https://docs.google.com/spreadsheets/d/12IhxHZbYF71dPl32PQpF_6pg9e9S8f9W4sTHt-B0KTg/edit#gid=39227585&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I have undoubtedly missed some options. In particular, I have not had the chance to evaluate paddleocr. As a stopgap, see &lt;a href=&quot;https://medium.com/@malshanCS/automating-table-data-extraction-tools-and-techniques-for-efficiency-a29df313cbda#629d&quot;&gt;this&lt;/a&gt; writeup. If you&amp;#39;d like an option added to the table, please let me know!&lt;/p&gt; &lt;h2&gt;Table&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;https://docs.google.com/spreadsheets/d/12IhxHZbYF71dPl32PQpF_6pg9e9S8f9W4sTHt-B0KTg/edit#gid=0&quot;&gt;See google sheets!&lt;/a&gt; Table is too big for reddit to format.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/conjuncti&quot;&gt; /u/conjuncti &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dclawv/pdf_table_extraction_the_definitive_guide_gmft/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dclawv/pdf_table_extraction_the_definitive_guide_gmft/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dclawv</id><link href="https://www.reddit.com/r/LangChain/comments/1dclawv/pdf_table_extraction_the_definitive_guide_gmft/" /><updated>2024-06-10T13:18:10+00:00</updated><published>2024-06-10T13:18:10+00:00</published><title>PDF Table Extraction, the Definitive Guide (+ gmft release!)</title></entry><entry><author><name>/u/Aggravating-Lack6666</name><uri>https://www.reddit.com/user/Aggravating-Lack6666</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;I have 2 cases of ambiguity&lt;/strong&gt; &lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Similar names within a table - Eg: constrained_demand, unconstrained_demand&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Same names across different tables. - Sales in both table1 and table 2&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I have built a chatbot using open-ai tools agents , giving it access to SQLDatabaseToolKit. There is prefix, suffix and FewShotPrompt Template to handle multiple different calculations and complexities of SQL queries. Now user can ask multiple queries of the below format .&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;What is the demand for 2024? - there is ambiguity as to if the user is asking constrained demand or unconstrained demand. Assumption that is no &amp;quot;demand&amp;quot; column . Expectation - LLM should figure out such ambiguity without any hardcoding and then ask back the user as to which column he is referring to. Once LLM gets user input, then query with the new info.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;What is the sales for brand1? there is ambiguity as to if the user is asking sales from table1 or table2. Expectation - LLM should figure out such ambiguity without any hardcoding and then ask back the user as to which table he is referring to. Once LLM gets user input, then query with the new info.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Cannot handle this in column description as even if the descriptions are different, we cannot make sense from the question. Need help in how to approach this. TIA!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Aggravating-Lack6666&quot;&gt; /u/Aggravating-Lack6666 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcvnzv/how_to_handle_ambiguous_column_names_when/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcvnzv/how_to_handle_ambiguous_column_names_when/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcvnzv</id><link href="https://www.reddit.com/r/LangChain/comments/1dcvnzv/how_to_handle_ambiguous_column_names_when/" /><updated>2024-06-10T20:27:18+00:00</updated><published>2024-06-10T20:27:18+00:00</published><title>How to handle ambiguous column names when converting Text-to-SQL in SQL Agent?</title></entry><entry><author><name>/u/EidolonAI</name><uri>https://www.reddit.com/user/EidolonAI</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcsu90/how_to_test_genai_applications/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/xvareROY2VMrdr0sCgsYHlMFYQmA9BA6Qu4yI44Xpgo.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=694e656794358d9bbed1855c12904b39dd41c41b&quot; alt=&quot;How to Test GenAI Applications&quot; title=&quot;How to Test GenAI Applications&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EidolonAI&quot;&gt; /u/EidolonAI &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.eidolonai.com/testing_llm_apps&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcsu90/how_to_test_genai_applications/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dcsu90</id><media:thumbnail url="https://external-preview.redd.it/xvareROY2VMrdr0sCgsYHlMFYQmA9BA6Qu4yI44Xpgo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=694e656794358d9bbed1855c12904b39dd41c41b" /><link href="https://www.reddit.com/r/LangChain/comments/1dcsu90/how_to_test_genai_applications/" /><updated>2024-06-10T18:35:15+00:00</updated><published>2024-06-10T18:35:15+00:00</published><title>How to Test GenAI Applications</title></entry><entry><author><name>/u/tisi3000</name><uri>https://www.reddit.com/user/tisi3000</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcwtxk/build_ai_automation_with_managed_triggers_human/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/xmfqjmle8t5d1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=40e33e68dd5565b3d24efe6ef00069c46a609370&quot; alt=&quot;Build AI automation with managed triggers, human approvals and retries&quot; title=&quot;Build AI automation with managed triggers, human approvals and retries&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/tisi3000&quot;&gt; /u/tisi3000 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/xmfqjmle8t5d1.png&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcwtxk/build_ai_automation_with_managed_triggers_human/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dcwtxk</id><media:thumbnail url="https://preview.redd.it/xmfqjmle8t5d1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=40e33e68dd5565b3d24efe6ef00069c46a609370" /><link href="https://www.reddit.com/r/LangChain/comments/1dcwtxk/build_ai_automation_with_managed_triggers_human/" /><updated>2024-06-10T21:14:57+00:00</updated><published>2024-06-10T21:14:57+00:00</published><title>Build AI automation with managed triggers, human approvals and retries</title></entry><entry><author><name>/u/FewGate7173</name><uri>https://www.reddit.com/user/FewGate7173</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dci0ny/i_built_a_free_notionlike_notebook_connected_your/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/M2ZuNWJqcGF5cDVkMSt7OnYpLebwJQAgLa8HfCmZbYL75AkiXKseS_hNaqFH.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=84f4e719c7e4b06a52770cd239cef12f918201e4&quot; alt=&quot;I built a free Notion-like notebook connected your personal knowledge&quot; title=&quot;I built a free Notion-like notebook connected your personal knowledge&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FewGate7173&quot;&gt; /u/FewGate7173 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/uam6gipayp5d1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dci0ny/i_built_a_free_notionlike_notebook_connected_your/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dci0ny</id><media:thumbnail url="https://external-preview.redd.it/M2ZuNWJqcGF5cDVkMSt7OnYpLebwJQAgLa8HfCmZbYL75AkiXKseS_hNaqFH.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=84f4e719c7e4b06a52770cd239cef12f918201e4" /><link href="https://www.reddit.com/r/LangChain/comments/1dci0ny/i_built_a_free_notionlike_notebook_connected_your/" /><updated>2024-06-10T10:10:22+00:00</updated><published>2024-06-10T10:10:22+00:00</published><title>I built a free Notion-like notebook connected your personal knowledge</title></entry><entry><author><name>/u/pavanpkulkarni</name><uri>https://www.reddit.com/user/pavanpkulkarni</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to build a RAG using Ollama, Pyspark. I wish to use my delta table as the source for this POC. Here&amp;#39;s what I have done so far&lt;/p&gt; &lt;p&gt;```python&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import pyspark from delta import * from langchain_community.document_loaders import PySparkDataFrameLoader from langchain_community.llms import Ollama from langchain_community.vectorstores import FAISS from langchain_community.embeddings import OllamaEmbeddings from langchain.text_splitter import RecursiveCharacterTextSplitter from langchain.chains import RetrievalQA from langchain.text_splitter import CharacterTextSplitter ollama_llm = Ollama(model=&amp;quot;phi&amp;quot;) ollama_emb = OllamaEmbeddings(model=&amp;quot;mxbai-embed-large&amp;quot;) # Read and Create df builder = pyspark.sql.SparkSession.builder.appName(&amp;quot;DeltaTutorial&amp;quot;) \ .config(&amp;quot;spark.sql.extensions&amp;quot;, &amp;quot;io.delta.sql.DeltaSparkSessionExtension&amp;quot;) \ .config(&amp;quot;spark.sql.catalog.spark_catalog&amp;quot;, &amp;quot;org.apache.spark.sql.delta.catalog.DeltaCatalog&amp;quot;) spark = configure_spark_with_delta_pip(builder).getOrCreate() df = spark.createDataFrame( [ (1, &amp;quot;foo&amp;quot;, &amp;quot;hello&amp;quot;), (2, &amp;quot;bar&amp;quot;, &amp;quot;world&amp;quot;), (3, &amp;quot;baz&amp;quot;, &amp;quot;!!!&amp;quot;), (4, &amp;quot;000&amp;quot;, &amp;quot;why&amp;quot;), (5, &amp;quot;111&amp;quot;, &amp;quot;who&amp;quot;), ], [&amp;quot;id&amp;quot;, &amp;quot;label&amp;quot;, &amp;quot;col3&amp;quot;] ) # load documents loader = PySparkDataFrameLoader(spark, df, page_content_column=&amp;quot;id&amp;quot;) documents = loader.load() print(documents) #[Document(page_content=&amp;#39;1&amp;#39;, metadata={&amp;#39;label&amp;#39;: &amp;#39;foo&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;hello&amp;#39;}), Document(page_content=&amp;#39;2&amp;#39;, metadata={&amp;#39;label&amp;#39;: &amp;#39;bar&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;world&amp;#39;}), Document(page_content=&amp;#39;3&amp;#39;, metadata={&amp;#39;label&amp;#39;: &amp;#39;baz&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;!!!&amp;#39;}), Document(page_content=&amp;#39;4&amp;#39;, metadata={&amp;#39;label&amp;#39;: &amp;#39;000&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;why&amp;#39;}), Document(page_content=&amp;#39;5&amp;#39;, metadata={&amp;#39;label&amp;#39;: &amp;#39;111&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;who&amp;#39;})] print(f&amp;quot;Number of documents: {len(documents)}&amp;quot;) #5 # Split and chunk documents text_splitter = CharacterTextSplitter(chunk_size=50, chunk_overlap=0, length_function=len) chunks = text_splitter.split_documents(documents) print(f&amp;quot;Number of chunks: {len(chunks)}&amp;quot;) #5 for i, _ in enumerate(chunks): print(f&amp;quot;chunk # {i} :: {chunks[i]}&amp;quot;) #chunk # 0 :: page_content=&amp;#39;1&amp;#39; metadata={&amp;#39;label&amp;#39;: &amp;#39;foo&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;hello&amp;#39;} #chunk # 1 :: page_content=&amp;#39;2&amp;#39; metadata={&amp;#39;label&amp;#39;: &amp;#39;bar&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;world&amp;#39;} #chunk # 2 :: page_content=&amp;#39;3&amp;#39; metadata={&amp;#39;label&amp;#39;: &amp;#39;baz&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;!!!&amp;#39;} #chunk # 3 :: page_content=&amp;#39;4&amp;#39; metadata={&amp;#39;label&amp;#39;: &amp;#39;000&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;why&amp;#39;} #chunk # 4 :: page_content=&amp;#39;5&amp;#39; metadata={&amp;#39;label&amp;#39;: &amp;#39;111&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;who&amp;#39;} # Embedding db = FAISS.from_documents(documents, ollama_emb) retrieval_qa = RetrievalQA.from_chain_type(llm=ollama_llm , chain_type=&amp;quot;stuff&amp;quot; , retriever=db.as_retriever() , return_source_documents=True) # Retrieve response. query = &amp;quot;Only using my data as source as context, what is the &amp;#39;label&amp;#39; where &amp;#39;col3&amp;#39; is &amp;#39;world&amp;#39; ?&amp;quot; result = retrieval_qa({&amp;quot;query&amp;quot;: query}) print(result) #{&amp;#39;query&amp;#39;: &amp;#39;Only using my data as source as context, what is the &amp;#39;label&amp;#39; where &amp;#39;col3&amp;#39; is &amp;#39;world&amp;#39; ?&amp;#39;, &amp;#39;result&amp;#39;: &amp;quot; Based on the provided context, I can see that the columns are labeled &amp;quot;who&amp;quot;, &amp;quot;why&amp;quot;, and &amp;quot;hello world&amp;quot;. Therefore, if &amp;quot;col3&amp;quot; is &amp;quot;world&amp;quot;, then the label is &amp;quot;hello&amp;quot;.&amp;quot;, &amp;#39;source_documents&amp;#39;: [Document(page_content=&amp;#39;5&amp;#39;, metadata={&amp;#39;label&amp;#39;: &amp;#39;111&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;who&amp;#39;}), Document(page_content=&amp;#39;4&amp;#39;, metadata={&amp;#39;label&amp;#39;: &amp;#39;000&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;why&amp;#39;}), Document(page_content=&amp;#39;2&amp;#39;, metadata={&amp;#39;label&amp;#39;: &amp;#39;bar&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;world&amp;#39;}), Document(page_content=&amp;#39;3&amp;#39;, metadata={&amp;#39;label&amp;#39;: &amp;#39;baz&amp;#39;, &amp;#39;col3&amp;#39;: &amp;#39;!!!&amp;#39;})]} print(&amp;quot;Result:&amp;quot;, result[&amp;quot;result&amp;quot;]) #Result: Based on the provided context, I can see that the columns are labeled &amp;quot;who&amp;quot;, &amp;quot;why&amp;quot;, and &amp;quot;hello world&amp;quot;. Therefore, if &amp;quot;col3&amp;quot; is &amp;quot;world&amp;quot;, then the label is &amp;quot;hello&amp;quot;. # Correct Response should&amp;#39;ve been &amp;quot;bar&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;```&lt;/p&gt; &lt;p&gt;Although the &lt;code&gt;df&lt;/code&gt; looks simple, yet the &lt;code&gt;RetrievalQA&lt;/code&gt; is unable to produce the correct output.&lt;/p&gt; &lt;p&gt;My questions are:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Am I missing something here? How do I get my RAG to produce the correct result?&lt;/li&gt; &lt;li&gt;CharacterTextSplitter does not seem to be splitting the document into chunks. How do I split the Document into chunks? I have tried playing around with &lt;code&gt;chunk_size&lt;/code&gt;. No matter what, I always end up with 5 chunks.&lt;/li&gt; &lt;li&gt;What could be the reason for not getting the correct Results for my simple question?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Below are my App Specs. I chose Phi due to laptop limitations. I&amp;#39;m on Mac 8GB. Unfortunately, the LLama2 model doxed my laptop&lt;/p&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th align=&quot;left&quot;&gt;Tool&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;Values&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;LLM&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;Ollama (Llama3)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;Embedding&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;mxbai-embed-large&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;VectorDB&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;FAISS&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;Langchain&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;0.2.3&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;Python&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;3.9&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;Pyspark&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;3.5.1&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;Any insights on this or directions to guide me will be helpful.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pavanpkulkarni&quot;&gt; /u/pavanpkulkarni &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcxfo0/how_to_build_rag_on_delta_tables_using_ollama/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcxfo0/how_to_build_rag_on_delta_tables_using_ollama/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcxfo0</id><link href="https://www.reddit.com/r/LangChain/comments/1dcxfo0/how_to_build_rag_on_delta_tables_using_ollama/" /><updated>2024-06-10T21:39:56+00:00</updated><published>2024-06-10T21:39:56+00:00</published><title>How to build RAG on Delta tables using Ollama, Pyspark and Langchain</title></entry><entry><author><name>/u/onlinebcwhynot</name><uri>https://www.reddit.com/user/onlinebcwhynot</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Here is my project repo: &lt;a href=&quot;https://github.com/saminkhan1/realtor-project&quot;&gt;https://github.com/saminkhan1/realtor-project&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I am building a AI agent using langgraph that talks to a SQL database to get information about real estate data. The questions were:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;What properties are available in New York?&lt;/li&gt; &lt;li&gt;Show me houses with at least 3 bedrooms and 2 bathrooms.&lt;/li&gt; &lt;li&gt;Do you have any properties under $500,000?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;It knew I was looking for houses in NY for the second question, but in the third it didn&amp;#39;t understand I want houses in NY, 3 bed 2 bath and less then 500k it only searched for houses in NY under 500k.&lt;/p&gt; &lt;p&gt;================================ Human Message =================================&lt;/p&gt; &lt;p&gt;What properties are available in New York?&lt;/p&gt; &lt;p&gt;================================== Ai Message ==================================&lt;/p&gt; &lt;p&gt;Here are some properties available in New York:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Price: $175,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 1&lt;/li&gt; &lt;li&gt;Acre Lot: 60&lt;/li&gt; &lt;li&gt;Address: 553526 Berlin, New York, 12022&lt;/li&gt; &lt;li&gt;House Size: 1176 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $425,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 2.02&lt;/li&gt; &lt;li&gt;Address: 263302 Claverack, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1600 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: November 24, 2021&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $225,000 &lt;ul&gt; &lt;li&gt;Beds: 4&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 0.24&lt;/li&gt; &lt;li&gt;Address: 871278 Copake, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1239 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: February 1, 2018&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $419,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 3&lt;/li&gt; &lt;li&gt;Acre Lot: 1.9&lt;/li&gt; &lt;li&gt;Address: 286373 Copake, New York, 12516&lt;/li&gt; &lt;li&gt;House Size: 1800 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Let me know if you need more information or if you have any specific preferences.&lt;/p&gt; &lt;p&gt;================================ Human Message =================================&lt;/p&gt; &lt;p&gt;Show me houses with at least 3 bedrooms and 2 bathrooms.&lt;/p&gt; &lt;p&gt;================================== Ai Message ==================================&lt;/p&gt; &lt;p&gt;Here are houses in New York with at least 3 bedrooms and 2 bathrooms:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Price: $425,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 2.02&lt;/li&gt; &lt;li&gt;Address: 263302 Claverack, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1600 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: November 24, 2021&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $225,000 &lt;ul&gt; &lt;li&gt;Beds: 4&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 0.24&lt;/li&gt; &lt;li&gt;Address: 871278 Copake, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1239 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: February 1, 2018&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $419,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 3&lt;/li&gt; &lt;li&gt;Acre Lot: 1.9&lt;/li&gt; &lt;li&gt;Address: 286373 Copake, New York, 12516&lt;/li&gt; &lt;li&gt;House Size: 1800 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $365,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 2.0&lt;/li&gt; &lt;li&gt;Address: 78544 Copake, New York, 12517&lt;/li&gt; &lt;li&gt;House Size: 1482 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Let me know if you would like more details or if you have any specific preferences.&lt;/p&gt; &lt;p&gt;================================ Human Message =================================&lt;/p&gt; &lt;p&gt;Do you have any properties under $500,000?&lt;/p&gt; &lt;p&gt;================================== Ai Message ==================================&lt;/p&gt; &lt;p&gt;I found some properties in New York under $500,000:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Price: $175,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 1&lt;/li&gt; &lt;li&gt;Acre Lot: 60.0&lt;/li&gt; &lt;li&gt;Address: 553526 Berlin, New York, 12022&lt;/li&gt; &lt;li&gt;House Size: 1176 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $425,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 2.02&lt;/li&gt; &lt;li&gt;Address: 263302 Claverack, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1600 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: November 24, 2021&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $225,000 &lt;ul&gt; &lt;li&gt;Beds: 4&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 0.24&lt;/li&gt; &lt;li&gt;Address: 871278 Copake, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1239 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: February 1, 2018&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $419,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 3&lt;/li&gt; &lt;li&gt;Acre Lot: 1.9&lt;/li&gt; &lt;li&gt;Address: 286373 Copake, New York, 12516&lt;/li&gt; &lt;li&gt;House Size: 1800 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $365,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 2.0&lt;/li&gt; &lt;li&gt;Address: 78544 Copake, New York, 12517&lt;/li&gt; &lt;li&gt;House Size: 1482 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Let me know if you need more information on any of these properties or if you have any specific preferences.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/onlinebcwhynot&quot;&gt; /u/onlinebcwhynot &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcprk4/how_to_get_ai_agent_to_do_follow_up_questions_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcprk4/how_to_get_ai_agent_to_do_follow_up_questions_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcprk4</id><link href="https://www.reddit.com/r/LangChain/comments/1dcprk4/how_to_get_ai_agent_to_do_follow_up_questions_and/" /><updated>2024-06-10T16:29:59+00:00</updated><published>2024-06-10T16:29:59+00:00</published><title>How to get AI Agent to do follow up questions and remember/apply previous request/arguments?</title></entry><entry><author><name>/u/c0mpu73</name><uri>https://www.reddit.com/user/c0mpu73</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am looking to build a RAG chatbot. My data-sources are classified into about 3 specific domains, and I want my RAG bot to know the difference between these domains and query only the necessary datasets, depending on the query.&lt;/p&gt; &lt;p&gt;I primarily work with Langchain and have embedded all my data-sources into a FAISS vector database (I tried ChromaDB, but found better results with FAISS, lmk if you have better suggestions). &lt;/p&gt; &lt;p&gt;I used several of Langchain&amp;#39;s retrievers, like the MultiVectorRetriever, a BM25 retriever and even tried pooling everything together with an EnsembleRetriever.&lt;/p&gt; &lt;p&gt;Though I get &amp;quot;passable&amp;quot; responses, more often than not, the model gets confused by the several retrieved documents. For a given query, my FAISS retriever pulls relevant documents from all the available data sources (as they are embedded in the same vectorstore). These data sources corrupt the quality of the generated response, as my LLM is now summarizing a document from domain B, when the question was clearly about domain A.&lt;/p&gt; &lt;p&gt;I understand that I cant expect perfect results from any RAG architecture, but I feel like a lot of my current issues will be solved if I figure out a way to teach the model to know the difference between the different data sources.&lt;/p&gt; &lt;p&gt;I considered metadata filtering (with PGVector in Langchain), but am pretty sure that this wont work, as my data-sources aren&amp;#39;t metadata rich. The only metadata I could have is the domain key.&lt;/p&gt; &lt;p&gt;So, what if I embed my different domains in different vector databases and use a Langchain agent function call to have the LLM selectively retrieve docs from each vectorstore depending on the question? I will probably be making more LLM calls and have some latency, but is this feasible?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/c0mpu73&quot;&gt; /u/c0mpu73 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcjs4r/agentic_rag_with_different_vector_stores/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcjs4r/agentic_rag_with_different_vector_stores/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcjs4r</id><link href="https://www.reddit.com/r/LangChain/comments/1dcjs4r/agentic_rag_with_different_vector_stores/" /><updated>2024-06-10T12:01:10+00:00</updated><published>2024-06-10T12:01:10+00:00</published><title>Agentic RAG with Different Vector Stores</title></entry><entry><author><name>/u/Revlong57</name><uri>https://www.reddit.com/user/Revlong57</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So, as the title says, for equations in a PDF, what markup language does the module PyPDFLoader use to represent math equations? For example, it extracted an equation from the document as &amp;quot;\n( )\n101\n10RMNT\nHH+−\n=&amp;quot; . Is that some sort of markup language, or is it just gibberish?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Revlong57&quot;&gt; /u/Revlong57 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcs5k0/what_markup_language_if_any_does_pypdfloader/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcs5k0/what_markup_language_if_any_does_pypdfloader/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcs5k0</id><link href="https://www.reddit.com/r/LangChain/comments/1dcs5k0/what_markup_language_if_any_does_pypdfloader/" /><updated>2024-06-10T18:07:01+00:00</updated><published>2024-06-10T18:07:01+00:00</published><title>What markup language, if any, does PyPDFLoader extract equations as?</title></entry><entry><author><name>/u/emersounds</name><uri>https://www.reddit.com/user/emersounds</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently working on a project where I&amp;#39;ve been using Langchain Agent Template from Reasoning Engine Docs. Recently, I came across Langgraph and now I want to try it to leverage its multi-agent functionality.&lt;/p&gt; &lt;p&gt;I&amp;#39;d like to know if anyone here has experience integrating Langgraph with Google Vertex AI Reasoning Engine.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve already tested the reasoning engine locally, but I encounter issues when running the set_up method on the deployed version in the reasoning engine. I just want to know if anyone has experience doing this.&lt;/p&gt; &lt;p&gt;Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/emersounds&quot;&gt; /u/emersounds &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcqnw9/has_anyone_integrated_langgraph_with_google/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcqnw9/has_anyone_integrated_langgraph_with_google/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcqnw9</id><link href="https://www.reddit.com/r/LangChain/comments/1dcqnw9/has_anyone_integrated_langgraph_with_google/" /><updated>2024-06-10T17:06:46+00:00</updated><published>2024-06-10T17:06:46+00:00</published><title>Has Anyone Integrated Langgraph with Google Vertex AI Reasoning Engine?</title></entry><entry><author><name>/u/startingastartup</name><uri>https://www.reddit.com/user/startingastartup</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Folks,&lt;/p&gt; &lt;p&gt;I wanted to ping the community to see if anyone would be interested in joining a few of us in our generative AI project. We&amp;#39;re trying to set up pipelines to help companies utilize RAG pipelines. &lt;/p&gt; &lt;p&gt;I don&amp;#39;t want to waste anyone&amp;#39;s time either. To be transparent, we&amp;#39;re actively seeking and courting investors, so we can&amp;#39;t offer monetary compensation until that happens. However, with the current investment in Gen AI and with what we&amp;#39;re building, I&amp;#39;m confident this won&amp;#39;t be the case for long. We&amp;#39;re happy to cover essential development costs and resources as needed. I know that sounds all just promises, but I want to be as upfront as possible. &lt;/p&gt; &lt;p&gt;Feel free to DM me if interested! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/startingastartup&quot;&gt; /u/startingastartup &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcpmw4/anyone_interested_in_collaboration/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcpmw4/anyone_interested_in_collaboration/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcpmw4</id><link href="https://www.reddit.com/r/LangChain/comments/1dcpmw4/anyone_interested_in_collaboration/" /><updated>2024-06-10T16:24:22+00:00</updated><published>2024-06-10T16:24:22+00:00</published><title>anyone interested in collaboration?</title></entry><entry><author><name>/u/Select-Coconut-1161</name><uri>https://www.reddit.com/user/Select-Coconut-1161</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, I am a Comp. Sci. student and I am using LangChain for one of my projects. I am working with transcription of a video. I was storing each speech segment as text and speaker and timestamp as metadata to a Chroma collection.&lt;/p&gt; &lt;p&gt;However, I have two problems: - I couldn&amp;#39;t manage to filter by speaker. I tried adding filter=[{speaker: speaker_1}] to retriever and also self query retriever but both did not work - Some context&amp;#39;s are omitted due to how I store data. For example, if speaker_1 asks &amp;quot;Where were you ar yesterday?&amp;quot; and speaker_2 says &amp;quot;at home&amp;quot;. When I query where was speaker_2 at yesterday, I see that speaker_1&amp;#39;s question is retrieved as context but not the answer, so I cannot get the answer. &lt;/p&gt; &lt;p&gt;I also did not want to include the last part of the previous sentence as it would make the timestamp accuracy problematic which is important for my project. I may add each previous sentence as metadata but I don&amp;#39;t know if this is way to go. Any ideas?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Select-Coconut-1161&quot;&gt; /u/Select-Coconut-1161 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcnfb7/how_do_i_improve_context_retrieved/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcnfb7/how_do_i_improve_context_retrieved/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcnfb7</id><link href="https://www.reddit.com/r/LangChain/comments/1dcnfb7/how_do_i_improve_context_retrieved/" /><updated>2024-06-10T14:53:08+00:00</updated><published>2024-06-10T14:53:08+00:00</published><title>How do I improve context retrieved?</title></entry><entry><author><name>/u/Slow_Painting_4908</name><uri>https://www.reddit.com/user/Slow_Painting_4908</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want my output in the below format, but the sql agent throws an error saying that &lt;/p&gt; &lt;p&gt;ValueError: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: &lt;/p&gt; &lt;p&gt;`### Sql Query&lt;br/&gt; ```sql&lt;br/&gt; SELECT&lt;br/&gt; frcst_amt_in_gc AS targeted_budget,&lt;br/&gt; actl_cst_in_gc AS actual_budget,&lt;br/&gt; (actl_cst_in_gc - frcst_amt_in_gc) AS deviation&lt;br/&gt; FROM&lt;br/&gt; prcur_frcst_fact_TEST&lt;br/&gt; ``` &lt;/p&gt; &lt;h3&gt;Result&lt;/h3&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th&gt;targeted_budget&lt;/th&gt; &lt;th&gt;actual_budget&lt;/th&gt; &lt;th&gt;deviation&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td&gt;59.82&lt;/td&gt; &lt;td&gt;304.41&lt;/td&gt; &lt;td&gt;244.58&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;178.53&lt;/td&gt; &lt;td&gt;2.56&lt;/td&gt; &lt;td&gt;-175.97&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;h3&gt;Summarized Insights from query&lt;/h3&gt; &lt;p&gt;The query results show the targeted budget, actual budget, and the deviation for each record in the `prcur_frcst_fact` table. The deviations indicate the difference between the actual cost and the forecasted amount. Positive deviations indicate that the actual cost exceeded the forecasted amount, while negative deviations indicate that the actual cost was less than the forecasted amount. &lt;/p&gt; &lt;h3&gt;Next Steps&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;**Analyze Deviations**: Identify the records with the highest positive and negative deviations to understand the reasons behind significant budget variances.&lt;br/&gt;&lt;/li&gt; &lt;li&gt;**Budget Adjustment**: Use the insights from the deviations to adjust future budget forecasts and improve accuracy.&lt;br/&gt;&lt;/li&gt; &lt;li&gt;**Cost Control**: Implement measures to control costs and reduce deviations, especially for records with high positive deviations.&lt;br/&gt;&lt;/li&gt; &lt;li&gt;**Further Segmentation**: Segment the data by different dimensions (e.g., geography, vendor, material) to gain deeper insights into budget performance across different segments.&lt;br/&gt;&lt;/li&gt; &lt;li&gt;**Historical Comparison**: Compare the current period&amp;#39;s deviations with historical data to identify trends and patterns in budget performance.`&lt;/li&gt; &lt;/ol&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Slow_Painting_4908&quot;&gt; /u/Slow_Painting_4908 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dchs6s/can_i_change_the_way_my_output_looks_in_creat_sql/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dchs6s/can_i_change_the_way_my_output_looks_in_creat_sql/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dchs6s</id><link href="https://www.reddit.com/r/LangChain/comments/1dchs6s/can_i_change_the_way_my_output_looks_in_creat_sql/" /><updated>2024-06-10T09:54:48+00:00</updated><published>2024-06-10T09:54:48+00:00</published><title>Can i change the way my output looks in creat sql agent ?</title></entry><entry><author><name>/u/Old_Cauliflower6316</name><uri>https://www.reddit.com/user/Old_Cauliflower6316</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently working on a project that would do some kind of an enterprise search for my company. The requirements are pretty basic - having an AI chatbot for the company&amp;#39;s employees, that would provide information about company&amp;#39;s information.&lt;/p&gt; &lt;p&gt;On the technical side, I&amp;#39;d have to ingest multiple data sources (Slack, Confluence, Notion, Google Docs, etc) into a single VectorDB (planned on using ChromaDB) and then do a basic RAG.&lt;/p&gt; &lt;p&gt;I was thinking of &amp;quot;building&amp;quot; it myself with Langchain, but I was wondering what the community thinks about it. These days, there are lots of products (Glean, Guru, etc) and open source projects (Quivr, AnythingLLM, etc) that does this.&lt;/p&gt; &lt;p&gt;What do you think are the main considerations for this? I&amp;#39;d like to learn what are the things that I should look out for when deciding whether to build v.s buy a solution.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Old_Cauliflower6316&quot;&gt; /u/Old_Cauliflower6316 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcgokb/enterprise_knowledge_search_build_vs_buy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcgokb/enterprise_knowledge_search_build_vs_buy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcgokb</id><link href="https://www.reddit.com/r/LangChain/comments/1dcgokb/enterprise_knowledge_search_build_vs_buy/" /><updated>2024-06-10T08:32:46+00:00</updated><published>2024-06-10T08:32:46+00:00</published><title>Enterprise knowledge search - Build v.s Buy</title></entry><entry><author><name>/u/Strange-Ant-4194</name><uri>https://www.reddit.com/user/Strange-Ant-4194</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Here is a program i&amp;#39;ve created using Ollama, LangGraph and Llama3:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain_community.chat_models import ChatOllama from langchain_core.output_parsers import JsonOutputParser from langchain_core.prompts import PromptTemplate from langchain_community.chat_models import ChatOllama from langchain_core.output_parsers import JsonOutputParser from langchain_core.prompts import PromptTemplate from langgraph.graph import END, StateGraph from pprint import pprint from langchain_core.output_parsers import StrOutputParser from typing import TypedDict import mod from langchain.tools.render import render_text_description local_llm = &amp;quot;llama3:8b&amp;quot; tools = [mod.check_calendar,mod.check_location,mod.send_message,mod.receive_call,mod.getContactInfo,mod.mute] rendered_tools = render_text_description(tools) print(rendered_tools) from operator import itemgetter def tool_chain(model_output): tool_map = {tool.name: tool for tool in tools} chosen_tool = tool_map[model_output[&amp;quot;name&amp;quot;]] return itemgetter(&amp;quot;arguments&amp;quot;) | chosen_tool contextllm = ChatOllama(model=local_llm, format=&amp;quot;json&amp;quot;, temperature=0) prompt = PromptTemplate( template=&amp;quot;&amp;quot;&amp;quot;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt; You are a helpful agent who will answer the user&amp;#39;s question to the best of your abilities using one or more of the tools available to you\n You have access to the following tools. Here is the name and description of the tools:%s\n Return the name and input of the tool to use. Return your response as a JSON blob with &amp;#39;name&amp;#39; and &amp;#39;arguments&amp;#39; keys. The value associated with the &amp;#39;arguments&amp;#39; key should be a dictionary of parameters. You are not allowed to return blank results &amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt; {inp}. Who is calling?\n &amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt; &amp;quot;&amp;quot;&amp;quot;%rendered_tools, input_variables=[&amp;quot;inp&amp;quot;], ) contextgatherer_chain = prompt | contextllm | JsonOutputParser() | tool_chain actionllm = ChatOllama(model=local_llm, format=&amp;quot;json&amp;quot;, temperature=0) prompt = PromptTemplate( template=&amp;quot;&amp;quot;&amp;quot;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt; You are a helpful agent who will select which tool is to be used depending on the context provided by the user and some rules.\n You have access to the following tools. Here is the name and description of the tools:%s\n Return the name and input of the tool to use. Return your response as a JSON blob with &amp;#39;name&amp;#39; and &amp;#39;arguments&amp;#39; keys. The value associated with the &amp;#39;arguments&amp;#39; key should be a dictionary of parameters. You are not allowed to return blank results &amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt; Context:{context}\n {inp}.\n\n Rules for tool calling:\n If the caller is &amp;#39;Kau&amp;#39;, the tool to be used is &amp;#39;receive_call&amp;#39;\n If the caller is &amp;#39;Priya&amp;#39;, the tool to be used is &amp;#39;send_message&amp;#39;\n For all other numbers, the tool to be used is &amp;#39;mute&amp;#39;\n &amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt; &amp;quot;&amp;quot;&amp;quot;%rendered_tools, input_variables=[&amp;quot;context&amp;quot;,&amp;#39;inp&amp;#39;], ) actiontaker_chain = prompt | actionllm | JsonOutputParser() class GraphState(TypedDict): &amp;quot;&amp;quot;&amp;quot; Represents the state of our graph. Attributes: input: User input generation: LLM generation cl: Contact list rs: Relationship list cal: Calendar ct: Current time &amp;quot;&amp;quot;&amp;quot; input:str generation: str cl:str rs:str cal:str ct:str con:str def callhandler(state): &amp;quot;&amp;quot;&amp;quot; Gathers the context and determines whether to receive the call or send a message Args: state (dict): The current graph state Returns: state (dict): Whether to send a message, receive the call, or mute the call &amp;quot;&amp;quot;&amp;quot; print(&amp;quot;---HANDLING---&amp;quot;) i = state[&amp;quot;input&amp;quot;] c=state[&amp;quot;con&amp;quot;] res1 = contextgatherer_chain.invoke({&amp;quot;inp&amp;quot;:i}) res2 = actiontaker_chain.invoke({&amp;quot;context&amp;quot;:res1,&amp;#39;inp&amp;#39;:i}) return {&amp;quot;generation&amp;quot;: res2} workflow = StateGraph(GraphState) workflow.add_node(&amp;quot;callhandler&amp;quot;, callhandler) workflow.set_entry_point(&amp;quot;callhandler&amp;quot;) workflow.add_edge(&amp;quot;callhandler&amp;quot;,END) app = workflow.compile() e=&amp;#39;incoming call from +911234567890&amp;#39;inputs = {&amp;quot;input&amp;quot;: e} for output in app.stream(inputs): for key, value in output.items(): pprint(f&amp;quot;Finished running: {key}:&amp;quot;) pprint(value[&amp;#39;generation&amp;#39;]) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output for the above is:&lt;/p&gt; &lt;p&gt;---HANDLING---&lt;/p&gt; &lt;p&gt;&amp;#39;Finished running: callhandler:&amp;#39;&lt;/p&gt; &lt;p&gt;{&amp;#39;arguments&amp;#39;: {&amp;#39;message&amp;#39;: &amp;#39;&amp;#39;, &amp;#39;recipient&amp;#39;: &amp;#39;+911234567890&amp;#39;},&lt;/p&gt; &lt;p&gt;&amp;#39;name&amp;#39;: &amp;#39;send_message&amp;#39;}&lt;/p&gt; &lt;p&gt;When i try to run the same program by enclosing the entire thing as a function( as i want to import this into another file) like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;def PA(): from langchain_community.chat_models import ChatOllama from langchain_core.output_parsers import JsonOutputParser from langchain_core.prompts import PromptTemplate from langchain_community.chat_models import ChatOllama from langchain_core.output_parsers import JsonOutputParser from langchain_core.prompts import PromptTemplate from langgraph.graph import END, StateGraph from pprint import pprint from langchain_core.output_parsers import StrOutputParser from typing import TypedDict import mod from langchain.tools.render import render_text_description local_llm = &amp;quot;llama3:8b&amp;quot; tools = [mod.check_calendar,mod.check_location,mod.send_message,mod.receive_call,mod.getContactInfo,mod.mute] rendered_tools = render_text_description(tools) print(rendered_tools) from operator import itemgetter def tool_chain(model_output): tool_map = {tool.name: tool for tool in tools} chosen_tool = tool_map[model_output[&amp;quot;name&amp;quot;]] return itemgetter(&amp;quot;arguments&amp;quot;) | chosen_tool contextllm = ChatOllama(model=local_llm, format=&amp;quot;json&amp;quot;, temperature=0) prompt = PromptTemplate( template=&amp;quot;&amp;quot;&amp;quot;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt; You are a helpful agent who will answer the user&amp;#39;s question to the best of your abilities using one or more of the tools available to you\n You have access to the following tools. Here is the name and description of the tools:%s\n Return the name and input of the tool to use. Return your response as a JSON blob with &amp;#39;name&amp;#39; and &amp;#39;arguments&amp;#39; keys. The value associated with the &amp;#39;arguments&amp;#39; key should be a dictionary of parameters. You are not allowed to return blank results &amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt; {inp}. Who is calling?\n &amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt; &amp;quot;&amp;quot;&amp;quot;%rendered_tools, input_variables=[&amp;quot;inp&amp;quot;], ) contextgatherer_chain = prompt | contextllm | JsonOutputParser() | tool_chain actionllm = ChatOllama(model=local_llm, format=&amp;quot;json&amp;quot;, temperature=0) prompt = PromptTemplate( template=&amp;quot;&amp;quot;&amp;quot;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt; You are a helpful agent who will select which tool is to be used depending on the context provided by the user and some rules.\n You have access to the following tools. Here is the name and description of the tools:%s\n Return the name and input of the tool to use. Return your response as a JSON blob with &amp;#39;name&amp;#39; and &amp;#39;arguments&amp;#39; keys. The value associated with the &amp;#39;arguments&amp;#39; key should be a dictionary of parameters. You are not allowed to return blank results &amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt; Context:{context}\n {inp}.\n\n Rules for tool calling:\n If the caller is &amp;#39;Kau&amp;#39;, the tool to be used is &amp;#39;receive_call&amp;#39;\n If the caller is &amp;#39;Priya&amp;#39;, the tool to be used is &amp;#39;send_message&amp;#39;\n For all other numbers, the tool to be used is &amp;#39;mute&amp;#39;\n &amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt; &amp;quot;&amp;quot;&amp;quot;%rendered_tools, input_variables=[&amp;quot;context&amp;quot;,&amp;#39;inp&amp;#39;], ) actiontaker_chain = prompt | actionllm | JsonOutputParser() class GraphState(TypedDict): &amp;quot;&amp;quot;&amp;quot; Represents the state of our graph. Attributes: input: User input generation: LLM generation cl: Contact list rs: Relationship list cal: Calendar ct: Current time &amp;quot;&amp;quot;&amp;quot; input:str generation: str cl:str rs:str cal:str ct:str con:str def callhandler(state): &amp;quot;&amp;quot;&amp;quot; Gathers the context and determines whether to receive the call or send a message Args: state (dict): The current graph state Returns: state (dict): Whether to send a message, receive the call, or mute the call &amp;quot;&amp;quot;&amp;quot; print(&amp;quot;---HANDLING---&amp;quot;) i = state[&amp;quot;input&amp;quot;] c=state[&amp;quot;con&amp;quot;] res1 = contextgatherer_chain.invoke({&amp;quot;inp&amp;quot;:i}) res2 = actiontaker_chain.invoke({&amp;quot;context&amp;quot;:res1,&amp;#39;inp&amp;#39;:i}) return {&amp;quot;generation&amp;quot;: res2} workflow = StateGraph(GraphState) workflow.add_node(&amp;quot;callhandler&amp;quot;, callhandler) workflow.set_entry_point(&amp;quot;callhandler&amp;quot;) workflow.add_edge(&amp;quot;callhandler&amp;quot;,END) app = workflow.compile() file1=open(&amp;quot;contactlist&amp;quot;,&amp;quot;r&amp;quot;) file2=open(&amp;quot;relationships&amp;quot;,&amp;quot;r&amp;quot;) file3=open(&amp;quot;calendar&amp;quot;,&amp;quot;r&amp;quot;) s1=file1.read() s2=file2.read() s3=file3.read() curt=&amp;quot;11:00.&amp;quot; e=&amp;#39;incoming call from +911234567890&amp;#39; f=s1+&amp;quot;\n\n&amp;quot;+s2+&amp;quot;\n\n&amp;quot;+s3+&amp;quot;\n\n&amp;quot;+curt+&amp;quot;\n\n&amp;quot;+e print(f) inputs = {&amp;quot;input&amp;quot;: e} for output in app.stream(inputs): for key, value in output.items(): pprint(f&amp;quot;Finished running: {key}:&amp;quot;) pprint(value[&amp;#39;generation&amp;#39;]) PA() &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output i get is:&lt;/p&gt; &lt;p&gt;---HANDLING---&lt;/p&gt; &lt;p&gt;&amp;#39;Finished running: callhandler:&amp;#39;&lt;/p&gt; &lt;p&gt;{&amp;#39;arguments&amp;#39;: {&amp;#39;caller&amp;#39;: &amp;#39;+911234567890&amp;#39;}, &amp;#39;name&amp;#39;: &amp;#39;receive_call&amp;#39;}&lt;/p&gt; &lt;p&gt;Here is the &amp;#39;mod&amp;#39; file in which ive defined the tools available to the LLM:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import os from langchain_core.tools import tool from typing import Annotated, Sequence, TypedDict from langchain.agents import AgentExecutor, create_react_agent from langchain_core.messages import BaseMessage, HumanMessage from langchain_openai import ChatOpenAI from langchain_core.runnables import RunnablePassthrough from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser import functools from langgraph.graph import StateGraph, END import operator import openai import time import random from langchain_community.chat_models import ChatOllama from langchain_core.output_parsers import JsonOutputParser from langchain_core.prompts import PromptTemplate from langchain_core.runnables import Runnable from langchain_core.exceptions import OutputParserException from langchain.tools.render import render_text_description_and_args from pprint import pprint u/tool def check_calendar() -&amp;gt; str: &amp;quot;&amp;quot;&amp;quot;Retrieve the list of current events from the user&amp;#39;s calender. This tool must be used only if the &amp;#39;context&amp;#39; provided by the user is empty&amp;quot;&amp;quot;&amp;quot; file=open(&amp;quot;calendar&amp;quot;,&amp;quot;r&amp;quot;) s=file.read() return s @tool def getContactInfo()-&amp;gt;str: &amp;quot;&amp;quot;&amp;quot;Retreive the the user&amp;#39;s contact list to determine who is calling when given an unknown number&amp;quot;&amp;quot;&amp;quot; file=open(&amp;quot;contactlist&amp;quot;,&amp;quot;r&amp;quot;) s=file.read() return s @tool def check_location() -&amp;gt; str: &amp;quot;&amp;quot;&amp;quot;Retrieve the current location of the user. This tool must be used only if the &amp;#39;context&amp;#39; provided by the user is empty&amp;quot;&amp;quot;&amp;quot; return &amp;quot;your location is Bengaluru&amp;quot; @tool def send_message(recipient: str, message: str) -&amp;gt; str: &amp;quot;&amp;quot;&amp;quot;Send a text message to the specified recipient with the provided message content. This tool must be used only if the &amp;#39;context&amp;#39; provided by the user is not empty&amp;quot;&amp;quot;&amp;quot; return f&amp;quot;Sent message to {recipient}: {message}&amp;quot; @tool def make_call(recipient: str) -&amp;gt; str: &amp;quot;&amp;quot;&amp;quot;Initiate a phone call to the specified recipient. This tool must be used only if the &amp;#39;context&amp;#39; provided by the user is not empty&amp;quot;&amp;quot;&amp;quot; return f&amp;quot;Calling {recipient}...&amp;quot; @tool def receive_call(caller: str) -&amp;gt; str: &amp;quot;&amp;quot;&amp;quot;Handle an incoming phone call from the specified caller. This tool must be used only if the &amp;#39;context&amp;#39; provided by the user is not empty&amp;quot;&amp;quot;&amp;quot; return f&amp;quot;Receiving call from {caller}...&amp;quot; @tool def op1(f:int,s:int)-&amp;gt;dict: &amp;quot;&amp;quot;&amp;quot;adds f and s&amp;quot;&amp;quot;&amp;quot; return {&amp;quot;answer&amp;quot;:f*s} @tool def op2(f:int,s:int)-&amp;gt;dict: &amp;quot;&amp;quot;&amp;quot;subtracts f and s&amp;quot;&amp;quot;&amp;quot; return {&amp;quot;answer&amp;quot;:f*s} @tool def getWeather(city:str): &amp;quot;&amp;quot;&amp;quot;returns the weather in &amp;#39;city&amp;quot;&amp;quot;&amp;quot; return &amp;quot;cloudy&amp;quot; @tool def mute(): &amp;quot;&amp;quot;&amp;quot;Mute an incoming call&amp;quot;&amp;quot;&amp;quot; return &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I have my reasons for structuring it this way.&lt;/p&gt; &lt;p&gt;Can someone please tell me why I&amp;#39;m getting different outputs?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Strange-Ant-4194&quot;&gt; /u/Strange-Ant-4194 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dci6cs/same_program_gives_different_results_when/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dci6cs/same_program_gives_different_results_when/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dci6cs</id><link href="https://www.reddit.com/r/LangChain/comments/1dci6cs/same_program_gives_different_results_when/" /><updated>2024-06-10T10:20:51+00:00</updated><published>2024-06-10T10:20:51+00:00</published><title>Same program gives different results when executed directly and when executed as a function</title></entry><entry><author><name>/u/Unique-Drink-9916</name><uri>https://www.reddit.com/user/Unique-Drink-9916</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a bunch of pdfs. Pages could go from 1 to 100 in each pdf. I want to do a similarity search on this set of pdfs with some content (query) and order them based on score (ascending order cosine similarity. Most relevant ones at the top).&lt;/p&gt; &lt;p&gt;Issue is while I can use pypdf loader and embeddings to create docs and store them in a vectorstore, How do I aggregate score for a whole pdf? Lets say page 3 of pdf 25 has relevant content. But how I do I compare the whole pdf to another pdf and order them based on similarity? Thanks!&lt;/p&gt; &lt;p&gt;Ps: Here I am storing each page as a document. No splitter used. If I want to embedd whole pdf it might be too much text. I am kind of stuck here.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Unique-Drink-9916&quot;&gt; /u/Unique-Drink-9916 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dch46a/comparing_pdfs_through_similarity_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dch46a/comparing_pdfs_through_similarity_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dch46a</id><link href="https://www.reddit.com/r/LangChain/comments/1dch46a/comparing_pdfs_through_similarity_search/" /><updated>2024-06-10T09:05:47+00:00</updated><published>2024-06-10T09:05:47+00:00</published><title>Comparing pdfs through similarity search</title></entry><entry><author><name>/u/Little-Meet4512</name><uri>https://www.reddit.com/user/Little-Meet4512</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;openai.BadRequestError: Error code: 400 - {&amp;#39;error&amp;#39;: {&amp;#39;message&amp;#39;: &amp;quot;An assistant message with &amp;#39;tool&lt;em&gt;calls&amp;#39; must be followed by tool messages responding to each &amp;#39;tool_call_id&amp;#39;. The following tool_call_ids did not have response messages: call_wdvsPX0sM6va49zF12nUIPm6&amp;quot;, &amp;#39;type&amp;#39;: &amp;#39;invalid_request_error&amp;#39;, &amp;#39;param&amp;#39;: &amp;#39;messages.[95].role&amp;#39;, &amp;#39;code&amp;#39;: None}} I am using two tools each tool is used for retriever.but I used this in agent . For tools I used create_retrival_tool For agents I used create_openai&lt;/em&gt; agent If any body about how to resolve this error please give me information &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Little-Meet4512&quot;&gt; /u/Little-Meet4512 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcg8lz/bad_request_error_from_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcg8lz/bad_request_error_from_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcg8lz</id><link href="https://www.reddit.com/r/LangChain/comments/1dcg8lz/bad_request_error_from_openai/" /><updated>2024-06-10T07:59:28+00:00</updated><published>2024-06-10T07:59:28+00:00</published><title>Bad request error from openai</title></entry><entry><author><name>/u/ventzpetkov</name><uri>https://www.reddit.com/user/ventzpetkov</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi All, &lt;/p&gt; &lt;p&gt;Released Easy LLMs, in case anyone else finds it helpful/useful:&lt;br/&gt; &lt;a href=&quot;https://github.com/ventz/easy-llms&quot;&gt;https://github.com/ventz/easy-llms&lt;/a&gt;&lt;br/&gt; pip install easy-llms &lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Easy &amp;quot;1-line&amp;quot; calling of every LLM from OpenAI, MS Azure, AWS Bedrock, GCP Vertex, and Ollama&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;It&amp;#39;s utilizing LangChain, but abstracting away all of the silly differences to make things easy. Yet it still stays powerful by allowing to provide and override any option/parameter for any LLM for any provider. &lt;/p&gt; &lt;p&gt;The goal initially was to be able to get started with any popular LLM, and &amp;quot;just get going&amp;quot; without having to think about how to authenticate, needed options and parameters, which classes you need, etc. &lt;/p&gt; &lt;p&gt;I&amp;#39;ve been using this internally to compare 40+ LLMs over the last 1.5 years, with millions of calls, and figured it&amp;#39;s time to clean this up and release it for others. It started with just OpenAI, and then quickly added Azure&amp;#39;s OpenAI. And then Vertex, and then Bedrock, and recently Ollama. As LangChain has been changing, I&amp;#39;ve been updating it.&lt;/p&gt; &lt;p&gt;I updated it to the latest non-0.2 LangChain version before releasing it (LangChain v0.2.x seems to have a bug with Google Vertex, so waiting on that before upgrading it)&lt;/p&gt; &lt;p&gt;If you find any bugs (or have ideas for improvement/feature requests), please reach out via the GitHub issues.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ventzpetkov&quot;&gt; /u/ventzpetkov &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbyxy4/easy_1line_calling_of_every_llm_from_openai_ms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbyxy4/easy_1line_calling_of_every_llm_from_openai_ms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dbyxy4</id><link href="https://www.reddit.com/r/LangChain/comments/1dbyxy4/easy_1line_calling_of_every_llm_from_openai_ms/" /><updated>2024-06-09T17:20:25+00:00</updated><published>2024-06-09T17:20:25+00:00</published><title>Easy &quot;1-line&quot; calling of every LLM from OpenAI, MS Azure, AWS Bedrock, GCP Vertex, and Ollama</title></entry><entry><author><name>/u/sarthakai</name><uri>https://www.reddit.com/user/sarthakai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;If you don&amp;#39;t want to use Guardrails because you anticipate prompt attacks that are more unique, you can train a custom classifier:&lt;/p&gt; &lt;p&gt;Step 1:&lt;/p&gt; &lt;p&gt;Create a balanced dataset of prompt injection user prompts.&lt;/p&gt; &lt;p&gt;These might be previous user attempts you’ve caught in your logs, or you can compile threats you anticipate relevant to your use case.&lt;/p&gt; &lt;p&gt;Here’s a dataset you can use as a starting point: &lt;a href=&quot;https://huggingface.co/datasets/deepset/prompt-injections&quot;&gt;https://huggingface.co/datasets/deepset/prompt-injections&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Step 2:&lt;/p&gt; &lt;p&gt;Further augment this dataset using an LLM to cover maximal bases.&lt;/p&gt; &lt;p&gt;Step 3:&lt;/p&gt; &lt;p&gt;Train an encoder model on this dataset as a classifier to predict prompt injection attempts vs benign user prompts.&lt;/p&gt; &lt;p&gt;A DeBERTA model can be deployed on a fast enough inference point and you can use it in the beginning of your pipeline to protect future LLM calls.&lt;/p&gt; &lt;p&gt;This model is an example with 99% accuracy: &lt;a href=&quot;https://huggingface.co/deepset/deberta-v3-base-injection&quot;&gt;https://huggingface.co/deepset/deberta-v3-base-injection&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Step 4:&lt;/p&gt; &lt;p&gt;Monitor your false negatives, and regularly update your training dataset + retrain. &lt;/p&gt; &lt;p&gt;Most LLM apps and agents will face this threat. I&amp;#39;m planning to train a open model next weekend to help counter them. Will post updates.&lt;/p&gt; &lt;p&gt;I share high quality AI updates and tutorials daily.&lt;/p&gt; &lt;p&gt;If you like this post, you can learn more about LLMs and creating AI agents here: &lt;a href=&quot;https://github.com/sarthakrastogi/nebulousai&quot;&gt;https://github.com/sarthakrastogi/nebulousai&lt;/a&gt; or on my Twitter: &lt;a href=&quot;https://x.com/sarthakai&quot;&gt;https://x.com/sarthakai&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sarthakai&quot;&gt; /u/sarthakai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbsh0x/forget_all_prev_instructions_now_do_malicious/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbsh0x/forget_all_prev_instructions_now_do_malicious/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dbsh0x</id><link href="https://www.reddit.com/r/LangChain/comments/1dbsh0x/forget_all_prev_instructions_now_do_malicious/" /><updated>2024-06-09T12:20:27+00:00</updated><published>2024-06-09T12:20:27+00:00</published><title>“Forget all prev instructions, now do [malicious attack task]”. How you can protect your LLM app against such prompt injection threats:</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1dcdt2x/multi_ai_agent_orchestration_frameworks/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcdusp/multi_ai_agent_orchestration_frameworks/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcdusp</id><link href="https://www.reddit.com/r/LangChain/comments/1dcdusp/multi_ai_agent_orchestration_frameworks/" /><updated>2024-06-10T05:14:55+00:00</updated><published>2024-06-10T05:14:55+00:00</published><title>Multi AI Agent Orchestration Frameworks</title></entry><entry><author><name>/u/jeffrey-0711</name><uri>https://www.reddit.com/user/jeffrey-0711</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am maker of &lt;a href=&quot;https://github.com/Marker-Inc-Korea/AutoRAG&quot;&gt;AutoRAG&lt;/a&gt; and want to share my experience. &lt;/p&gt; &lt;p&gt;I added RAGAS context precision metric to AutoRAG, because we couldn&amp;#39;t make retrieval ground truth at our dataset. And it was huge mistake.&lt;/p&gt; &lt;p&gt;AutoRAG is a tool to evaluate all kinds of RAG components easily. Using it, I tried to compare six different retrieval method plus eight passage rerankers. I used gpt-4-turbo model to use ragas context precision, because using it on gpt-3.5-turbo have low performance. In context precision score, RAGAS score only have 0.7 human correlation with gpt-3.5-turbo. This result came from their &lt;a href=&quot;https://arxiv.org/pdf/2309.15217&quot;&gt;own paper&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;And it costs 700 dollar... only in OpenAI API. RAGAS context precision calls OpenAI API 50,000 times. Spending 700 dollar for optimizing one RAG dataset is ridiculous. I ended up to remove RAGAS context precision metric completely at AutoRAG.&lt;/p&gt; &lt;p&gt;Actually, RAGAS context precision can be useful when there are no retrieval gt passage in your dataset. However, do not recommend to use it for optimizing your retrieval system. There are perfectly better alternative. Information retreival metrics like F1, NDCG, or mAP. (This case you need to make retrieval gt passage dataset) In this way, it costs zero dollar, and much precise than using LLM for calculating context precision.&lt;/p&gt; &lt;p&gt;I hope my experience is helpful for someone to evaluate or optimize their retrieval system while making RAG.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jeffrey-0711&quot;&gt; /u/jeffrey-0711 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbmqii/i_spent_700_on_evaluating_100_rag_qa_set_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbmqii/i_spent_700_on_evaluating_100_rag_qa_set_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dbmqii</id><link href="https://www.reddit.com/r/LangChain/comments/1dbmqii/i_spent_700_on_evaluating_100_rag_qa_set_using/" /><updated>2024-06-09T05:55:09+00:00</updated><published>2024-06-09T05:55:09+00:00</published><title>I spent 700$ on evaluating 100 RAG QA set using RAGAS context precision.</title></entry><entry><author><name>/u/Sweaty-Minimum5423</name><uri>https://www.reddit.com/user/Sweaty-Minimum5423</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://youtu.be/b3XsvoFWp4c?si=2Y7eBx2_MobnzOno&quot;&gt;https://youtu.be/b3XsvoFWp4c?si=2Y7eBx2_MobnzOno&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Has anyone tried the multi agent workflow in the tutorial? I find that if the user query is only a single intent. It could route to the correct place and get the response without problem.&lt;/p&gt; &lt;p&gt;However, if the user query got multiple intent: like booking hotel and booking car at the same time: The agent in the booking hotel might think it has tool to book the car as well although it doesn’t, especially when car booking workflow and tool have been invoked before this multiple intent query. I’m guessing the problem is likely because all workflow can share state where some part of the state has the history of invoking car booking tool before. So the agent in hotel booking workflow sees it and think it also has this car booking tool.&lt;/p&gt; &lt;p&gt;Sometimes the flow might works when the hotel-booking agent answers the hotel booking part then invoke CompleteOrEscalate tool which is to pass the dialog back to the primary assistant and reroute the query again to car booking workflow.However, the CompleteOrEscalate tool is not properly invoked as the agent prefer invoking the imaginary tool as stated above.&lt;/p&gt; &lt;p&gt;They have added the entry node to help this problem but still it doesn’t work well at least for OpenAI GPT4. Is there an upgraded version Chatbot flow to solve this issue? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sweaty-Minimum5423&quot;&gt; /u/Sweaty-Minimum5423 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbzvk5/customer_bot_tutorial_issue/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbzvk5/customer_bot_tutorial_issue/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dbzvk5</id><link href="https://www.reddit.com/r/LangChain/comments/1dbzvk5/customer_bot_tutorial_issue/" /><updated>2024-06-09T18:00:58+00:00</updated><published>2024-06-09T18:00:58+00:00</published><title>Customer bot tutorial issue</title></entry><entry><author><name>/u/sundaysexisthebest</name><uri>https://www.reddit.com/user/sundaysexisthebest</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So obviously langchain was frowned upon by a lot of genAI devs, for being too abstract, confusing, over-complicating (and poor documentation ofc). I want some more recent opinion on this, maybe what’s the alternatives? Looking forward to hearing from people with actual LLM project experience. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sundaysexisthebest&quot;&gt; /u/sundaysexisthebest &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbw8dk/langchainlanggraph_critique_update/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbw8dk/langchainlanggraph_critique_update/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dbw8dk</id><link href="https://www.reddit.com/r/LangChain/comments/1dbw8dk/langchainlanggraph_critique_update/" /><updated>2024-06-09T15:22:52+00:00</updated><published>2024-06-09T15:22:52+00:00</published><title>Langchain/langgraph critique update?</title></entry><entry><author><name>/u/peenuty</name><uri>https://www.reddit.com/user/peenuty</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone 👋,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been working on &lt;a href=&quot;http://llm-ui.com&quot;&gt;llm-ui&lt;/a&gt;, an MIT open source library which allows developers to build custom UIs for LLM responses.&lt;/p&gt; &lt;p&gt;It operates on any LLM output, so should work nicely with LangChain&lt;/p&gt; &lt;p&gt;If anyone here is building custom UIs for LangChain I&amp;#39;d love to hear your thoughts.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;http://llm-ui.com&quot;&gt;llm-ui.com&lt;/a&gt;&lt;br/&gt; &lt;a href=&quot;https://github.com/llm-ui-kit/llm-ui&quot;&gt;https://github.com/llm-ui-kit/llm-ui&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/peenuty&quot;&gt; /u/peenuty &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbo39f/ui_library_for_langchain_output/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dbo39f/ui_library_for_langchain_output/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dbo39f</id><link href="https://www.reddit.com/r/LangChain/comments/1dbo39f/ui_library_for_langchain_output/" /><updated>2024-06-09T07:24:33+00:00</updated><published>2024-06-09T07:24:33+00:00</published><title>UI Library for LangChain output</title></entry></feed>