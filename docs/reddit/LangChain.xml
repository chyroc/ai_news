<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-21T09:47:33+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Vissidarte_2021</name><uri>https://www.reddit.com/user/Vissidarte_2021</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx0pqy/ocr_and_document_parsing_rag_engine_ragflow_v060/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/TE-1_AgX-OAAo1YOAgrT7H6HrjwTDsbIkrvCckmm9RY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=90306a1b43428e283da0b003ba5af50779f4c44e&quot; alt=&quot;OCR and document parsing RAG engine RAGFlow v0.6.0 released&quot; title=&quot;OCR and document parsing RAG engine RAGFlow v0.6.0 released&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Vissidarte_2021&quot;&gt; /u/Vissidarte_2021 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/infiniflow/ragflow&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx0pqy/ocr_and_document_parsing_rag_engine_ragflow_v060/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cx0pqy</id><media:thumbnail url="https://external-preview.redd.it/TE-1_AgX-OAAo1YOAgrT7H6HrjwTDsbIkrvCckmm9RY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=90306a1b43428e283da0b003ba5af50779f4c44e" /><link href="https://www.reddit.com/r/LangChain/comments/1cx0pqy/ocr_and_document_parsing_rag_engine_ragflow_v060/" /><updated>2024-05-21T05:50:18+00:00</updated><published>2024-05-21T05:50:18+00:00</published><title>OCR and document parsing RAG engine RAGFlow v0.6.0 released</title></entry><entry><author><name>/u/nocodeblackbox</name><uri>https://www.reddit.com/user/nocodeblackbox</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all, i&amp;#39;ve seen some mention&amp;#39;s around here briefly about comparing LangChain&amp;#39;s tooling (or even just building out your retrieval models yourself by removing abstractions) to the current state of assistant&amp;#39;s API (w/ v2)&lt;/p&gt; &lt;p&gt;At the time of release I could see why more leaned towards langhain&amp;#39;s framework, but with the recent advancements of assistant&amp;#39;s api (v2), including improved retrieval systems, new vector stores, as well as function calling via tool_choice. I&amp;#39;m really considering using their endpoint for a new project considering costs, latency, and retrieval system&amp;#39;s will get better over time.&lt;/p&gt; &lt;p&gt;I used LangChain&amp;#39;s Js framework when it first came out, and we sort of transitioned to creating our own functions to avoid some of the abstraction layers, but now it almost seems archaic to build your own. At least for the majority of use-cases I see. And of course, I could see cost as a factor here, considering assistants is significantly more expensive, especially if you&amp;#39;re using code interpreter, but you also have to consider the opportunity cost you&amp;#39;d save not building out your own tooling system. Definetly a cost trade-off to consider here for firms (and not just dev&amp;#39;s building their own projects).&lt;/p&gt; &lt;p&gt;So user&amp;#39;s of OpenAI model&amp;#39;s, I&amp;#39;d love to learn why you went one route or the other for some projects. Is it cost? quality of responses? latency? or just don&amp;#39;t like the idea of being vendor-locked to an api? All idea&amp;#39;s/statements are welcome. Genuinely trying to learn here.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nocodeblackbox&quot;&gt; /u/nocodeblackbox &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1ln4/langchain_framework_vs_new_assistants_api_with_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1ln4/langchain_framework_vs_new_assistants_api_with_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx1ln4</id><link href="https://www.reddit.com/r/LangChain/comments/1cx1ln4/langchain_framework_vs_new_assistants_api_with_rag/" /><updated>2024-05-21T06:51:41+00:00</updated><published>2024-05-21T06:51:41+00:00</published><title>LangChain Framework vs New Assistants API with RAG</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I see both ParentDocumentRetriever and Reranking as promising techniques for improving the RAG system. Has anyone tried to combine these two techniques, so first use the ParentDocumentRetreiver and then rerank the results, e.g. with ColBERT?&lt;/p&gt; &lt;p&gt;I think one limitation is the max_tokens of Colbert that do not fit to the retrieved, bigger chunks. One think would be to first rerank the smaller chunks, but I am not sure how to implement this with langchain.&lt;/p&gt; &lt;p&gt;But would be interesting to see which experiences you guys have.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx37pi/anyone_tried_parentdocumentretreiver_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx37pi/anyone_tried_parentdocumentretreiver_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx37pi</id><link href="https://www.reddit.com/r/LangChain/comments/1cx37pi/anyone_tried_parentdocumentretreiver_with/" /><updated>2024-05-21T08:48:46+00:00</updated><published>2024-05-21T08:48:46+00:00</published><title>Anyone tried ParentDocumentRetreiver with Reranking</title></entry><entry><author><name>/u/hwchase17</name><uri>https://www.reddit.com/user/hwchase17</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all! One of the constant things we&amp;#39;ve heard from the community here is a desire for better docs. We&amp;#39;ve spent a lot of time over the past two weeks overhauling the documentation for 0.2. Some things include: versioned docs, a conceptual guide, much simpler navigation and organization, &amp;quot;langchain over time&amp;quot;, etc&lt;/p&gt; &lt;p&gt;We wrote a blog going through some of these two things as well as our thought process: &lt;a href=&quot;https://blog.langchain.dev/documentation-refresh-for-langchain-v0-2/&quot;&gt;https://blog.langchain.dev/documentation-refresh-for-langchain-v0-2/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;We genuinely would love any feedback, no matter how small, on the new docs and ways to keep on improving them. A lot of the changes have been directly influenced by the community here - we really appreciate the feedback and ideas, so I hope you all know that :) Docs are a key focus of ours going forward, and we&amp;#39;ll be monitoring this thread pretty actively for ideas to implement!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hwchase17&quot;&gt; /u/hwchase17 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwkaq9/02_docs_refresh/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwkaq9/02_docs_refresh/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cwkaq9</id><link href="https://www.reddit.com/r/LangChain/comments/1cwkaq9/02_docs_refresh/" /><updated>2024-05-20T16:52:27+00:00</updated><published>2024-05-20T16:52:27+00:00</published><title>0.2 docs refresh</title></entry><entry><author><name>/u/Honest-Worth3677</name><uri>https://www.reddit.com/user/Honest-Worth3677</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1i6x/gpt4o_create_your_own_real_time_ai/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/J3cOD-xoF6Fj0wsFxTWIME-Z0MsLHNlRk2rrqAgfFiM.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fa98313e0770836c57adced6640b225cceebfafd&quot; alt=&quot;GPT-4o: Create your own Real time AI girlfriend/translator that talks ❤️ Crazy or Creepy?&quot; title=&quot;GPT-4o: Create your own Real time AI girlfriend/translator that talks ❤️ Crazy or Creepy?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Honest-Worth3677&quot;&gt; /u/Honest-Worth3677 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=2NFZdGj3jqk&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1i6x/gpt4o_create_your_own_real_time_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cx1i6x</id><media:thumbnail url="https://external-preview.redd.it/J3cOD-xoF6Fj0wsFxTWIME-Z0MsLHNlRk2rrqAgfFiM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa98313e0770836c57adced6640b225cceebfafd" /><link href="https://www.reddit.com/r/LangChain/comments/1cx1i6x/gpt4o_create_your_own_real_time_ai/" /><updated>2024-05-21T06:45:00+00:00</updated><published>2024-05-21T06:45:00+00:00</published><title>GPT-4o: Create your own Real time AI girlfriend/translator that talks ❤️ Crazy or Creepy?</title></entry><entry><author><name>/u/_stupendous_man_</name><uri>https://www.reddit.com/user/_stupendous_man_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have data in open search in multiple indices, each index with different schema.&lt;br/&gt; I have data at more granular level in open search. I need to aggregate the data and use aggregated data into RAG pipeline.&lt;/p&gt; &lt;p&gt;I am planning to use milvus as vector db but I am not able to finalise on what text should we create embeddings on.&lt;br/&gt; One open search index for example contains user website visits like&lt;br/&gt; ip_address, user_name, visited_url, website_type&lt;br/&gt; some other may contain user actions like&lt;br/&gt; ip_address, user_name, action [install/uninstall], command, details &lt;/p&gt; &lt;p&gt;from these different types of data in indices, i am planning to create different collections in vector db.&lt;br/&gt; what should i create embedding on in vector db ? &lt;/p&gt; &lt;p&gt;prompt should be able to answer like&lt;br/&gt; what all things observed from user ABC&lt;br/&gt; are there any install actions from by user who visited site like XYZ. &lt;/p&gt; &lt;p&gt;I can not use sql db for this as questions could be more natural search than just give me X where Y type of questions. &lt;/p&gt; &lt;p&gt;New to RAG, so not able to figure out how one embeddings perform betters others.&lt;br/&gt; One plan is to just append values of a record and build embedding on it.&lt;br/&gt; Other one is to create verbose text from the record and build embedding on it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/_stupendous_man_&quot;&gt; /u/_stupendous_man_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx264a/rag_on_multiple_structured_data_streams/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx264a/rag_on_multiple_structured_data_streams/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx264a</id><link href="https://www.reddit.com/r/LangChain/comments/1cx264a/rag_on_multiple_structured_data_streams/" /><updated>2024-05-21T07:30:14+00:00</updated><published>2024-05-21T07:30:14+00:00</published><title>RAG on multiple structured data streams.</title></entry><entry><author><name>/u/yasserius</name><uri>https://www.reddit.com/user/yasserius</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;LLM noob here, not sure how to build this or it probably already exists.&lt;/p&gt; &lt;p&gt;I am looking for a self-hosted LLM bot app that has custom trained knowledge from local text e.g. 10k epubs from arxiv but also can have access to google search API for finding the latest resources regarding a certain query e.g. &amp;quot;tell me the latest developments in stable diffusion models&amp;quot; and it should be able to go through the stable diffusion site and white papers to build a precise answer.&lt;/p&gt; &lt;p&gt;Obviously this LLM needs to be finetuned on the new data? e.g. 10k epubs?&lt;/p&gt; &lt;p&gt;But the google search API results need to be input into the context window so that it can use the info?&lt;/p&gt; &lt;p&gt;Ultimately this model should be runnable locally or on colab, without all the corporate censoring on chatgpt and gemini.&lt;/p&gt; &lt;p&gt;Please tell me if this exists already in langchain or some other repo, detailed links and guidelines would be the best (assume I have no LLM experience, but am an average python programmer.)&lt;/p&gt; &lt;p&gt;Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/yasserius&quot;&gt; /u/yasserius &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1tjp/llm_bots_that_have_current_knowledge_and_google/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1tjp/llm_bots_that_have_current_knowledge_and_google/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx1tjp</id><link href="https://www.reddit.com/r/LangChain/comments/1cx1tjp/llm_bots_that_have_current_knowledge_and_google/" /><updated>2024-05-21T07:05:53+00:00</updated><published>2024-05-21T07:05:53+00:00</published><title>LLM bots that have current knowledge and google search skills?</title></entry><entry><author><name>/u/No-Hat-9739</name><uri>https://www.reddit.com/user/No-Hat-9739</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, I&amp;#39;m looking to build a flexible, customizable, and high-performing chatbot using LangChain/LangGraph and LLM technology. I&amp;#39;m currently torn between two options: using the Vercel AI SDK with Next.js or Chainlit with Python. Which solution do you think is the best for building a chatbot today, considering factors like ease of use, scalability, and performance? Thanks in advance for your insights!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No-Hat-9739&quot;&gt; /u/No-Hat-9739 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1fdd/vercel_ai_sdk_vs_chainlit_for_chatbot_project/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx1fdd/vercel_ai_sdk_vs_chainlit_for_chatbot_project/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx1fdd</id><link href="https://www.reddit.com/r/LangChain/comments/1cx1fdd/vercel_ai_sdk_vs_chainlit_for_chatbot_project/" /><updated>2024-05-21T06:39:23+00:00</updated><published>2024-05-21T06:39:23+00:00</published><title>Vercel AI SDK vs chainlit for chatbot project</title></entry><entry><author><name>/u/iamgodot_</name><uri>https://www.reddit.com/user/iamgodot_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I&amp;#39;m trying to build RAG chain following this &lt;a href=&quot;https://js.langchain.com/v0.1/docs/expression_language/cookbook/retrieval/#conversational-retrieval-chain&quot;&gt;tutorial&lt;/a&gt;, and I&amp;#39;m using Vercel sdk for the streaming api and ui building. While I tried their support for Langchain &lt;a href=&quot;https://sdk.vercel.ai/providers/legacy-providers/langchain&quot;&gt;here&lt;/a&gt;, things didn&amp;#39;t work properly. There&amp;#39;s no error but not any response showing either. With the 2 packages mixed together, I&amp;#39;m not even sure where to debug, would really appreciate for some help, thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/iamgodot_&quot;&gt; /u/iamgodot_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx052b/how_to_stream_response_a_rag_chain_with_vercel_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cx052b/how_to_stream_response_a_rag_chain_with_vercel_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cx052b</id><link href="https://www.reddit.com/r/LangChain/comments/1cx052b/how_to_stream_response_a_rag_chain_with_vercel_ai/" /><updated>2024-05-21T05:12:10+00:00</updated><published>2024-05-21T05:12:10+00:00</published><title>How to stream response a RAG chain with Vercel ai sdk</title></entry><entry><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Do you know any applications that are built with LangChain? Let&amp;#39;s make a list. I&amp;#39;m wondering how well the tech has matured and how heavily is it used in production apps.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwmp22/products_built_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwmp22/products_built_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cwmp22</id><link href="https://www.reddit.com/r/LangChain/comments/1cwmp22/products_built_with_langchain/" /><updated>2024-05-20T18:31:59+00:00</updated><published>2024-05-20T18:31:59+00:00</published><title>Products built with LangChain</title></entry><entry><author><name>/u/Front-Show7358</name><uri>https://www.reddit.com/user/Front-Show7358</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello all. Disclaimer I&amp;#39;m a total newbie. Disclaimer 2 the user base is trusted so no need to fear about the dangers of implementing this for something like a public facing customer support bot.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve got a RAG chatbot trained on some long PDFs (user manuals and stuff like that). One feature I&amp;#39;d like to implement is the ability for the user to correct the response given by the model, and for the model to learn from that.&lt;br/&gt; One very hacky idea I had was to use few-shot prompting and every time a user makes a correction, update the system prompt with the question and corrected answer. The user base for this bot would be very small, but still this idea seems kind of terrible lol.&lt;/p&gt; &lt;p&gt;Links to any resources where I can learn more would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Front-Show7358&quot;&gt; /u/Front-Show7358 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwk82e/chatbot_that_can_be_corrected_by_users/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwk82e/chatbot_that_can_be_corrected_by_users/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cwk82e</id><link href="https://www.reddit.com/r/LangChain/comments/1cwk82e/chatbot_that_can_be_corrected_by_users/" /><updated>2024-05-20T16:49:17+00:00</updated><published>2024-05-20T16:49:17+00:00</published><title>chatbot that can be corrected by users</title></entry><entry><author><name>/u/esmussein_</name><uri>https://www.reddit.com/user/esmussein_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I am currently building a location search assistant which, given an image or its textual description, retrieves the top k most similar locations by performing a multimodal RAG with langchain and chromaDB. While it seems pretty standard, I have been thinking about the different ways by which this kind RAG can be achieved. Specifically, I am thinking between:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;Embedding images and location description, separately, by using CLIP and GPT-4, respectively. To keep track of the location, I would include the corresponding location metadata during the insert&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Employing GPT-4 vision model to provide a summary description of a location given all their images and store it together with the location description as one textual embedding&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The first approach looks more precise to me since performing storing the summary description of multiple images would encounter a loss of details. On the other side, it is still unclear to me how to handle scenarios in which users perform searching with both text and and image: which domain (vision or textual) would be preferred to retrieve the most similar locations?&lt;/p&gt; &lt;p&gt;Am I missing something? What would you suggest in this case?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/esmussein_&quot;&gt; /u/esmussein_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwpoc1/multimodal_rag_with_text_and_images_vs_textual/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwpoc1/multimodal_rag_with_text_and_images_vs_textual/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cwpoc1</id><link href="https://www.reddit.com/r/LangChain/comments/1cwpoc1/multimodal_rag_with_text_and_images_vs_textual/" /><updated>2024-05-20T20:33:43+00:00</updated><published>2024-05-20T20:33:43+00:00</published><title>Multimodal RAG with text and images vs textual embeddings of images</title></entry><entry><author><name>/u/Kooky_Impression9575</name><uri>https://www.reddit.com/user/Kooky_Impression9575</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw9ft2/tutorial_to_get_started_with_fastapi_and/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/y5cgfLGf7bWy1SRl8eB3f87PaPs8s_pKmip6Z9NHVgQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=56cf4a5c1cb79cd1c4f1d214042f1b963ac6fc73&quot; alt=&quot;Tutorial to get started with FastAPI and Langchain ChromaDB&quot; title=&quot;Tutorial to get started with FastAPI and Langchain ChromaDB&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Kooky_Impression9575&quot;&gt; /u/Kooky_Impression9575 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://medium.com/gitconnected/building-vector-databases-with-fastapi-and-chromadb-0a1cd96fab08&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw9ft2/tutorial_to_get_started_with_fastapi_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cw9ft2</id><media:thumbnail url="https://external-preview.redd.it/y5cgfLGf7bWy1SRl8eB3f87PaPs8s_pKmip6Z9NHVgQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=56cf4a5c1cb79cd1c4f1d214042f1b963ac6fc73" /><link href="https://www.reddit.com/r/LangChain/comments/1cw9ft2/tutorial_to_get_started_with_fastapi_and/" /><updated>2024-05-20T07:06:14+00:00</updated><published>2024-05-20T07:06:14+00:00</published><title>Tutorial to get started with FastAPI and Langchain ChromaDB</title></entry><entry><author><name>/u/Independent-Bat1553</name><uri>https://www.reddit.com/user/Independent-Bat1553</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Everyone, &lt;/p&gt; &lt;p&gt;At Libra we&amp;#39;re building AI agents capable of executing entire litigation workflows autonomously. &lt;a href=&quot;http://libratech.ai/&quot;&gt;Libra&lt;/a&gt; is a seed stage company with a few pilot enterprise customers. At the moment we&amp;#39;re a team of 5 based in Berlin and raised a $1M pre-seed round. We&amp;#39;re looking for a full-stack engineer to join us full-time onsite/hybrid. If you&amp;#39;re excited about building the future of litigation, apply &lt;a href=&quot;https://www.linkedin.com/jobs/view/3913562327&quot;&gt;here&lt;/a&gt; or reach out [directly](mailto:&lt;a href=&quot;mailto:viktors@libratech.ai&quot;&gt;viktors@libratech.ai&lt;/a&gt;)!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Independent-Bat1553&quot;&gt; /u/Independent-Bat1553 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwg46f/looking_for_fullstack_engineer_legal_ai_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwg46f/looking_for_fullstack_engineer_legal_ai_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cwg46f</id><link href="https://www.reddit.com/r/LangChain/comments/1cwg46f/looking_for_fullstack_engineer_legal_ai_agents/" /><updated>2024-05-20T13:52:09+00:00</updated><published>2024-05-20T13:52:09+00:00</published><title>Looking for full-stack engineer | Legal AI Agents | Libra | Berlin, Germany</title></entry><entry><author><name>/u/HomunMage</name><uri>https://www.reddit.com/user/HomunMage</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwdflb/anyone_want_to_join_to_dev_node_based_visualized/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/90TUmwmgt2MagXVEpNYJfMuEHBeCJAO1cB5n11-aEqM.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9c6420a5634a87440c8122d26c1ddcc3b32e3f93&quot; alt=&quot;Anyone want to join to dev node based visualized editor for LangGraph?&quot; title=&quot;Anyone want to join to dev node based visualized editor for LangGraph?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HomunMage&quot;&gt; /u/HomunMage &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/crewai/comments/1cvhip4/i_made_a_gui_for_crewai_node_based_visualized/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwdflb/anyone_want_to_join_to_dev_node_based_visualized/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cwdflb</id><media:thumbnail url="https://external-preview.redd.it/90TUmwmgt2MagXVEpNYJfMuEHBeCJAO1cB5n11-aEqM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9c6420a5634a87440c8122d26c1ddcc3b32e3f93" /><link href="https://www.reddit.com/r/LangChain/comments/1cwdflb/anyone_want_to_join_to_dev_node_based_visualized/" /><updated>2024-05-20T11:38:21+00:00</updated><published>2024-05-20T11:38:21+00:00</published><title>Anyone want to join to dev node based visualized editor for LangGraph?</title></entry><entry><author><name>/u/leminhnguyenai</name><uri>https://www.reddit.com/user/leminhnguyenai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have tried to learn LangChain both on Python and Javascript, and from what I learnt, I can tell that Javascript is not supported as much as Python, but also I haven&amp;#39;t really use it enough to really know the limit, so my question is how much is a gap between javascript and python with langchain &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/leminhnguyenai&quot;&gt; /u/leminhnguyenai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwc0vx/javascript_vs_python/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cwc0vx/javascript_vs_python/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cwc0vx</id><link href="https://www.reddit.com/r/LangChain/comments/1cwc0vx/javascript_vs_python/" /><updated>2024-05-20T10:12:06+00:00</updated><published>2024-05-20T10:12:06+00:00</published><title>Javascript vs Python</title></entry><entry><author><name>/u/UpvoteBeast</name><uri>https://www.reddit.com/user/UpvoteBeast</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw8d4m/becoming_an_ai_utility_function_exercise_part_1/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/NBvvOm-AFhX8B-nd4qegFfO5W_7GQyxKzC0f1mErdl0.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=014348137f2ff002fa2778a0c83126c5cefc3d10&quot; alt=&quot;Becoming an AI Utility Function Exercise – Part 1&quot; title=&quot;Becoming an AI Utility Function Exercise – Part 1&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpvoteBeast&quot;&gt; /u/UpvoteBeast &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://dly.to/IOYpYpBZc55&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw8d4m/becoming_an_ai_utility_function_exercise_part_1/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cw8d4m</id><media:thumbnail url="https://external-preview.redd.it/NBvvOm-AFhX8B-nd4qegFfO5W_7GQyxKzC0f1mErdl0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=014348137f2ff002fa2778a0c83126c5cefc3d10" /><link href="https://www.reddit.com/r/LangChain/comments/1cw8d4m/becoming_an_ai_utility_function_exercise_part_1/" /><updated>2024-05-20T05:51:11+00:00</updated><published>2024-05-20T05:51:11+00:00</published><title>Becoming an AI Utility Function Exercise – Part 1</title></entry><entry><author><name>/u/psy_slayer</name><uri>https://www.reddit.com/user/psy_slayer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey! I&amp;#39;m facing issues in connecting custom frontend with dialogflow cx API (detect_intent), while trying to get parameter input in dialogflowcx. Has anybody worked on this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/psy_slayer&quot;&gt; /u/psy_slayer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw89go/dialogflow_cx_with_custom_frontend/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw89go/dialogflow_cx_with_custom_frontend/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cw89go</id><link href="https://www.reddit.com/r/LangChain/comments/1cw89go/dialogflow_cx_with_custom_frontend/" /><updated>2024-05-20T05:44:10+00:00</updated><published>2024-05-20T05:44:10+00:00</published><title>Dialogflow cx with custom frontend</title></entry><entry><author><name>/u/bwenneker</name><uri>https://www.reddit.com/user/bwenneker</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to match photos of official letters (printed, not handwritten) with one template of that same letter in PDF format from a whole set of template PDFs. One of the templates contains roughly the same text, but features like salutations are different.&lt;/p&gt; &lt;p&gt;I was thinking of:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;1. Creating embeddings of the photo and PDF and then doing a similarity search. 2. Converting the photo and templates to text and comparing them at the sentence level. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The easiest would be if the photo and template had a QR code, but that’s not possible.&lt;/p&gt; &lt;p&gt;Any help is greatly appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bwenneker&quot;&gt; /u/bwenneker &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw9hco/how_to_match_a_photo_of_a_printed_letter_with_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw9hco/how_to_match_a_photo_of_a_printed_letter_with_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cw9hco</id><link href="https://www.reddit.com/r/LangChain/comments/1cw9hco/how_to_match_a_photo_of_a_printed_letter_with_a/" /><updated>2024-05-20T07:09:21+00:00</updated><published>2024-05-20T07:09:21+00:00</published><title>How to match a photo of a printed letter with a template pdf with almost the same text</title></entry><entry><author><name>/u/Hot-Finger-1340</name><uri>https://www.reddit.com/user/Hot-Finger-1340</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using Open ai Api to stream the answer , I want to replicate the Stop generation function as in the chatgpt interface , can someone help me with how to stop token generation and not just streaming.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Hot-Finger-1340&quot;&gt; /u/Hot-Finger-1340 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw8j5z/how_to_stop_token_generation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw8j5z/how_to_stop_token_generation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cw8j5z</id><link href="https://www.reddit.com/r/LangChain/comments/1cw8j5z/how_to_stop_token_generation/" /><updated>2024-05-20T06:02:32+00:00</updated><published>2024-05-20T06:02:32+00:00</published><title>How to stop token Generation</title></entry><entry><author><name>/u/WolvesOfAllStreets</name><uri>https://www.reddit.com/user/WolvesOfAllStreets</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I noticed many LLM observability and monitoring tools are launched every week or so now. Are these tools actually used by real startups and companies, or are they more like &amp;quot;solutions in search of a problem&amp;quot;?&lt;/p&gt; &lt;p&gt;These tools seem to do one or a combination of the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;monitor LLM inputs and outputs&lt;/strong&gt; for prompt injection, adversarial attacks, profanity, off-topic content, etc&lt;/li&gt; &lt;li&gt;&lt;strong&gt;monitor LLM metrics over time&lt;/strong&gt; use such as cost, latency, readability, output length, custom metrics (tone, mood, etc), drift&lt;/li&gt; &lt;li&gt;&lt;strong&gt;prompt management&lt;/strong&gt; including a/b testing, versioning, a gold standard set&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;What have you observed? Do companies that have their own LLM-powered features or products use these monitoring tools?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/WolvesOfAllStreets&quot;&gt; /u/WolvesOfAllStreets &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw0mkt/are_llm_observability_tools_solutions_in_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw0mkt/are_llm_observability_tools_solutions_in_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cw0mkt</id><link href="https://www.reddit.com/r/LangChain/comments/1cw0mkt/are_llm_observability_tools_solutions_in_search/" /><updated>2024-05-19T22:47:35+00:00</updated><published>2024-05-19T22:47:35+00:00</published><title>Are LLM observability tools solutions in search of a problem?</title></entry><entry><author><name>/u/Emcf</name><uri>https://www.reddit.com/user/Emcf</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;see title &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Emcf&quot;&gt; /u/Emcf &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw61uj/is_there_a_standardizedoptimal_way_to_do_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cw61uj/is_there_a_standardizedoptimal_way_to_do_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cw61uj</id><link href="https://www.reddit.com/r/LangChain/comments/1cw61uj/is_there_a_standardizedoptimal_way_to_do_rag/" /><updated>2024-05-20T03:27:19+00:00</updated><published>2024-05-20T03:27:19+00:00</published><title>Is there a standardized/optimal way to do RAG context expansion?</title></entry><entry><author><name>/u/Melodic_Roll_2386</name><uri>https://www.reddit.com/user/Melodic_Roll_2386</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, Langchain community! I wanna talk about a project I&amp;#39;m working on and wanted to know if it&amp;#39;s possible to do and if thats the best way of doing it. Resources that can help me would be quite welcome!&lt;/p&gt; &lt;p&gt;What I have regarding this API project is the &lt;a href=&quot;http://app.py&quot;&gt;app.py&lt;/a&gt; here &lt;a href=&quot;https://github.com/Briqz23/Interactive_RAG_e-book/blob/main/agentapi/app.py&quot;&gt;https://github.com/Briqz23/Interactive_RAG_e-book/blob/main/agentapi/app.py&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Project Idea: An e-book where users can interact with the characters.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Current Implementation:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;API endpoint: /character_id/user_input&lt;/li&gt; &lt;li&gt;Data sources and tools: &lt;ul&gt; &lt;li&gt; FAISS DB with the book&amp;#39;s PDF embedded and a retriever for it&lt;/li&gt; &lt;li&gt; Tools in the toolkit include:&lt;/li&gt; &lt;li&gt;WikipediaQueryRun&lt;/li&gt; &lt;li&gt; ArxivQueryRun&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt; An agent uses OpenAI LLM, all the tools, and the contextualize_q_prompt to select the best answer.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Objective:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;When the agent retrieves an answer from WikipediaQueryRun or ArxivQueryRun, it does not follow the instruction to behave as the specified character. I want to resolve this issue and implement another agent to check for hallucinations or ensure it behaves correctly. I am using a Langchain agent but intend to use a CrewAI agent.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Challenges:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I am struggling to implement the chat_history feature in more complex scenarios, especially with the FastAPI API.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;End Goal:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Create an API that processes user input and chat history. The input goes to an agent that queries various sources for the best answer. Another agent verifies the response&amp;#39;s accuracy before the API returns the final answer.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Melodic_Roll_2386&quot;&gt; /u/Melodic_Roll_2386 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cvosry/what_are_my_possibilities_here_in_my_project/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cvosry/what_are_my_possibilities_here_in_my_project/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cvosry</id><link href="https://www.reddit.com/r/LangChain/comments/1cvosry/what_are_my_possibilities_here_in_my_project/" /><updated>2024-05-19T13:53:39+00:00</updated><published>2024-05-19T13:53:39+00:00</published><title>What are my possibilities here in my project?</title></entry><entry><author><name>/u/jdogbro12</name><uri>https://www.reddit.com/user/jdogbro12</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cvqo11/how_many_samples_are_necessary_to_achieve_good/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/7b1L1YqNUq7jkFKzx8gv6rubIZxHwnOisReL56kCqxY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6b44f854e12a234cd3b122c7a91ca541b1128e88&quot; alt=&quot;How many samples are necessary to achieve good RAG performance with DSPy?&quot; title=&quot;How many samples are necessary to achieve good RAG performance with DSPy?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jdogbro12&quot;&gt; /u/jdogbro12 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://docs.parea.ai/tutorials/dspy-rag-trace-evaluate/tutorial&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cvqo11/how_many_samples_are_necessary_to_achieve_good/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cvqo11</id><media:thumbnail url="https://external-preview.redd.it/7b1L1YqNUq7jkFKzx8gv6rubIZxHwnOisReL56kCqxY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6b44f854e12a234cd3b122c7a91ca541b1128e88" /><link href="https://www.reddit.com/r/LangChain/comments/1cvqo11/how_many_samples_are_necessary_to_achieve_good/" /><updated>2024-05-19T15:20:51+00:00</updated><published>2024-05-19T15:20:51+00:00</published><title>How many samples are necessary to achieve good RAG performance with DSPy?</title></entry><entry><author><name>/u/kasikciozan</name><uri>https://www.reddit.com/user/kasikciozan</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;So yeah i want the agent to automatically save data, for example, my name, birthday, my friends, emails, events, stuff like that.&lt;/p&gt; &lt;p&gt;How can I do that, any suggestions would be welcomed!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kasikciozan&quot;&gt; /u/kasikciozan &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cvlhjx/i_want_my_agent_to_identify_and_save/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cvlhjx/i_want_my_agent_to_identify_and_save/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cvlhjx</id><link href="https://www.reddit.com/r/LangChain/comments/1cvlhjx/i_want_my_agent_to_identify_and_save/" /><updated>2024-05-19T10:46:26+00:00</updated><published>2024-05-19T10:46:26+00:00</published><title>I want my agent to identify and save important/personal/relevant information to mongodb as i talk to it.</title></entry></feed>