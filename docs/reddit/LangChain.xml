<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-06-01T19:45:52+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/rmanoj_11</name><uri>https://www.reddit.com/user/rmanoj_11</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, I am new to building RAG application. I have no idea about how to make the LLM to answer with all the knowledge about 1000s of articles. Let&amp;#39;s say I have 1000s of success stories about various businesses, now I want LLM to craft a winning strategy.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rmanoj_11&quot;&gt; /u/rmanoj_11 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5slpr/how_can_i_get_cumulative_answer_after_analysing/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5slpr/how_can_i_get_cumulative_answer_after_analysing/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5slpr</id><link href="https://www.reddit.com/r/LangChain/comments/1d5slpr/how_can_i_get_cumulative_answer_after_analysing/" /><updated>2024-06-01T17:50:56+00:00</updated><published>2024-06-01T17:50:56+00:00</published><title>How can I get cumulative answer after analysing 1000s of articles?</title></entry><entry><author><name>/u/noodleswind</name><uri>https://www.reddit.com/user/noodleswind</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sx4v/how_would_you_design_the_supervisor_in_the/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/qbhzq8tt204d1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=efd0dcd8ba05ea5558dec93d893e8b3da6b7734b&quot; alt=&quot;How would you design the supervisor in the following diagram?&quot; title=&quot;How would you design the supervisor in the following diagram?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/noodleswind&quot;&gt; /u/noodleswind &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/qbhzq8tt204d1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sx4v/how_would_you_design_the_supervisor_in_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d5sx4v</id><media:thumbnail url="https://preview.redd.it/qbhzq8tt204d1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=efd0dcd8ba05ea5558dec93d893e8b3da6b7734b" /><link href="https://www.reddit.com/r/LangChain/comments/1d5sx4v/how_would_you_design_the_supervisor_in_the/" /><updated>2024-06-01T18:05:04+00:00</updated><published>2024-06-01T18:05:04+00:00</published><title>How would you design the supervisor in the following diagram?</title></entry><entry><author><name>/u/trj_flash75</name><uri>https://www.reddit.com/user/trj_flash75</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Fast LLM RAG inference using Groq and Langchain Streaming. &lt;/p&gt; &lt;p&gt;Groq is introducing a new, simpler processing architecture designed specifically for the performance requirements of machine learning applications and other compute-intensive workloads. The simpler hardware also saves developer resources by eliminating the need for profiling, and also makes it easier to deploy AI solutions at scale. &lt;/p&gt; &lt;p&gt;Resource: &lt;a href=&quot;https://www.youtube.com/watch?v=frMdOL8knqg&quot;&gt;https://www.youtube.com/watch?v=frMdOL8knqg&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/trj_flash75&quot;&gt; /u/trj_flash75 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sb5s/faster_llm_inference_using_groq_and_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sb5s/faster_llm_inference_using_groq_and_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5sb5s</id><link href="https://www.reddit.com/r/LangChain/comments/1d5sb5s/faster_llm_inference_using_groq_and_langchain/" /><updated>2024-06-01T17:37:25+00:00</updated><published>2024-06-01T17:37:25+00:00</published><title>Faster LLM Inference using Groq and Langchain Streaming</title></entry><entry><author><name>/u/Long_Respond1735</name><uri>https://www.reddit.com/user/Long_Respond1735</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;anyone used langchain with browser automation and gpt4o?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Long_Respond1735&quot;&gt; /u/Long_Respond1735 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sc9r/langchain_with_vision_browser/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sc9r/langchain_with_vision_browser/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5sc9r</id><link href="https://www.reddit.com/r/LangChain/comments/1d5sc9r/langchain_with_vision_browser/" /><updated>2024-06-01T17:38:51+00:00</updated><published>2024-06-01T17:38:51+00:00</published><title>langchain with vision browser</title></entry><entry><author><name>/u/i_am_innovative</name><uri>https://www.reddit.com/user/i_am_innovative</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;No Body &lt;/p&gt; &lt;p&gt;I guess you understood what is mean..&lt;/p&gt; &lt;p&gt;out of these i only knew about LlamaCpp&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/i_am_innovative&quot;&gt; /u/i_am_innovative &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5qcgw/what_are_the_different_ways_we_can_load_llama/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5qcgw/what_are_the_different_ways_we_can_load_llama/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5qcgw</id><link href="https://www.reddit.com/r/LangChain/comments/1d5qcgw/what_are_the_different_ways_we_can_load_llama/" /><updated>2024-06-01T16:06:13+00:00</updated><published>2024-06-01T16:06:13+00:00</published><title>What are the different ways we can load llama model into Langchain ?</title></entry><entry><author><name>/u/ruhelaji</name><uri>https://www.reddit.com/user/ruhelaji</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can anyone explain me parameters of this function some of the parameters is &amp;quot;structured_query_translator&amp;quot;, &amp;quot;chain_kwargs&amp;quot;, &amp;quot;enable_limit&amp;quot;, &amp;quot;kwargs&amp;quot;. Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ruhelaji&quot;&gt; /u/ruhelaji &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5lhsg/selfqueryretrieverfrom_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5lhsg/selfqueryretrieverfrom_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5lhsg</id><link href="https://www.reddit.com/r/LangChain/comments/1d5lhsg/selfqueryretrieverfrom_llm/" /><updated>2024-06-01T12:04:48+00:00</updated><published>2024-06-01T12:04:48+00:00</published><title>selfqueryretriever.from_llm()</title></entry><entry><author><name>/u/sks8100</name><uri>https://www.reddit.com/user/sks8100</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Have any of you successfully deployed langchain in prod? As in actually getting money for a saas business of some sort? Tell me your experience? Whats your usecase and what Lang product did you use? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sks8100&quot;&gt; /u/sks8100 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d521s1/have_you_gone_to_prod/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d521s1/have_you_gone_to_prod/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d521s1</id><link href="https://www.reddit.com/r/LangChain/comments/1d521s1/have_you_gone_to_prod/" /><updated>2024-05-31T18:06:27+00:00</updated><published>2024-05-31T18:06:27+00:00</published><title>Have you gone to prod?</title></entry><entry><author><name>/u/Loh_</name><uri>https://www.reddit.com/user/Loh_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a RAG system with a Vector DB (Miley’s) everything is working fine. However now the business want to summarize and translate the documents inside our Knowledge Base. So, we know how to summarize the documents or translate it, the problem is how I will take that decision from a query from the user? Do we need to use agents or some Router?&lt;/p&gt; &lt;p&gt;How are you doing it? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Loh_&quot;&gt; /u/Loh_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d59ax3/rag_decisión/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d59ax3/rag_decisión/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d59ax3</id><link href="https://www.reddit.com/r/LangChain/comments/1d59ax3/rag_decisión/" /><updated>2024-05-31T23:28:31+00:00</updated><published>2024-05-31T23:28:31+00:00</published><title>RAG Decisión</title></entry><entry><author><name>/u/CodebuddyGuy</name><uri>https://www.reddit.com/user/CodebuddyGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I followed the tutorial on langchain for 0.2 for setting up Typesense but it just won&amp;#39;t find it.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://i.imgur.com/8yPyU90.png&quot;&gt;https://i.imgur.com/8yPyU90.png&lt;/a&gt;&lt;/p&gt; &lt;p&gt;My package.json looks like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;{ &amp;quot;name&amp;quot;: &amp;quot;vite-react-typescript-starter&amp;quot;, &amp;quot;private&amp;quot;: true, &amp;quot;version&amp;quot;: &amp;quot;0.0.1&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;module&amp;quot;, &amp;quot;scripts&amp;quot;: { &amp;quot;dev&amp;quot;: &amp;quot;nodemon -w src/server -x tsx src/server/main.ts&amp;quot;, &amp;quot;start&amp;quot;: &amp;quot;cross-env NODE_ENV=production tsx src/server/main.ts&amp;quot;, &amp;quot;build&amp;quot;: &amp;quot;vite build&amp;quot;, &amp;quot;test&amp;quot;: &amp;quot;vitest&amp;quot; }, &amp;quot;dependencies&amp;quot;: { &amp;quot;@langchain/community&amp;quot;: &amp;quot;^0.2.4&amp;quot;, &amp;quot;@langchain/openai&amp;quot;: &amp;quot;^0.1.0&amp;quot;, &amp;quot;@langchain/weaviate&amp;quot;: &amp;quot;^0.0.4&amp;quot;, &amp;quot;cross-env&amp;quot;: &amp;quot;^7.0.3&amp;quot;, &amp;quot;dotenv&amp;quot;: &amp;quot;^16.4.5&amp;quot;, &amp;quot;express&amp;quot;: &amp;quot;^4.18.2&amp;quot;, &amp;quot;langchain&amp;quot;: &amp;quot;^0.1.0&amp;quot;, &amp;quot;puppeteer&amp;quot;: &amp;quot;^19.11.1&amp;quot;, &amp;quot;react&amp;quot;: &amp;quot;^18.2.0&amp;quot;, &amp;quot;react-dom&amp;quot;: &amp;quot;^18.2.0&amp;quot;, &amp;quot;tsx&amp;quot;: &amp;quot;^4.3.0&amp;quot;, &amp;quot;typescript&amp;quot;: &amp;quot;^5.3.2&amp;quot;, &amp;quot;typesense&amp;quot;: &amp;quot;^1.8.2&amp;quot;, &amp;quot;vite-express&amp;quot;: &amp;quot;*&amp;quot;, &amp;quot;weaviate&amp;quot;: &amp;quot;^0.0.14&amp;quot;, &amp;quot;weaviate-ts-client&amp;quot;: &amp;quot;^2.2.0&amp;quot; }, &amp;quot;devDependencies&amp;quot;: { &amp;quot;@types/express&amp;quot;: &amp;quot;^4.17.21&amp;quot;, &amp;quot;@types/node&amp;quot;: &amp;quot;^20.9.3&amp;quot;, &amp;quot;@types/react&amp;quot;: &amp;quot;^18.0.38&amp;quot;, &amp;quot;@types/react-dom&amp;quot;: &amp;quot;^18.2.16&amp;quot;, &amp;quot;@vitejs/plugin-react&amp;quot;: &amp;quot;^4.2.0&amp;quot;, &amp;quot;nodemon&amp;quot;: &amp;quot;^3.0.1&amp;quot;, &amp;quot;vite&amp;quot;: &amp;quot;^5.0.2&amp;quot;, &amp;quot;vitest&amp;quot;: &amp;quot;^1.6.0&amp;quot; } } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Am I missing something?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CodebuddyGuy&quot;&gt; /u/CodebuddyGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5bnf8/was_typesense_removed_from_langchainjs_02_it/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5bnf8/was_typesense_removed_from_langchainjs_02_it/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5bnf8</id><link href="https://www.reddit.com/r/LangChain/comments/1d5bnf8/was_typesense_removed_from_langchainjs_02_it/" /><updated>2024-06-01T01:28:42+00:00</updated><published>2024-06-01T01:28:42+00:00</published><title>Was Typesense removed from LangchainJS 0.2? It</title></entry><entry><author><name>/u/sks8100</name><uri>https://www.reddit.com/user/sks8100</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I find langchain interesting to use as I’ve build some initial small pet projects off it but a lot of learning has been done by reading articles and watching some videos. Watching anything put out by landchain is far too complex. They just dump blocks of code and following it is an absolute headache &lt;/p&gt; &lt;p&gt;Are you guys funding the same issue? Also are there any solid langgraph examples where people are using agents and tools to get sql data from a Postgres database? Any examples would be appreciated &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sks8100&quot;&gt; /u/sks8100 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4lwt0/am_i_the_only_one_who_feels_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4lwt0/am_i_the_only_one_who_feels_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4lwt0</id><link href="https://www.reddit.com/r/LangChain/comments/1d4lwt0/am_i_the_only_one_who_feels_langgraph/" /><updated>2024-05-31T03:15:05+00:00</updated><published>2024-05-31T03:15:05+00:00</published><title>Am I the only one who feels LangGraph documentation and tutorials by lanfchain absolutely suck?</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am facing an issue of agent not being able to pick the appropriate tool for the appropriate response?&lt;/p&gt; &lt;p&gt;Need to find better ways to evaluate my prompts. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d53me9/best_resources_on_evaluation_agents_and_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d53me9/best_resources_on_evaluation_agents_and_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d53me9</id><link href="https://www.reddit.com/r/LangChain/comments/1d53me9/best_resources_on_evaluation_agents_and_tools/" /><updated>2024-05-31T19:13:12+00:00</updated><published>2024-05-31T19:13:12+00:00</published><title>Best resources on Evaluation / Agents and Tools</title></entry><entry><author><name>/u/AnEdgeLordWeeb</name><uri>https://www.reddit.com/user/AnEdgeLordWeeb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! Does anyone have any idea as to how I can stream &lt;strong&gt;ONLY&lt;/strong&gt; the last message (which should also be the response received by the user) generated by my sequence of agents? I&amp;#39;m trying to build an UI for my LangGraph chatbot using Chainlit, but with the condition of only streaming the part of the message that I want to be displayed. Can anyone help me with that, please? Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnEdgeLordWeeb&quot;&gt; /u/AnEdgeLordWeeb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d54v75/how_to_stream_the_last_message_final_response_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d54v75/how_to_stream_the_last_message_final_response_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d54v75</id><link href="https://www.reddit.com/r/LangChain/comments/1d54v75/how_to_stream_the_last_message_final_response_in/" /><updated>2024-05-31T20:07:19+00:00</updated><published>2024-05-31T20:07:19+00:00</published><title>How to stream the last message (final response) in LangGraph?</title></entry><entry><author><name>/u/Fluffy_Gur7742</name><uri>https://www.reddit.com/user/Fluffy_Gur7742</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi&lt;/p&gt; &lt;p&gt;I am trying to develop log analysis tool using llms&lt;/p&gt; &lt;p&gt;My requirements are as follows:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;It should extract and find failure lines having some pattern specified in the prompt.&lt;/li&gt; &lt;li&gt;It should load the image of given path from the logs.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Can some please guide how can I create RAG for this data and extract using llm?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fluffy_Gur7742&quot;&gt; /u/Fluffy_Gur7742 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4tmdo/log_analyzer_using_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4tmdo/log_analyzer_using_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4tmdo</id><link href="https://www.reddit.com/r/LangChain/comments/1d4tmdo/log_analyzer_using_llm/" /><updated>2024-05-31T11:44:48+00:00</updated><published>2024-05-31T11:44:48+00:00</published><title>log analyzer using llm</title></entry><entry><author><name>/u/NexWolff</name><uri>https://www.reddit.com/user/NexWolff</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using Langchain&amp;#39;s SQL Agent to execute queries in natural language on my MS-SQL database. Here is my code:&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.agent_toolkits import create_sql_agent&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_openai import ChatOpenAI&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.utilities import SQLDatabase&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;import os&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;db = SQLDatabase.from_uri(&amp;quot;mssql+pyodbc:///?odbc_connect=DRIVER={ODBC Driver 17 for SQL Server};SERVER=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;model_name = &amp;quot;gpt-4&amp;quot;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;openai_api_key = os.environ[&amp;quot;OPENAI_API_KEY&amp;quot;]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;llm = ChatOpenAI(model_name=model_name, temperature=0.0)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;agent = create_sql_agent(llm, db=db, agent_type=&amp;quot;openai-tools&amp;quot;, verbose=True)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;agent.invoke({&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;&amp;quot;input&amp;quot;: &amp;quot;How many article are there?&amp;quot;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;})&lt;/code&gt;&lt;/p&gt; &lt;p&gt;When I run this, the agent starts hallucinating and tries to access a table named &amp;quot;article,&amp;quot; which does not exist. The verbose parameter shows that it should retrieve all tables in the database, but it does not get the correct tables. What could be the issue?&lt;/p&gt; &lt;p&gt;Additionally, I would like to provide metadata to explain the individual tables, but the &amp;quot;metadata&amp;quot; parameter is not accepted.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/NexWolff&quot;&gt; /u/NexWolff &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4y683/cant_retrieve_tables_and_how_can_i_pass_metadata/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4y683/cant_retrieve_tables_and_how_can_i_pass_metadata/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4y683</id><link href="https://www.reddit.com/r/LangChain/comments/1d4y683/cant_retrieve_tables_and_how_can_i_pass_metadata/" /><updated>2024-05-31T15:21:28+00:00</updated><published>2024-05-31T15:21:28+00:00</published><title>Cant retrieve tables and how can i pass metadata?</title></entry><entry><author><name>/u/mr_house7</name><uri>https://www.reddit.com/user/mr_house7</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m using Langchain with LLama.cpp-python because it I was the fastest solution I found out.&lt;/p&gt; &lt;p&gt;I notice an issue on Llama.cpp github that stated that LLama.cpp-python is significantly slower than the original LLama.cpp, which I found to be true, at least for the tests I ran.&lt;/p&gt; &lt;p&gt;I was wondering if there is any way to use only LLama.cpp with Langchain and not Llama.cpp-python.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mr_house7&quot;&gt; /u/mr_house7 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4t3du/langchain_with_llamacpp_not_llamacpppython/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4t3du/langchain_with_llamacpp_not_llamacpppython/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4t3du</id><link href="https://www.reddit.com/r/LangChain/comments/1d4t3du/langchain_with_llamacpp_not_llamacpppython/" /><updated>2024-05-31T11:13:22+00:00</updated><published>2024-05-31T11:13:22+00:00</published><title>Langchain with Llama.cpp not Llama.cpp-python</title></entry><entry><author><name>/u/Sensitive-Pen-1229</name><uri>https://www.reddit.com/user/Sensitive-Pen-1229</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, due to suboptimal documentation, I really struggle to get the results of a evaluation via the langsmith client. If someone could help, that would be amazing!&lt;/p&gt; &lt;p&gt;this is how I create the the exaluation:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;evaluate( predict_using_rag_chain, data=hum_dataset_name, evaluators=get_correctness_evaluators(), experiment_prefix=&amp;quot;correctness&amp;quot;, metadata=metadata ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;On langsmith I can see the results, e.g. via Projects &amp;gt; Evaluators. But if I use &lt;code&gt;client.list_runs(project_name=&amp;quot;evaluators&amp;quot;)&lt;/code&gt; the results contain all runs and I didnt find any correct metadata, e.g. the unique experiment name (e.g. experiment = &amp;quot;correctness-329f6d79&amp;quot;) to filter out a single evaluation on the dataset.&lt;/p&gt; &lt;p&gt;Would be amazing if you have an answer, I cannot imagine I am the only one with that problem.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sensitive-Pen-1229&quot;&gt; /u/Sensitive-Pen-1229 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4xmvw/langsmith_get_test_results_python_sdk/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4xmvw/langsmith_get_test_results_python_sdk/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4xmvw</id><link href="https://www.reddit.com/r/LangChain/comments/1d4xmvw/langsmith_get_test_results_python_sdk/" /><updated>2024-05-31T14:58:09+00:00</updated><published>2024-05-31T14:58:09+00:00</published><title>Langsmith - Get Test Results Python SDK</title></entry><entry><author><name>/u/jscraft</name><uri>https://www.reddit.com/user/jscraft</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ssom/why_learn_langchain_as_a_javascript_developer/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/2347JJ6JbmR5WGmdxSM3iu0OnGohPD3MltcLei8lmx8.jpg?width=108&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7a4559964a97155995aa6f0c96a36eebba24728a&quot; alt=&quot;Why learn LangChain (as a JavaScript developer)?&quot; title=&quot;Why learn LangChain (as a JavaScript developer)?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jscraft&quot;&gt; /u/jscraft &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.js-craft.io/blog/learn-langchain-javascript-developer/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ssom/why_learn_langchain_as_a_javascript_developer/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d4ssom</id><media:thumbnail url="https://external-preview.redd.it/2347JJ6JbmR5WGmdxSM3iu0OnGohPD3MltcLei8lmx8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a4559964a97155995aa6f0c96a36eebba24728a" /><link href="https://www.reddit.com/r/LangChain/comments/1d4ssom/why_learn_langchain_as_a_javascript_developer/" /><updated>2024-05-31T10:55:03+00:00</updated><published>2024-05-31T10:55:03+00:00</published><title>Why learn LangChain (as a JavaScript developer)?</title></entry><entry><author><name>/u/MoronSlayer42</name><uri>https://www.reddit.com/user/MoronSlayer42</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using RunnableWithMessageHistory for an application that needs sources and chat history. But unlike ConversationBufferWindowMemory there is no way to limit memory in RunnableWithMessageHistory, any way I can limit the chat history to a specific number of turns?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MoronSlayer42&quot;&gt; /u/MoronSlayer42 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4n1ci/limiting_memory_in_runnablewithmessagehistory/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4n1ci/limiting_memory_in_runnablewithmessagehistory/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4n1ci</id><link href="https://www.reddit.com/r/LangChain/comments/1d4n1ci/limiting_memory_in_runnablewithmessagehistory/" /><updated>2024-05-31T04:18:38+00:00</updated><published>2024-05-31T04:18:38+00:00</published><title>Limiting memory in RunnableWithMessageHistory</title></entry><entry><author><name>/u/Own_Mud1038</name><uri>https://www.reddit.com/user/Own_Mud1038</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I&amp;#39;m a newbie in the world of RAGs and LLMs but is it normal that the document retrieval takes 9-10 minutes?&lt;/p&gt; &lt;p&gt;I&amp;#39;m using locally the llama3:8b model with ollama, Chroma es a vectorstore but these parts are quite fast compared to the invoke() method which is the slowest one. My computer has 64 GB of RAM.&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Own_Mud1038&quot;&gt; /u/Own_Mud1038 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4p6t9/long_running_time_for_document_retrieval_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4p6t9/long_running_time_for_document_retrieval_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4p6t9</id><link href="https://www.reddit.com/r/LangChain/comments/1d4p6t9/long_running_time_for_document_retrieval_with/" /><updated>2024-05-31T06:36:22+00:00</updated><published>2024-05-31T06:36:22+00:00</published><title>Long running time for document retrieval with ollama3</title></entry><entry><author><name>/u/cr33dcode</name><uri>https://www.reddit.com/user/cr33dcode</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I need a way to ingest 10 PDFs containing financial information and then I need to able to ask an LLM to make me custom charts and graphs based on the data there is in those 10PDFs. need the LLM to have context of all 120 PDFs or it to do a good job. How do i proceed ahead with something like this? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cr33dcode&quot;&gt; /u/cr33dcode &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4o9yr/im_trying_out_a_new_tool_and_i_need_some_help/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4o9yr/im_trying_out_a_new_tool_and_i_need_some_help/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4o9yr</id><link href="https://www.reddit.com/r/LangChain/comments/1d4o9yr/im_trying_out_a_new_tool_and_i_need_some_help/" /><updated>2024-05-31T05:34:53+00:00</updated><published>2024-05-31T05:34:53+00:00</published><title>I'm trying out a new tool and I need some help</title></entry><entry><author><name>/u/No-Channel1897</name><uri>https://www.reddit.com/user/No-Channel1897</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;h2&gt;Famous YouTube Personality Finance Chat Bot&lt;/h2&gt; &lt;hr/&gt; &lt;ul&gt; &lt;li&gt;I want to create a chat bot on a famous YouTube personality.&lt;/li&gt; &lt;li&gt;The bot will talk and have an attitude similar to that person.&lt;/li&gt; &lt;li&gt;I will built this with python, Django, and LangChain.&lt;/li&gt; &lt;li&gt;I will use their YouTube videos to give context to the LLM.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;To-do&lt;/h2&gt; &lt;hr/&gt; &lt;ol&gt; &lt;li&gt;Build a simple RAG&lt;/li&gt; &lt;li&gt;Maintain chat history in PG Vector&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Suggest any extra ideas on this.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No-Channel1897&quot;&gt; /u/No-Channel1897 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ngwg/famous_youtube_personality_finance_chat_bot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ngwg/famous_youtube_personality_finance_chat_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4ngwg</id><link href="https://www.reddit.com/r/LangChain/comments/1d4ngwg/famous_youtube_personality_finance_chat_bot/" /><updated>2024-05-31T04:44:46+00:00</updated><published>2024-05-31T04:44:46+00:00</published><title>Famous YouTube Personality Finance Chat Bot</title></entry><entry><author><name>/u/Jamb9876</name><uri>https://www.reddit.com/user/Jamb9876</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using directoryloader to load pdfs but I need to process them and remove certain words that are found in them. &lt;/p&gt; &lt;p&gt;I would prefer not to stop using langchain but this is a big issue as I get errors loading my data into a graphing database. &lt;/p&gt; &lt;p&gt;I could convert the Document into a dict and process but then how do I convert it back for chunking and embedding?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jamb9876&quot;&gt; /u/Jamb9876 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ihev/preprocessing_using_directoryloader/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4ihev/preprocessing_using_directoryloader/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4ihev</id><link href="https://www.reddit.com/r/LangChain/comments/1d4ihev/preprocessing_using_directoryloader/" /><updated>2024-05-31T00:14:42+00:00</updated><published>2024-05-31T00:14:42+00:00</published><title>Preprocessing using directoryloader</title></entry><entry><author><name>/u/Major-Giraffe-2483</name><uri>https://www.reddit.com/user/Major-Giraffe-2483</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I&amp;#39;m very new to LLMs and I got confused on how to proceed. At the moment I want to use LanChain and ChatGPT.&lt;/p&gt; &lt;p&gt;I have this task:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;in the backend of my app I have a few functions that query SQL database and return a JSON&lt;/li&gt; &lt;li&gt;the ChatBot should take the user question as an input&lt;/li&gt; &lt;li&gt;the ChatBot should choose which functions to call&lt;/li&gt; &lt;li&gt;based on the JSON object/s returned the ChatBot should be able to answer the user`s question&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I&amp;#39;m not sure what would be the best approach here - RAG, Agent, OpenAI Function calling. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Major-Giraffe-2483&quot;&gt; /u/Major-Giraffe-2483 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4a55w/help_on_creating_a_chatbot_for_inapp_private_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4a55w/help_on_creating_a_chatbot_for_inapp_private_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4a55w</id><link href="https://www.reddit.com/r/LangChain/comments/1d4a55w/help_on_creating_a_chatbot_for_inapp_private_data/" /><updated>2024-05-30T17:59:52+00:00</updated><published>2024-05-30T17:59:52+00:00</published><title>Help on creating a ChatBot for in-app private data</title></entry><entry><author><name>/u/Plus_Reaction3578</name><uri>https://www.reddit.com/user/Plus_Reaction3578</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks, I was just wondering if there is a feature on the langSmith where we can manually evaluate the inputs/outputs of our LLM. On the documentation they talk about how there can be manual evaluators that can be set up but I can&amp;#39;t seem to find it.&lt;/p&gt; &lt;p&gt;any help would be appreciated.&lt;/p&gt; &lt;p&gt;thanks in advance &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Plus_Reaction3578&quot;&gt; /u/Plus_Reaction3578 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4d5mp/question_about_manual_testing_on_langsmith_hub/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4d5mp/question_about_manual_testing_on_langsmith_hub/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d4d5mp</id><link href="https://www.reddit.com/r/LangChain/comments/1d4d5mp/question_about_manual_testing_on_langsmith_hub/" /><updated>2024-05-30T20:08:05+00:00</updated><published>2024-05-30T20:08:05+00:00</published><title>Question about manual testing on LangSmith hub</title></entry><entry><author><name>/u/Your_Quantum_Friend</name><uri>https://www.reddit.com/user/Your_Quantum_Friend</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So, I am working on a RAG framework and for that I am currently using ChromaDB with all-MiniLM-L6-v2 embedding function. But one of my colleague suggested using Elastic Search for they mentioned it is much faster and accurate. So I did my own testing and found that for top_k=5, ES is 100% faster than ChromaDB. For all top_k values, ES is performing much faster. Also for top_k = 5, ES retrieved current document link 37% times accurately than ChromaDB. &lt;/p&gt; &lt;p&gt;However, when I read things online, it is mentioned that ChromaDB is faster and is used by many companies as their go to vectordb. What do you think could be the possible reason for this? Is there anything that I can use to improve ChromaDB&amp;#39;s performance and accuracy?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Your_Quantum_Friend&quot;&gt; /u/Your_Quantum_Friend &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3xtlq/is_elastic_search_better_than_chromadb/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d3xtlq/is_elastic_search_better_than_chromadb/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d3xtlq</id><link href="https://www.reddit.com/r/LangChain/comments/1d3xtlq/is_elastic_search_better_than_chromadb/" /><updated>2024-05-30T06:51:11+00:00</updated><published>2024-05-30T06:51:11+00:00</published><title>Is Elastic search better than ChromaDB?</title></entry></feed>