<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-07-23T22:46:25+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/gwen_from_nile</name><uri>https://www.reddit.com/user/gwen_from_nile</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am rather new to the AI space (my background is data infrastructure), so I am documenting my journey as I&amp;#39;m learning. This time I built an AI Code Assistant that uses RAG to answer questions about different repositories.&lt;/p&gt; &lt;p&gt;I blogged everything I learned while building this - Schema design, use of LangChain (tbh, not sure it was a good choice...), choice of models, streaming chat UX...&lt;/p&gt; &lt;p&gt;You can see the app here: &lt;a href=&quot;https://code-assist-nile.vercel.app&quot;&gt;https://code-assist-nile.vercel.app&lt;/a&gt;&lt;br/&gt; And the blog: &lt;a href=&quot;https://www.thenile.dev/blog/building_code_assistant&quot;&gt;https://www.thenile.dev/blog/building_code_assistant&lt;/a&gt;&lt;br/&gt; The code is here: &lt;a href=&quot;https://github.com/niledatabase/niledatabase/tree/main/examples/ai/code_assist/&quot;&gt;https://github.com/niledatabase/niledatabase/tree/main/examples/ai/code_assist/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gwen_from_nile&quot;&gt; /u/gwen_from_nile &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eadv0e/i_build_a_ragbased_multitenant_ai_code_assistant/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eadv0e/i_build_a_ragbased_multitenant_ai_code_assistant/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eadv0e</id><link href="https://www.reddit.com/r/LangChain/comments/1eadv0e/i_build_a_ragbased_multitenant_ai_code_assistant/" /><updated>2024-07-23T17:35:24+00:00</updated><published>2024-07-23T17:35:24+00:00</published><title>I build a RAG-based multi-tenant AI Code Assistant with OpenAI, LangChain, Postgres and PG Vector</title></entry><entry><author><name>/u/Acanthocephala_Salt</name><uri>https://www.reddit.com/user/Acanthocephala_Salt</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eageaq/exciting_news_from_meta_llama_31_is_here/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/4gnJFgu6Xo73DTSmQcJ5IIl2IzPp6vj2y5cONfUo6q4.jpg&quot; alt=&quot;Exciting News from Meta [Llama 3.1 is Here]&quot; title=&quot;Exciting News from Meta [Llama 3.1 is Here]&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Meta has just released its latest LLM model, Llama 3.1, marking a significant step in accessible artificial intelligence. Here are the key points from the announcement:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;405B version.&lt;/strong&gt; There is a new Llama 3.1 405B version. That’s right &lt;em&gt;405 Billion parameters.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Expanded context length&lt;/strong&gt;: Now all llama 3.1 models offer a context length of &lt;strong&gt;128K tokens&lt;/strong&gt;, 16 times its previous 8K context length from Llama 3. This allows for more advanced use cases, such as long-form text summarization, multilingual conversational agents, and coding assistants&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Model evaluations&lt;/strong&gt;: The model evaluations released by Meta are as follows:&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/zjcxaf93jbed1.png?width=3201&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=31191792e788799899102d882d3170acc34ea19b&quot;&gt;Llama 405B&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/h1x4jcy6jbed1.png?width=3201&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4fb34e2d110345a34e1715d16be8951d0edc637b&quot;&gt;Llama 8B&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;4. API Coming Soon:&lt;/strong&gt; Users will be able to access and utilize Llama 3.1 models through &lt;a href=&quot;http://awanllm.com/&quot;&gt;awanllm.com&lt;/a&gt; soon. Stay tuned for updates in this post!&lt;/p&gt; &lt;p&gt;Source: &lt;a href=&quot;https://ai.meta.com/blog/meta-llama-3-1/&quot;&gt;https://ai.meta.com/blog/meta-llama-3-1/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Acanthocephala_Salt&quot;&gt; /u/Acanthocephala_Salt &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eageaq/exciting_news_from_meta_llama_31_is_here/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eageaq/exciting_news_from_meta_llama_31_is_here/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1eageaq</id><media:thumbnail url="https://a.thumbs.redditmedia.com/4gnJFgu6Xo73DTSmQcJ5IIl2IzPp6vj2y5cONfUo6q4.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1eageaq/exciting_news_from_meta_llama_31_is_here/" /><updated>2024-07-23T19:17:49+00:00</updated><published>2024-07-23T19:17:49+00:00</published><title>Exciting News from Meta [Llama 3.1 is Here]</title></entry><entry><author><name>/u/NasserAAA</name><uri>https://www.reddit.com/user/NasserAAA</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What are your thoughts on using MongoDB as vectorstore for your apps.&lt;/p&gt; &lt;p&gt;I was working on prototype locally for the most of its time but right now we are moving to hosting on streamlit, what are your recommendations for vectorstores.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/NasserAAA&quot;&gt; /u/NasserAAA &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaffzv/mongodb_as_vectorstore/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaffzv/mongodb_as_vectorstore/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eaffzv</id><link href="https://www.reddit.com/r/LangChain/comments/1eaffzv/mongodb_as_vectorstore/" /><updated>2024-07-23T18:39:44+00:00</updated><published>2024-07-23T18:39:44+00:00</published><title>MongoDB as vectorstore</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1ead2of/how_to_use_llama_31_in_local_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ead6zf/how_to_use_llama_31_codes_explained/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ead6zf</id><link href="https://www.reddit.com/r/LangChain/comments/1ead6zf/how_to_use_llama_31_codes_explained/" /><updated>2024-07-23T17:08:15+00:00</updated><published>2024-07-23T17:08:15+00:00</published><title>How to use Llama 3.1? Codes explained</title></entry><entry><author><name>/u/srvking</name><uri>https://www.reddit.com/user/srvking</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Guys,&lt;/p&gt; &lt;p&gt;Has anybody used Qdrant in the cloud, especially Azure and has gone live and in production? We are trying to insert 884 points with a production grade cluster in azure eastus and it takes about 6-8 seconds and that too with gRPC. Http takes even longer.&lt;/p&gt; &lt;p&gt;We are absolutely sure that this is the time taken by Qdrant Remote Client provided by their official package because we have enabled all the logging and can pin-point which operation takes time.&lt;/p&gt; &lt;p&gt;We created a support ticket with the Qdrant team as well, but have been ghosted by them. &lt;/p&gt; &lt;p&gt;Wondering if Qdrant is right choice and if it is, how do people insert points faster? We do have metadata and chunk text in the point. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/srvking&quot;&gt; /u/srvking &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaabwv/is_qdrant_cloud_production_ready/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaabwv/is_qdrant_cloud_production_ready/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eaabwv</id><link href="https://www.reddit.com/r/LangChain/comments/1eaabwv/is_qdrant_cloud_production_ready/" /><updated>2024-07-23T15:14:06+00:00</updated><published>2024-07-23T15:14:06+00:00</published><title>Is Qdrant cloud Production Ready?</title></entry><entry><author><name>/u/Direct-Station9581</name><uri>https://www.reddit.com/user/Direct-Station9581</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;from langgraph_state import GraphState from langgraph.graph import END, StateGraph from langgraph.checkpoint.memory import MemorySaver from nodes import build_strategy, human_feedback, decision_node, rag_node, database_search, web_search_node, sql_search_node, state_printer from edges import rag_database_websearch_sqlseqrch, strategy_decision workflow = StateGraph(GraphState) workflow.add_node(&amp;quot;build_strategy&amp;quot;, build_strategy) workflow.add_node(&amp;quot;human_feedback&amp;quot;, human_feedback) workflow.add_node(&amp;quot;decision_node&amp;quot;, decision_node) workflow.add_node(&amp;quot;rag_node&amp;quot;, rag_node) workflow.add_node(&amp;quot;database_search&amp;quot;, database_search) workflow.add_node(&amp;quot;web_search_node&amp;quot;, web_search_node) workflow.add_node(&amp;quot;sql_search_node&amp;quot;, sql_search_node) workflow.add_node(&amp;quot;state_printer&amp;quot;, state_printer) workflow.set_entry_point(&amp;quot;build_strategy&amp;quot;) workflow.add_edge(&amp;quot;build_strategy&amp;quot;, &amp;quot;human_feedback&amp;quot;) workflow.add_conditional_edges( &amp;quot;human_feedback&amp;quot;, strategy_decision, { &amp;quot;yes&amp;quot;: &amp;quot;decision_node&amp;quot;, &amp;quot;no&amp;quot;: &amp;quot;build_strategy&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;decision_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;rag_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;database_search&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;web_search_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;sql_search_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_edge(&amp;quot;state_printer&amp;quot;, END) memory = MemorySaver() app = workflow.compile(checkpointer=memory, interrupt_before=[&amp;quot;human_feedback&amp;quot;]) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I have created a graph with human feedback using langgraph. After &lt;strong&gt;strategy node&lt;/strong&gt; is executed. It should interrupt before &lt;strong&gt;human_feedback node&lt;/strong&gt; and ask from the user that if the strategy made by the agent is correct or wrong in case if it is correct it will proceed to the next nodes and if not then it will go to strategy node again.&lt;/p&gt; &lt;p&gt;For my first condition in case it is correct it is working fine. But when it is wrong the strategy node executes but donot go to the next nodes and the program terminates.&lt;/p&gt; &lt;p&gt;This is the issue if anyone can help. Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Direct-Station9581&quot;&gt; /u/Direct-Station9581 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea3p2i/human_in_the_loop_in_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea3p2i/human_in_the_loop_in_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea3p2i</id><link href="https://www.reddit.com/r/LangChain/comments/1ea3p2i/human_in_the_loop_in_langgraph/" /><updated>2024-07-23T09:40:10+00:00</updated><published>2024-07-23T09:40:10+00:00</published><title>Human In The Loop In Langgraph</title></entry><entry><author><name>/u/DifficultArugula8304</name><uri>https://www.reddit.com/user/DifficultArugula8304</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to give my client the option to construct new agents and create flows for input and output like vectorizing input and parsing output and storing it in a database. Is there any opensource tool with a UI that can do this? The language it&amp;#39;s written in doesn&amp;#39;t really matter, all options are welcome.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DifficultArugula8304&quot;&gt; /u/DifficultArugula8304 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaedlh/looking_for_an_opensource_framework_to_manage/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1eaedlh/looking_for_an_opensource_framework_to_manage/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1eaedlh</id><link href="https://www.reddit.com/r/LangChain/comments/1eaedlh/looking_for_an_opensource_framework_to_manage/" /><updated>2024-07-23T17:56:20+00:00</updated><published>2024-07-23T17:56:20+00:00</published><title>Looking for an opensource framework to manage agents</title></entry><entry><author><name>/u/emersoftware</name><uri>https://www.reddit.com/user/emersoftware</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I want to force function calling with Gemini. Does anyone know how to do this?&lt;/p&gt; &lt;p&gt;I have checked the documentation for Vertex AI and Langchain but couldn&amp;#39;t find any information. In the Vertex AI docs, I found a parameter that could be passed, but I don&amp;#39;t know how to pass it using Langchain. I am using &lt;code&gt;ChatVertexAI().bind_tools()&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Regards!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/emersoftware&quot;&gt; /u/emersoftware &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ead44f/forced_function_calling_in_vertex_ai_gemini/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ead44f/forced_function_calling_in_vertex_ai_gemini/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ead44f</id><link href="https://www.reddit.com/r/LangChain/comments/1ead44f/forced_function_calling_in_vertex_ai_gemini/" /><updated>2024-07-23T17:05:05+00:00</updated><published>2024-07-23T17:05:05+00:00</published><title>Forced function calling in vertex ai gemini??</title></entry><entry><author><name>/u/Expensive-Rub3117</name><uri>https://www.reddit.com/user/Expensive-Rub3117</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea7g23/multiagentdataanalysis_aidriven_data_analysis/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/1JX3PzIaTRXFic9OMARqVvTPnyE1x5FcNLG2jrAgYEU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=eca0d0f2c1e87731dab2321618072174b07b7430&quot; alt=&quot;Multi-agent-DataAnalysis AI-Driven Data Analysis System&quot; title=&quot;Multi-agent-DataAnalysis AI-Driven Data Analysis System&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;h1&gt;# Advanced AI-Driven Data Analysis System: A LangGraph Implementation&lt;/h1&gt; &lt;h2&gt;Project Overview&lt;/h2&gt; &lt;p&gt;I&amp;#39;ve developed a sophisticated data analysis system that leverages the power of LangGraph, showcasing its capabilities in integrating various AI architectures and methodologies. This system is designed to serve as a comprehensive example of how LangGraph can be used to streamline complex data analysis tasks by orchestrating multiple AI agents and architectural patterns.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/lntq41fap9ed1.jpg?width=610&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7b2f31c450c495ebe2eb3d5a1e75522223ae1267&quot;&gt;https://preview.redd.it/lntq41fap9ed1.jpg?width=610&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7b2f31c450c495ebe2eb3d5a1e75522223ae1267&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Key Features&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;**LangGraph-Powered Architecture**: The system demonstrates LangGraph&amp;#39;s flexibility by incorporating:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Supervisor agents for overseeing the analysis process&lt;/li&gt; &lt;li&gt;Chain-of-thought reasoning for complex problem-solving&lt;/li&gt; &lt;li&gt;Critic agents for quality assurance and error checking&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;**Innovative Note Taker Agent**: A standout feature that highlights LangGraph&amp;#39;s extensibility:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Continuously records the current state of the project&lt;/li&gt; &lt;li&gt;Provides a more efficient alternative to transmitting complete historical information&lt;/li&gt; &lt;li&gt;Enhances the system&amp;#39;s ability to maintain context and continuity across different analysis stages&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;**Adaptive Workflow**: Showcases LangGraph&amp;#39;s dynamic routing capabilities, adjusting the analysis approach based on the data and task at hand.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Why It&amp;#39;s a Valuable LangGraph Example&lt;/h2&gt; &lt;p&gt;This implementation serves as an excellent case study for LangGraph users by demonstrating:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Integration of diverse AI agent types within a unified framework&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Efficient state management using the innovative Note Taker agent&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Real-world application of LangGraph in complex data analysis scenarios&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Contribution to LangGraph&lt;/h2&gt; &lt;p&gt;I am eager to contribute this project as an example in the official LangGraph repository. My goals are to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;Provide a comprehensive, real-world example of LangGraph&amp;#39;s capabilities&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Help other developers understand advanced LangGraph implementations&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Contribute to the growth and adoption of LangGraph in the AI community&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Project Repository&lt;/h2&gt; &lt;p&gt;For a deeper dive into the codebase, architecture, and implementation details, please visit the project&amp;#39;s GitHub repository:&lt;/p&gt; &lt;p&gt;[AI-Driven Data Analysis System on GitHub](&lt;a href=&quot;https://github.com/starpig1129/Multi-agent-DataAnalysis&quot;&gt;https://github.com/starpig1129/Multi-agent-DataAnalysis&lt;/a&gt;)&lt;/p&gt; &lt;p&gt;I welcome feedback and collaboration to refine this example for potential inclusion in the LangGraph documentation or example collection.&lt;/p&gt; &lt;h2&gt;Next Steps&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;I am open to adapting the project to better align with LangGraph&amp;#39;s documentation standards.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;I would appreciate guidance on the best way to submit this as a potential official example.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;I&amp;#39;m eager to collaborate with the LangGraph community to enhance this example and make it as valuable as possible for other users.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Feel free to explore the repository, and I look forward to any feedback or suggestions for improving this as a LangGraph example!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Expensive-Rub3117&quot;&gt; /u/Expensive-Rub3117 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea7g23/multiagentdataanalysis_aidriven_data_analysis/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea7g23/multiagentdataanalysis_aidriven_data_analysis/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ea7g23</id><media:thumbnail url="https://external-preview.redd.it/1JX3PzIaTRXFic9OMARqVvTPnyE1x5FcNLG2jrAgYEU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eca0d0f2c1e87731dab2321618072174b07b7430" /><link href="https://www.reddit.com/r/LangChain/comments/1ea7g23/multiagentdataanalysis_aidriven_data_analysis/" /><updated>2024-07-23T13:09:57+00:00</updated><published>2024-07-23T13:09:57+00:00</published><title>Multi-agent-DataAnalysis AI-Driven Data Analysis System</title></entry><entry><author><name>/u/jscraft</name><uri>https://www.reddit.com/user/jscraft</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Made this 2 part tutorial about Tool Calling in LangChain.js&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Part 1️: &lt;a href=&quot;https://www.js-craft.io/blog/tool-calling-langchain-js/&quot;&gt;https://www.js-craft.io/blog/tool-calling-langchain-js/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 2: &lt;a href=&quot;https://www.js-craft.io/blog/tool-calling-langchain-js-toolmessage-schemas/&quot;&gt;https://www.js-craft.io/blog/tool-calling-langchain-js-toolmessage-schemas/&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Hope you will find it useful and any feedback is welcomed!&lt;/p&gt; &lt;p&gt;PS: I think it was one of the most time-consuming tutorials to make, as things here are not quite intuitive. At least for me :) &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jscraft&quot;&gt; /u/jscraft &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea79dp/tool_calling_tutorial_for_langchainjs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea79dp/tool_calling_tutorial_for_langchainjs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea79dp</id><link href="https://www.reddit.com/r/LangChain/comments/1ea79dp/tool_calling_tutorial_for_langchainjs/" /><updated>2024-07-23T13:01:21+00:00</updated><published>2024-07-23T13:01:21+00:00</published><title>Tool Calling tutorial for LangChain.js</title></entry><entry><author><name>/u/Plane_Past129</name><uri>https://www.reddit.com/user/Plane_Past129</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can we apply RAG to JSON files. Currently we are using unstructured for parsing different types of file types. But, it doesn&amp;#39;t have integration with json file. Can anyone experienced this before?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Plane_Past129&quot;&gt; /u/Plane_Past129 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea5lco/rag_for_json/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea5lco/rag_for_json/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea5lco</id><link href="https://www.reddit.com/r/LangChain/comments/1ea5lco/rag_for_json/" /><updated>2024-07-23T11:35:09+00:00</updated><published>2024-07-23T11:35:09+00:00</published><title>RAG for JSON</title></entry><entry><author><name>/u/thumbsdrivesmecrazy</name><uri>https://www.reddit.com/user/thumbsdrivesmecrazy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The article discusses various strategies and techniques for implementing RAG to large-scale code repositories, as well as potential benefits and limitations of the approach as well as show how RAG can improve developer productivity and code quality in large software projects: &lt;a href=&quot;https://www.codium.ai/blog/rag-for-large-scale-code-repos/&quot;&gt;RAG with 10K Code Repos&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thumbsdrivesmecrazy&quot;&gt; /u/thumbsdrivesmecrazy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea4nhz/applying_rag_to_largescale_code_repositories_guide/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea4nhz/applying_rag_to_largescale_code_repositories_guide/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea4nhz</id><link href="https://www.reddit.com/r/LangChain/comments/1ea4nhz/applying_rag_to_largescale_code_repositories_guide/" /><updated>2024-07-23T10:40:54+00:00</updated><published>2024-07-23T10:40:54+00:00</published><title>Applying RAG to Large-Scale Code Repositories - Guide</title></entry><entry><author><name>/u/ha1lyeah</name><uri>https://www.reddit.com/user/ha1lyeah</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, Need help in finding a docker image containing both Ollama and langchain to ease the creation/development of use cases. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ha1lyeah&quot;&gt; /u/ha1lyeah &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea4ccw/docker_image_with_ollama_and_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea4ccw/docker_image_with_ollama_and_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea4ccw</id><link href="https://www.reddit.com/r/LangChain/comments/1ea4ccw/docker_image_with_ollama_and_langchain/" /><updated>2024-07-23T10:21:37+00:00</updated><published>2024-07-23T10:21:37+00:00</published><title>Docker image with Ollama and langchain</title></entry><entry><author><name>/u/nshefeek</name><uri>https://www.reddit.com/user/nshefeek</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all,&lt;/p&gt; &lt;p&gt;This is my first take on something that is related to LLM and RAG systems. I&amp;#39;ve been working on a Retrieval-Augmented Generation (RAG) based question answering system which generate answers to the queries from uploaded documents, and I&amp;#39;d love to get your feedback, suggestions, and ideas for improvements. The system uses FastAPI, LangChain and Streamlit for a minimal UI.&lt;/p&gt; &lt;p&gt;Key features of the system:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Document upload and processing&lt;/li&gt; &lt;li&gt;Directory processing for batch document addition&lt;/li&gt; &lt;li&gt;FAISS vector store for efficient document retrieval&lt;/li&gt; &lt;li&gt;GPT4All for generating embeddings and answering questions&lt;/li&gt; &lt;li&gt;Asynchronous operations for improved performance&lt;/li&gt; &lt;li&gt;WebSocket support for real-time question answering&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;GitHub Repository: &lt;a href=&quot;https://github.com/nshefeek/docGPT.git&quot;&gt;docGPT&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Some specific areas I&amp;#39;m looking for feedback on:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Code quality and best practices.&lt;/li&gt; &lt;li&gt;Usage of LangChain.&lt;/li&gt; &lt;li&gt;The approach to improve query response timing.&lt;/li&gt; &lt;li&gt;A better approach to splitting the documents in such a way that the embeddings generated maintains a metadata that can be used to trace back to the original source doument.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Current state of the project:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Able to upload a PDF, TXT or CSV document.&lt;/li&gt; &lt;li&gt;Able to upload a directory of PDF documents. But since Streamlit has no widget for folder upload, the folder path has to be input as text.&lt;/li&gt; &lt;li&gt;Queries return somewhat relevant answers, but the returned metadata can&amp;#39;t be used to backtrack to the exact source location (like the paragraph from which the answer was inferred etc.).&lt;/li&gt; &lt;li&gt;Query times vary between 120-180 seconds.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Thank you in advance for your time and expertise. I&amp;#39;m looking forward to your insights and suggestions to help improve this project!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nshefeek&quot;&gt; /u/nshefeek &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9j3cq/built_a_rag_system_for_internal_documents_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9j3cq/built_a_rag_system_for_internal_documents_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9j3cq</id><link href="https://www.reddit.com/r/LangChain/comments/1e9j3cq/built_a_rag_system_for_internal_documents_using/" /><updated>2024-07-22T16:50:25+00:00</updated><published>2024-07-22T16:50:25+00:00</published><title>Built a RAG system for internal documents using LangChain, FastAPI, and a frontend with Streamlit. What could have been done better?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;GraphRAG has been the talk of the town since Microsoft released the viral gitrepo on GraphRAG, which uses Knowledge Graphs for the RAG framework to talk to external resources compared to vector DBs as in the case of standard RAG. The below YouTube playlist covers the following tutorials to get started on GraphRAG&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;What is GraphRAG?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;How GraphRAG works?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;GraphRAG using LangChain&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;GraphRAG for CSV data&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;GraphRAG for JSON&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Knowledge Graphs using LangChain&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;RAG vs GraphRAG&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLnH2pfPCPZsIaT48BT9zmLmkhYa_R1PhN&quot;&gt;https://www.youtube.com/playlist?list=PLnH2pfPCPZsIaT48BT9zmLmkhYa_R1PhN&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9wc8q/graphrag_tutorials_using_langchain_for_beginners/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9wc8q/graphrag_tutorials_using_langchain_for_beginners/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9wc8q</id><link href="https://www.reddit.com/r/LangChain/comments/1e9wc8q/graphrag_tutorials_using_langchain_for_beginners/" /><updated>2024-07-23T02:11:52+00:00</updated><published>2024-07-23T02:11:52+00:00</published><title>GraphRAG tutorials (using LangChain) for beginners</title></entry><entry><author><name>/u/Both_Acadia_6598</name><uri>https://www.reddit.com/user/Both_Acadia_6598</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all,&lt;/p&gt; &lt;p&gt;I&amp;#39;m using the LangChain React agent infrastructure and encountering various string-related issues.&lt;br/&gt; For instance, I often get errors like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&amp;quot;The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.&amp;quot;&lt;/li&gt; &lt;li&gt;&amp;quot;Could not parse LLM output.&amp;quot;&lt;/li&gt; &lt;li&gt;&amp;quot;An output parsing error occurred.&amp;quot;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Currently, I have some ad-hoc methods to fix the outputs, which involve a lot of string manipulation. I&amp;#39;m wondering if this is the right approach to handle these issues.&lt;/p&gt; &lt;p&gt;I tried using the handle_parsing_errors argument, but it doesn&amp;#39;t seem to be a good solution.&lt;/p&gt; &lt;p&gt;What do you think?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Both_Acadia_6598&quot;&gt; /u/Both_Acadia_6598 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea2inm/troubleshooting_string_errors_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea2inm/troubleshooting_string_errors_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea2inm</id><link href="https://www.reddit.com/r/LangChain/comments/1ea2inm/troubleshooting_string_errors_in_langchain/" /><updated>2024-07-23T08:20:08+00:00</updated><published>2024-07-23T08:20:08+00:00</published><title>Troubleshooting string Errors in LangChain</title></entry><entry><author><name>/u/kingai404</name><uri>https://www.reddit.com/user/kingai404</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone! I’m excited to share a new project: an Investment Research Project leveraging CrewAI and Composio to conduct investment research, analyze data, and provide investment recommendations.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Objectives&lt;/strong&gt;&lt;br/&gt; This project sets up a system of agents to streamline investment research and analysis, ultimately generating insightful investment recommendations.&lt;br/&gt; Implementation Details&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Tools Used&lt;/strong&gt;&lt;br/&gt; Composio, CrewAI, SERP, Python&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Setup&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Navigate to the project directory.&lt;/li&gt; &lt;li&gt;Run the setup file.&lt;/li&gt; &lt;li&gt;Fill in the &lt;code&gt;.env&lt;/code&gt; file with your secrets.&lt;/li&gt; &lt;li&gt;Run the Python script.&lt;/li&gt; &lt;li&gt;Alternatively, run the IPython Notebook &lt;code&gt;investment_analyst.ipynb&lt;/code&gt; in Jupyter for an interactive experience.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;br/&gt; The system will populate your Notion page with comprehensive investment data and analysis.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Repo&lt;/strong&gt;: &lt;a href=&quot;https://git.new/Invest&quot;&gt;GitHub Repository&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Feel free to explore the project, give it a star if you find it useful, and let me know your thoughts or suggestions for improvements!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kingai404&quot;&gt; /u/kingai404 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9ys5f/make_your_own_intelligent_investment_analyst_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9ys5f/make_your_own_intelligent_investment_analyst_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9ys5f</id><link href="https://www.reddit.com/r/LangChain/comments/1e9ys5f/make_your_own_intelligent_investment_analyst_agent/" /><updated>2024-07-23T04:20:03+00:00</updated><published>2024-07-23T04:20:03+00:00</published><title>Make your own Intelligent Investment Analyst Agent</title></entry><entry><author><name>/u/sidharth_07</name><uri>https://www.reddit.com/user/sidharth_07</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I would love to get your expertise and advice on building a RAG chatbot for an e-commerce company. I&amp;#39;m currently exploring Graph-RAG and hybrid search, but I&amp;#39;m feeling overwhelmed by the amount of data. The company has about 100 products, along with data such as blogs, articles, FAQs, etc., which sometimes reference specific products. I would like to know how I can move forward with this project. Any help is much appreciated.&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sidharth_07&quot;&gt; /u/sidharth_07 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea0qw5/cs_rag_chatbot_for_a_hardware_ecom_company/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea0qw5/cs_rag_chatbot_for_a_hardware_ecom_company/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea0qw5</id><link href="https://www.reddit.com/r/LangChain/comments/1ea0qw5/cs_rag_chatbot_for_a_hardware_ecom_company/" /><updated>2024-07-23T06:22:45+00:00</updated><published>2024-07-23T06:22:45+00:00</published><title>CS RAG CHATBOT for a hardware e-com company</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Knowledge Graph is the buzz word since GraphRAG has came in which is quite useful for Graph Analytics over unstructured data. This video demonstrates how to use LangChain to build a stand alone Knowledge Graph from text : &lt;a href=&quot;https://youtu.be/YnhG_arZEj0&quot;&gt;https://youtu.be/YnhG_arZEj0&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9etyn/knowledge_graph_using_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9etyn/knowledge_graph_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9etyn</id><link href="https://www.reddit.com/r/LangChain/comments/1e9etyn/knowledge_graph_using_langchain/" /><updated>2024-07-22T13:52:04+00:00</updated><published>2024-07-22T13:52:04+00:00</published><title>Knowledge Graph using LangChain</title></entry><entry><author><name>/u/nicolashoferer</name><uri>https://www.reddit.com/user/nicolashoferer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;What are you using to evaluate and monitor your RAG applications? &lt;/p&gt; &lt;p&gt;I&amp;#39;ve been using LangSmith, but I&amp;#39;m not satisfied with it so far. In my opinion, the UX is bad and it lacks an effective way to compare different prompts. I&amp;#39;m now considering experimenting with PromptLayer, as it seems to offer better features. &lt;/p&gt; &lt;p&gt;Our situation is a bit complex, though. We&amp;#39;re experimenting with two different approaches: a multi-chain setup and one based on function calling. So we&amp;#39;re really looking to compare entire workflows rather than just individual prompts.&lt;/p&gt; &lt;p&gt;Has anyone found a good solution for monitoring, and more importantly, evaluating these kinds of setups? I&amp;#39;d appreciate any insights or recommendations.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nicolashoferer&quot;&gt; /u/nicolashoferer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9e3lb/automatic_rag_evaluation_monitoring/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9e3lb/automatic_rag_evaluation_monitoring/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9e3lb</id><link href="https://www.reddit.com/r/LangChain/comments/1e9e3lb/automatic_rag_evaluation_monitoring/" /><updated>2024-07-22T13:18:34+00:00</updated><published>2024-07-22T13:18:34+00:00</published><title>Automatic RAG Evaluation + Monitoring</title></entry><entry><author><name>/u/thedabking123</name><uri>https://www.reddit.com/user/thedabking123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I noticed that it didn&amp;#39;t always call the vectorstore when asked a q- and for those answers it was always giving generic answers&lt;/p&gt; &lt;p&gt;react agent documentation: &lt;a href=&quot;https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/#code&quot;&gt;https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/#code&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thedabking123&quot;&gt; /u/thedabking123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9sc59/is_there_a_way_to_force_the_prebuilt_react_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9sc59/is_there_a_way_to_force_the_prebuilt_react_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9sc59</id><link href="https://www.reddit.com/r/LangChain/comments/1e9sc59/is_there_a_way_to_force_the_prebuilt_react_agent/" /><updated>2024-07-22T23:06:01+00:00</updated><published>2024-07-22T23:06:01+00:00</published><title>Is there a way to force the prebuilt react agent to call tools (vector store) for each question asked? If not what's a good alternative?</title></entry><entry><author><name>/u/mallerius</name><uri>https://www.reddit.com/user/mallerius</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey I&amp;#39;m developing a customer service chatbot that answers questions on a specific topic based on knowledge provided to the bot. In my system prompt I tell it to only answer related questions and refuse to answer unrelated stuff. However it still answers questions like &amp;quot;why is the sky blue?&amp;quot; and so on. Do you guys have any tips on how to improve this? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mallerius&quot;&gt; /u/mallerius &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9jii5/how_to_restrict_chatbot_from_answering_unrelated/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9jii5/how_to_restrict_chatbot_from_answering_unrelated/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9jii5</id><link href="https://www.reddit.com/r/LangChain/comments/1e9jii5/how_to_restrict_chatbot_from_answering_unrelated/" /><updated>2024-07-22T17:07:24+00:00</updated><published>2024-07-22T17:07:24+00:00</published><title>How to restrict chatbot from answering unrelated questions?</title></entry><entry><author><name>/u/Cautious-External177</name><uri>https://www.reddit.com/user/Cautious-External177</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am developing a chatbot app where I am using Langchain to feed it documents. I have completed the backend logic for the app, including controllers, tables and real-time chat (using pusher) in Laravel. I plan to use Flutter for the frontend. How can I integrate the model in Laravel?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Cautious-External177&quot;&gt; /u/Cautious-External177 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9s7iw/langchain_chatbot_integration_in_laravel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9s7iw/langchain_chatbot_integration_in_laravel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9s7iw</id><link href="https://www.reddit.com/r/LangChain/comments/1e9s7iw/langchain_chatbot_integration_in_laravel/" /><updated>2024-07-22T23:00:49+00:00</updated><published>2024-07-22T23:00:49+00:00</published><title>Langchain chatbot integration in Laravel</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This tutorial explains how to use GraphRAG using JSON file and LangChain. This involves 1. Converting json to text 2. Create Knowledge Graph 3. Create GraphQA chain&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/wXTs3cmZuJA?si=dnwTo6BHbK8WgGEF&quot;&gt;https://youtu.be/wXTs3cmZuJA?si=dnwTo6BHbK8WgGEF&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e967n3/graphrag_using_json_and_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e967n3/graphrag_using_json_and_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e967n3</id><link href="https://www.reddit.com/r/LangChain/comments/1e967n3/graphrag_using_json_and_langchain/" /><updated>2024-07-22T05:11:53+00:00</updated><published>2024-07-22T05:11:53+00:00</published><title>GraphRAG using JSON and LangChain</title></entry><entry><author><name>/u/Intelligent-Try-4558</name><uri>https://www.reddit.com/user/Intelligent-Try-4558</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;When I populate my chromadb, it takes a long time. To add ~3,000 docs can take upwards of 10 minutes, and adding any more docs afterwards will take much longer. When adding to the db, it is only using ~10% GPU and CPU usage. Is there any way to speed this process up or use more resources when populating the DB?&lt;/p&gt; &lt;p&gt;For context, I&amp;#39;m using random textbooks to populate the DB with rn, but this issue happens no matter the content I&amp;#39;m adding to the DB.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;#Embedding function I use embeddings = OllamaEmbeddings(model=&amp;quot;nomic-embed-text&amp;quot;) #This block is what takes forever new_chunk_ids = [chunk.metadata[&amp;quot;id&amp;quot;] for chunk in new_chunks] db.add_documents(new_chunks, ids=new_chunk_ids) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Intelligent-Try-4558&quot;&gt; /u/Intelligent-Try-4558 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9h5dq/chroma_db_taking_long_time_to_populate/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9h5dq/chroma_db_taking_long_time_to_populate/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9h5dq</id><link href="https://www.reddit.com/r/LangChain/comments/1e9h5dq/chroma_db_taking_long_time_to_populate/" /><updated>2024-07-22T15:30:03+00:00</updated><published>2024-07-22T15:30:03+00:00</published><title>Chroma DB taking long time to populate</title></entry></feed>