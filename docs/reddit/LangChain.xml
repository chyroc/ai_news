<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-06-03T22:05:44+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/gaharavara</name><uri>https://www.reddit.com/user/gaharavara</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I ask this because there landing page looks like a full blown product page with no clarity whatsover - it looks as if it is a commercial sass.&lt;/p&gt; &lt;p&gt;Are there any alternative projects which are less salesy ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gaharavara&quot;&gt; /u/gaharavara &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d73efm/is_langchain_even_open_source_now/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d73efm/is_langchain_even_open_source_now/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d73efm</id><link href="https://www.reddit.com/r/LangChain/comments/1d73efm/is_langchain_even_open_source_now/" /><updated>2024-06-03T12:38:41+00:00</updated><published>2024-06-03T12:38:41+00:00</published><title>is langchain even open source now</title></entry><entry><author><name>/u/ToeIntelligent4472</name><uri>https://www.reddit.com/user/ToeIntelligent4472</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d76hik/multimodal_rag_for_urls_and_files_in_40_lines_of/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/-mAfb9t0guA0H1dceryMi5qlhUSFDO-P0-cNoUgga-U.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=892232bf8252c0ae789a7962dc44abb2212d9ca6&quot; alt=&quot;Multimodal RAG for URLs and Files, in 40 Lines of Python&quot; title=&quot;Multimodal RAG for URLs and Files, in 40 Lines of Python&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ToeIntelligent4472&quot;&gt; /u/ToeIntelligent4472 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://medium.com/@emcf1/multimodal-rag-for-urls-and-files-easier-than-langchain-01a12d35777e&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d76hik/multimodal_rag_for_urls_and_files_in_40_lines_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d76hik</id><media:thumbnail url="https://external-preview.redd.it/-mAfb9t0guA0H1dceryMi5qlhUSFDO-P0-cNoUgga-U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=892232bf8252c0ae789a7962dc44abb2212d9ca6" /><link href="https://www.reddit.com/r/LangChain/comments/1d76hik/multimodal_rag_for_urls_and_files_in_40_lines_of/" /><updated>2024-06-03T14:58:29+00:00</updated><published>2024-06-03T14:58:29+00:00</published><title>Multimodal RAG for URLs and Files, in 40 Lines of Python</title></entry><entry><author><name>/u/bartselen</name><uri>https://www.reddit.com/user/bartselen</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I&amp;#39;m trying to create an LLM-based system that allows me to &amp;quot;interact&amp;quot; with my chat logs and draw conclusions from them. A few examples: * Find &amp;quot;sub&amp;quot;-conversations or messages in which a certain topic is talked about and perhaps even summarize all of those &amp;quot;sub&amp;quot;-conversations (and it&amp;#39;s important not to miss any, which is something I&amp;#39;ve been struggling with) * Find people in my group chats that talk a lot about certain topics And other similar prompts that I give the LLM.&lt;/p&gt; &lt;p&gt;Right now my solution is pretty simple. I processed all my messages with recursive character chunking and each message into a document, while using a Parent Document Retriever to get more context (in the future I plan on using semantic chunking to make the parent documents full sub-conversations). Those are then put into a vector database, and A basic conversational RAG agent (I currently use mixtral-instruct) with langchain. The conversations are injected as JSON as context.&lt;/p&gt; &lt;p&gt;First of all, I would love to know what approach you guys would take to this problem in each part of it - the embedding, the retrieval (is RAG even the solution here?), the context format, the agent, etc. I&amp;#39;m a newbie to LLMs and AI in general and I really want to hear the opinions of people with experience&lt;/p&gt; &lt;p&gt;Secondly, I have a few problems I&amp;#39;ve encountered with my setup, mainly: * Because I currently don&amp;#39;t split my documents semantically, I receive a big part of the conversation (up to 4k+ tokens). mixtral seems to, for some reason, ignore some of my context and only remembers it starting from some arbitrary index, unless I really shorten it down to several hundreds of tokens. I don&amp;#39;t understand why this happens as it should have a 32k context window. One solution I thought of was switching to llama3-8b (only 8k but might work better because it&amp;#39;s a better model). This is a huge roadblock for this project and I&amp;#39;d appreciate any help here * I&amp;#39;m not sure how to approach the not missing conversations part, as I&amp;#39;m always going to have a limited context. How do I make it so the agent continues fetching the rest of the convesations that were less relevant in the vector similarity search, like continually do it or something.&lt;/p&gt; &lt;p&gt;Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bartselen&quot;&gt; /u/bartselen &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d7ghuk/rag_for_im_chat_logs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d7ghuk/rag_for_im_chat_logs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d7ghuk</id><link href="https://www.reddit.com/r/LangChain/comments/1d7ghuk/rag_for_im_chat_logs/" /><updated>2024-06-03T21:43:51+00:00</updated><published>2024-06-03T21:43:51+00:00</published><title>RAG for IM chat logs</title></entry><entry><author><name>/u/No-Bill5112</name><uri>https://www.reddit.com/user/No-Bill5112</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Most LLMs, especially chat models, have some way they expect prompt to be formatted for things to work correctly (Example: &lt;a href=&quot;https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/&quot;&gt;https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/&lt;/a&gt;). However, the Langchain prompts abstraction hides all that away and just lets users create their prompts in a clean, generalized way (&lt;a href=&quot;https://python.langchain.com/v0.1/docs/modules/model%5C_io/prompts/quick%5C_start/&quot;&gt;https://python.langchain.com/v0.1/docs/modules/model\_io/prompts/quick\_start/&lt;/a&gt;). My assumption would be that, behind the scenes, Langchain is handling those details. But I can&amp;#39;t find any information that indicates either way. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No-Bill5112&quot;&gt; /u/No-Bill5112 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d78e78/does_langchain_handle_prompt_formatting/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d78e78/does_langchain_handle_prompt_formatting/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d78e78</id><link href="https://www.reddit.com/r/LangChain/comments/1d78e78/does_langchain_handle_prompt_formatting/" /><updated>2024-06-03T16:17:24+00:00</updated><published>2024-06-03T16:17:24+00:00</published><title>Does Langchain handle prompt formatting?</title></entry><entry><author><name>/u/Kooky_Impression9575</name><uri>https://www.reddit.com/user/Kooky_Impression9575</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d783sg/chat_with_csv_files_using_googles_gemini_flash_no/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/PHwpPHD812gpy_gx0fgMsqxTD-KB_THw9HCBN_yskfY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=02ab10f7e791098d6774af2fafc1e270e6feba45&quot; alt=&quot;Chat with CSV Files Using Google’s Gemini Flash: No Langchain!&quot; title=&quot;Chat with CSV Files Using Google’s Gemini Flash: No Langchain!&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Kooky_Impression9575&quot;&gt; /u/Kooky_Impression9575 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://levelup.gitconnected.com/chat-with-csv-files-using-googles-gemini-flash-no-langchain-0e8f79d63348&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d783sg/chat_with_csv_files_using_googles_gemini_flash_no/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d783sg</id><media:thumbnail url="https://external-preview.redd.it/PHwpPHD812gpy_gx0fgMsqxTD-KB_THw9HCBN_yskfY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02ab10f7e791098d6774af2fafc1e270e6feba45" /><link href="https://www.reddit.com/r/LangChain/comments/1d783sg/chat_with_csv_files_using_googles_gemini_flash_no/" /><updated>2024-06-03T16:05:29+00:00</updated><published>2024-06-03T16:05:29+00:00</published><title>Chat with CSV Files Using Google’s Gemini Flash: No Langchain!</title></entry><entry><author><name>/u/Sweaty-Minimum5423</name><uri>https://www.reddit.com/user/Sweaty-Minimum5423</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, anyone is using OpenGPT for the deployment? I wonder how to use the latest gpt4o which require newer version of langchain. If I upgrade langchain package, it will crash. Any advice or walk around?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sweaty-Minimum5423&quot;&gt; /u/Sweaty-Minimum5423 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d7837n/opengpt_with_gpt4o/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d7837n/opengpt_with_gpt4o/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d7837n</id><link href="https://www.reddit.com/r/LangChain/comments/1d7837n/opengpt_with_gpt4o/" /><updated>2024-06-03T16:04:52+00:00</updated><published>2024-06-03T16:04:52+00:00</published><title>OpenGPT with gpt4o</title></entry><entry><author><name>/u/DetchKing</name><uri>https://www.reddit.com/user/DetchKing</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What are the alternatives to langchain agents ?&lt;/p&gt; &lt;p&gt;Working on a product that is on production . We use heavily OpenAI LLM to take decisions. However, we are integrating tools and we are thinking to use langchain agents for that. We already did a project with langchain agents before and it was very easy for us to use their agents. Any alternative on how we can do this without using langchain ? &lt;/p&gt; &lt;p&gt;Here is a use case : based on a client choice on a conversation with a chatbot , we need to call a tool.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DetchKing&quot;&gt; /u/DetchKing &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6xgql/what_are_the_alternatives_to_langchain_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6xgql/what_are_the_alternatives_to_langchain_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d6xgql</id><link href="https://www.reddit.com/r/LangChain/comments/1d6xgql/what_are_the_alternatives_to_langchain_agents/" /><updated>2024-06-03T05:57:07+00:00</updated><published>2024-06-03T05:57:07+00:00</published><title>What are the alternatives to langchain agents</title></entry><entry><author><name>/u/weighty8</name><uri>https://www.reddit.com/user/weighty8</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, langchain noob here. I have some data that I want to use for question answering. That data has information on different camera models and their specs. What I’m trying to do is retrieving the one that suites the provided use case best. So far I’ve been done some experiments with langchain and also preprocessing the prompt but with not so much success. &lt;/p&gt; &lt;p&gt;My question is: has anyone done anything similar to this? Would langchain even be the right choice here? If so, how would you approach this? &lt;/p&gt; &lt;p&gt;Thanks in advance &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/weighty8&quot;&gt; /u/weighty8 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d78ov3/need_help_with_my_use_case/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d78ov3/need_help_with_my_use_case/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d78ov3</id><link href="https://www.reddit.com/r/LangChain/comments/1d78ov3/need_help_with_my_use_case/" /><updated>2024-06-03T16:29:27+00:00</updated><published>2024-06-03T16:29:27+00:00</published><title>Need help with my use case</title></entry><entry><author><name>/u/kasikciozan</name><uri>https://www.reddit.com/user/kasikciozan</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, when using langgraph checkpointer to store the chat history, if a tool call fails, the subsequent tool calls will fail with an error:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;openai.BadRequestError: Error code: 400 - {&amp;#39;error&amp;#39;: {&amp;#39;message&amp;#39;: &amp;quot;An assistant message with &amp;#39;tool_calls&amp;#39; must be followed by tool messages responding to each &amp;#39;tool_call_id&amp;#39;. The following tool_call_ids did not have response messages: call_v5dzbL3NBrFZ7Z4xZExU9AUv&amp;quot;, &amp;#39;type&amp;#39;: &amp;#39;invalid_request_error&amp;#39;, &amp;#39;param&amp;#39;: &amp;#39;messages.[8].role&amp;#39;, &amp;#39;code&amp;#39;: None}} &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If I don&amp;#39;t use a checkpointer, nothing breaks. I&amp;#39;m stuck because of this error, and need some help!&lt;/p&gt; &lt;p&gt;Also started a discussion on langgraph repo:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/langchain-ai/langgraph/discussions/544&quot;&gt;https://github.com/langchain-ai/langgraph/discussions/544&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kasikciozan&quot;&gt; /u/kasikciozan &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d71axk/langgraph_using_checkpointer_makes_the_tool_calls/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d71axk/langgraph_using_checkpointer_makes_the_tool_calls/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d71axk</id><link href="https://www.reddit.com/r/LangChain/comments/1d71axk/langgraph_using_checkpointer_makes_the_tool_calls/" /><updated>2024-06-03T10:36:25+00:00</updated><published>2024-06-03T10:36:25+00:00</published><title>Langgraph: Using CheckPointer makes the tool calls break, if a tool call has failed</title></entry><entry><author><name>/u/FunInformation2332</name><uri>https://www.reddit.com/user/FunInformation2332</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I want to build a RAG chatbot using case texts but I can&amp;#39;t get good results in similarity search. &lt;/p&gt; &lt;p&gt;When I think about the reasons for this, I suspect that repetitive sentences in legal texts are the problem. How can I overcome this problem? I have tried semantic chunking, parent document retrival, almost everything. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FunInformation2332&quot;&gt; /u/FunInformation2332 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6mnum/rag_with_legal_texts/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6mnum/rag_with_legal_texts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d6mnum</id><link href="https://www.reddit.com/r/LangChain/comments/1d6mnum/rag_with_legal_texts/" /><updated>2024-06-02T20:32:59+00:00</updated><published>2024-06-02T20:32:59+00:00</published><title>RAG with legal texts</title></entry><entry><author><name>/u/rarchit</name><uri>https://www.reddit.com/user/rarchit</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am currently developing an app using langserve that requires a user to be authenticated to load files into the vectorstore and for retrieving documents as well:&lt;/p&gt; &lt;p&gt;Based on the example provided here:&lt;br/&gt; &lt;a href=&quot;https://github.com/langchain-ai/langserve/blob/main/examples/auth/per_req_config_modifier/server.py&quot;&gt;https://github.com/langchain-ai/langserve/blob/main/examples/auth/per_req_config_modifier/server.py&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I have come up with this so far which works perfectly for the &amp;quot;invoke&amp;quot; request:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;class PerUserQuery(RunnableSerializable): &amp;quot;&amp;quot;&amp;quot; A custom runnable that returns a list of documents for the given user. The runnable is configurable by the user, and the search results are filtered by the user ID. &amp;quot;&amp;quot;&amp;quot; user_id: Optional[str] vectorstore: VectorStore class Config: # Allow arbitrary types since VectorStore is an abstract interface # and not a pydantic model arbitrary_types_allowed = True def get_rag_chain(self, query): def format_docs(docs): return &amp;quot;\n\n&amp;quot;.join(doc.page_content for doc in docs) retriever = self.vectorstore.similarity_search( query, k=10, filter={&amp;quot;user_id&amp;quot;: {&amp;quot;$eq&amp;quot;: self.user_id}} ) formatted_docs = format_docs(retriever) setup_and_retrieval = RunnableParallel( {&amp;quot;context&amp;quot;: lambda x: formatted_docs, &amp;quot;question&amp;quot;: RunnablePassthrough()} ) prompt = hub.pull(&amp;quot;rarchit/rag-prompt-bullet&amp;quot;) llm = get_llm() rag_chain = setup_and_retrieval | prompt | llm | StrOutputParser() return rag_chain def _invoke( self, input: str, config: Optional[RunnableConfig] = None, **kwargs: Any ) -&amp;gt; List[Document]: &amp;quot;&amp;quot;&amp;quot; Invoke the retriever &amp;quot;&amp;quot;&amp;quot; rag_chain = self.get_rag_chain(query=input) return rag_chain.invoke(str(input)) def invoke( self, input: str, config: Optional[RunnableConfig] = None, **kwargs ) -&amp;gt; List[Document]: return self._call_with_config(self._invoke, input, config, **kwargs) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;However I am unable modify the endpoint to stream the response. If anyone could help out with the same I would really appreciate it. Currently stuck here&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rarchit&quot;&gt; /u/rarchit &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6x1k9/streaming_in_langserve_with_the_per_req_config/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6x1k9/streaming_in_langserve_with_the_per_req_config/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d6x1k9</id><link href="https://www.reddit.com/r/LangChain/comments/1d6x1k9/streaming_in_langserve_with_the_per_req_config/" /><updated>2024-06-03T05:28:36+00:00</updated><published>2024-06-03T05:28:36+00:00</published><title>Streaming in Langserve with the `per_req_config_modifier`</title></entry><entry><author><name>/u/Naanu__Yaaru</name><uri>https://www.reddit.com/user/Naanu__Yaaru</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am trying to build a RAG, the use-case is to upload some pdf files and ask questions about it. The stack include: streamlit, langchain, ollama(mistral ig) and chroma db. Only questions related to the uploaded pdf file(s) must be answered. In case there is a question not related to the pdf file content, the answer should be &amp;quot;I don&amp;#39;t know&amp;quot; or &amp;quot;not related to the context&amp;quot;. How can this be done ..?? Is it related to the prompt ?? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Naanu__Yaaru&quot;&gt; /u/Naanu__Yaaru &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6tih5/consider_questions_related_to_the_uploaded_files/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6tih5/consider_questions_related_to_the_uploaded_files/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d6tih5</id><link href="https://www.reddit.com/r/LangChain/comments/1d6tih5/consider_questions_related_to_the_uploaded_files/" /><updated>2024-06-03T02:03:27+00:00</updated><published>2024-06-03T02:03:27+00:00</published><title>Consider questions related to the uploaded files...</title></entry><entry><author><name>/u/Strange_Network7987</name><uri>https://www.reddit.com/user/Strange_Network7987</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone!&lt;br/&gt; Im a starter on playing with langchain and currently trying out llms using Ollama, but im kinda fuzzy on how to select a model for a specific use (embedding, text generation, code generation etc.) from such a wide range of models. Im pretty much using Llama3 for every use case. Can anyone help me? Much appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Strange_Network7987&quot;&gt; /u/Strange_Network7987 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6o48l/llm_model_selection/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6o48l/llm_model_selection/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d6o48l</id><link href="https://www.reddit.com/r/LangChain/comments/1d6o48l/llm_model_selection/" /><updated>2024-06-02T21:37:35+00:00</updated><published>2024-06-02T21:37:35+00:00</published><title>Llm model selection</title></entry><entry><author><name>/u/MountainBlock</name><uri>https://www.reddit.com/user/MountainBlock</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey,&lt;/p&gt; &lt;p&gt;I&amp;#39;m relatively new to Langchain and have primarily worked with chains and retrievers. Recently, I discovered agents and tools, and they seem quite powerful.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve successfully set up an SQL agent following the documentation. Now, I&amp;#39;m interested in creating an agent that can browse both an SQL database and document-based sources.&lt;/p&gt; &lt;p&gt;I saw in the documentation that it&amp;#39;s possible to use multiple tools, like combining &lt;a href=&quot;https://python.langchain.com/v0.2/docs/how_to/agent_executor/&quot;&gt;Tavily and a retriever tool.&lt;/a&gt; &lt;/p&gt; &lt;p&gt;I&amp;#39;d appreciate if someone could let me know where it&amp;#39;s possible to build such an agent and where to look for relevant resources? So far, it&amp;#39;s been quite difficult to find anything that can point me in the right direction.&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MountainBlock&quot;&gt; /u/MountainBlock &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6ern3/is_it_possible_to_create_an_agent_that_can_query/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6ern3/is_it_possible_to_create_an_agent_that_can_query/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d6ern3</id><link href="https://www.reddit.com/r/LangChain/comments/1d6ern3/is_it_possible_to_create_an_agent_that_can_query/" /><updated>2024-06-02T14:39:45+00:00</updated><published>2024-06-02T14:39:45+00:00</published><title>Is it possible to create an agent that can query a MySQL database and answer questions about a document?</title></entry><entry><author><name>/u/rsdnoob_official</name><uri>https://www.reddit.com/user/rsdnoob_official</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to interact with an external API using RequestsPostTool, AIPluginTool, and create_openai_tools_agent. But I am always getting this error:&lt;/p&gt; &lt;p&gt;TypeError: RequestsPostTool._run() got an unexpected keyword argument &amp;#39;url&amp;#39;&lt;/p&gt; &lt;p&gt;I checked the logs from Langsmith and it seems the issue is caused by double quotations outside the JSON string and not inside the JSON string. This causes RequestsPostTool._run() function to not work in the code.&lt;/p&gt; &lt;p&gt;My question is how to resolve this error efficiently or how to validate the output of LLM before it pass the input to RequestsPostTool._run()&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rsdnoob_official&quot;&gt; /u/rsdnoob_official &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6ebjn/typeerror_requestsposttool_run_got_an_unexpected/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6ebjn/typeerror_requestsposttool_run_got_an_unexpected/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d6ebjn</id><link href="https://www.reddit.com/r/LangChain/comments/1d6ebjn/typeerror_requestsposttool_run_got_an_unexpected/" /><updated>2024-06-02T14:18:28+00:00</updated><published>2024-06-02T14:18:28+00:00</published><title>TypeError: RequestsPostTool._run() got an unexpected keyword argument 'url'</title></entry><entry><author><name>/u/trj_flash75</name><uri>https://www.reddit.com/user/trj_flash75</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This video covers:&lt;br/&gt; - How to use Streamlit Secrets to hide your API keys&lt;br/&gt; - Importance of requirements.txt file&lt;br/&gt; - Deploy the LLM application on Streamlit and get a sharable link&lt;br/&gt; - Also learn how to fix the Chroma and SQLite3 issues while deploying your application built using Langchain and Chroma vector base.&lt;/p&gt; &lt;p&gt;Watch here: &lt;a href=&quot;https://www.youtube.com/watch?v=7BBzM2qCZvc&quot;&gt;https://www.youtube.com/watch?v=7BBzM2qCZvc&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/trj_flash75&quot;&gt; /u/trj_flash75 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6bkbr/deploy_langchain_streaming_rag_app_on_streamlit/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6bkbr/deploy_langchain_streaming_rag_app_on_streamlit/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d6bkbr</id><link href="https://www.reddit.com/r/LangChain/comments/1d6bkbr/deploy_langchain_streaming_rag_app_on_streamlit/" /><updated>2024-06-02T11:50:09+00:00</updated><published>2024-06-02T11:50:09+00:00</published><title>Deploy Langchain Streaming RAG app on Streamlit</title></entry><entry><author><name>/u/Remarkable-Leg5291</name><uri>https://www.reddit.com/user/Remarkable-Leg5291</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6dvnw/chatgpt_refusenot_aware_of_its_function_calling/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/AC2fqq5Fun0b1UiLP8D4arZcJpGSC8HC-F5VpOHAvwA.jpg&quot; alt=&quot;ChatGPT refuse/not aware of its function calling capability, and don't call functions even when there are functions available for it&quot; title=&quot;ChatGPT refuse/not aware of its function calling capability, and don't call functions even when there are functions available for it&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m new to LangChain, and currently learning LangGraph. This morning things are fine, I was trying to replicate the AgentExecutor using LangGraph as presented in their Youtube videos, and the agent (GPT 4.0) was able to use the web search tool (DuckDuckGo, btw) to search for information about weather, and return to me correct answer. &lt;/p&gt; &lt;p&gt;However, in the evening of the same day, I could not do so anymore. The model refuse to give me real time data about weather. It got worse: when I specifically asked it to use function call to perform search about weather, but it even denying it function call capabilities.&lt;/p&gt; &lt;p&gt;Do anyone knows why this is the case? It is so frustrating!&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/sl8oai2fz54d1.png?width=1441&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c257cb67bbbd91c60fd17ea239c4adef9df891b2&quot;&gt;This is the screenshot of my agent denying me. Hurt!&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Remarkable-Leg5291&quot;&gt; /u/Remarkable-Leg5291 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6dvnw/chatgpt_refusenot_aware_of_its_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6dvnw/chatgpt_refusenot_aware_of_its_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d6dvnw</id><media:thumbnail url="https://b.thumbs.redditmedia.com/AC2fqq5Fun0b1UiLP8D4arZcJpGSC8HC-F5VpOHAvwA.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1d6dvnw/chatgpt_refusenot_aware_of_its_function_calling/" /><updated>2024-06-02T13:57:06+00:00</updated><published>2024-06-02T13:57:06+00:00</published><title>ChatGPT refuse/not aware of its function calling capability, and don't call functions even when there are functions available for it</title></entry><entry><author><name>/u/baka-sensie</name><uri>https://www.reddit.com/user/baka-sensie</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, &lt;/p&gt; &lt;p&gt;I recently started learning langchain and am developing a simple app in which first we enter user&amp;#39;s name then one agent finds their linkedin profile url and based on that writes a short summary about them, but I am facing an issue where the url is often times another redirecting link to the main profile page url, but when the redirecting link is forwarded to Proxycurl API(api to access linkedin page through url) which is not able to detect it, how should i go about this problem? &lt;/p&gt; &lt;p&gt;Thanks. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/baka-sensie&quot;&gt; /u/baka-sensie &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6dm3b/hi_folks_need_help_regarding_react_agents_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d6dm3b/hi_folks_need_help_regarding_react_agents_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d6dm3b</id><link href="https://www.reddit.com/r/LangChain/comments/1d6dm3b/hi_folks_need_help_regarding_react_agents_and/" /><updated>2024-06-02T13:43:29+00:00</updated><published>2024-06-02T13:43:29+00:00</published><title>Hi folks, need help regarding ReAct agents and working with urls.</title></entry><entry><author><name>/u/pmz</name><uri>https://www.reddit.com/user/pmz</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d69knm/running_langchainjs_applications_on_aws_lambda/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/geuYofjAJgV8mQtT1sIRFLZktEhj3q4mi7utWrop-Rw.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b7e51526a2cee0b2832384ff598c6ed090b84b79&quot; alt=&quot;Running LangChain.js Applications on AWS Lambda&quot; title=&quot;Running LangChain.js Applications on AWS Lambda&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pmz&quot;&gt; /u/pmz &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://community.aws/content/2grhh3vrinYLsg3xkFNCe4LCcUL/running-langchain-js-applications-on-aws-lambda&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d69knm/running_langchainjs_applications_on_aws_lambda/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d69knm</id><media:thumbnail url="https://external-preview.redd.it/geuYofjAJgV8mQtT1sIRFLZktEhj3q4mi7utWrop-Rw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b7e51526a2cee0b2832384ff598c6ed090b84b79" /><link href="https://www.reddit.com/r/LangChain/comments/1d69knm/running_langchainjs_applications_on_aws_lambda/" /><updated>2024-06-02T09:34:04+00:00</updated><published>2024-06-02T09:34:04+00:00</published><title>Running LangChain.js Applications on AWS Lambda</title></entry><entry><author><name>/u/rmanoj_11</name><uri>https://www.reddit.com/user/rmanoj_11</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, I am new to building RAG application. I have no idea about how to make the LLM to answer with all the knowledge about 1000s of articles. Let&amp;#39;s say I have 1000s of success stories about various businesses, now I want LLM to craft a winning strategy.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rmanoj_11&quot;&gt; /u/rmanoj_11 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5slpr/how_can_i_get_cumulative_answer_after_analysing/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5slpr/how_can_i_get_cumulative_answer_after_analysing/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5slpr</id><link href="https://www.reddit.com/r/LangChain/comments/1d5slpr/how_can_i_get_cumulative_answer_after_analysing/" /><updated>2024-06-01T17:50:56+00:00</updated><published>2024-06-01T17:50:56+00:00</published><title>How can I get cumulative answer after analysing 1000s of articles?</title></entry><entry><author><name>/u/noodleswind</name><uri>https://www.reddit.com/user/noodleswind</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sx4v/how_would_you_design_the_supervisor_in_the/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/qbhzq8tt204d1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=efd0dcd8ba05ea5558dec93d893e8b3da6b7734b&quot; alt=&quot;How would you design the supervisor in the following diagram?&quot; title=&quot;How would you design the supervisor in the following diagram?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/noodleswind&quot;&gt; /u/noodleswind &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/qbhzq8tt204d1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sx4v/how_would_you_design_the_supervisor_in_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1d5sx4v</id><media:thumbnail url="https://preview.redd.it/qbhzq8tt204d1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=efd0dcd8ba05ea5558dec93d893e8b3da6b7734b" /><link href="https://www.reddit.com/r/LangChain/comments/1d5sx4v/how_would_you_design_the_supervisor_in_the/" /><updated>2024-06-01T18:05:04+00:00</updated><published>2024-06-01T18:05:04+00:00</published><title>How would you design the supervisor in the following diagram?</title></entry><entry><author><name>/u/giagara</name><uri>https://www.reddit.com/user/giagara</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In my RAG LLM I want to return the documents used to produce the answer. I don&amp;#39;t want ALL the documents, but just the one or two that open ai used to produce the answer. &lt;/p&gt; &lt;p&gt;Example&lt;/p&gt; &lt;p&gt;Question: what day is today? &lt;/p&gt; &lt;p&gt;Documents retrieved - doc1 chunk1: on that day the sky was red - doc2 chunk15: today is Saturday - doc3 chunk666: my name is Michael and I was born two days before my wife &lt;/p&gt; &lt;p&gt;Answer: today it&amp;#39;s Saturday (doc2) &lt;/p&gt; &lt;p&gt;With returning source documents, my context contains all three documents, but just doc2 have been used to answer the question. &lt;/p&gt; &lt;p&gt;At the moment I&amp;#39;m asking open ai to put a separator at the end of the question and write a json with the doc index (from 1 to 5), and then pick the context[index], but it&amp;#39;s not as robust as I like. &lt;/p&gt; &lt;p&gt;Any suggestions? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/giagara&quot;&gt; /u/giagara &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5xa86/return_only_used_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5xa86/return_only_used_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5xa86</id><link href="https://www.reddit.com/r/LangChain/comments/1d5xa86/return_only_used_documents/" /><updated>2024-06-01T21:25:56+00:00</updated><published>2024-06-01T21:25:56+00:00</published><title>Return only used documents</title></entry><entry><author><name>/u/trj_flash75</name><uri>https://www.reddit.com/user/trj_flash75</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Fast LLM RAG inference using Groq and Langchain Streaming. &lt;/p&gt; &lt;p&gt;Groq is introducing a new, simpler processing architecture designed specifically for the performance requirements of machine learning applications and other compute-intensive workloads. The simpler hardware also saves developer resources by eliminating the need for profiling, and also makes it easier to deploy AI solutions at scale. &lt;/p&gt; &lt;p&gt;Resource: &lt;a href=&quot;https://www.youtube.com/watch?v=frMdOL8knqg&quot;&gt;https://www.youtube.com/watch?v=frMdOL8knqg&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/trj_flash75&quot;&gt; /u/trj_flash75 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sb5s/faster_llm_inference_using_groq_and_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sb5s/faster_llm_inference_using_groq_and_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5sb5s</id><link href="https://www.reddit.com/r/LangChain/comments/1d5sb5s/faster_llm_inference_using_groq_and_langchain/" /><updated>2024-06-01T17:37:25+00:00</updated><published>2024-06-01T17:37:25+00:00</published><title>Faster LLM Inference using Groq and Langchain Streaming</title></entry><entry><author><name>/u/Long_Respond1735</name><uri>https://www.reddit.com/user/Long_Respond1735</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;anyone used langchain with browser automation and gpt4o?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Long_Respond1735&quot;&gt; /u/Long_Respond1735 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sc9r/langchain_with_vision_browser/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5sc9r/langchain_with_vision_browser/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5sc9r</id><link href="https://www.reddit.com/r/LangChain/comments/1d5sc9r/langchain_with_vision_browser/" /><updated>2024-06-01T17:38:51+00:00</updated><published>2024-06-01T17:38:51+00:00</published><title>langchain with vision browser</title></entry><entry><author><name>/u/i_am_innovative</name><uri>https://www.reddit.com/user/i_am_innovative</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;No Body &lt;/p&gt; &lt;p&gt;I guess you understood what is mean..&lt;/p&gt; &lt;p&gt;out of these i only knew about LlamaCpp&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/i_am_innovative&quot;&gt; /u/i_am_innovative &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5qcgw/what_are_the_different_ways_we_can_load_llama/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d5qcgw/what_are_the_different_ways_we_can_load_llama/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1d5qcgw</id><link href="https://www.reddit.com/r/LangChain/comments/1d5qcgw/what_are_the_different_ways_we_can_load_llama/" /><updated>2024-06-01T16:06:13+00:00</updated><published>2024-06-01T16:06:13+00:00</published><title>What are the different ways we can load llama model into Langchain ?</title></entry></feed>