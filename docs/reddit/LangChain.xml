<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-30T23:22:12+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Automatic-Highway-75</name><uri>https://www.reddit.com/user/Automatic-Highway-75</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks, I want to share a side project I‚Äôve been working on during weekends: AutoCoder! üë®‚Äçüíªüë©‚Äçüíª&lt;br/&gt; ü§ñ A description-to-pull-request bot that can answer questions, and make code changes to Github repo through natural language instructions. It‚Äôs powered by LLM function calling and built with&lt;br/&gt; - üß† &lt;a href=&quot;https://github.com/TengHu/ActionWeaver&quot;&gt;ActionWeaver&lt;/a&gt; for function calling orchestration.&lt;br/&gt; - üìö &lt;a href=&quot;https://www.linkedin.com/company/llamaindex/&quot;&gt;LlamaIndex&lt;/a&gt; for RAG, including code chunking and advanced RAG technique like Hypothetical Document Embeddings!&lt;br/&gt; - üõ†Ô∏è &lt;a href=&quot;https://www.langchain.com/langsmith&quot;&gt;LangSmith&lt;/a&gt; for powerful LLM tracing and debugging!&lt;br/&gt; - API toolings from LangChain Community.&lt;br/&gt; It&amp;#39;s incredible what a single developer can leverage existing AI libraries to create something like this in a short time! &lt;/p&gt; &lt;p&gt;Please checkout the codebase below üëá&lt;br/&gt; Github Repo: &lt;a href=&quot;https://github.com/TengHu/AutoCoder&quot;&gt;https://github.com/TengHu/AutoCoder&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Automatic-Highway-75&quot;&gt; /u/Automatic-Highway-75 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aeq95t/autocoder_a_descriptiontopullrequest_coding_bot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aeq95t/autocoder_a_descriptiontopullrequest_coding_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aeq95t</id><link href="https://www.reddit.com/r/LangChain/comments/1aeq95t/autocoder_a_descriptiontopullrequest_coding_bot/" /><updated>2024-01-30T14:55:43+00:00</updated><published>2024-01-30T14:55:43+00:00</published><title>AutoCoder: A description-to-pull-request coding bot built with ActionWeaver, LlamaIndex and LangChain/LangSmith</title></entry><entry><author><name>/u/stoicbats_</name><uri>https://www.reddit.com/user/stoicbats_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I am currently tackling a project that involves a list of various brand names within a specific domain. For instance:&lt;/p&gt; &lt;p&gt;&lt;code&gt;domain_names = [&amp;#39;xyz&amp;#39;, &amp;#39;yza&amp;#39;, &amp;#39;tra&amp;#39;, &amp;#39;world&amp;#39;]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;My goal is to develop a search s capable of analyzing word similarity. Specifically, the system should accept a word and return the top &amp;#39;k&amp;#39; words that are most similar to it. I have experimented with OpenAI embeddings, particularly the latest Embedding Version 3 (3072 dimensions), but the results have been unsatisfactory.&lt;/p&gt; &lt;p&gt;Could someone suggest the most effective approaches for searching word-level similarities ?In the era of GPT, Would it be advisable to train my own Word2Vec model?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/stoicbats_&quot;&gt; /u/stoicbats_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aevsuu/in_the_era_of_gpt_building_an_effective_word/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aevsuu/in_the_era_of_gpt_building_an_effective_word/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aevsuu</id><link href="https://www.reddit.com/r/LangChain/comments/1aevsuu/in_the_era_of_gpt_building_an_effective_word/" /><updated>2024-01-30T18:42:19+00:00</updated><published>2024-01-30T18:42:19+00:00</published><title>In the era of GPT, building an effective word similarity search in 2023</title></entry><entry><author><name>/u/marcuss171</name><uri>https://www.reddit.com/user/marcuss171</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aey6gi/get_openai_callback_not_working_when_using_agent/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/2_9q3TSXV0C94uCFK3v7tn0X9sdrY5mnwzQK8rN1ZzY.jpg&quot; alt=&quot;get_openai_callback not working when using Agent Executor after updating to latest version of Langchain&quot; title=&quot;get_openai_callback not working when using Agent Executor after updating to latest version of Langchain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;h3&gt;Description&lt;/h3&gt; &lt;p&gt;I&amp;#39;m trying to use the get_openai_callback from langchain_community.callbacks to get the number of token and costs incurred in using the agent but I am getting zero on everything, as you can see here when I print.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/9lbv5ocaymfc1.png?width=412&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3d7282b8c88c39bdacf48a4a6ad867c0fdc574bd&quot;&gt;https://preview.redd.it/9lbv5ocaymfc1.png?width=412&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3d7282b8c88c39bdacf48a4a6ad867c0fdc574bd&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I have also set up a custom callback handler to go deep into the issue and what I found is that ChatOpenAI from langchain_openai does not call ainvoke as ChatOpenAI langchain.chat_models did.&lt;/p&gt; &lt;p&gt;THank you for your help&lt;/p&gt; &lt;h3&gt;Code&lt;/h3&gt; &lt;pre&gt;&lt;code&gt;import os import traceback from typing import Any, Dict, List, Optional from uuid import UUID from langchain_community.callbacks import get_openai_callback from langchain_core.agents import AgentFinish from langchain_openai import ChatOpenAI from langchain.prompts import PromptTemplate from langchain.tools.render import render_text_description from langchain.agents.format_scratchpad import format_log_to_str from langchain.agents.output_parsers import ReActSingleInputOutputParser from langchain.schema import HumanMessage, LLMResult from langchain.callbacks.base import AsyncCallbackHandler from langchain.agents import AgentExecutor from app.services.llm.prompt import prompt_raw from app.services.llm.tools.build_tools import tools from app.classes.CustomBuffer import CustomConversationBufferMemory memory = CustomConversationBufferMemory(memory_key=&amp;quot;chat_history&amp;quot;, return_messages=True) class MyCustomAsyncHandler(AsyncCallbackHandler): async def on_llm_end(self, response: LLMResult, **kwargs: Any) -&amp;gt; None: &amp;quot;&amp;quot;&amp;quot;Run when chain ends running.&amp;quot;&amp;quot;&amp;quot; print(&amp;quot;RESPONSE: &amp;quot;, response) print(&amp;quot;Hi! I just woke up. Your llm is ending&amp;quot;) async def ask_assistant(input: str) -&amp;gt; str: prompt = PromptTemplate.from_template(prompt_raw) prompt = prompt.partial( language=&amp;quot;Spanish&amp;quot;, tools=render_text_description(tools), tool_names=&amp;quot;, &amp;quot;.join([t.name for t in tools]), ) llm = ChatOpenAI( temperature=0, model_name=&amp;quot;gpt-4&amp;quot;, openai_api_key=os.environ[&amp;quot;OPENAI_API_KEY&amp;quot;], callbacks=[MyCustomAsyncHandler()], ) llm_with_stop = llm.bind(stop=[&amp;quot;\nObservation&amp;quot;]) agent = ( { &amp;quot;input&amp;quot;: lambda x: x[&amp;quot;input&amp;quot;], &amp;quot;agent_scratchpad&amp;quot;: lambda x: format_log_to_str(x[&amp;quot;intermediate_steps&amp;quot;]), &amp;quot;chat_history&amp;quot;: lambda x: x[&amp;quot;chat_history&amp;quot;], } | prompt | llm_with_stop | ReActSingleInputOutputParser() ) agent_executor = AgentExecutor( agent=agent, tools=tools, verbose=True, memory=memory, max_execution_time=60, handle_parsing_errors=True, ) with get_openai_callback() as cb: clara_ai_resp = await agent_executor.ainvoke({&amp;quot;input&amp;quot;: input}) clara_ai_output = clara_ai_resp[&amp;quot;output&amp;quot;] print(&amp;quot;CB: &amp;quot;, cb) return clara_ai_output, input, cb &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/marcuss171&quot;&gt; /u/marcuss171 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aey6gi/get_openai_callback_not_working_when_using_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aey6gi/get_openai_callback_not_working_when_using_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1aey6gi</id><media:thumbnail url="https://b.thumbs.redditmedia.com/2_9q3TSXV0C94uCFK3v7tn0X9sdrY5mnwzQK8rN1ZzY.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1aey6gi/get_openai_callback_not_working_when_using_agent/" /><updated>2024-01-30T20:18:08+00:00</updated><published>2024-01-30T20:18:08+00:00</published><title>get_openai_callback not working when using Agent Executor after updating to latest version of Langchain</title></entry><entry><author><name>/u/aniketmaurya</name><uri>https://www.reddit.com/user/aniketmaurya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aet9j9/document_search_and_retrieval_using_rag_powered/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/duoat8J8634e4Rv2ZQhE_tm9r0z0kHVcItCWmCNZjF4.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3519deab9d721c281488cc974e88b2b288109bd0&quot; alt=&quot;Document Search And Retrieval Using RAG - powered by Langchain&quot; title=&quot;Document Search And Retrieval Using RAG - powered by Langchain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://lightning.ai/lightning-ai/studios/document-search-and-retrieval-using-rag&quot;&gt;This Studio&lt;/a&gt; is a minimal reproducible pipeline to retrieve semantically similar documents based on the input query. The next step for this Studio involves connecting an LLM and engaging in a chat with your document through the retrieval pipeline.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;The retriever pipeline in this Studio is composed of the following components:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Document Loader&lt;/strong&gt;: Load the document (.txt, .pdf, .docx, .ppt) and perform text cleaning &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Text Splitter&lt;/strong&gt;: Split the document texts into multiple chunks &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Embedding Generation&lt;/strong&gt;: Generate vector representation of text chunks&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Vector database&lt;/strong&gt;: Embed and store each of the chunks and store in a vector DB &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Retriever and Reranking&lt;/strong&gt;: Retrieve data based on query similarity&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/idqetsa1zlfc1.png?width=3058&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a1b47eb6c477e7762bc745875cda45e9d08500e&quot;&gt;https://preview.redd.it/idqetsa1zlfc1.png?width=3058&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a1b47eb6c477e7762bc745875cda45e9d08500e&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://lightning.ai/lightning-ai/studios/document-search-and-retrieval-using-rag&quot;&gt;https://lightning.ai/lightning-ai/studios/document-search-and-retrieval-using-rag&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/aniketmaurya&quot;&gt; /u/aniketmaurya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aet9j9/document_search_and_retrieval_using_rag_powered/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aet9j9/document_search_and_retrieval_using_rag_powered/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1aet9j9</id><media:thumbnail url="https://external-preview.redd.it/duoat8J8634e4Rv2ZQhE_tm9r0z0kHVcItCWmCNZjF4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3519deab9d721c281488cc974e88b2b288109bd0" /><link href="https://www.reddit.com/r/LangChain/comments/1aet9j9/document_search_and_retrieval_using_rag_powered/" /><updated>2024-01-30T17:01:10+00:00</updated><published>2024-01-30T17:01:10+00:00</published><title>Document Search And Retrieval Using RAG - powered by Langchain</title></entry><entry><author><name>/u/Fine-Firefighter-120</name><uri>https://www.reddit.com/user/Fine-Firefighter-120</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I&amp;#39;m curious as to how I can convert approximately 200,000 words of journaling that I have done into a book. It&amp;#39;s messy, unedited stuff that I&amp;#39;ve put down. I just want to throw it into a database somehow and ask chatgpt to make sense of it. Is that something that is possible now?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I think I need to put the content into a vector store database somehow and use langchain to query it? I wonder if there&amp;#39;s just a desktop app or a LLM wrapper somewhere that can already do this. Would love to be able to do this without having to learn python!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thanks for any wisdom you guys can provide!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fine-Firefighter-120&quot;&gt; /u/Fine-Firefighter-120 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aepyv5/convert_journal_into_a_book/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aepyv5/convert_journal_into_a_book/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aepyv5</id><link href="https://www.reddit.com/r/LangChain/comments/1aepyv5/convert_journal_into_a_book/" /><updated>2024-01-30T14:42:35+00:00</updated><published>2024-01-30T14:42:35+00:00</published><title>Convert journal into a book</title></entry><entry><author><name>/u/devinbost</name><uri>https://www.reddit.com/user/devinbost</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I noticed that GPT-4 turbo is great with tons of context. However, the output I get is too limited to rewrite all 100,000 input tokens. I&amp;#39;m trying to find a strategy that would allow me to take a legacy code base and have the LLM rewrite the entire thing. I tried a test to see if I could get ChatGPT to generate part of the result until it hits its token limit and then continue when I say next, but it doesn&amp;#39;t seem to totally follow the instructions. See the smoke test here: &lt;a href=&quot;https://chat.openai.com/share/19c19e6c-0adf-4087-b83b-affe5886498e&quot;&gt;https://chat.openai.com/share/19c19e6c-0adf-4087-b83b-affe5886498e&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I think it would be cool to use this approach to rewrite old code to use LCEL, for example.&lt;/p&gt; &lt;p&gt;Any ideas?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/devinbost&quot;&gt; /u/devinbost &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aedmys/looking_for_ideas_on_how_to_code_gen_a_100000/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aedmys/looking_for_ideas_on_how_to_code_gen_a_100000/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aedmys</id><link href="https://www.reddit.com/r/LangChain/comments/1aedmys/looking_for_ideas_on_how_to_code_gen_a_100000/" /><updated>2024-01-30T02:35:48+00:00</updated><published>2024-01-30T02:35:48+00:00</published><title>Looking for ideas on how to code gen a 100,000 token refactor</title></entry><entry><author><name>/u/sizzlingham</name><uri>https://www.reddit.com/user/sizzlingham</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone! I am a newbie to Langchain amd just want to ask for sequential chains, is there another way (besides introducing callbacks) to reduce error propagation of the model‚Äôs output from one chain to the next? For example, of the output from the first chain is wrong, then it will be passed to the next chain and affects the subsequent responses. Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sizzlingham&quot;&gt; /u/sizzlingham &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aefwi8/sequential_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aefwi8/sequential_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aefwi8</id><link href="https://www.reddit.com/r/LangChain/comments/1aefwi8/sequential_chain/" /><updated>2024-01-30T04:31:25+00:00</updated><published>2024-01-30T04:31:25+00:00</published><title>Sequential Chain</title></entry><entry><author><name>/u/d3the_h3ll0w</name><uri>https://www.reddit.com/user/d3the_h3ll0w</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae5fwi/searching_youtube_with_langchain_tools_streamlit/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/155DtY3G4XZlDaIpDtzSo7jEzWtBdwlnyoGucKjwfo4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9447ddad191458ea03eb58f9e7035a59501ef2cf&quot; alt=&quot;Searching Youtube with Langchain Tools + Streamlit&quot; title=&quot;Searching Youtube with Langchain Tools + Streamlit&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/d3the_h3ll0w&quot;&gt; /u/d3the_h3ll0w &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://jdsemrau.substack.com/p/searching-youtube-with-langchain&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae5fwi/searching_youtube_with_langchain_tools_streamlit/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ae5fwi</id><media:thumbnail url="https://external-preview.redd.it/155DtY3G4XZlDaIpDtzSo7jEzWtBdwlnyoGucKjwfo4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9447ddad191458ea03eb58f9e7035a59501ef2cf" /><link href="https://www.reddit.com/r/LangChain/comments/1ae5fwi/searching_youtube_with_langchain_tools_streamlit/" /><updated>2024-01-29T20:34:19+00:00</updated><published>2024-01-29T20:34:19+00:00</published><title>Searching Youtube with Langchain Tools + Streamlit</title></entry><entry><author><name>/u/Euloghtos</name><uri>https://www.reddit.com/user/Euloghtos</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello all again, &lt;/p&gt; &lt;p&gt;I have a chromadb with thousands of images and documents, and i have some collections depending on some criteria i use on the different files i want to save, for example Financial_Documents , Technical_documents , Technical_Images etc. &lt;/p&gt; &lt;p&gt;Now i want to chat with the LLM for these documents, for this i want the AI to search the db and the collections and return me some result for which we can have a conversation.&lt;/p&gt; &lt;p&gt;So my question is : how will the AI understand when to search a specific collection? Also which agent is best for such a task?&lt;/p&gt; &lt;p&gt;Thank you in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Euloghtos&quot;&gt; /u/Euloghtos &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aej16x/chromadb_with_multiple_collections_and_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aej16x/chromadb_with_multiple_collections_and_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aej16x</id><link href="https://www.reddit.com/r/LangChain/comments/1aej16x/chromadb_with_multiple_collections_and_agents/" /><updated>2024-01-30T07:43:22+00:00</updated><published>2024-01-30T07:43:22+00:00</published><title>ChromaDb with multiple collections and Agents</title></entry><entry><author><name>/u/Electronic-Letter592</name><uri>https://www.reddit.com/user/Electronic-Letter592</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to implement RAG for a 100 pages document that has a hierarchical structure of chapters, sub-chapters, etc. Therefore I chunk the document into smaller paragraphs. In many cases, a chunk within a sub-chapter makes only sense in the context of the title of the sub-chapter, e.g. (6.1 Method ABC, 6.1.1 Disadvantages).&lt;/p&gt; &lt;p&gt;I wonder what are the most common approaches in RAG to handle hierarchical structures, which are very common in longer documents?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Electronic-Letter592&quot;&gt; /u/Electronic-Letter592 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae3urf/rag_for_documents_with_chapters_and_subchapters/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae3urf/rag_for_documents_with_chapters_and_subchapters/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ae3urf</id><link href="https://www.reddit.com/r/LangChain/comments/1ae3urf/rag_for_documents_with_chapters_and_subchapters/" /><updated>2024-01-29T19:29:37+00:00</updated><published>2024-01-29T19:29:37+00:00</published><title>RAG for documents with chapters and sub-chapters</title></entry><entry><author><name>/u/CantaloupeLeading646</name><uri>https://www.reddit.com/user/CantaloupeLeading646</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;what are some good notebooks or repos that i could use to start playing around with a system that chains together multiple operations including RAG operation?&lt;/p&gt; &lt;p&gt;i want in the end to have a system that does the following:&lt;/p&gt; &lt;p&gt;input -&amp;gt; enters some LLM that outputs another text -&amp;gt; retrieve some documents and output multiple different texts -&amp;gt; for each of the outputted texts go through another LLM&lt;/p&gt; &lt;p&gt;i know it shouldn&amp;#39;t be very complicated but i have a hard time getting started and i don&amp;#39;t see anything that does that but I&amp;#39;m sure it exists. &lt;/p&gt; &lt;p&gt;specifically, i don&amp;#39;t see anywhere an example of a chain that passes the output of an LLM as the input to another LLM instance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CantaloupeLeading646&quot;&gt; /u/CantaloupeLeading646 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adxilw/good_starting_points_for_a_new_project_involving/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adxilw/good_starting_points_for_a_new_project_involving/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adxilw</id><link href="https://www.reddit.com/r/LangChain/comments/1adxilw/good_starting_points_for_a_new_project_involving/" /><updated>2024-01-29T15:10:01+00:00</updated><published>2024-01-29T15:10:01+00:00</published><title>good starting points for a new project involving chains of LLM operations</title></entry><entry><author><name>/u/kecepa5669</name><uri>https://www.reddit.com/user/kecepa5669</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Are there any research tools available to do research on the internet for free? Has anyone had any good or bad experiences with this type of task?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kecepa5669&quot;&gt; /u/kecepa5669 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae7y59/free_internet_research_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ae7y59/free_internet_research_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ae7y59</id><link href="https://www.reddit.com/r/LangChain/comments/1ae7y59/free_internet_research_tools/" /><updated>2024-01-29T22:17:15+00:00</updated><published>2024-01-29T22:17:15+00:00</published><title>Free internet research tools?</title></entry><entry><author><name>/u/pr1vacyn0eb</name><uri>https://www.reddit.com/user/pr1vacyn0eb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I can write the code, but it seems all-over-the-place. Not very reusable.&lt;/p&gt; &lt;p&gt;I like my csv, but the world likes their jsons formatted in alpeca/openAI/mistral/(did I miss any?). &lt;/p&gt; &lt;p&gt;When you do the final comparison between your model&amp;#39;s output and the correct answer, you are doing this in a dataframe/csv. &lt;/p&gt; &lt;p&gt;When you run multiple rounds of prompt testings, I suppose I could flatten this each time. &lt;/p&gt; &lt;p&gt;What does langchain do for this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pr1vacyn0eb&quot;&gt; /u/pr1vacyn0eb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adx6ny/why_does_it_seem_prompt_testing_is_hard_is_it/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adx6ny/why_does_it_seem_prompt_testing_is_hard_is_it/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adx6ny</id><link href="https://www.reddit.com/r/LangChain/comments/1adx6ny/why_does_it_seem_prompt_testing_is_hard_is_it/" /><updated>2024-01-29T14:55:28+00:00</updated><published>2024-01-29T14:55:28+00:00</published><title>Why does it seem prompt testing is hard? Is it data formatting? Or the actual testing?</title></entry><entry><author><name>/u/webNoob13</name><uri>https://www.reddit.com/user/webNoob13</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have qa pairs like ```&lt;/p&gt; &lt;h1&gt;Example question-answer pairs&lt;/h1&gt; &lt;p&gt;qa_pairs = [ {&amp;quot;question&amp;quot;: &amp;quot;Who leads the rebellion in &amp;#39;Animal Farm&amp;#39;?&amp;quot;, &amp;quot;answer&amp;quot;: &amp;quot;The pigs, specially Snowball and Napoleon, leads the rebellion.&amp;quot;}, {&amp;quot;question&amp;quot;: &amp;quot;What is the main theme of &amp;#39;Animal Farm&amp;#39;?&amp;quot;, &amp;quot;answer&amp;quot;: &amp;quot;The main theme are the corruption of power.&amp;quot;}, {&amp;quot;question&amp;quot;: &amp;quot;What happens to Boxer in the novel?&amp;quot;, &amp;quot;answer&amp;quot;: &amp;quot;Boxer is send to a slaughterhouse by the pigs.&amp;quot;} ] &lt;code&gt; Then I&amp;#39;m trying to iterate them like &lt;/code&gt; def create_grading_prompt(qa_pair): return [ (&amp;quot;system&amp;quot;, &amp;quot;You are a helpful AI bot. Your name is {name}.&amp;quot;), (&amp;quot;human&amp;quot;, f&amp;quot;Question: {qa_pair[&amp;#39;question&amp;#39;]}\nAnswer: {qa_pair[&amp;#39;answer&amp;#39;]}\n\nPlease grade the grammar of the answer based on the following rubric:\n{grammar_rubric}&amp;quot;) ]&lt;/p&gt; &lt;h1&gt;Process each question-answer pair&lt;/h1&gt; &lt;p&gt;for qa&lt;em&gt;pair in qa_pairs: grammar_and_grading_chain = SequentialChain([ ChatPromptTemplate.from_messages(create_grading_prompt(qa_pair)), llm, StrOutputParser() ]) result = grammar_and_grading_chain.invoke(qa_pair) print(f&amp;quot;Question: {qa_pair[&amp;#39;question&amp;#39;]}\nAnswer: {qa_pair[&amp;#39;answer&amp;#39;]}\nGrade: {result}\n&amp;quot;) &lt;code&gt; throws &lt;/code&gt; { &amp;quot;name&amp;quot;: &amp;quot;TypeError&amp;quot;, &amp;quot;message&amp;quot;: &amp;quot;Serializable.&lt;/em&gt;&lt;em&gt;init&lt;/em&gt;_() takes 1 positional argument but 2 were given&amp;quot;, &amp;quot;stack&amp;quot;: &amp;quot;--------------------------------------------------------------------------- TypeError Traceback (most recent call last) Cell In[6], line 9 7 # Process each question-answer pair 8 for qa_pair in qa_pairs: ----&amp;gt; 9 grammar_and_grading_chain = SequentialChain([ 10 ChatPromptTemplate.from_messages(create_grading_prompt(qa_pair)), 11 llm, 12 StrOutputParser() 13 ]) 14 result = grammar_and_grading_chain.invoke(qa_pair) 15 print(f\&amp;quot;Question: {qa_pair[&amp;#39;question&amp;#39;]}\ Answer: {qa_pair[&amp;#39;answer&amp;#39;]}\ Grade: {result}\ \&amp;quot;)&lt;/p&gt; &lt;p&gt;TypeError: Serializable.&lt;strong&gt;init&lt;/strong&gt;() takes 1 positional argument but 2 were given&amp;quot; } &lt;code&gt; because my previous try was throwing this same error. My previous try &lt;/code&gt; grammar_and_grading_chain = SequentialChain([ ChatPromptTemplate(lambda qa_pair: f&amp;quot;Question: {qa_pair[&amp;#39;question&amp;#39;]}\nAnswer: {qa_pair[&amp;#39;answer&amp;#39;]}\n\nPlease grade the grammar of the answer based on the following rubric:\n{grammar_rubric}&amp;quot;), llm, StrOutputParser() ])&lt;/p&gt; &lt;h1&gt;Process each question-answer pair&lt;/h1&gt; &lt;p&gt;for qa_pair in qa_pairs: result = grammar_and_grading_chain.invoke(qa_pair) print(f&amp;quot;Question: {qa_pair[&amp;#39;question&amp;#39;]}\nAnswer: {qa_pair[&amp;#39;answer&amp;#39;]}\nGrade: {result}\n&amp;quot;) ``` I looked at documentation here: &lt;a href=&quot;https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#&quot;&gt;https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#&lt;/a&gt; and don&amp;#39;t understand what I&amp;#39;m doing wrong.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/webNoob13&quot;&gt; /u/webNoob13 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adu5e9/chatprompttemplate_keeps_telling_me_i_have_2/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adu5e9/chatprompttemplate_keeps_telling_me_i_have_2/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adu5e9</id><link href="https://www.reddit.com/r/LangChain/comments/1adu5e9/chatprompttemplate_keeps_telling_me_i_have_2/" /><updated>2024-01-29T12:27:13+00:00</updated><published>2024-01-29T12:27:13+00:00</published><title>ChatPromptTemplate keeps telling me I have 2 arguments</title></entry><entry><author><name>/u/RatioAltruistic9324</name><uri>https://www.reddit.com/user/RatioAltruistic9324</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everybody!&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently developing some agents on Langchain for many purpose. Some are just documents analysis or data extraction from documents, and other are more Chatbot Rag based The first category are not really agents, they are refine chain (a bit modified from the LCEL turo one) + stuff one And the second is Langchain Agents (ZeroShotPrompt)&lt;/p&gt; &lt;p&gt;Both run with GPT4&lt;/p&gt; &lt;p&gt;But here is the thing :&lt;/p&gt; &lt;p&gt;For the first category, as the pdf can goes to 5 to 20 pages, my agents take several minutes to handle them Also, I remarqued that the more I put a defined structure in the prompt to extracr information, the more it is long (can go up to 10min)&lt;/p&gt; &lt;p&gt;And for the second category, as there is a multi query retrieval Generation based on pinecone, it also take 1 min before generation.&lt;/p&gt; &lt;p&gt;I look for conceptual way to explain that. We see a lot of agent out there which are more fast &lt;/p&gt; &lt;ul&gt; &lt;li&gt;is it the framework Langchain that slow down everything?&lt;/li&gt; &lt;li&gt;is I had a local model would it be faster ?&lt;/li&gt; &lt;li&gt;is because of the Rag too complex?&lt;/li&gt; &lt;li&gt;how could I drastically shorten my prompt but keeping clear schema for data extraction?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Thanks you all for your help !&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RatioAltruistic9324&quot;&gt; /u/RatioAltruistic9324 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adqrwj/speed_up_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adqrwj/speed_up_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adqrwj</id><link href="https://www.reddit.com/r/LangChain/comments/1adqrwj/speed_up_agents/" /><updated>2024-01-29T08:47:18+00:00</updated><published>2024-01-29T08:47:18+00:00</published><title>Speed up Agents</title></entry><entry><author><name>/u/mac_bateman</name><uri>https://www.reddit.com/user/mac_bateman</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, I&amp;#39;m trying to use these two guides from the Langchain documentation:&lt;/p&gt; &lt;p&gt;- &lt;a href=&quot;https://python.langchain.com/docs/use_cases/question_answering/citations&quot;&gt;https://python.langchain.com/docs/use_cases/question_answering/citations&lt;/a&gt;&lt;/p&gt; &lt;p&gt;- &lt;a href=&quot;https://python.langchain.com/docs/use_cases/question_answering/chat_history&quot;&gt;https://python.langchain.com/docs/use_cases/question_answering/chat_history&lt;/a&gt;&lt;/p&gt; &lt;p&gt;to create a chain that will return structured output with citations but also will accept chat_history. &lt;/p&gt; &lt;p&gt;Has anyone managed to create something similar using LCEL? &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mac_bateman&quot;&gt; /u/mac_bateman &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1advsq8/lcel_citations_chain_with_chat_history/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1advsq8/lcel_citations_chain_with_chat_history/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1advsq8</id><link href="https://www.reddit.com/r/LangChain/comments/1advsq8/lcel_citations_chain_with_chat_history/" /><updated>2024-01-29T13:52:40+00:00</updated><published>2024-01-29T13:52:40+00:00</published><title>LCEL - Citations chain with chat history</title></entry><entry><author><name>/u/glip-glop-evil</name><uri>https://www.reddit.com/user/glip-glop-evil</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to use langchain with GPT for a search tool. The search database query has a language code (en or zh) and when the tool is used, the language code is determined from the user query.&lt;/p&gt; &lt;p&gt;How can I get langchain to run the tool twice - in all available language codes translating the user query when necessary and compare the search content and get the most appropriate one before returning an answer? &lt;/p&gt; &lt;p&gt;Does this need to be done via the prompt or a more programmatic approach?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/glip-glop-evil&quot;&gt; /u/glip-glop-evil &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adpw9c/language_switching_with_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adpw9c/language_switching_with_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adpw9c</id><link href="https://www.reddit.com/r/LangChain/comments/1adpw9c/language_switching_with_tools/" /><updated>2024-01-29T07:46:15+00:00</updated><published>2024-01-29T07:46:15+00:00</published><title>Language switching with tools</title></entry><entry><author><name>/u/ashpreetbedi</name><uri>https://www.reddit.com/user/ashpreetbedi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi reddit, I built an AI that can interact with the Hacker News API: &lt;a href=&quot;https://hn.aidev.run&quot;&gt;https://hn.aidev.run&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You can ask questions like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;What&amp;#39;s on hackernews about AI?&lt;/li&gt; &lt;li&gt;What&amp;#39;s on hackernews about iPhone?&lt;/li&gt; &lt;li&gt;What&amp;#39;s trending on hackernews?&lt;/li&gt; &lt;li&gt;What are users showing on hackernews?&lt;/li&gt; &lt;li&gt;What are users asking on hackernews?&lt;/li&gt; &lt;li&gt;Summarize this story: &lt;a href=&quot;https://news.ycombinator.com/item?id=39156778&quot;&gt;https://news.ycombinator.com/item?id=39156778&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It uses function calling to query the HN api.&lt;/p&gt; &lt;p&gt;To answer questions about a particular topic, it‚Äôll search its knowledge base (a vector db that is periodically updated with the ‚Äútop stories‚Äù) and get details about those stories from the API.&lt;/p&gt; &lt;p&gt;This is pretty barebones and I built it today in &amp;lt; 2 hours, so it probably won‚Äôt meet your high standards. If you give it a try, I‚Äôd love your feedback on how I can improve it.&lt;/p&gt; &lt;p&gt;If you‚Äôre interested, I built this using &lt;a href=&quot;https://github.com/phidatahq/phidata&quot;&gt;phidata&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thanks for reading and would love to hear what you think.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashpreetbedi&quot;&gt; /u/ashpreetbedi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adarpa/hackernews_ai_built_using_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adarpa/hackernews_ai_built_using_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adarpa</id><link href="https://www.reddit.com/r/LangChain/comments/1adarpa/hackernews_ai_built_using_function_calling/" /><updated>2024-01-28T19:28:17+00:00</updated><published>2024-01-28T19:28:17+00:00</published><title>HackerNews AI built using function calling</title></entry><entry><author><name>/u/Hungry-Connection645</name><uri>https://www.reddit.com/user/Hungry-Connection645</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, I&amp;#39;m trying to familiarize myself with the internals of the langchain python package, I noticed that langchain and langchain_core are separated and in the internal code they have similar sub packages. my question is what is the need for this separation and what is the thought process behind what should be implemented in langchain vs langchain_core. Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Hungry-Connection645&quot;&gt; /u/Hungry-Connection645 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad9x8c/why_separate_langchain_and_langchain_core_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad9x8c/why_separate_langchain_and_langchain_core_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad9x8c</id><link href="https://www.reddit.com/r/LangChain/comments/1ad9x8c/why_separate_langchain_and_langchain_core_for/" /><updated>2024-01-28T18:53:53+00:00</updated><published>2024-01-28T18:53:53+00:00</published><title>Why separate langchain and langchain_core for python package</title></entry><entry><author><name>/u/Benjamona97</name><uri>https://www.reddit.com/user/Benjamona97</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Im looking for a production level vector db, so I was thinking about plain pg + pgvector, the problem is that I can&amp;#39;t find an easy way of finding a good library to interact with it, so far I&amp;#39;m using raw queries like this (i will leave code at the bottom). I don&amp;#39;t know if this is the best way apart from chroma, weaviate, pinecone, etc etc this is going to be at production level por mi company to be used internally.&lt;br/&gt; WITH vector_matches AS (&lt;br/&gt; SELECT document_id, 1 - (embedding &amp;lt;=&amp;gt; %s) AS similarity&lt;br/&gt; FROM documents_embeddings&lt;br/&gt; WHERE 1 - (embedding &amp;lt;=&amp;gt; %s) &amp;gt; %s&lt;br/&gt; ORDER BY similarity DESC&lt;br/&gt; LIMIT %s&lt;br/&gt; )&lt;br/&gt; SELECT d.page_content, d.metadata, d.file_id, vm.similarity&lt;br/&gt; FROM documents d&lt;br/&gt; INNER JOIN vector_matches vm ON d.id = vm.document_id &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Benjamona97&quot;&gt; /u/Benjamona97 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adf3o6/looking_for_a_production_level_vector_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adf3o6/looking_for_a_production_level_vector_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adf3o6</id><link href="https://www.reddit.com/r/LangChain/comments/1adf3o6/looking_for_a_production_level_vector_db/" /><updated>2024-01-28T22:29:16+00:00</updated><published>2024-01-28T22:29:16+00:00</published><title>Looking for a production level vector db</title></entry><entry><author><name>/u/Xerxes_Artemisia</name><uri>https://www.reddit.com/user/Xerxes_Artemisia</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad2hcq/streamlit_run_apppy_blank_screen_help_vscode/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/7jx0iOSXrRqXqAo25L6_dP-LHrDNQDvR_eYBTULyOOY.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c42e7ed72cf80343b339e6911558dba6cf300b4b&quot; alt=&quot;Streamlit run app.py - blank screen help ( vscode) - OpenAI chat bot project&quot; title=&quot;Streamlit run app.py - blank screen help ( vscode) - OpenAI chat bot project&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I&amp;#39;m a newbie programmer and having mind boggling issue of my app not deploying...it is a chat bot...everything seems to be fine just the error was Inport error: Openai can&amp;#39;t be imported from langchain. I don&amp;#39;t know..have scoured the internet for the fixes, but unable to find a solution.&lt;/p&gt; &lt;p&gt;Saw a tutorial from free coding camp on YouTube and it seems to work in that tutorial. I followed step by step even checked multiple times.&lt;/p&gt; &lt;p&gt;If someone can help me find out what is wrong I will be very grateful.&lt;/p&gt; &lt;p&gt;It may be a simple thing or complex I don&amp;#39;t know as I don&amp;#39;t have a 360 degree understanding of python libraries or streamlit requirements. I followed the tutorial 100% though. I can say that.&lt;/p&gt; &lt;p&gt;I reached 1:14:00 in the video&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Xerxes_Artemisia&quot;&gt; /u/Xerxes_Artemisia &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/x0AnCE9SE4A?si=Yb1LMCiz5AJ1RE7E&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad2hcq/streamlit_run_apppy_blank_screen_help_vscode/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ad2hcq</id><media:thumbnail url="https://external-preview.redd.it/7jx0iOSXrRqXqAo25L6_dP-LHrDNQDvR_eYBTULyOOY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c42e7ed72cf80343b339e6911558dba6cf300b4b" /><link href="https://www.reddit.com/r/LangChain/comments/1ad2hcq/streamlit_run_apppy_blank_screen_help_vscode/" /><updated>2024-01-28T13:18:32+00:00</updated><published>2024-01-28T13:18:32+00:00</published><title>Streamlit run app.py - blank screen help ( vscode) - OpenAI chat bot project</title></entry><entry><author><name>/u/stoicbats_</name><uri>https://www.reddit.com/user/stoicbats_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I have converted some domain-specific name vectors into embeddings, with a dataset size of 200k words. All the embeddings were generated using OpenAI&amp;#39;s embedding model 3 (3072 dim per embedding) . Now I am planning to implement semantic search similarity. Given a domain keyword, I want to find the top 5 most similar matches. After embedding all 280k words, the size of the JSON file containing the embeddings is around 30GB.&lt;/p&gt; &lt;p&gt;I am new to this domain and evaluating the best options.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Should I use a cloud vector database like Pinecone or Typsense, or host locally on DigitalOcean?&lt;/li&gt; &lt;li&gt;If I go with a cloud option like Typsense, what configuration (RAM, etc.) would I need for 280k embeddings (30GB in size)? And how much would it likely cost?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I have been confused for the past few days and unable to find useful resources. Any help or advice you could provide would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/stoicbats_&quot;&gt; /u/stoicbats_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acxxbw/best_practices_for_semantic_search_on_200k/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acxxbw/best_practices_for_semantic_search_on_200k/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acxxbw</id><link href="https://www.reddit.com/r/LangChain/comments/1acxxbw/best_practices_for_semantic_search_on_200k/" /><updated>2024-01-28T08:19:24+00:00</updated><published>2024-01-28T08:19:24+00:00</published><title>Best Practices for Semantic Search on 200k vectors (30GB) Worth of Embeddings?</title></entry><entry><author><name>/u/worldender999</name><uri>https://www.reddit.com/user/worldender999</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building an app using LangChain to integrate with ChatGPT. I need a vector DB to store the embeddings. I want to use an on-prem option, not a cloud one. There are quite a few options I see from my searches. Wondering what folks would recommend. Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/worldender999&quot;&gt; /u/worldender999 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad52as/what_is_the_best_onprem_vector_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad52as/what_is_the_best_onprem_vector_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad52as</id><link href="https://www.reddit.com/r/LangChain/comments/1ad52as/what_is_the_best_onprem_vector_db/" /><updated>2024-01-28T15:27:08+00:00</updated><published>2024-01-28T15:27:08+00:00</published><title>What is the best on-prem vector db</title></entry><entry><author><name>/u/rkubc</name><uri>https://www.reddit.com/user/rkubc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on extracting information from PDFs containing tables using OpenAI, LangChain, and FAISS. My focus is on extracting value especially regarding specific keywords present in these documents. I&amp;#39;m looking for advice on optimal chunking strategies for these PDFs to ensure comprehensive information extraction without losing key details. Any insights or best practices would be greatly appreciated!&lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rkubc&quot;&gt; /u/rkubc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acudx2/efficient_chunking_strategies_for_pdf_information/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acudx2/efficient_chunking_strategies_for_pdf_information/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acudx2</id><link href="https://www.reddit.com/r/LangChain/comments/1acudx2/efficient_chunking_strategies_for_pdf_information/" /><updated>2024-01-28T04:40:05+00:00</updated><published>2024-01-28T04:40:05+00:00</published><title>Efficient Chunking Strategies for PDF Information Extraction with AI Tools</title></entry><entry><author><name>/u/Fr4nkWh1te</name><uri>https://www.reddit.com/user/Fr4nkWh1te</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am creating a chatbot over the data of my &lt;strong&gt;static React website&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;I fetch the page files from the file system using the &lt;a href=&quot;https://js.langchain.com/docs/modules/data_connection/document_loaders/file_directory&quot;&gt;DirectoryLoader&lt;/a&gt;. I could use a web loader but I want it to work even in local development.&lt;/p&gt; &lt;p&gt;The issue is the text splitter.&lt;/p&gt; &lt;p&gt;I couldn&amp;#39;t find a proper text splitter for JSX (React) code. But I seem to get decent results with the &lt;a href=&quot;https://js.langchain.com/docs/modules/data_connection/document_transformers/code_splitter#html&quot;&gt;HTML recursive text splitter&lt;/a&gt;, probably because JSX and HTML are so similar.&lt;/p&gt; &lt;p&gt;Before I send my documents to the HTML splitter, I &lt;strong&gt;remove all import statements and class names&lt;/strong&gt; (to get rid of the unnecessary clutter). I keep everything else (which might include some JavaScript code).&lt;/p&gt; &lt;p&gt;Is my approach fine? Is the HTML splitter suited for this use case? Is it normal that there is no text overlap in the generated documents?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fr4nkWh1te&quot;&gt; /u/Fr4nkWh1te &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad4eye/use_html_splitter_for_jsx_react_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad4eye/use_html_splitter_for_jsx_react_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad4eye</id><link href="https://www.reddit.com/r/LangChain/comments/1ad4eye/use_html_splitter_for_jsx_react_code/" /><updated>2024-01-28T14:57:12+00:00</updated><published>2024-01-28T14:57:12+00:00</published><title>Use HTML splitter for JSX (React) code?</title></entry></feed>