<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-04-13T10:20:03+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Kashasaurus</name><uri>https://www.reddit.com/user/Kashasaurus</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2xhfe/how_do_actually_save_a_document_output_to_local/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/xcYaoIyuOKSlDj1z6nI_taHQOrahr2-8MKAsQg8bA6k.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f6559a6cb8a872e58dac8b7fc561b681e96d648c&quot; alt=&quot;How do actually save a document output to local disc for langgraph? &quot; title=&quot;How do actually save a document output to local disc for langgraph? &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I‚Äôm following along with this example of a multi agent hierarchical system. The end output should be a document written to disc. I can output the conversation to txt and can see that a document ‚Äúhas been finished and saved to disc‚Äù, but that‚Äôs just what the agent says but I can see any code that actually says to save to disc. I have supergraph.stream, but again, that just outputs the conversation. How do I output the actually document they made? &lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Kashasaurus&quot;&gt; /u/Kashasaurus &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/langchain-ai/langgraph/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2xhfe/how_do_actually_save_a_document_output_to_local/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c2xhfe</id><media:thumbnail url="https://external-preview.redd.it/xcYaoIyuOKSlDj1z6nI_taHQOrahr2-8MKAsQg8bA6k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f6559a6cb8a872e58dac8b7fc561b681e96d648c" /><link href="https://www.reddit.com/r/LangChain/comments/1c2xhfe/how_do_actually_save_a_document_output_to_local/" /><updated>2024-04-13T08:54:00+00:00</updated><published>2024-04-13T08:54:00+00:00</published><title>How do actually save a document output to local disc for langgraph?</title></entry><entry><author><name>/u/dongjy</name><uri>https://www.reddit.com/user/dongjy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Had test in prod, pinecone is slow&lt;/p&gt; &lt;p&gt;Qdrant does not perform well when large amount of collections being created.&lt;/p&gt; &lt;p&gt;So I am searching for other great options.&lt;/p&gt; &lt;p&gt;I want at least 4 features.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;open source and self hosted&lt;/li&gt; &lt;li&gt;Vectors can be offloaded to disk because there is too much data to store in RAM.&lt;/li&gt; &lt;li&gt;Capability to store 10k-100k collections without much overhead.&lt;/li&gt; &lt;li&gt;in active development and support&lt;/li&gt; &lt;/ol&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dongjy&quot;&gt; /u/dongjy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2t59t/best_vector_database_for_large_scale_data_besides/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2t59t/best_vector_database_for_large_scale_data_besides/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c2t59t</id><link href="https://www.reddit.com/r/LangChain/comments/1c2t59t/best_vector_database_for_large_scale_data_besides/" /><updated>2024-04-13T04:12:33+00:00</updated><published>2024-04-13T04:12:33+00:00</published><title>Best vector database for large scale data, besides qdrant and pinecone</title></entry><entry><author><name>/u/the_travelo_</name><uri>https://www.reddit.com/user/the_travelo_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How can I get my LLM to use multiple tools (not just one out of many) to answer my user query?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/the_travelo_&quot;&gt; /u/the_travelo_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2vqzk/how_to_use_multiple_tools_at_once/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2vqzk/how_to_use_multiple_tools_at_once/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c2vqzk</id><link href="https://www.reddit.com/r/LangChain/comments/1c2vqzk/how_to_use_multiple_tools_at_once/" /><updated>2024-04-13T06:53:12+00:00</updated><published>2024-04-13T06:53:12+00:00</published><title>How to use multiple tools at once</title></entry><entry><author><name>/u/ZuckyFox</name><uri>https://www.reddit.com/user/ZuckyFox</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2vpvu/query_mongodb_using_langchain/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/eGAi58FXawEUOXhEgIh6a9bgVF0XrJwndViH8bhP3_U.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f24d8a6ff752e3c661407689a4103d12d5c6d4b8&quot; alt=&quot;Query MongoDB using Langchain&quot; title=&quot;Query MongoDB using Langchain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Have you ever faced challenges while connecting NOSQL databases like MongoDB. Check out this video ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ZuckyFox&quot;&gt; /u/ZuckyFox &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/boN1KkfcMZE?si=FxBtzWciboVP7XLE&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2vpvu/query_mongodb_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c2vpvu</id><media:thumbnail url="https://external-preview.redd.it/eGAi58FXawEUOXhEgIh6a9bgVF0XrJwndViH8bhP3_U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f24d8a6ff752e3c661407689a4103d12d5c6d4b8" /><link href="https://www.reddit.com/r/LangChain/comments/1c2vpvu/query_mongodb_using_langchain/" /><updated>2024-04-13T06:51:20+00:00</updated><published>2024-04-13T06:51:20+00:00</published><title>Query MongoDB using Langchain</title></entry><entry><author><name>/u/isthatashark</name><uri>https://www.reddit.com/user/isthatashark</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/isthatashark&quot;&gt; /u/isthatashark &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://vectorize.io/rag-vector-database-traps/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2adpi/5_rag_vector_database_traps_and_how_to_avoid_them/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c2adpi</id><link href="https://www.reddit.com/r/LangChain/comments/1c2adpi/5_rag_vector_database_traps_and_how_to_avoid_them/" /><updated>2024-04-12T14:20:30+00:00</updated><published>2024-04-12T14:20:30+00:00</published><title>5 RAG Vector Database Traps and How to Avoid Them</title></entry><entry><author><name>/u/Jopp1993</name><uri>https://www.reddit.com/user/Jopp1993</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello I would like to know which embedded model would be best suited for transcriptions of mostly recorded zoom sessions / spoken language. I would like to ask specific questions about topics that were covered. Getting detailed answers and summaries.&lt;/p&gt; &lt;p&gt;Currently I am using:&lt;/p&gt; &lt;p&gt;Salesforce/SFR-Embedding-Mistral -&amp;gt; which is pretty slow on my Macbook M1 Pro&lt;/p&gt; &lt;p&gt;mixedbread-ai/mxbai-embed-large-v1&lt;/p&gt; &lt;p&gt;Are there better models suited for my task?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jopp1993&quot;&gt; /u/Jopp1993 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2l33u/best_embedded_models_for_transcriptionsspoken/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2l33u/best_embedded_models_for_transcriptionsspoken/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c2l33u</id><link href="https://www.reddit.com/r/LangChain/comments/1c2l33u/best_embedded_models_for_transcriptionsspoken/" /><updated>2024-04-12T21:39:25+00:00</updated><published>2024-04-12T21:39:25+00:00</published><title>Best embedded models for transcriptions/spoken language?</title></entry><entry><author><name>/u/LockyYud</name><uri>https://www.reddit.com/user/LockyYud</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I don&amp;#39;t understand why it&amp;#39;s better for ELECTRA to use the alternate token detection task instead of the MLM task while MLM in Bert still replaced token with 10%. Can you explain it to me?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LockyYud&quot;&gt; /u/LockyYud &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2kdwz/about_electra/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2kdwz/about_electra/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c2kdwz</id><link href="https://www.reddit.com/r/LangChain/comments/1c2kdwz/about_electra/" /><updated>2024-04-12T21:09:53+00:00</updated><published>2024-04-12T21:09:53+00:00</published><title>About ELECTRA</title></entry><entry><author><name>/u/shiv11afk</name><uri>https://www.reddit.com/user/shiv11afk</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Title&lt;/p&gt; &lt;p&gt;I can see that in ReAct, there&amp;#39;s thought-action(which tool)-output. What does it do in when the type is openai_functions? Like how does it choose the tools in that case? I wanna understand the internal difference&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/shiv11afk&quot;&gt; /u/shiv11afk &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2cnuo/difference_between_react_and_openai_functions/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2cnuo/difference_between_react_and_openai_functions/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c2cnuo</id><link href="https://www.reddit.com/r/LangChain/comments/1c2cnuo/difference_between_react_and_openai_functions/" /><updated>2024-04-12T15:53:36+00:00</updated><published>2024-04-12T15:53:36+00:00</published><title>Difference between ReAct and OpenAI functions Agent type</title></entry><entry><author><name>/u/zmobie_slayre</name><uri>https://www.reddit.com/user/zmobie_slayre</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I know how to use set_debug or LangSmith to see what happens in each step of an LCEL chain when it does run. But sometimes I&amp;#39;ll change a bunch of stuff, and my chain won&amp;#39;t run at all anymore. I&amp;#39;ll just get an error like:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;TypeError: unsupported operands type(s) for |: &amp;#39;dict&amp;#39; and &amp;#39;function&amp;#39; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This error points to the first line of the chain, which isn&amp;#39;t very helpful for understanding where exactly in the chain the problem is, especially if that chain has a bunch of steps. Is there a good way to debug and diagnose these errors?&lt;/p&gt; &lt;p&gt;This is an issue that I keep running into with non-trivial chains.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zmobie_slayre&quot;&gt; /u/zmobie_slayre &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2bq58/how_do_people_typically_debug_typeerror_in_lcel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2bq58/how_do_people_typically_debug_typeerror_in_lcel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c2bq58</id><link href="https://www.reddit.com/r/LangChain/comments/1c2bq58/how_do_people_typically_debug_typeerror_in_lcel/" /><updated>2024-04-12T15:16:15+00:00</updated><published>2024-04-12T15:16:15+00:00</published><title>How do people typically debug TypeError in LCEL ?</title></entry><entry><author><name>/u/D3NN152000</name><uri>https://www.reddit.com/user/D3NN152000</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all,&lt;/p&gt; &lt;p&gt;At my company, we want to automate some RAG-related process, and we are using LangChain. We will have access to some human-verified data, that matches up certain questions with passages from PDF documents. Now to improve the performance of our tool, I thought it might be useful to fine-tune the embeddings model somehow, as opposed to using the &amp;quot;default&amp;quot; Azure OpenAI embeddings that are available. &lt;/p&gt; &lt;p&gt;From what I gather online, most ways of training such a model would involve having pairs of sentences, and ranking their similarity. The problem is that in our data set, we only have &amp;quot;perfect matches&amp;quot; so to say. Would I still be able to meaningfully train my own embeddings model, and how? Sources or code examples are very much welcome.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/D3NN152000&quot;&gt; /u/D3NN152000 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2a8bi/training_own_embedding_model_for_custom_usecase/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c2a8bi/training_own_embedding_model_for_custom_usecase/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c2a8bi</id><link href="https://www.reddit.com/r/LangChain/comments/1c2a8bi/training_own_embedding_model_for_custom_usecase/" /><updated>2024-04-12T14:14:17+00:00</updated><published>2024-04-12T14:14:17+00:00</published><title>Training own embedding model for custom use-case</title></entry><entry><author><name>/u/99OG121314</name><uri>https://www.reddit.com/user/99OG121314</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Every example I see online with the Cohere re-ranker, uses the base vector store retriever as the retriever.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;It does not use ensemble, or parent document, or multi query etc. Any help appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/99OG121314&quot;&gt; /u/99OG121314 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c29o79/has_anyone_used_the_reranker_api_from_cohere_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c29o79/has_anyone_used_the_reranker_api_from_cohere_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c29o79</id><link href="https://www.reddit.com/r/LangChain/comments/1c29o79/has_anyone_used_the_reranker_api_from_cohere_with/" /><updated>2024-04-12T13:50:49+00:00</updated><published>2024-04-12T13:50:49+00:00</published><title>Has anyone used the Re-ranker API from Cohere with one a LangChain retriever that isn't the base one?</title></entry><entry><author><name>/u/sebastianstehle</name><uri>https://www.reddit.com/user/sebastianstehle</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I integrated dall-e into my chat application using this class: &lt;a href=&quot;https://js.langchain.com/docs/integrations/tools/dalle&quot;&gt;https://js.langchain.com/docs/integrations/tools/dalle&lt;/a&gt; &lt;/p&gt; &lt;p&gt;It works fine, somehow and the URL is returned. But OpenAI makes modifications to the result. It always seems to shorten the URL and removes query parameters.&lt;/p&gt; &lt;p&gt;I tried to change the result a little bit, but no success:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;protected async _call(arg: string): Promise&amp;lt;string&amp;gt; { try { const result = await this.wrapper.invoke(arg); return `Return the following URL. Do not change it. &amp;lt;URL&amp;gt;${result}&amp;lt;/URL&amp;gt;`; } catch (error) { return &amp;#39;Failed&amp;#39;; } } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I am actually not sure, if it is really OpenAI that removes the query parameters, but who else could it be? It seems to be a general topic: &lt;a href=&quot;https://community.openai.com/t/gpt-changing-the-response-url/555778&quot;&gt;https://community.openai.com/t/gpt-changing-the-response-url/555778&lt;/a&gt; &lt;/p&gt; &lt;p&gt;So I would be happy if I could just bypass the LLM for these tool calls or find another solution. I could also base64 encode the URL and decode it later or something like that, but I have not tried it yet.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sebastianstehle&quot;&gt; /u/sebastianstehle &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c24si0/return_the_tool_output_without_any_modifications/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c24si0/return_the_tool_output_without_any_modifications/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c24si0</id><link href="https://www.reddit.com/r/LangChain/comments/1c24si0/return_the_tool_output_without_any_modifications/" /><updated>2024-04-12T09:25:10+00:00</updated><published>2024-04-12T09:25:10+00:00</published><title>Return the tool output without any modifications</title></entry><entry><author><name>/u/thewouser</name><uri>https://www.reddit.com/user/thewouser</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all!&lt;/p&gt; &lt;p&gt;I am building a RAG system for my private/work related files. Followed some guidelines and got a basic version running.&lt;/p&gt; &lt;p&gt;Naturally i wanted to step up my game and change the recursive character splitter with the &amp;#39;SemanticChunker&amp;#39;. Script will be below. I am running in some struggles i cant seem to find the answers on while searching around.&lt;/p&gt; &lt;p&gt;Import things in my situation: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Everything needs to run local&lt;/li&gt; &lt;li&gt;PDF data&lt;/li&gt; &lt;li&gt;Dutch text&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The language part makes it the most difficult i feel. Tried various LLMS but seem to run in a &amp;#39;killed&amp;#39; when i try to create the database when i attempt to use huggingfaceembeddings for &amp;#39;multilingual-e5-large-instruct&amp;#39; or &amp;#39;BGE-M3&amp;#39; which are supposed to be multilangual embedding models.&lt;/p&gt; &lt;p&gt;What does work is using olloma and mistral 7B instruct for example.&lt;/p&gt; &lt;p&gt;So far my questions are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Can you use any LLM for the SemanticChunker?&lt;/li&gt; &lt;li&gt;Is a language specific LLM/embedding model a hard requirement?&lt;/li&gt; &lt;li&gt;Is it possible/needed to use a different LLM for the SemanticChunker and creating the vectorDB?&lt;/li&gt; &lt;li&gt;Will an LLM ike mistral instruct V2 even provide decent results?&lt;/li&gt; &lt;li&gt;Any examples/pointers?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Any advice and tips is much appreciated! Thanks in advance!&lt;/p&gt; &lt;p&gt;&lt;code&gt;import os&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.llms import Ollama&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.vectorstores import Chroma&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain.text_splitter import RecursiveCharacterTextSplitter&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain.chains import RetrievalQA&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.document_loaders import TextLoader&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.document_loaders import PyPDFLoader&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.document_loaders import DirectoryLoader&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from InstructorEmbedding import INSTRUCTOR&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.embeddings import HuggingFaceInstructEmbeddings&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.embeddings import OllamaEmbeddings&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.embeddings import HuggingFaceEmbeddings&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from transformers import AutoTokenizer, AutoModel&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_community.embeddings import HuggingFaceBgeEmbeddings&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langchain_experimental.text_splitter import SemanticChunker&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;### Load and process the text files&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;loader = DirectoryLoader(&amp;#39;/MEDIA/NHG/test/&amp;#39;, glob=&amp;quot;./*.pdf&amp;quot;, loader_cls=PyPDFLoader)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;documents = loader.load()&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;#### here we are using OpenAI embeddings but in future we will swap out to local embeddings&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;#ollama = OllamaEmbeddings(base_url=&amp;quot;http://192.168.1.141:11434&amp;quot;, model=&amp;quot;nomic-embed-text&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;ollama = OllamaEmbeddings(base_url=&amp;quot;http://192.168.1.141:11434&amp;quot;, model=&amp;quot;mistral:instruct&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;#model = HuggingFaceEmbeddings(model_name=&amp;quot;intfloat/multilingual-e5-large-instruct&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;#model = HuggingFaceBgeEmbeddings(model_name=&amp;quot;BAAI/bge-m3&amp;quot;, model_kwargs={&amp;#39;device&amp;#39;: &amp;#39;cpu&amp;#39;}, encode_kwargs={&amp;#39;normalize_embeddings&amp;#39;: True})&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;###splitting the text&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;#text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;text_splitter = SemanticChunker(ollama)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;texts = text_splitter.split_documents(documents)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;print(&amp;quot;Lengte van de teksten semantic:&amp;quot;, len(texts)) #Voor feedback&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;### Embed and store the texts&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;persist_directory = &amp;#39;./ChromaDB&amp;#39;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;vectordb = Chroma.from_documents(documents=texts, embedding=ollama, persist_directory=persist_directory)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;vectordb.persist()&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;vectordb = None&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;print(&amp;quot;DB gemaakt&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thewouser&quot;&gt; /u/thewouser &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c27lkv/help_with_semantic_chunker/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c27lkv/help_with_semantic_chunker/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c27lkv</id><link href="https://www.reddit.com/r/LangChain/comments/1c27lkv/help_with_semantic_chunker/" /><updated>2024-04-12T12:13:13+00:00</updated><published>2024-04-12T12:13:13+00:00</published><title>Help with semantic chunker</title></entry><entry><author><name>/u/ANil1729</name><uri>https://www.reddit.com/user/ANil1729</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1gliw/opensource_list_of_best_ai_agents/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/JlFLixcOHRxzP3EXxWwg21yeIMVEEyoSyTlFhqKWqL8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4a358d9f60d584d9df1370ecff183edd06834924&quot; alt=&quot;Open-source list of best AI agents&quot; title=&quot;Open-source list of best AI agents&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ANil1729&quot;&gt; /u/ANil1729 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/SamurAIGPT/Best-AI-Agents&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1gliw/opensource_list_of_best_ai_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1c1gliw</id><media:thumbnail url="https://external-preview.redd.it/JlFLixcOHRxzP3EXxWwg21yeIMVEEyoSyTlFhqKWqL8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4a358d9f60d584d9df1370ecff183edd06834924" /><link href="https://www.reddit.com/r/LangChain/comments/1c1gliw/opensource_list_of_best_ai_agents/" /><updated>2024-04-11T14:33:23+00:00</updated><published>2024-04-11T14:33:23+00:00</published><title>Open-source list of best AI agents</title></entry><entry><author><name>/u/Snoo_26595</name><uri>https://www.reddit.com/user/Snoo_26595</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;How do I fix the following?&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Invalid argument provided to Gemini: 400 Please ensure that multiturn requests alternate between user and model.Invalid argument provided to Gemini: 400 Please ensure that multiturn requests alternate between user and model. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I am trying to contextualize the query before similarity search on qdrant so the query is reformulated for similarity search to work properly based on chat history.&lt;/p&gt; &lt;p&gt;Here is how I&amp;#39;ve formulated the chat history&lt;/p&gt; &lt;p&gt;&lt;code&gt;chat_history_messages = chat_history.chat_mesages.values_list(&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;&amp;quot;message&amp;quot;, &amp;quot;sender&amp;quot;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;).order_by(&amp;quot;created_at&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;for message, sender in chat_history_messages:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;if sender == &amp;quot;bot&amp;quot;:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;chat_history_messages_rag_format.append(AIMessage(content=message))&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;else:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;chat_history_messages_rag_format.append(&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;HumanMessage(content=message)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Here&amp;#39;s how im trying to call the llm&lt;/p&gt; &lt;pre&gt;&lt;code&gt; contextualize_q_system_prompt = &amp;quot;&amp;quot;&amp;quot;Given a chat history and the latest user question \ which might reference context in the chat history, formulate a standalone question \ which can be understood without the chat history. Do NOT answer the question, \ just reformulate it if needed and otherwise return it as is.&amp;quot;&amp;quot;&amp;quot; template = ChatPromptTemplate.from_messages(contextualize_q_system_prompt) # context = &amp;quot;&amp;quot; chain = template | llm chat_history_messages_rag_format.pop() print(chat_history_messages_rag_format) response = chain.invoke( {&amp;quot;context&amp;quot;: chat_history_messages_rag_format, &amp;quot;question&amp;quot;: query} ) query = response &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The array which is being passed to &amp;quot;context&amp;quot; key looks like this: [HumanMessage(content=&amp;#39;Why cells&amp;#39;), AIMessage(content=&amp;#39;Histograms are very simple to quickly understand your data, which tell about values of data like central tendency, dispersion, outliers, etc. thanks for asking!&amp;#39;)]&lt;/p&gt; &lt;p&gt;NOTE: I have no idea what I&amp;#39;m doing. I&amp;#39;m not an AI developer, don&amp;#39;t understand the basics. I&amp;#39;m just a backend dev thrown into this, so any help would be nice.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Snoo_26595&quot;&gt; /u/Snoo_26595 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c21u43/langchain_rag_with_chatgooglegenerativeai_error/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c21u43/langchain_rag_with_chatgooglegenerativeai_error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c21u43</id><link href="https://www.reddit.com/r/LangChain/comments/1c21u43/langchain_rag_with_chatgooglegenerativeai_error/" /><updated>2024-04-12T06:07:26+00:00</updated><published>2024-04-12T06:07:26+00:00</published><title>Langchain rag with ChatGoogleGenerativeAI Error</title></entry><entry><author><name>/u/Cold_Set_</name><uri>https://www.reddit.com/user/Cold_Set_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, me and my team were looking for integrate inside our RAG company model the most decent pdf parser, we need one that can also parse tables and schemes and keep the information intact (or at least not completely broken when it will be sent to the vector database). We already tried Pypdf, pdfPlumber, Unstructured and Nougat, but all of these libraries weren&amp;#39;t good enough for our needs. Do you guys know any other alternative?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Cold_Set_&quot;&gt; /u/Cold_Set_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1ksv6/best_libraryframework_for_parsing_pdf_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1ksv6/best_libraryframework_for_parsing_pdf_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c1ksv6</id><link href="https://www.reddit.com/r/LangChain/comments/1c1ksv6/best_libraryframework_for_parsing_pdf_documents/" /><updated>2024-04-11T17:25:27+00:00</updated><published>2024-04-11T17:25:27+00:00</published><title>Best library/framework for parsing PDF documents with table inside?</title></entry><entry><author><name>/u/chainlit</name><uri>https://www.reddit.com/user/chainlit</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;You can now build your AI agent in Python using LangChain and OpenAI and embed it - as a chatbot or copilot - in an existing software üî•&lt;/p&gt; &lt;p&gt;üìû Function Calling: your Copilot can even take actions on the website&lt;br/&gt; üå† Widget UI &amp;amp; UX customisation&lt;br/&gt; üîê CORS &amp;amp; Authentication to manage who can access the copilot&lt;/p&gt; &lt;p&gt;Simply add event listeners to your code to have the agent interact with the software!&lt;/p&gt; &lt;p&gt;It unlocks many use cases: Customer Support Chatbots, Lead Generation Chatbots or Software Copilots &amp;amp; more&lt;/p&gt; &lt;p&gt;Docs: &lt;a href=&quot;https://docs.chainlit.io/deployment/copilot&quot;&gt;https://docs.chainlit.io/deployment/copilot&lt;/a&gt;&lt;br/&gt; Example: &lt;a href=&quot;https://github.com/Chainlit/cookbook/tree/main/copilot&quot;&gt;https://github.com/Chainlit/cookbook/tree/main/copilot&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/chainlit&quot;&gt; /u/chainlit &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1m2jb/chainlit_copilot_mode_embed_your_langchain_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1m2jb/chainlit_copilot_mode_embed_your_langchain_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c1m2jb</id><link href="https://www.reddit.com/r/LangChain/comments/1c1m2jb/chainlit_copilot_mode_embed_your_langchain_agent/" /><updated>2024-04-11T18:17:36+00:00</updated><published>2024-04-11T18:17:36+00:00</published><title>Chainlit Copilot mode: Embed your LangChain Agent as a copilot on a website or software</title></entry><entry><author><name>/u/Diligent_Eye1248</name><uri>https://www.reddit.com/user/Diligent_Eye1248</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi!&lt;/p&gt; &lt;p&gt;I&amp;#39;m new to LLM-based applications and mainly just trying stuff for fun and learning to improve my skills and knowledge but I was wondering how do you discover ideas/tools that can help improve your way of interacting between data and LLMs in applications which are not RAG, for which I find there are a lot of resources. I have done some simple use case that works pretty well when everything is fine, but also breaks a lot, but overall it didn&amp;#39;t require me some deep knowledge of the space and I&amp;#39;m feeling like I can improve a lot upon my initial code by solving these issues using what people in the space developed or thought of for that. I&amp;#39;m not talking about tools and ideas for RAG which are very abundant, but for all the other applications that don&amp;#39;t require the level of sophistication RAG applications do.&lt;/p&gt; &lt;p&gt;My use case is extracting structured data from documents. I have coded a small python program to which I give a document (.pdf or .txt) and I give it a query (a string, in natural language) that&amp;#39;s intended to extract structured data from these documents and put it into a JSON. For example if my document talks about different startups, how much capital they&amp;#39;ve raised etc., I can ask &amp;quot;extract the names of the startups the document is talking about and how much capital they&amp;#39;ve raised in their first series&amp;quot; and get a JSON that contains that.&lt;/p&gt; &lt;p&gt;I consider this a simple use case, it&amp;#39;s not a RAG use case, it&amp;#39;s a simple use case of, at least how I think of it, &amp;quot;chunking =&amp;gt; LLM call =&amp;gt; output cleaning&amp;quot; but I want to either go beyond that if it&amp;#39;s possible or explore better ideas to do each of these small steps (like are there ways to do better chunking that the traditional ones of recursive text splitting etc.?). I feel like just trying to do this in any other way without using LLMs can already be a great step for me but I don&amp;#39;t know where to look at.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Diligent_Eye1248&quot;&gt; /u/Diligent_Eye1248 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1g07n/how_do_you_discover_toolsideas_that_might_help/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1g07n/how_do_you_discover_toolsideas_that_might_help/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c1g07n</id><link href="https://www.reddit.com/r/LangChain/comments/1c1g07n/how_do_you_discover_toolsideas_that_might_help/" /><updated>2024-04-11T14:08:49+00:00</updated><published>2024-04-11T14:08:49+00:00</published><title>How do you discover tools/ideas that might help improve your LLM-based apps which are not RAG?</title></entry><entry><author><name>/u/vvkuka</name><uri>https://www.reddit.com/user/vvkuka</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey! We summarised Harrison Chase&amp;#39;s talk on the evolution of AI agents and their applications during AI Ascent. Maybe it will be useful for you as well:&lt;/p&gt; &lt;p&gt;He identified 3 critical areas of development:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Planning&lt;/li&gt; &lt;li&gt;UX&lt;/li&gt; &lt;li&gt;Memory&lt;/li&gt; &lt;/ul&gt; &lt;ol&gt; &lt;li&gt;Planning:&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Chase highlighted the need for AI agents to plan strategically beyond basic action and feedback loops, which current language models struggle with for complex tasks.&lt;/p&gt; &lt;p&gt;He discussed the ongoing research and development efforts to enhance planning capabilities, like external prompting strategies and cognitive architectures. Are these just short-term fixes or essential long-term requirements for AI agent development?&lt;/p&gt; &lt;ol&gt; &lt;li&gt;User Experience (UX):&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Chase is particularly enthusiastic about the user experience (UX) of interacting with AI agents. He emphasizes that achieving a balance between human involvement and agent autonomy is essential for effective application.&lt;/p&gt; &lt;p&gt;He discussed innovative UX features such as the ability to rewind and edit agent actions, which enhance reliability and control over the agent&amp;#39;s decisions. These developments aim to make agents more user-friendly and adaptable to specific user needs and corrections.&lt;/p&gt; &lt;ol&gt; &lt;li&gt; Memory:&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Memory is a key area for advancement in AI agents. Two essential types are procedural memory (task performance) and personalized memory (user preferences or facts).&lt;/p&gt; &lt;p&gt;He provided examples of how agents could use memory to enhance their interactions, such as adapting communication styles based on previous interactions or recalling personal details to personalize conversations.&lt;/p&gt; &lt;p&gt;What&amp;#39;s next for AI agents?&lt;/p&gt; &lt;p&gt;Full talk: &lt;a href=&quot;https://www.youtube.com/watch?v=pBBe1pk8hf4&amp;amp;list=PLOhHNjZItNnOoPxOF3dmq30UxYqFuxXKn&amp;amp;index=7&quot;&gt;https://www.youtube.com/watch?v=pBBe1pk8hf4&amp;amp;list=PLOhHNjZItNnOoPxOF3dmq30UxYqFuxXKn&amp;amp;index=7&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/vvkuka&quot;&gt; /u/vvkuka &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1c0md/we_summarised_harrison_chases_talk_on_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1c0md/we_summarised_harrison_chases_talk_on_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c1c0md</id><link href="https://www.reddit.com/r/LangChain/comments/1c1c0md/we_summarised_harrison_chases_talk_on_the/" /><updated>2024-04-11T10:49:11+00:00</updated><published>2024-04-11T10:49:11+00:00</published><title>We summarised Harrison Chase's talk on the evolution of AI agents and their applications</title></entry><entry><author><name>/u/CharmingViolinist962</name><uri>https://www.reddit.com/user/CharmingViolinist962</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to create a PDF RAG chatbot for RFP. Extracted text using pypdf and extracted tables using tabula..now trying to create a multimodal RAG using ChromaDB.&lt;br/&gt; tables im trying to summarise using Llama2 with prompt to preserve relationship between rows and columns&lt;br/&gt; text I split using recursive text splitter&lt;br/&gt; i add both to RAG&lt;br/&gt; but i feel the table insertion into RAG isnt correct for proper QA&lt;br/&gt; kindly guide me &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CharmingViolinist962&quot;&gt; /u/CharmingViolinist962 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1lsk6/tables_context_length_issue_in_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1lsk6/tables_context_length_issue_in_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c1lsk6</id><link href="https://www.reddit.com/r/LangChain/comments/1c1lsk6/tables_context_length_issue_in_rag/" /><updated>2024-04-11T18:06:37+00:00</updated><published>2024-04-11T18:06:37+00:00</published><title>Tables context length issue in RAG</title></entry><entry><author><name>/u/Illustrious_Treat188</name><uri>https://www.reddit.com/user/Illustrious_Treat188</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Illustrious_Treat188&quot;&gt; /u/Illustrious_Treat188 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ChatGPTCoding/comments/1c1klmk/multivector_rag_for_drugs_pdf_missing_context_i/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1kmnv/multivector_rag_for_drugs_pdf_missing_context_i/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c1kmnv</id><link href="https://www.reddit.com/r/LangChain/comments/1c1kmnv/multivector_rag_for_drugs_pdf_missing_context_i/" /><updated>2024-04-11T17:18:26+00:00</updated><published>2024-04-11T17:18:26+00:00</published><title>Multivector RAG for drugs pdf, missing context, I need help</title></entry><entry><author><name>/u/Jean_dta</name><uri>https://www.reddit.com/user/Jean_dta</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How do you add moderation to your models; for example limit to my model to only answer question relationated with Life Science and Health.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jean_dta&quot;&gt; /u/Jean_dta &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1p30i/moderation_topic_llm_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1p30i/moderation_topic_llm_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c1p30i</id><link href="https://www.reddit.com/r/LangChain/comments/1c1p30i/moderation_topic_llm_openai/" /><updated>2024-04-11T20:17:51+00:00</updated><published>2024-04-11T20:17:51+00:00</published><title>MODERATION TOPIC / LLM OPENAI</title></entry><entry><author><name>/u/Jean_dta</name><uri>https://www.reddit.com/user/Jean_dta</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;HELP: How can I make a rag Q/A app that allows the user to upload a pdf to the conversation and so that the model can understand the context of the pdf; I tried to perform an ensemble retrievel but at some point the chunks lose the context of the entire pdf&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jean_dta&quot;&gt; /u/Jean_dta &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1o7nj/rag_qa_pdf_conversation_langchain_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1o7nj/rag_qa_pdf_conversation_langchain_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c1o7nj</id><link href="https://www.reddit.com/r/LangChain/comments/1c1o7nj/rag_qa_pdf_conversation_langchain_openai/" /><updated>2024-04-11T19:43:27+00:00</updated><published>2024-04-11T19:43:27+00:00</published><title>RAG Q/A | PDF Conversation | Langchain | OpenAI</title></entry><entry><author><name>/u/Puzzleheaded_Bee5489</name><uri>https://www.reddit.com/user/Puzzleheaded_Bee5489</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building a Summarizer, or you can say it&amp;#39;s a kind of report generation for fraudulent transactions (fraud not confirmed, but just alerted) using LLM. I&amp;#39;m using OpenAI GPT-4 to perform the summarization task. I&amp;#39;ve tried my best to improve the prompt to generate the best summary/report with insights into the data. Some of these improvements include:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Providing metadata of the tables involved.&lt;/li&gt; &lt;li&gt;Assigning a role to the LLM.&lt;/li&gt; &lt;li&gt;Providing a few-shot examples on how to generate the summary.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Currently, I&amp;#39;m not using LangChain for the summarization task. However, &lt;strong&gt;are there any other techniques that can generate the summary/report in a better way without losing the context? Will LangChain help me in improving the summary?&lt;/strong&gt; &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;PS: I&amp;#39;m a newbie to this field, please pardon me if there is any mistake in my explanation.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Puzzleheaded_Bee5489&quot;&gt; /u/Puzzleheaded_Bee5489 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1ltfp/improving_the_summarisation_capability_of_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1ltfp/improving_the_summarisation_capability_of_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c1ltfp</id><link href="https://www.reddit.com/r/LangChain/comments/1c1ltfp/improving_the_summarisation_capability_of_llm/" /><updated>2024-04-11T18:07:32+00:00</updated><published>2024-04-11T18:07:32+00:00</published><title>Improving the summarisation capability of LLM - will LangChain help?</title></entry><entry><author><name>/u/scorchy38</name><uri>https://www.reddit.com/user/scorchy38</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;from langchain_openai import ChatOpenAI from langchain_openai import OpenAIEmbeddings from langchain.chains import RetrievalQA from langchain_mongodb import MongoDBAtlasVectorSearch from langchain.output_parsers import PydanticOutputParser from langchain.prompts import PromptTemplate from src.models.steps import Steps def get_steps(query, mongo_uri, mongo_db_name): vector_store = MongoDBAtlasVectorSearch.from_connection_string( mongo_uri, mongo_db_name + &amp;quot;.&amp;quot; + &amp;quot;taskVectors&amp;quot;, OpenAIEmbeddings(disallowed_special=()), index_name=&amp;quot;default&amp;quot;, ) llm = ChatOpenAI(model=&amp;quot;gpt-3.5-turbo&amp;quot;) parser = PydanticOutputParser(pydantic_object=Steps) prompt = PromptTemplate( template=&amp;quot;Answer the query attached very precisely, give the output in the structure specified. &amp;quot; &amp;quot;Just say no if you don&amp;#39;t find the answer in current context. &amp;quot; &amp;quot;You have to map every field in structure to the appropriate value. &amp;quot; &amp;quot;For example to map elementId you should see from the output what is the value of key elementId from &amp;quot; &amp;quot;the context. &amp;quot; &amp;quot;You will find it like this ...\&amp;quot;elementId\&amp;quot;: \&amp;quot;Go to Page 2\&amp;quot;,.... &amp;quot; &amp;quot;So you will map Go to Page 2 to elementId in the structure. &amp;quot; &amp;quot;If you find multiple actionElements return all of them in the particular structures, &amp;quot; &amp;quot;remember final output is gonna be multiple objects &amp;quot; &amp;quot;Also for the scrollDetails field, populate an array, even if there is one or no object, it should &amp;quot; &amp;quot;be an array of those objects, like this &amp;quot; &amp;quot;...\&amp;quot;listView\&amp;quot;: \&amp;quot;index\&amp;quot;: 0, \&amp;quot;scrollOffsetX\&amp;quot;: 0..... should be populated as &amp;quot; &amp;quot;[...\&amp;quot;viewId\&amp;quot;: \&amp;quot;listView\&amp;quot;, \&amp;quot;offsets\&amp;quot;: \&amp;quot;x\&amp;quot;: 0, \&amp;quot;y\&amp;quot;: 405 ....]&amp;quot; &amp;quot;This is very crucial, wrong answers can cause serious problems.&amp;quot; + &amp;quot;\n{format_instructions}\n{query}\n&amp;quot;, input_variables=[&amp;quot;query&amp;quot;], partial_variables={&amp;quot;format_instructions&amp;quot;: parser.get_format_instructions()}, ) chain = prompt | llm | parser retriever = vector_store.as_retriever( search_type=&amp;quot;similarity&amp;quot;, search_kwargs={&amp;quot;k&amp;quot;: 25}, ) qa = RetrievalQA.from_chain_type(llm=chain, chain_type=&amp;quot;stuff&amp;quot;, retriever=retriever, return_source_documents=True) retriever_output = qa.invoke(query) return retriever_output &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I added pydantic output parser to this function to parse my output in a particular structure, and I think everything almost works correctly, the output I get is:&lt;br/&gt; &lt;code&gt;{&amp;#39;text&amp;#39;: Steps(root=[Action(elementId=&amp;#39;Go to Page 2&amp;#39;, position=Position(x=252, y=100, width=116, height=48), value=&amp;#39;Go to Page 2&amp;#39;, scrollDetails=[ScrollDetail(viewId=&amp;#39;mainScrollLayout&amp;#39;, offsets=Offsets(x=0, y=0))], viewName=&amp;#39;MainActivity&amp;#39;), Action(elementId=&amp;#39;showBottomSheetButton&amp;#39;, position=Position(x=20, y=630, width=352, height=48), value=&amp;#39;Show Bottom Sheet&amp;#39;, scrollDetails=[ScrollDetail(viewId=&amp;#39;mainScrollLayout&amp;#39;, offsets=Offsets(x=0, y=0))], viewName=&amp;#39;MainActivity&amp;#39;), Action(elementId=&amp;#39;backButton&amp;#39;, position=Position(x=16, y=96, width=88, height=48), value=&amp;#39;Back&amp;#39;, scrollDetails=[ScrollDetail(viewId=&amp;#39;listView&amp;#39;, offsets=Offsets(x=0, y=405))], viewName=&amp;#39;PageActivity&amp;#39;)])}&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Steps&lt;/code&gt; is a &lt;code&gt;RootModel&lt;/code&gt; that should have an array of &lt;code&gt;Actions&lt;/code&gt;, which is correct, but I am getting this unidentified model &lt;code&gt;Generation&lt;/code&gt; on top of steps which has this field &lt;code&gt;text&lt;/code&gt; as you see in the output which expects a string, and hence the validation fails with error: &lt;/p&gt; &lt;p&gt;&lt;code&gt;pydantic.v1.error_wrappers.ValidationError: 1 validation error for Generation&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;text&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;str type expected (type=type_error.str)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Not sure where this &lt;code&gt;Generation&lt;/code&gt; model is coming from, I tried making &lt;code&gt;Steps&lt;/code&gt; a &lt;code&gt;BaseModel&lt;/code&gt;, still the same issue. &lt;/p&gt; &lt;p&gt;How do I get this Generation out of the way? Or what can I do to fix this?&lt;br/&gt; I am fairly new to &lt;code&gt;Langchain&lt;/code&gt; and &lt;code&gt;OutputParsers&lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/scorchy38&quot;&gt; /u/scorchy38 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1l8zp/langchain_pydanctic_openai_pydanticv1error/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1c1l8zp/langchain_pydanctic_openai_pydanticv1error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1c1l8zp</id><link href="https://www.reddit.com/r/LangChain/comments/1c1l8zp/langchain_pydanctic_openai_pydanticv1error/" /><updated>2024-04-11T17:44:26+00:00</updated><published>2024-04-11T17:44:26+00:00</published><title>Langchain + Pydanctic + OpenAI : pydantic.v1.error_wrappers.ValidationError: 1 validation error for Generation</title></entry></feed>