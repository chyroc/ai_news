<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-04-28T22:36:34+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Brave-Guide-7470</name><uri>https://www.reddit.com/user/Brave-Guide-7470</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, I tested this app called talkdai/dialog on Github, and it allowed me to deploy a RAG with my customized content in just some few minutes and a Docker-compose file.&lt;/p&gt; &lt;p&gt;It&amp;#39;s totally based on langchain right now, and with a toml file with my prompt and model settings, I was able to deploy it online using caddy and a simple PGVector instance.&lt;/p&gt; &lt;p&gt;Is there any other application that does that?&lt;/p&gt; &lt;p&gt;Here is the link for the source code: &lt;a href=&quot;https://github.com/talkdai/dialog&quot;&gt;https://github.com/talkdai/dialog&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Brave-Guide-7470&quot;&gt; /u/Brave-Guide-7470 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf7q6y/langchain_wrapper_for_easy_rag_deployments/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf7q6y/langchain_wrapper_for_easy_rag_deployments/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cf7q6y</id><link href="https://www.reddit.com/r/LangChain/comments/1cf7q6y/langchain_wrapper_for_easy_rag_deployments/" /><updated>2024-04-28T14:30:22+00:00</updated><published>2024-04-28T14:30:22+00:00</published><title>LangChain Wrapper for easy RAG Deployments</title></entry><entry><author><name>/u/Relevant-Ad9432</name><uri>https://www.reddit.com/user/Relevant-Ad9432</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I recently tried to make a chatbot, and it was really frustrating to have chatgpt not work (idk why but it just couldn&amp;#39;t answer langchain questions , maybe the training cutoff date) , the docs are not so well arranged... And even if I do somehow get the code to work, it does not perform very well bcz I don&amp;#39;t know much in the first place, I have a theoretical understanding of ML, but idk what are the diff kind of chains, retrievers, agents... I just find it to be a lot of things which are scattered all over the place&lt;/p&gt; &lt;p&gt;So, can someone pls recommend me a course on langchain which consolidates all the different techniques (chains, agents, vectordb etc.) And goes a bit in depth for everything, like how does this chain work or the diff methods of querying to the vectordb... Also feel free to recommend courses other than langchain, it&amp;#39;s just langchain is the only LLM framework I know... &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Relevant-Ad9432&quot;&gt; /u/Relevant-Ad9432 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf5fse/recommend_me_some_courses_for_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf5fse/recommend_me_some_courses_for_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cf5fse</id><link href="https://www.reddit.com/r/LangChain/comments/1cf5fse/recommend_me_some_courses_for_llm/" /><updated>2024-04-28T12:38:17+00:00</updated><published>2024-04-28T12:38:17+00:00</published><title>Recommend me some courses for LLM</title></entry><entry><author><name>/u/jim_andr</name><uri>https://www.reddit.com/user/jim_andr</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jim_andr&quot;&gt; /u/jim_andr &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfbqf9/has_langchain_become_mature_for_production/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfbqf9/has_langchain_become_mature_for_production/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cfbqf9</id><link href="https://www.reddit.com/r/LangChain/comments/1cfbqf9/has_langchain_become_mature_for_production/" /><updated>2024-04-28T17:24:07+00:00</updated><published>2024-04-28T17:24:07+00:00</published><title>Has langchain become mature for production environments?</title></entry><entry><author><name>/u/Aggravating-Floor-38</name><uri>https://www.reddit.com/user/Aggravating-Floor-38</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, need advice on techniques that really elevate rag from naive to an advanced system. I&amp;#39;ve built a rag system that scrapes data from the internet and uses that as context. I&amp;#39;ve worked a bit on chunking strategy and worked extensively on cleaning strategy for the scraped data, query expansion and rewriting, but haven&amp;#39;t done much else. I don&amp;#39;t think I can work on the metadata extraction aspect because I&amp;#39;m using local llms and using them for summaries and QA pairs of the entire scraped db would take too long to do in real time. Also since my systems Open Domain, would fine-tuning the embedding model be useful? Would really appreciate input on that. What other things do you think could be worked on (impressive flashy stuff lol)&lt;/p&gt; &lt;p&gt;I was thinking hybrid search but then I&amp;#39;m also hearing knowledge graphs are great? idk. Saw a paper that just came out last month about context-tuning for retrieval in rag - but can&amp;#39;t find any implementations or discourse around that. Lot of ramble sorry but yeah basically what else can I do to really elevate my RAG system - so far I&amp;#39;m thinking better parsing - processing tables etc., self-rag seems really useful so maybe incorporate that?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Aggravating-Floor-38&quot;&gt; /u/Aggravating-Floor-38 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf97bh/leveling_up_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf97bh/leveling_up_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cf97bh</id><link href="https://www.reddit.com/r/LangChain/comments/1cf97bh/leveling_up_rag/" /><updated>2024-04-28T15:36:08+00:00</updated><published>2024-04-28T15:36:08+00:00</published><title>Leveling up RAG</title></entry><entry><author><name>/u/DancingDorritos</name><uri>https://www.reddit.com/user/DancingDorritos</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfha4g/langchain_with_azure_openai_gpt4/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/d9e3rud6daxc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2fd6fe6d165ce79c6f8d81269c251168e8a484e6&quot; alt=&quot;Langchain with Azure OpenAI gpt4&quot; title=&quot;Langchain with Azure OpenAI gpt4&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’ve been recently trying to get (title) working on a simple python file - just by following the docs - however no matter what YouTube video or documentation I follow, it seems I always get that the error shown in the attached photo. &lt;/p&gt; &lt;p&gt;I’m confused what to do - there must definitely be a way to use langchain with gpt 4 Azure OpenAI. &lt;/p&gt; &lt;p&gt;Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DancingDorritos&quot;&gt; /u/DancingDorritos &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/d9e3rud6daxc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfha4g/langchain_with_azure_openai_gpt4/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cfha4g</id><media:thumbnail url="https://preview.redd.it/d9e3rud6daxc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2fd6fe6d165ce79c6f8d81269c251168e8a484e6" /><link href="https://www.reddit.com/r/LangChain/comments/1cfha4g/langchain_with_azure_openai_gpt4/" /><updated>2024-04-28T21:11:57+00:00</updated><published>2024-04-28T21:11:57+00:00</published><title>Langchain with Azure OpenAI gpt4</title></entry><entry><author><name>/u/djang_odude</name><uri>https://www.reddit.com/user/djang_odude</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/@sreedeep200/how-langchain-and-chatgpt-plugins-are-getting-attacked-by-this-bug-9a47807b66a3&quot;&gt;https://medium.com/@sreedeep200/how-langchain-and-chatgpt-plugins-are-getting-attacked-by-this-bug-9a47807b66a3&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/djang_odude&quot;&gt; /u/djang_odude &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf9wl3/how_langchain_and_chatgpt_plugins_are_getting/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf9wl3/how_langchain_and_chatgpt_plugins_are_getting/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cf9wl3</id><link href="https://www.reddit.com/r/LangChain/comments/1cf9wl3/how_langchain_and_chatgpt_plugins_are_getting/" /><updated>2024-04-28T16:06:13+00:00</updated><published>2024-04-28T16:06:13+00:00</published><title>How LangChain and ChatGPT plugins are getting attacked by this bug</title></entry><entry><author><name>/u/Calm-Number5851</name><uri>https://www.reddit.com/user/Calm-Number5851</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;Large Language Models&lt;/strong&gt;, or LLMs, are advanced AI systems that enhance text prediction to an exceptional level — imagine the autocorrect &amp;amp; text prediction on your phone, but far more sophisticated.&lt;/p&gt; &lt;p&gt;When you type &amp;quot;I am going to the...&amp;quot;, your phone might suggest words like &amp;quot;store&amp;quot; or &amp;quot;gym.&amp;quot;, based on the words you wrote before. LLMs operate similarly, but on a much larger scale, using vast amounts of text to predict and generate language accurately.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The Core Pillars of LLMs are:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Transformer Models&lt;/strong&gt; - the backbone of most LLMs, these models process data by breaking down input text into smaller parts (tokens) and analyzing the relationships between them. This helps the model understand and generate language based on the context provided.Just like our brain uses neurons to process and relay information, transformer models use tokens to process and generate language, making sense of the input based on context.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Training&lt;/strong&gt; - LLMs learn by consuming vast amounts of text data, from websites like Wikipedia to books and articles. This training allows them to understand language patterns and context, and, as a result, generate better text.It’s just like reading hundreds of books to enhance your knowledge and master a subject, we feed LLMs with text data from diverse sources like Wikipedia and various books to help them learn, though with a small caveat — LLMs can do this anywhere from 100-1000 times &lt;em&gt;faster&lt;/em&gt; than us.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Fine-tuning&lt;/strong&gt; - after their initial training, LLMs can be fine-tuned with specific data sets to perform tasks like translation, content generation, or even coding.With fine-tuning, you’re giving your little helper a specific role &amp;amp; legend to fill — for example, &amp;quot;Sir Code-a-lot”, who, after his rigorous initial training, is now sharpening the specific skills needed to slay the mighty dragons in the C++ Language.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;And if you want to see how different your autocorrect &amp;amp; text prediction on your phone is from actual Large Language Models – then here’s a cool visual showing the sheer scale of the various GPT LLMs Essentially, LLMs predict what comes next, depending on the context &amp;amp; your input. If you’re a programmer and you’re writing code in Python, and use an LLM-powered code editor, the model understands every line of code you’ve written and suggests the next one accurately!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The History of LLMs &amp;amp; Transformers&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The evolution of LLMs (&lt;strong&gt;Large Language Models&lt;/strong&gt;) began with the introduction of the Transformer model by Google at NeurIPS 2017. &lt;/p&gt; &lt;p&gt;This model introduced a new approach called &amp;quot;attention mechanisms&amp;quot; that improves how machines understand the context within text. Basically, a Transformer allows the model to focus on different parts of the input data at different times, improving its ability to generate accurate and contextually appropriate responses.&lt;/p&gt; &lt;p&gt;This model led to significant developments such as BERT and GPT models. GPT models, starting from GPT-1 to the latest iterations like GPT-3.5 and GPT-4, have significantly advanced in capabilities, achieving tasks that range from simple text generation to complex decision-making and problem-solving tasks.&lt;/p&gt; &lt;p&gt;And you know what’s the best part about LLMs becoming mainstream? &lt;/p&gt; &lt;p&gt;Nearly every SaaS company is leveraging them by building apps to solve the problems we creators &amp;amp; entrepreneurs face daily – responding to emails, scheduling meetings, finding time for family and leisure, data entry, everything you could imagine — there’s an LLM-based tool for it now.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm-Number5851&quot;&gt; /u/Calm-Number5851 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cff5pa/llms_or_what_even_are_those/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cff5pa/llms_or_what_even_are_those/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cff5pa</id><link href="https://www.reddit.com/r/LangChain/comments/1cff5pa/llms_or_what_even_are_those/" /><updated>2024-04-28T19:45:37+00:00</updated><published>2024-04-28T19:45:37+00:00</published><title>LLMs Or What Even Are Those?</title></entry><entry><author><name>/u/Distinct-Target7503</name><uri>https://www.reddit.com/user/Distinct-Target7503</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone... &lt;/p&gt; &lt;p&gt;I build an advanced RAG pipeline, and that include an agent that should get data from web, opening links from web search results... Anyway, I&amp;#39;ve zero past experience with web scraping, and my html knowledge is really basic. I&amp;#39;m going mad trying to extract the main text from web pages without lot of noise from tag, headers and other UI elements. As temporary solution, I added an llm agent &amp;quot;in the middle&amp;quot;, using it to clean the scraped text... But that&amp;#39;s slow, expensive (using cloud providers) and fondamentally inefficient. &lt;/p&gt; &lt;p&gt;Someone can give me some tips/help? There is some library, repo or framework that may help me? &lt;/p&gt; &lt;p&gt;Any kind of replay will be really appreciate! &lt;/p&gt; &lt;p&gt;Thanks in advance for your time. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Distinct-Target7503&quot;&gt; /u/Distinct-Target7503 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf2dwc/what_web_scraper_for_web_search_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf2dwc/what_web_scraper_for_web_search_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cf2dwc</id><link href="https://www.reddit.com/r/LangChain/comments/1cf2dwc/what_web_scraper_for_web_search_agent/" /><updated>2024-04-28T09:28:27+00:00</updated><published>2024-04-28T09:28:27+00:00</published><title>What web scraper for web search agent?</title></entry><entry><author><name>/u/acageinsearchofabird</name><uri>https://www.reddit.com/user/acageinsearchofabird</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Specifically, legal documents.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/acageinsearchofabird&quot;&gt; /u/acageinsearchofabird &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceztk1/has_anyone_utilized_agents_for_document/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceztk1/has_anyone_utilized_agents_for_document/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ceztk1</id><link href="https://www.reddit.com/r/LangChain/comments/1ceztk1/has_anyone_utilized_agents_for_document/" /><updated>2024-04-28T06:35:41+00:00</updated><published>2024-04-28T06:35:41+00:00</published><title>Has anyone utilized agents for document summarization and information extraction?</title></entry><entry><author><name>/u/AccomplishedLion6322</name><uri>https://www.reddit.com/user/AccomplishedLion6322</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for a part-time LLM engineer to build some AI agent workflows. It&amp;#39;s remote.&lt;/p&gt; &lt;p&gt;Most job boards don&amp;#39;t seem to have this category yet. And the person I&amp;#39;d want wouldn&amp;#39;t need to have tons of AI or software engineering experience anyway. They just need to be technical-enough, a fan of GenAI, and familiar with LLM tooling.&lt;/p&gt; &lt;p&gt;Any good ideas on where to find them?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AccomplishedLion6322&quot;&gt; /u/AccomplishedLion6322 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cejzmq/where_to_hire_llm_engineers_who_know_tools_like/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cejzmq/where_to_hire_llm_engineers_who_know_tools_like/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cejzmq</id><link href="https://www.reddit.com/r/LangChain/comments/1cejzmq/where_to_hire_llm_engineers_who_know_tools_like/" /><updated>2024-04-27T17:31:42+00:00</updated><published>2024-04-27T17:31:42+00:00</published><title>Where to hire LLM engineers who know tools like LangChain? Most job board don't distinguish LLM engineers from typical AI or software engineers</title></entry><entry><author><name>/u/Visual-Librarian6601</name><uri>https://www.reddit.com/user/Visual-Librarian6601</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi I am writing a Nodejs library that uses LLM to process documents. I plan to support LLMs in OpenAI, Groq, Ollama. Is it a good practice to directly to use Langchain or Llama Index in my npm library and introduce it as a dependency?&lt;/p&gt; &lt;p&gt;Yes? (the code will be simpler and supporting multiple LLMs out of the box) today I do use Langchain in my bigger project that includes the code I want to split into this library.&lt;/p&gt; &lt;p&gt;Or shall I use separate LLM APIs like OpenAi’s directly. Or maybe try Llama Index&lt;/p&gt; &lt;p&gt;Any feedback is welcome 🙏 &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Visual-Librarian6601&quot;&gt; /u/Visual-Librarian6601 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceyzjy/use_langchain_vs_individual_llm_api_in_an_npm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceyzjy/use_langchain_vs_individual_llm_api_in_an_npm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ceyzjy</id><link href="https://www.reddit.com/r/LangChain/comments/1ceyzjy/use_langchain_vs_individual_llm_api_in_an_npm/" /><updated>2024-04-28T05:42:26+00:00</updated><published>2024-04-28T05:42:26+00:00</published><title>Use Langchain vs individual LLM API in an npm library</title></entry><entry><author><name>/u/Sea_Application1815</name><uri>https://www.reddit.com/user/Sea_Application1815</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I keep getting this error when using LangSmith:&lt;br/&gt; HTTPError: [Errno 403 Client Error: Forbidden for url: &lt;a href=&quot;https://api.smith.langchain.com/datasets%5C&quot;&gt;https://api.smith.langchain.com/datasets\&lt;/a&gt;] {&amp;quot;detail&amp;quot;:&amp;quot;Forbidden&amp;quot;}&lt;/p&gt; &lt;p&gt;This was working fine just yesterday :(&lt;/p&gt; &lt;pre&gt;&lt;code&gt;os.environ[&amp;#39;LANGCHAIN_TRACING_V2&amp;#39;] = &amp;#39;true&amp;#39; os.environ[&amp;quot;LANGCHAIN_ENDPOINT&amp;quot;] = &amp;quot;https://api.smith.langchain.com&amp;quot; os.environ[&amp;quot;LANGCHAIN_API_KEY&amp;quot;] = os.getenv(&amp;quot;LANGCHAIN_API_KEY&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I have accessed the api_keys.&lt;/p&gt; &lt;p&gt;How do I fix this? Can someone please help?&lt;/p&gt; &lt;p&gt;Edit: I am also importing&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langsmith import Client client = Client() &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sea_Application1815&quot;&gt; /u/Sea_Application1815 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cennxi/langchain_client_connection_error/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cennxi/langchain_client_connection_error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cennxi</id><link href="https://www.reddit.com/r/LangChain/comments/1cennxi/langchain_client_connection_error/" /><updated>2024-04-27T20:08:39+00:00</updated><published>2024-04-27T20:08:39+00:00</published><title>LangChain client connection error</title></entry><entry><author><name>/u/ava69_open</name><uri>https://www.reddit.com/user/ava69_open</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, our small engineering team is exploring RAG for querying our massive internal document system. It&amp;#39;s exciting, but also a little overwhelming with all the choices - LLMs, embedding models, vector databases, hyperparameters... you name it!&lt;/p&gt; &lt;p&gt;Here&amp;#39;s what we&amp;#39;re thinking:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Manually create a test set of 10-20 custom Q&amp;amp;As (should we allow multiple answer options?).&lt;/li&gt; &lt;li&gt;Automate deployment of various combinations: different LLMs, hyperparameters, embedding models, etc.&lt;/li&gt; &lt;li&gt;Compare the generated answers to our gold standard answers (thinking ROUGE score for evaluation).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Does this approach sound reasonable? Are there any tools or frameworks out there that can streamline this process for a small team like ours? Any advice would be greatly appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ava69_open&quot;&gt; /u/ava69_open &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8z9h/diving_into_rag_with_a_small_team/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8z9h/diving_into_rag_with_a_small_team/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce8z9h</id><link href="https://www.reddit.com/r/LangChain/comments/1ce8z9h/diving_into_rag_with_a_small_team/" /><updated>2024-04-27T07:47:07+00:00</updated><published>2024-04-27T07:47:07+00:00</published><title>Diving into RAG with a Small Team</title></entry><entry><author><name>/u/Calm-Number5851</name><uri>https://www.reddit.com/user/Calm-Number5851</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cemgtd/microsoft_launches_tiny_ai_model_phi3/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/rrnQmZ9aRteVTnRSbSR6JHNFl-AMLM7WDd2nxsP19ew.jpg&quot; alt=&quot;Microsoft Launches Tiny AI Model Phi-3 &quot; title=&quot;Microsoft Launches Tiny AI Model Phi-3 &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Microsoft announced its smallest AI model yet, Phi-3. This model, measuring just 3.8 billion parameters, was learned from ‘bedtime stories’ created by other LLMs. Thanks to innovations in learning, the company says this family outperforms the same and next-size models on a range of tests assessing language, programming, and math abilities.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/dav6udi2m2xc1.jpg?width=2000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=cc3538181ff7ad3a69064991c7b0dff507eb7ee6&quot;&gt;https://preview.redd.it/dav6udi2m2xc1.jpg?width=2000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=cc3538181ff7ad3a69064991c7b0dff507eb7ee6&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The new model is available in the Microsoft Azure AI Model Catalog and on Hugging Face, as well as Ollama, a lightweight framework for running models on a local machine. Microsoft says it will also be available as an NVIDIA NIM microservice with a standard API interface that can be deployed anywhere.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm-Number5851&quot;&gt; /u/Calm-Number5851 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cemgtd/microsoft_launches_tiny_ai_model_phi3/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cemgtd/microsoft_launches_tiny_ai_model_phi3/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cemgtd</id><media:thumbnail url="https://b.thumbs.redditmedia.com/rrnQmZ9aRteVTnRSbSR6JHNFl-AMLM7WDd2nxsP19ew.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1cemgtd/microsoft_launches_tiny_ai_model_phi3/" /><updated>2024-04-27T19:16:47+00:00</updated><published>2024-04-27T19:16:47+00:00</published><title>Microsoft Launches Tiny AI Model Phi-3</title></entry><entry><author><name>/u/Familyinalicante</name><uri>https://www.reddit.com/user/Familyinalicante</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am trying to fire out how to create tool for agent to work with Simple rest API (build with Fast API, no auth). I am just learning and couldn&amp;#39;t find practical implementation. I&amp;#39;ve read about using API chain but My api have 4 endpoints. It&amp;#39;s really basic one &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Familyinalicante&quot;&gt; /u/Familyinalicante &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceonep/agent_tool_to_work_with_rest_api/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceonep/agent_tool_to_work_with_rest_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ceonep</id><link href="https://www.reddit.com/r/LangChain/comments/1ceonep/agent_tool_to_work_with_rest_api/" /><updated>2024-04-27T20:51:42+00:00</updated><published>2024-04-27T20:51:42+00:00</published><title>Agent tool to work with rest API</title></entry><entry><author><name>/u/madwzdri</name><uri>https://www.reddit.com/user/madwzdri</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Are there any libraries that can allow me to create a shareable versions of rag documents using links. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I am looking to create a system that will allow me to share a document using links with an LLM trained using RAG. How would you go about this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/madwzdri&quot;&gt; /u/madwzdri &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cefdw6/sharing_rag_enhanced_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cefdw6/sharing_rag_enhanced_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cefdw6</id><link href="https://www.reddit.com/r/LangChain/comments/1cefdw6/sharing_rag_enhanced_documents/" /><updated>2024-04-27T14:09:11+00:00</updated><published>2024-04-27T14:09:11+00:00</published><title>Sharing RAG enhanced documents</title></entry><entry><author><name>/u/QueRoub</name><uri>https://www.reddit.com/user/QueRoub</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have built a RAG application and I am getting back the source file from which the LLM answered a question.&lt;/p&gt; &lt;p&gt;My issue is that a document is always retrieved but the LLM might not give an answer based on that.&lt;/p&gt; &lt;p&gt;I would like to capture this case when I call the chain. &lt;/p&gt; &lt;p&gt;Is that possible?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/QueRoub&quot;&gt; /u/QueRoub &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9jnl/capture_case_where_llm_did_not_find_any_answer_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9jnl/capture_case_where_llm_did_not_find_any_answer_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce9jnl</id><link href="https://www.reddit.com/r/LangChain/comments/1ce9jnl/capture_case_where_llm_did_not_find_any_answer_in/" /><updated>2024-04-27T08:24:37+00:00</updated><published>2024-04-27T08:24:37+00:00</published><title>Capture case where LLM did not find any answer in context</title></entry><entry><author><name>/u/QueRoub</name><uri>https://www.reddit.com/user/QueRoub</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a way to get back similarity scores from retrievers?&lt;/p&gt; &lt;p&gt;If not, do you know any reliable function that computes similarity score between user&amp;#39;s query and retrieved chunks?&lt;/p&gt; &lt;p&gt;My issue is that I am working with non-English documents and many custom similarity score computation functions don&amp;#39;t work very accurately. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/QueRoub&quot;&gt; /u/QueRoub &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9fh1/can_you_get_back_similarity_scores_from_retrievers/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9fh1/can_you_get_back_similarity_scores_from_retrievers/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce9fh1</id><link href="https://www.reddit.com/r/LangChain/comments/1ce9fh1/can_you_get_back_similarity_scores_from_retrievers/" /><updated>2024-04-27T08:16:50+00:00</updated><published>2024-04-27T08:16:50+00:00</published><title>Can you get back similarity scores from retrievers?</title></entry><entry><author><name>/u/prime_danger</name><uri>https://www.reddit.com/user/prime_danger</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a complex documentation and multiple requirements. I ask a question about a requirement which itself has requirements from the same document. Kindly advice on what should I use and how do I build?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/prime_danger&quot;&gt; /u/prime_danger &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8lzd/how_to_build_an_agent_that_goes_back_and_forth/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8lzd/how_to_build_an_agent_that_goes_back_and_forth/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce8lzd</id><link href="https://www.reddit.com/r/LangChain/comments/1ce8lzd/how_to_build_an_agent_that_goes_back_and_forth/" /><updated>2024-04-27T07:22:24+00:00</updated><published>2024-04-27T07:22:24+00:00</published><title>How to build an agent that goes back and forth into the vector db</title></entry><entry><author><name>/u/Diligent_Eye1248</name><uri>https://www.reddit.com/user/Diligent_Eye1248</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://dly.to/emJTz7UM5hG&quot;&gt;Learn&lt;/a&gt; how to build an anime character generator using LangChain and OpenAI. No HTML or CSS required, just use Streamlit to create a simple web interface. Activate the virtual environment, install the necessary libraries, and run the code. Get creative and generate unique anime character names with different themes, along with wise, dramatic, or humorous quotes. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Diligent_Eye1248&quot;&gt; /u/Diligent_Eye1248 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce7m2u/building_an_anime_character_generator_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce7m2u/building_an_anime_character_generator_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce7m2u</id><link href="https://www.reddit.com/r/LangChain/comments/1ce7m2u/building_an_anime_character_generator_with/" /><updated>2024-04-27T06:18:58+00:00</updated><published>2024-04-27T06:18:58+00:00</published><title>Building an Anime Character Generator with LangChain and OpenAI</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/learnmachinelearning/comments/1ce70vu/what_is_llm_jailbreak_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce71lz/what_is_llm_jailbreak_explained/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce71lz</id><link href="https://www.reddit.com/r/LangChain/comments/1ce71lz/what_is_llm_jailbreak_explained/" /><updated>2024-04-27T05:44:12+00:00</updated><published>2024-04-27T05:44:12+00:00</published><title>What is LLM Jailbreak explained</title></entry><entry><author><name>/u/RoboCoachTech</name><uri>https://www.reddit.com/user/RoboCoachTech</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;It has been a long time since our last update on &lt;a href=&quot;https://github.com/RoboCoachTechnologies/ROScribe&quot;&gt;ROScribe&lt;/a&gt; (an open source tool for robot integration and software generation using LLM). In our first releases of ROScribe, we autogenerated the entire robot software in ROS (in python) using LLMs and LangChain. Then, later on, we trained ROScribe with all open source repositories available on ROS-index (python or C++) to enable a code-retrieval feature.&lt;/p&gt; &lt;p&gt;The last step was to seamlessly combine these two different methods (Code generation &amp;amp; Code retrieval) to create an ultimate solution that first looks at what codes are available and then only generates code for the parts which aren&amp;#39;t available and tie them together. This problem proved to be more challenging that we thought, and it took us a while to get it done.&lt;/p&gt; &lt;p&gt;It is done now. We made our version 0.1.0 release a few days ago.&lt;/p&gt; &lt;p&gt;Here is a short demo that shows a 2D mapping with Lidar using ROScribe v0.1.0:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=AWnC6s2nK-k&quot;&gt;https://www.youtube.com/watch?v=AWnC6s2nK-k&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I will post more details later. For now you can find extra info in our github:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/RoboCoachTechnologies/ROScribe&quot;&gt;https://github.com/RoboCoachTechnologies/ROScribe&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RoboCoachTech&quot;&gt; /u/RoboCoachTech &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdwvui/code_generation_integrated_with_code_retrieval/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdwvui/code_generation_integrated_with_code_retrieval/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cdwvui</id><link href="https://www.reddit.com/r/LangChain/comments/1cdwvui/code_generation_integrated_with_code_retrieval/" /><updated>2024-04-26T21:17:35+00:00</updated><published>2024-04-26T21:17:35+00:00</published><title>Code generation integrated with code retrieval for robot applications using LangChain</title></entry><entry><author><name>/u/Any_Material_2850</name><uri>https://www.reddit.com/user/Any_Material_2850</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am looking for someone who would be willing to coach me and help me get started in building a bot. Am on a Mac. Is this something that someone would be willing to do?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Any_Material_2850&quot;&gt; /u/Any_Material_2850 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce6ndb/looking_for_a_coach_paid/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce6ndb/looking_for_a_coach_paid/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce6ndb</id><link href="https://www.reddit.com/r/LangChain/comments/1ce6ndb/looking_for_a_coach_paid/" /><updated>2024-04-27T05:20:15+00:00</updated><published>2024-04-27T05:20:15+00:00</published><title>Looking for a coach (paid)</title></entry><entry><author><name>/u/typing_username</name><uri>https://www.reddit.com/user/typing_username</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am building a mock interview bot with langchain js and fireworks ai api.&lt;/p&gt; &lt;p&gt;but getting an continuous output like this in the response:&lt;/p&gt; &lt;p&gt;response &amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;{&amp;quot;response&amp;quot;: &amp;quot;Welcome to the interview for the React Developer position! Can you please tell me a little about yourself and why you&amp;#39;re interested in this role?&amp;quot;, &amp;quot;feedback&amp;quot;: null}&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;{&amp;quot;response&amp;quot;: &amp;quot;What experience do you have with React and its ecosystem, and can you give me an example of a project you&amp;#39;ve worked on that you&amp;#39;re particularly proud of?&amp;quot;, &amp;quot;feedback&amp;quot;: null}&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;{&amp;quot;response&amp;quot;: &amp;quot;How do you handle state management in React applications, and have you used any libraries like Redux or MobX in your previous projects?&amp;quot;, &amp;quot;feedback&amp;quot;: null}&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;{&amp;quot;response&amp;quot;: &amp;quot;Can you explain the concept of a &amp;#39;Higher-Order Component&amp;#39; in React and give an example of how you would use it in a real-world scenario?&amp;quot;, &amp;quot;feedback&amp;quot;: null}&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;{&amp;quot;response&amp;quot;: &amp;quot;How do you optimize the performance of a React application, and what tools or techniques have you used in the past to improve rendering efficiency?&amp;quot;, &amp;quot;feedback&amp;quot;: null}&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;sometimes it is returning the code, Can you tell me how to get a single and correct response? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/typing_username&quot;&gt; /u/typing_username &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce742z/need_help_with_llama_3/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce742z/need_help_with_llama_3/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce742z</id><link href="https://www.reddit.com/r/LangChain/comments/1ce742z/need_help_with_llama_3/" /><updated>2024-04-27T05:48:10+00:00</updated><published>2024-04-27T05:48:10+00:00</published><title>Need Help with Llama 3</title></entry><entry><author><name>/u/alimhabidi</name><uri>https://www.reddit.com/user/alimhabidi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdvd9a/book_recommendation_mastering_nlp_from/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/sg4at7g9tvwc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=64377b74227d5d75d0bbf2115c0974c1b8b48b5e&quot; alt=&quot;Book recommendation: Mastering NLP from Foundations to LLMs&quot; title=&quot;Book recommendation: Mastering NLP from Foundations to LLMs&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;🚀 Exciting News! 🚀 The wait is over ⭐&lt;/p&gt; &lt;p&gt;Mastering NLP from Foundations to LLMs: Apply advanced rule-based techniques to LLMs and solve real-world business problems using Python&lt;/p&gt; &lt;p&gt;Hi everyone, I&amp;#39;m thrilled to share with you all that the much-awaited book authored by leading experts Lior Gazit and Meysam Ghaffari, Ph.D. is finally here! 🎉&lt;/p&gt; &lt;p&gt;Enhance your NLP proficiency with modern frameworks like LangChain, explore mathematical foundations and code samples, and gain expert insights into current and future trends&lt;/p&gt; &lt;p&gt;💡 Dive deep into the fascinating world of Natural Language Processing with this comprehensive guide. Whether you&amp;#39;re just starting out or looking to enhance your skills, this book has got you covered.&lt;/p&gt; &lt;p&gt;🔑 Key Features: - Learn how to build Python-driven solutions focusing on NLP, LLMs, RAGs, and GPT. - Master embedding techniques and machine learning principles for real-world applications. - Understand the mathematical foundations of NLP and deep learning designs. - Plus, get a free PDF eBook when you purchase the print or Kindle version!&lt;/p&gt; &lt;p&gt;📘 Book Description: From laying down the groundwork of machine learning to exploring advanced concepts like LLMs, this book takes you on an enlightening journey. Dive into linear algebra, optimization, probability, and statistics – all the essentials you need to conquer ML and NLP. And the best part? You&amp;#39;ll find practical Python code samples throughout!&lt;/p&gt; &lt;p&gt;By the end, you&amp;#39;ll be delving into the nitty-gritty of LLMs&amp;#39; theory, design, and applications, alongside expert insights on the future trends in NLP.&lt;/p&gt; &lt;p&gt;Not only this, the book features Expert Insights by Stalwarts from the industry : • Xavier (Xavi) Amatriain, VP of Product, Core ML/AI, Google • Melanie Garson, Cyber Policy &amp;amp; Tech Geopolitics Lead at Tony Blair Institute for Global Change, and Associate Professor at University College London • Nitzan Mekel-Bobrov, Ph.D., CAIO, Ebay • David Sontag, Professor at MIT and CEO at Layer Health • John Halamka, M.D., M.S., president of the Mayo Clinic Platform&lt;/p&gt; &lt;p&gt;Foreword and Impressions by leading Expert Asha Saxena&lt;/p&gt; &lt;p&gt;🔍 What You Will Learn: - Master the mathematical foundations of machine learning and NLP. - Implement advanced techniques for preprocessing text data and analysis. - Design ML-NLP systems in Python. - Model and classify text using traditional and deep learning methods. - Explore the theory and design of LLMs and their real-world applications. - Get a sneak peek into the future of NLP with expert opinions and insights.&lt;/p&gt; &lt;p&gt;📢 Don&amp;#39;t miss out on this incredible opportunity to expand your NLP skills! Grab your copy now and embark on an exciting learning journey.&lt;/p&gt; &lt;p&gt;Amazon US &lt;a href=&quot;https://www.amazon.com/Mastering-NLP-Foundations-LLMs-Techniques/dp/1804619183/&quot;&gt;https://www.amazon.com/Mastering-NLP-Foundations-LLMs-Techniques/dp/1804619183/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/alimhabidi&quot;&gt; /u/alimhabidi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/sg4at7g9tvwc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdvd9a/book_recommendation_mastering_nlp_from/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cdvd9a</id><media:thumbnail url="https://preview.redd.it/sg4at7g9tvwc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=64377b74227d5d75d0bbf2115c0974c1b8b48b5e" /><link href="https://www.reddit.com/r/LangChain/comments/1cdvd9a/book_recommendation_mastering_nlp_from/" /><updated>2024-04-26T20:15:23+00:00</updated><published>2024-04-26T20:15:23+00:00</published><title>Book recommendation: Mastering NLP from Foundations to LLMs</title></entry></feed>