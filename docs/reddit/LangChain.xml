<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-29T09:51:11+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/glip-glop-evil</name><uri>https://www.reddit.com/user/glip-glop-evil</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to use langchain with GPT for a search tool. The search database query has a language code (en or zh) and when the tool is used, the language code is determined from the user query.&lt;/p&gt; &lt;p&gt;How can I get langchain to run the tool twice - in all available language codes translating the user query when necessary and compare the search content and get the most appropriate one before returning an answer? &lt;/p&gt; &lt;p&gt;Does this need to be done via the prompt or a more programmatic approach?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/glip-glop-evil&quot;&gt; /u/glip-glop-evil &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adpw9c/language_switching_with_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adpw9c/language_switching_with_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adpw9c</id><link href="https://www.reddit.com/r/LangChain/comments/1adpw9c/language_switching_with_tools/" /><updated>2024-01-29T07:46:15+00:00</updated><published>2024-01-29T07:46:15+00:00</published><title>Language switching with tools</title></entry><entry><author><name>/u/RatioAltruistic9324</name><uri>https://www.reddit.com/user/RatioAltruistic9324</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everybody!&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently developing some agents on Langchain for many purpose. Some are just documents analysis or data extraction from documents, and other are more Chatbot Rag based The first category are not really agents, they are refine chain (a bit modified from the LCEL turo one) + stuff one And the second is Langchain Agents (ZeroShotPrompt)&lt;/p&gt; &lt;p&gt;Both run with GPT4&lt;/p&gt; &lt;p&gt;But here is the thing :&lt;/p&gt; &lt;p&gt;For the first category, as the pdf can goes to 5 to 20 pages, my agents take several minutes to handle them Also, I remarqued that the more I put a defined structure in the prompt to extracr information, the more it is long (can go up to 10min)&lt;/p&gt; &lt;p&gt;And for the second category, as there is a multi query retrieval Generation based on pinecone, it also take 1 min before generation.&lt;/p&gt; &lt;p&gt;I look for conceptual way to explain that. We see a lot of agent out there which are more fast &lt;/p&gt; &lt;ul&gt; &lt;li&gt;is it the framework Langchain that slow down everything?&lt;/li&gt; &lt;li&gt;is I had a local model would it be faster ?&lt;/li&gt; &lt;li&gt;is because of the Rag too complex?&lt;/li&gt; &lt;li&gt;how could I drastically shorten my prompt but keeping clear schema for data extraction?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Thanks you all for your help !&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RatioAltruistic9324&quot;&gt; /u/RatioAltruistic9324 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adqrwj/speed_up_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adqrwj/speed_up_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adqrwj</id><link href="https://www.reddit.com/r/LangChain/comments/1adqrwj/speed_up_agents/" /><updated>2024-01-29T08:47:18+00:00</updated><published>2024-01-29T08:47:18+00:00</published><title>Speed up Agents</title></entry><entry><author><name>/u/ashpreetbedi</name><uri>https://www.reddit.com/user/ashpreetbedi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi reddit, I built an AI that can interact with the Hacker News API: &lt;a href=&quot;https://hn.aidev.run&quot;&gt;https://hn.aidev.run&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You can ask questions like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;What&amp;#39;s on hackernews about AI?&lt;/li&gt; &lt;li&gt;What&amp;#39;s on hackernews about iPhone?&lt;/li&gt; &lt;li&gt;What&amp;#39;s trending on hackernews?&lt;/li&gt; &lt;li&gt;What are users showing on hackernews?&lt;/li&gt; &lt;li&gt;What are users asking on hackernews?&lt;/li&gt; &lt;li&gt;Summarize this story: &lt;a href=&quot;https://news.ycombinator.com/item?id=39156778&quot;&gt;https://news.ycombinator.com/item?id=39156778&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It uses function calling to query the HN api.&lt;/p&gt; &lt;p&gt;To answer questions about a particular topic, it’ll search its knowledge base (a vector db that is periodically updated with the “top stories”) and get details about those stories from the API.&lt;/p&gt; &lt;p&gt;This is pretty barebones and I built it today in &amp;lt; 2 hours, so it probably won’t meet your high standards. If you give it a try, I’d love your feedback on how I can improve it.&lt;/p&gt; &lt;p&gt;If you’re interested, I built this using &lt;a href=&quot;https://github.com/phidatahq/phidata&quot;&gt;phidata&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thanks for reading and would love to hear what you think.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashpreetbedi&quot;&gt; /u/ashpreetbedi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adarpa/hackernews_ai_built_using_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adarpa/hackernews_ai_built_using_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adarpa</id><link href="https://www.reddit.com/r/LangChain/comments/1adarpa/hackernews_ai_built_using_function_calling/" /><updated>2024-01-28T19:28:17+00:00</updated><published>2024-01-28T19:28:17+00:00</published><title>HackerNews AI built using function calling</title></entry><entry><author><name>/u/Hungry-Connection645</name><uri>https://www.reddit.com/user/Hungry-Connection645</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, I&amp;#39;m trying to familiarize myself with the internals of the langchain python package, I noticed that langchain and langchain_core are separated and in the internal code they have similar sub packages. my question is what is the need for this separation and what is the thought process behind what should be implemented in langchain vs langchain_core. Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Hungry-Connection645&quot;&gt; /u/Hungry-Connection645 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad9x8c/why_separate_langchain_and_langchain_core_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad9x8c/why_separate_langchain_and_langchain_core_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad9x8c</id><link href="https://www.reddit.com/r/LangChain/comments/1ad9x8c/why_separate_langchain_and_langchain_core_for/" /><updated>2024-01-28T18:53:53+00:00</updated><published>2024-01-28T18:53:53+00:00</published><title>Why separate langchain and langchain_core for python package</title></entry><entry><author><name>/u/Benjamona97</name><uri>https://www.reddit.com/user/Benjamona97</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Im looking for a production level vector db, so I was thinking about plain pg + pgvector, the problem is that I can&amp;#39;t find an easy way of finding a good library to interact with it, so far I&amp;#39;m using raw queries like this (i will leave code at the bottom). I don&amp;#39;t know if this is the best way apart from chroma, weaviate, pinecone, etc etc this is going to be at production level por mi company to be used internally.&lt;br/&gt; WITH vector_matches AS (&lt;br/&gt; SELECT document_id, 1 - (embedding &amp;lt;=&amp;gt; %s) AS similarity&lt;br/&gt; FROM documents_embeddings&lt;br/&gt; WHERE 1 - (embedding &amp;lt;=&amp;gt; %s) &amp;gt; %s&lt;br/&gt; ORDER BY similarity DESC&lt;br/&gt; LIMIT %s&lt;br/&gt; )&lt;br/&gt; SELECT d.page_content, d.metadata, d.file_id, vm.similarity&lt;br/&gt; FROM documents d&lt;br/&gt; INNER JOIN vector_matches vm ON d.id = vm.document_id &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Benjamona97&quot;&gt; /u/Benjamona97 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adf3o6/looking_for_a_production_level_vector_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1adf3o6/looking_for_a_production_level_vector_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1adf3o6</id><link href="https://www.reddit.com/r/LangChain/comments/1adf3o6/looking_for_a_production_level_vector_db/" /><updated>2024-01-28T22:29:16+00:00</updated><published>2024-01-28T22:29:16+00:00</published><title>Looking for a production level vector db</title></entry><entry><author><name>/u/Xerxes_Artemisia</name><uri>https://www.reddit.com/user/Xerxes_Artemisia</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad2hcq/streamlit_run_apppy_blank_screen_help_vscode/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/7jx0iOSXrRqXqAo25L6_dP-LHrDNQDvR_eYBTULyOOY.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c42e7ed72cf80343b339e6911558dba6cf300b4b&quot; alt=&quot;Streamlit run app.py - blank screen help ( vscode) - OpenAI chat bot project&quot; title=&quot;Streamlit run app.py - blank screen help ( vscode) - OpenAI chat bot project&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I&amp;#39;m a newbie programmer and having mind boggling issue of my app not deploying...it is a chat bot...everything seems to be fine just the error was Inport error: Openai can&amp;#39;t be imported from langchain. I don&amp;#39;t know..have scoured the internet for the fixes, but unable to find a solution.&lt;/p&gt; &lt;p&gt;Saw a tutorial from free coding camp on YouTube and it seems to work in that tutorial. I followed step by step even checked multiple times.&lt;/p&gt; &lt;p&gt;If someone can help me find out what is wrong I will be very grateful.&lt;/p&gt; &lt;p&gt;It may be a simple thing or complex I don&amp;#39;t know as I don&amp;#39;t have a 360 degree understanding of python libraries or streamlit requirements. I followed the tutorial 100% though. I can say that.&lt;/p&gt; &lt;p&gt;I reached 1:14:00 in the video&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Xerxes_Artemisia&quot;&gt; /u/Xerxes_Artemisia &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/x0AnCE9SE4A?si=Yb1LMCiz5AJ1RE7E&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad2hcq/streamlit_run_apppy_blank_screen_help_vscode/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ad2hcq</id><media:thumbnail url="https://external-preview.redd.it/7jx0iOSXrRqXqAo25L6_dP-LHrDNQDvR_eYBTULyOOY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c42e7ed72cf80343b339e6911558dba6cf300b4b" /><link href="https://www.reddit.com/r/LangChain/comments/1ad2hcq/streamlit_run_apppy_blank_screen_help_vscode/" /><updated>2024-01-28T13:18:32+00:00</updated><published>2024-01-28T13:18:32+00:00</published><title>Streamlit run app.py - blank screen help ( vscode) - OpenAI chat bot project</title></entry><entry><author><name>/u/stoicbats_</name><uri>https://www.reddit.com/user/stoicbats_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I have converted some domain-specific name vectors into embeddings, with a dataset size of 200k words. All the embeddings were generated using OpenAI&amp;#39;s embedding model 3 (3072 dim per embedding) . Now I am planning to implement semantic search similarity. Given a domain keyword, I want to find the top 5 most similar matches. After embedding all 280k words, the size of the JSON file containing the embeddings is around 30GB.&lt;/p&gt; &lt;p&gt;I am new to this domain and evaluating the best options.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Should I use a cloud vector database like Pinecone or Typsense, or host locally on DigitalOcean?&lt;/li&gt; &lt;li&gt;If I go with a cloud option like Typsense, what configuration (RAM, etc.) would I need for 280k embeddings (30GB in size)? And how much would it likely cost?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I have been confused for the past few days and unable to find useful resources. Any help or advice you could provide would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/stoicbats_&quot;&gt; /u/stoicbats_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acxxbw/best_practices_for_semantic_search_on_200k/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acxxbw/best_practices_for_semantic_search_on_200k/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acxxbw</id><link href="https://www.reddit.com/r/LangChain/comments/1acxxbw/best_practices_for_semantic_search_on_200k/" /><updated>2024-01-28T08:19:24+00:00</updated><published>2024-01-28T08:19:24+00:00</published><title>Best Practices for Semantic Search on 200k vectors (30GB) Worth of Embeddings?</title></entry><entry><author><name>/u/worldender999</name><uri>https://www.reddit.com/user/worldender999</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building an app using LangChain to integrate with ChatGPT. I need a vector DB to store the embeddings. I want to use an on-prem option, not a cloud one. There are quite a few options I see from my searches. Wondering what folks would recommend. Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/worldender999&quot;&gt; /u/worldender999 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad52as/what_is_the_best_onprem_vector_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad52as/what_is_the_best_onprem_vector_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad52as</id><link href="https://www.reddit.com/r/LangChain/comments/1ad52as/what_is_the_best_onprem_vector_db/" /><updated>2024-01-28T15:27:08+00:00</updated><published>2024-01-28T15:27:08+00:00</published><title>What is the best on-prem vector db</title></entry><entry><author><name>/u/rkubc</name><uri>https://www.reddit.com/user/rkubc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on extracting information from PDFs containing tables using OpenAI, LangChain, and FAISS. My focus is on extracting value especially regarding specific keywords present in these documents. I&amp;#39;m looking for advice on optimal chunking strategies for these PDFs to ensure comprehensive information extraction without losing key details. Any insights or best practices would be greatly appreciated!&lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rkubc&quot;&gt; /u/rkubc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acudx2/efficient_chunking_strategies_for_pdf_information/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acudx2/efficient_chunking_strategies_for_pdf_information/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acudx2</id><link href="https://www.reddit.com/r/LangChain/comments/1acudx2/efficient_chunking_strategies_for_pdf_information/" /><updated>2024-01-28T04:40:05+00:00</updated><published>2024-01-28T04:40:05+00:00</published><title>Efficient Chunking Strategies for PDF Information Extraction with AI Tools</title></entry><entry><author><name>/u/Fr4nkWh1te</name><uri>https://www.reddit.com/user/Fr4nkWh1te</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am creating a chatbot over the data of my &lt;strong&gt;static React website&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;I fetch the page files from the file system using the &lt;a href=&quot;https://js.langchain.com/docs/modules/data_connection/document_loaders/file_directory&quot;&gt;DirectoryLoader&lt;/a&gt;. I could use a web loader but I want it to work even in local development.&lt;/p&gt; &lt;p&gt;The issue is the text splitter.&lt;/p&gt; &lt;p&gt;I couldn&amp;#39;t find a proper text splitter for JSX (React) code. But I seem to get decent results with the &lt;a href=&quot;https://js.langchain.com/docs/modules/data_connection/document_transformers/code_splitter#html&quot;&gt;HTML recursive text splitter&lt;/a&gt;, probably because JSX and HTML are so similar.&lt;/p&gt; &lt;p&gt;Before I send my documents to the HTML splitter, I &lt;strong&gt;remove all import statements and class names&lt;/strong&gt; (to get rid of the unnecessary clutter). I keep everything else (which might include some JavaScript code).&lt;/p&gt; &lt;p&gt;Is my approach fine? Is the HTML splitter suited for this use case? Is it normal that there is no text overlap in the generated documents?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fr4nkWh1te&quot;&gt; /u/Fr4nkWh1te &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad4eye/use_html_splitter_for_jsx_react_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad4eye/use_html_splitter_for_jsx_react_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad4eye</id><link href="https://www.reddit.com/r/LangChain/comments/1ad4eye/use_html_splitter_for_jsx_react_code/" /><updated>2024-01-28T14:57:12+00:00</updated><published>2024-01-28T14:57:12+00:00</published><title>Use HTML splitter for JSX (React) code?</title></entry><entry><author><name>/u/Spare_Cancel3205</name><uri>https://www.reddit.com/user/Spare_Cancel3205</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to store Langchain Documents in the qdrant database(docker). When I try storing them in the db. I am getting this error. Please help me solve this.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;UnexpectedResponse: Unexpected Response: 400 (Bad Request)&lt;/p&gt; &lt;p&gt;Raw response content:&lt;/p&gt; &lt;p&gt;b&amp;#39;{&amp;quot;status&amp;quot;:{&amp;quot;error&amp;quot;:&amp;quot;Payload error: JSON payload (46866880 bytes) is larger than allowed (limit: 33554432 bytes).&amp;quot;},&amp;quot;time&amp;quot;:0.0}&amp;#39;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Spare_Cancel3205&quot;&gt; /u/Spare_Cancel3205 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad0vvg/qdrant_db_payload_limit_exceeded_error/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ad0vvg/qdrant_db_payload_limit_exceeded_error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ad0vvg</id><link href="https://www.reddit.com/r/LangChain/comments/1ad0vvg/qdrant_db_payload_limit_exceeded_error/" /><updated>2024-01-28T11:42:25+00:00</updated><published>2024-01-28T11:42:25+00:00</published><title>Qdrant DB: Payload Limit Exceeded Error</title></entry><entry><author><name>/u/Traditional-Fish-517</name><uri>https://www.reddit.com/user/Traditional-Fish-517</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Nice blog article about how to build an AI therapist with LangChain: &lt;a href=&quot;https://blog.langchain.dev/mental-health-therapy-as-an-llm-state-machine/&quot;&gt;https://blog.langchain.dev/mental-health-therapy-as-an-llm-state-machine/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Traditional-Fish-517&quot;&gt; /u/Traditional-Fish-517 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acou6m/langchain_blog_on_ai_mental_health_therapy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acou6m/langchain_blog_on_ai_mental_health_therapy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acou6m</id><link href="https://www.reddit.com/r/LangChain/comments/1acou6m/langchain_blog_on_ai_mental_health_therapy/" /><updated>2024-01-27T23:57:31+00:00</updated><published>2024-01-27T23:57:31+00:00</published><title>LangChain Blog on AI mental health therapy</title></entry><entry><author><name>/u/aniketmaurya</name><uri>https://www.reddit.com/user/aniketmaurya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to rerank my retrieved documents but couldn&amp;#39;t find an example on Langchain. Ant pointers would help. (not looking for context compression)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/aniketmaurya&quot;&gt; /u/aniketmaurya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acywew/is_there_a_reranking_example_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acywew/is_there_a_reranking_example_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acywew</id><link href="https://www.reddit.com/r/LangChain/comments/1acywew/is_there_a_reranking_example_with_langchain/" /><updated>2024-01-28T09:27:00+00:00</updated><published>2024-01-28T09:27:00+00:00</published><title>Is there a reranking example with Langchain?</title></entry><entry><author><name>/u/dima11235813</name><uri>https://www.reddit.com/user/dima11235813</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I use webpilot and vox script all the time and wondering if there are examples of achieving this with LangChain.&lt;/p&gt; &lt;p&gt;I especially like both because I can provide a url and get all that info in context, which seems like even ChatGPT 4 with Bing can&amp;#39;t be relied on to do it consistently.&lt;/p&gt; &lt;p&gt;I have some examples in this article I generated.&lt;br/&gt; &lt;a href=&quot;https://www.learninternetgrow.com/real-time-search-with-llms/&quot;&gt;https://www.learninternetgrow.com/real-time-search-with-llms/&lt;/a&gt; &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dima11235813&quot;&gt; /u/dima11235813 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1achbg7/has_anyone_found_an_example_of_coupling_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1achbg7/has_anyone_found_an_example_of_coupling_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1achbg7</id><link href="https://www.reddit.com/r/LangChain/comments/1achbg7/has_anyone_found_an_example_of_coupling_langchain/" /><updated>2024-01-27T18:25:11+00:00</updated><published>2024-01-27T18:25:11+00:00</published><title>Has anyone found an example of coupling LangChain with external URL requests?</title></entry><entry><author><name>/u/cambridgecoder415</name><uri>https://www.reddit.com/user/cambridgecoder415</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;from langchain.chains import RetrievalQA from langchain.chat_models import ChatOpenAI from langchain.document_loaders import CSVLoader from langchain.vectorstores import DocArrayInMemorySearch from IPython.display import display, Markdown from langchain.llms import OpenAI file = &amp;#39;OutdoorClothingCatalog_1000.csv&amp;#39; loader = CSVLoader(file_path=file) print(loader) from langchain.indexes import VectorstoreIndexCreator index = VectorstoreIndexCreator( vectorstore_cls=DocArrayInMemorySearch ).from_loaders([loader]) query =&amp;quot;Please list all your shirts with sun protection \ in a table in markdown and summarize each one.&amp;quot; from langchain_openai import ChatOpenAI model_name = &amp;#39;gpt-3.5-turbo-instruct&amp;#39; llm_replacement_model = ChatOpenAI(temperature=0.0, model=model_name, openai_api_key=openai.api_key) response = index.query(query, llm=llm_replacement_model &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;--------------------------------------------------------------------------- ValidationError Traceback (most recent call last) Cell In[22], line 5 3 model_name = &amp;#39;gpt-3.5-turbo-instruct&amp;#39; 4 llm_replacement_model = ChatOpenAI(temperature=0.0, model=model_name, openai_api_key=openai.api_key) ----&amp;gt; 5 response = index.query(query, llm=llm_replacement_model) File ~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/langchain/indexes/vectorstore.py:46, in VectorStoreIndexWrapper.query(self, question, llm, retriever_kwargs, **kwargs) 42 retriever_kwargs = retriever_kwargs or {} 43 chain = RetrievalQA.from_chain_type( 44 llm, retriever=self.vectorstore.as_retriever(**retriever_kwargs), **kwargs 45 ) ---&amp;gt; 46 return chain.run(question) File ~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:145, in deprecated.&amp;lt;locals&amp;gt;.deprecate.&amp;lt;locals&amp;gt;.warning_emitting_wrapper(*args, **kwargs) 143 warned = True 144 emit_warning() --&amp;gt; 145 return wrapped(*args, **kwargs) File ~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/langchain/chains/base.py:538, in Chain.run(self, callbacks, tags, metadata, *args, **kwargs) 536 if len(args) != 1: 537 raise ValueError(&amp;quot;`run` supports only one positional argument.&amp;quot;) --&amp;gt; 538 return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[ 539 _output_key 540 ] ... Field required [type=missing, input_value={&amp;#39;embedding&amp;#39;: [0.00682570..., -0.02392816262769903]}, input_type=dict] For further information visit https://errors.pydantic.dev/2.5/v/missing metadata Field required [type=missing, input_value={&amp;#39;embedding&amp;#39;: [0.00682570..., -0.02392816262769903]}, input_type=dict] For further information visit https://errors.pydantic.dev/2.5/v/missing &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Help, this is from a course I&amp;#39;m taking on Deep learning&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cambridgecoder415&quot;&gt; /u/cambridgecoder415 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aceuxq/query_csv_code_not_working_help/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aceuxq/query_csv_code_not_working_help/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aceuxq</id><link href="https://www.reddit.com/r/LangChain/comments/1aceuxq/query_csv_code_not_working_help/" /><updated>2024-01-27T16:38:41+00:00</updated><published>2024-01-27T16:38:41+00:00</published><title>Query CSV code not working help!</title></entry><entry><author><name>/u/Dealwap1337</name><uri>https://www.reddit.com/user/Dealwap1337</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How can I ensure that the order of extracted documents in Langchain is maintained? I have a RAG app that allows users to query documents, but I&amp;#39;ve noticed that some numbered data is extracted in the wrong order. &lt;/p&gt; &lt;p&gt;For example, the documents may contain numbered items from 1 to 50, but when the final result is returned, the 2nd item may appear last and the 50th item may appear first. I need to maintain the same order as it appears in the original document.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Dealwap1337&quot;&gt; /u/Dealwap1337 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ac80ys/how_to_maintain_extracted_document_order/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ac80ys/how_to_maintain_extracted_document_order/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ac80ys</id><link href="https://www.reddit.com/r/LangChain/comments/1ac80ys/how_to_maintain_extracted_document_order/" /><updated>2024-01-27T10:31:31+00:00</updated><published>2024-01-27T10:31:31+00:00</published><title>How to Maintain extracted Document Order</title></entry><entry><author><name>/u/Ill_Bodybuilder3499</name><uri>https://www.reddit.com/user/Ill_Bodybuilder3499</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;JinaAi just released an Embeddingmodel with a context size of 8k. I was wondering what are the advantages of Long Context Embedding models for a Rag Use Case?&lt;/p&gt; &lt;p&gt;Happy for discussion!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ill_Bodybuilder3499&quot;&gt; /u/Ill_Bodybuilder3499 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ac7t19/what_ist_the_advantage_of_long_context_embedding/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ac7t19/what_ist_the_advantage_of_long_context_embedding/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ac7t19</id><link href="https://www.reddit.com/r/LangChain/comments/1ac7t19/what_ist_the_advantage_of_long_context_embedding/" /><updated>2024-01-27T10:16:10+00:00</updated><published>2024-01-27T10:16:10+00:00</published><title>What ist the advantage of Long Context Embedding Models for Rag</title></entry><entry><author><name>/u/Datenschieber</name><uri>https://www.reddit.com/user/Datenschieber</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am a noob experimenting with LLMs and i am looking for a reliable method for merging / combining two texts into one credible sounding merged text. Does that take a langchain based RAG or am i simply too stupid to engineer the right prompt in a mixtral or something similar? :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Datenschieber&quot;&gt; /u/Datenschieber &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acbcqn/how_do_i_merge_combine_two_texts_into_one/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1acbcqn/how_do_i_merge_combine_two_texts_into_one/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1acbcqn</id><link href="https://www.reddit.com/r/LangChain/comments/1acbcqn/how_do_i_merge_combine_two_texts_into_one/" /><updated>2024-01-27T13:55:58+00:00</updated><published>2024-01-27T13:55:58+00:00</published><title>How do i merge / combine two texts into one?</title></entry><entry><author><name>/u/Slow-Associate-127</name><uri>https://www.reddit.com/user/Slow-Associate-127</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone.... Recently I have got a project where I need to retrieve some financial documents using RAG....The process is 1. The query will be around 20 to 30 page long pdf document. 2. The document contains some information requirements...Those requirements will be stored in my db....based on the requirements of the pdf I need to fetch the existing documents from the db....&lt;/p&gt; &lt;p&gt;Can anyone please help me out with this.... Thanks in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Slow-Associate-127&quot;&gt; /u/Slow-Associate-127 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ac32g9/document_retrieval_using_llms_from_long_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ac32g9/document_retrieval_using_llms_from_long_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ac32g9</id><link href="https://www.reddit.com/r/LangChain/comments/1ac32g9/document_retrieval_using_llms_from_long_documents/" /><updated>2024-01-27T05:06:53+00:00</updated><published>2024-01-27T05:06:53+00:00</published><title>Document retrieval using llm's from long documents</title></entry><entry><author><name>/u/jubjub07</name><uri>https://www.reddit.com/user/jubjub07</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;As the title says, I&amp;#39;m working to enable an app I wrote that generates SQL to allow it to work from a locally served LLM instead of one in the cloud. This is a requirement for a couple of customers, so I&amp;#39;ve been experimenting...&lt;/p&gt; &lt;p&gt;I&amp;#39;m using the create_sql_agent function... I&amp;#39;m supplying the prompts as well as some custom tools that feed in appropriate metadata about the database. Against OpenAI or AzureOpenAI it works fine.&lt;/p&gt; &lt;p&gt;When I run against Ollama, I&amp;#39;ve tried a bunch of models - SQLcoder, LLama70b, Mixtral8x7b, etc. And I get the same result... I can watch the agent work away (via my own debugging as well as LangSmith).. &lt;/p&gt; &lt;p&gt;The agent runs typically follow the same general path as the OpenAI runs, with one exception - I can see the final SQL statement generated, but after executing the statement and getting a perfectly fine answer (and identifying it as such) it goes into a kind of loop and never exits the chain. &lt;/p&gt; &lt;p&gt;I&amp;#39;ve toyed with supplying &amp;quot;stop=&amp;quot; tokens etc, but I just don&amp;#39;t see what&amp;#39;s going on.&lt;/p&gt; &lt;p&gt;There&amp;#39;s so many moving pieces that I thought someone might have an idea where to look... &lt;/p&gt; &lt;p&gt;It&amp;#39;s possible that it&amp;#39;s a prompt format issue - I know the prompt format between the Llama models and OpenAI models are pretty different... with special tokens, etc. but I&amp;#39;m utterly unclear how that would change things, since up to the point it should &amp;quot;exit&amp;quot; and return the final answer it works pretty well.&lt;/p&gt; &lt;p&gt;I&amp;#39;ll add that I created a custom &amp;quot;handler&amp;quot; to extract the final sql statement it creates, since the sql agent returns the &amp;quot;answer&amp;quot; rather than the SQL statement. My handler is looking for invocation of the sql_db_query tool which indicates that the sql has been generated and is being sent off for execution - I grab the string at that point and save it for later... that works in openai, but not in any of the other models I&amp;#39;ve tried.&lt;/p&gt; &lt;p&gt;I do get some different results with different models...&lt;/p&gt; &lt;p&gt;Most have given the above general issue - generating a good answer, but then never stopping.&lt;/p&gt; &lt;p&gt;mixtral:8x7b-instruct-v0.1-q5_K_M - was weird. It didn&amp;#39;t seem to want to use the tools I provided and sort of skipped some steps. It generated SQL that had no relation to the actual database - so it wasn&amp;#39;t using any of the tools - then when it came time to run the SQL it DID generate, it messed up that name of the sql_db_query tool:&lt;/p&gt; &lt;p&gt;&amp;quot;{&amp;#39;requested_tool_name&amp;#39;: &amp;#39;sql\\_db\\_query&amp;#39;, &amp;#39;available_tool_names&amp;#39;: [&amp;#39;sql_db_query&amp;#39;, &amp;#39;sql_db_schema&amp;#39;, &amp;#39;sql_db_list_tables&amp;#39;, &amp;#39;sql_db_query_checker&amp;#39;, &amp;#39;sql_get_few_shot_examples&amp;#39;, &amp;#39;sql_get_column_descriptions&amp;#39;, &amp;#39;get_column_to_table_cross_reference&amp;#39;, &amp;#39;get_hierarchies&amp;#39;, &amp;#39;sql_get_table_descriptions&amp;#39;]}&amp;quot;&lt;/p&gt; &lt;p&gt;No other model did this... &lt;/p&gt; &lt;p&gt;SO, I&amp;#39;m wondering if anyone else has had the same struggle, or can point me in some direction to figure this out... it feels like I&amp;#39;m so very close, just missing one key ingredient!&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jubjub07&quot;&gt; /u/jubjub07 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abwoh6/so_close_switching_from_openai_models_to_local/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abwoh6/so_close_switching_from_openai_models_to_local/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1abwoh6</id><link href="https://www.reddit.com/r/LangChain/comments/1abwoh6/so_close_switching_from_openai_models_to_local/" /><updated>2024-01-26T23:46:28+00:00</updated><published>2024-01-26T23:46:28+00:00</published><title>So close... Switching from Openai models to local models served by Ollama</title></entry><entry><author><name>/u/rkubc</name><uri>https://www.reddit.com/user/rkubc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on a project using Langchain involving information extraction from PDF documents, each ranging from 5-10 pages. My primary goal is to extract information based on approximately 26 keywords, which I load from a CSV file.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s an overview of my current setup:&lt;/p&gt; &lt;p&gt;Basic Language Chain Components: I&amp;#39;m using a loader, a recursive splitter set to 500 with an overlap of 300, and an Ensemble Retriever BM25)and MultiQuery Retriever setup with FAISS, where each component has a .5 weight for each.&lt;/p&gt; &lt;p&gt;FAISS Library Usage: In the FAISS library, I&amp;#39;m employing the from_documents method and a retriever.&lt;/p&gt; &lt;p&gt;OpenAI Integration: After combining the top 2 chunks for each keyword, I&amp;#39;m feeding the data into OpenAI with prompt.&lt;/p&gt; &lt;p&gt;However, I&amp;#39;m encountering an issue where the results are about 8-10% hallucinated or inaccurate.&lt;/p&gt; &lt;p&gt;I&amp;#39;m looking for advice on how to improve the accuracy of my information extraction process. Are there any specific parameters or techniques in better chunking, FAISS or with OpenAI that I should consider consider or tweaking? Any insights or suggestions would be greatly appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rkubc&quot;&gt; /u/rkubc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abvyps/overcoming_810_inaccuracy_in_pdf_keyword/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abvyps/overcoming_810_inaccuracy_in_pdf_keyword/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1abvyps</id><link href="https://www.reddit.com/r/LangChain/comments/1abvyps/overcoming_810_inaccuracy_in_pdf_keyword/" /><updated>2024-01-26T23:14:36+00:00</updated><published>2024-01-26T23:14:36+00:00</published><title>Overcoming 8-10% Inaccuracy in PDF Keyword Extraction Using Faiss and OpenAI – Need Advice</title></entry><entry><author><name>/u/gollum1632</name><uri>https://www.reddit.com/user/gollum1632</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, I am just starting with RAG.&lt;/p&gt; &lt;p&gt;I want to retrieve building regulations ( max height, area, etc) information from pdfs using a llm. &lt;/p&gt; &lt;p&gt;the pdfs contains both text and data. I am currently using PypdfLoader from langchain to load the pdfs. Splitting using recursive character split, embedding using open ai and storing it in chroma db.&lt;/p&gt; &lt;p&gt;Sometimes the llm doesn’t retrive the information correctly. don’t know if it is because of the parsing of pdfs. &lt;/p&gt; &lt;p&gt;Any help in improving the system is greatly appreciated. Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gollum1632&quot;&gt; /u/gollum1632 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abuv1f/need_help_improving_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abuv1f/need_help_improving_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1abuv1f</id><link href="https://www.reddit.com/r/LangChain/comments/1abuv1f/need_help_improving_rag/" /><updated>2024-01-26T22:27:26+00:00</updated><published>2024-01-26T22:27:26+00:00</published><title>Need help improving RAG</title></entry><entry><author><name>/u/redd-dev</name><uri>https://www.reddit.com/user/redd-dev</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am currently using Mixtral 8x7B Instruct v0.1 - GPTQ and was wondering what is currently the best open source LLM to use to output SQL code?&lt;/p&gt; &lt;p&gt;Would really appreciate any input on this. Many thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/redd-dev&quot;&gt; /u/redd-dev &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abiozm/what_is_the_best_open_source_llm_for_outputting/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abiozm/what_is_the_best_open_source_llm_for_outputting/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1abiozm</id><link href="https://www.reddit.com/r/LangChain/comments/1abiozm/what_is_the_best_open_source_llm_for_outputting/" /><updated>2024-01-26T13:45:42+00:00</updated><published>2024-01-26T13:45:42+00:00</published><title>What is the best open source LLM for outputting SQL code</title></entry><entry><author><name>/u/Electronic-Letter592</name><uri>https://www.reddit.com/user/Electronic-Letter592</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I recently heard about promptflow, a tool to create end to end LLM processes. Is it more a competitor to langchain, can I combine both, or what is the difference to langchain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Electronic-Letter592&quot;&gt; /u/Electronic-Letter592 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abpzp2/can_i_combine_langchain_with_prompflow/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abpzp2/can_i_combine_langchain_with_prompflow/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1abpzp2</id><link href="https://www.reddit.com/r/LangChain/comments/1abpzp2/can_i_combine_langchain_with_prompflow/" /><updated>2024-01-26T19:01:15+00:00</updated><published>2024-01-26T19:01:15+00:00</published><title>Can I combine LangChain with PrompFlow?</title></entry><entry><author><name>/u/Euloghtos</name><uri>https://www.reddit.com/user/Euloghtos</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello , lets say that we prompt the user to add documents , which the app chunks , embeds and adds to a vector database. &lt;/p&gt; &lt;p&gt;How can we avoid inserting the same document twice? Is there any way it can be done with langchain?&lt;/p&gt; &lt;p&gt;I really cant find a way around.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Euloghtos&quot;&gt; /u/Euloghtos &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abkaif/avoid_duplicates_inside_a_chroma_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1abkaif/avoid_duplicates_inside_a_chroma_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1abkaif</id><link href="https://www.reddit.com/r/LangChain/comments/1abkaif/avoid_duplicates_inside_a_chroma_db/" /><updated>2024-01-26T15:00:54+00:00</updated><published>2024-01-26T15:00:54+00:00</published><title>Avoid duplicates inside a chroma db</title></entry></feed>