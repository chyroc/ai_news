<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-10T10:56:17+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Sensitive-Pen-1229</name><uri>https://www.reddit.com/user/Sensitive-Pen-1229</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hey guys&lt;/p&gt; &lt;p&gt;I use correctness, hallucination &amp;amp; relevance score to evaluate a RAG chain on langsmith. &lt;/p&gt; &lt;p&gt;Generally, do you think 3.5 is good enough to evaluate the outcomes?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sensitive-Pen-1229&quot;&gt; /u/Sensitive-Pen-1229 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1coj65b/evaluation_models_gpt35_vs_gpt_4_turbo/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1coj65b/evaluation_models_gpt35_vs_gpt_4_turbo/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1coj65b</id><link href="https://www.reddit.com/r/LangChain/comments/1coj65b/evaluation_models_gpt35_vs_gpt_4_turbo/" /><updated>2024-05-10T06:47:09+00:00</updated><published>2024-05-10T06:47:09+00:00</published><title>Evaluation Models - GPT-3.5 vs. GPT 4 Turbo</title></entry><entry><author><name>/u/mahadevbhakti</name><uri>https://www.reddit.com/user/mahadevbhakti</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Tell me if this idea is feasible and how I can pull this off&lt;/p&gt; &lt;p&gt;I have a langchain agent that does function calling, but one shortcoming is that it fails to answer queries from the pulled data many times, &lt;/p&gt; &lt;p&gt;Can I store this pulled data into a knowledge graph vector database as this data is for holiday packages with key value relations such as duration, price, location, ref_id etc and sub categories like fare sets, cabin sub categories etc. &lt;/p&gt; &lt;p&gt;How can I make my langchain agent in python better using knowledge graphs and making it answer follow up questions using RAG on the last fetched data?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mahadevbhakti&quot;&gt; /u/mahadevbhakti &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cokru8/function_calling_rag_langchain_tool_calling_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cokru8/function_calling_rag_langchain_tool_calling_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cokru8</id><link href="https://www.reddit.com/r/LangChain/comments/1cokru8/function_calling_rag_langchain_tool_calling_agent/" /><updated>2024-05-10T08:41:18+00:00</updated><published>2024-05-10T08:41:18+00:00</published><title>Function Calling + RAG + Langchain Tool Calling Agent + REDIS Memory</title></entry><entry><author><name>/u/kedu16</name><uri>https://www.reddit.com/user/kedu16</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, in the previous version of code, I had something like this:&lt;/p&gt; &lt;p&gt;qa = RetrievalQA.from_chain_type(&lt;br/&gt; llm=llm,&lt;br/&gt; chain_type_kwargs={&amp;quot;prompt&amp;quot;: prompt},&lt;br/&gt; retriever=retriever,&lt;br/&gt; return_source_documents=True, &lt;br/&gt; tags = tags,&lt;br/&gt; metadata = metadata &lt;br/&gt; )&lt;br/&gt; basically its a Multivector retriever with RetrievalQA. In LCEL chain it is like below:&lt;/p&gt; &lt;p&gt;chain = (&lt;br/&gt; {&amp;quot;context&amp;quot;: retriever, &amp;quot;question&amp;quot;: RunnablePassthrough()}&lt;br/&gt; | prompt&lt;br/&gt; | model&lt;br/&gt; | StrOutputParser()&lt;br/&gt; )&lt;br/&gt; The question I have is, how to add additional parameters in the above LCEL chain?&lt;br/&gt; additional parameters:&lt;br/&gt; return_source_documents=True, &lt;br/&gt; tags = tags,&lt;br/&gt; metadata = metadata &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kedu16&quot;&gt; /u/kedu16 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1colp4k/just_a_question_on_lcel_vs_retrievalqa/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1colp4k/just_a_question_on_lcel_vs_retrievalqa/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1colp4k</id><link href="https://www.reddit.com/r/LangChain/comments/1colp4k/just_a_question_on_lcel_vs_retrievalqa/" /><updated>2024-05-10T09:48:22+00:00</updated><published>2024-05-10T09:48:22+00:00</published><title>Just a question on LCEL vs RetrievalQA</title></entry><entry><author><name>/u/Far_Possibility_6278</name><uri>https://www.reddit.com/user/Far_Possibility_6278</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone tried phi3 for text2sql in postgres? I am trying and can&amp;#39;t generate a correct query&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Far_Possibility_6278&quot;&gt; /u/Far_Possibility_6278 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1colhlx/phi3_text2sql/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1colhlx/phi3_text2sql/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1colhlx</id><link href="https://www.reddit.com/r/LangChain/comments/1colhlx/phi3_text2sql/" /><updated>2024-05-10T09:33:12+00:00</updated><published>2024-05-10T09:33:12+00:00</published><title>Phi3 text2sql</title></entry><entry><author><name>/u/Informal-Victory8655</name><uri>https://www.reddit.com/user/Informal-Victory8655</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, guys. I&amp;#39;ve made a langchain chatbot agent and I want to deploy it as a simple flask app.&lt;br/&gt; I&amp;#39;m not sure, how the unique conversation sessions would be managed like a single endpoint would be used to invoke the agent but how the flask would ensure that this request belong to a specific user interacting with chatbot and we know there could be multiple users interacting with chatbot at same time. &lt;/p&gt; &lt;p&gt;So I wanna learn how to manage these kind of sessions and using credentials is not an option.&lt;/p&gt; &lt;p&gt;one more thing, how the agent memory would be specified per user session in deployment?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Informal-Victory8655&quot;&gt; /u/Informal-Victory8655 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cokd2v/how_to_deploy_langchain_chatbot_agent_using_flask/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cokd2v/how_to_deploy_langchain_chatbot_agent_using_flask/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cokd2v</id><link href="https://www.reddit.com/r/LangChain/comments/1cokd2v/how_to_deploy_langchain_chatbot_agent_using_flask/" /><updated>2024-05-10T08:11:40+00:00</updated><published>2024-05-10T08:11:40+00:00</published><title>How to deploy langchain chatbot (agent) using flask api and identify and manage unique user conversation sessions?</title></entry><entry><author><name>/u/Just_Guide7361</name><uri>https://www.reddit.com/user/Just_Guide7361</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey,&lt;/p&gt; &lt;p&gt;Like many others I am working on a RAG Q&amp;amp;A Chatbot. I have many pdfs related to a certain topic. My goal is to help the end-user answer questions based on the information in the pdfs. From the perspective of GIGO I am first evaluation how well I can retrieve information related to certain questions. However, I am not certain about my approach.&lt;/p&gt; &lt;p&gt;I am using precision at k, recall at k and ndcg at k as my evaluation metrics; next I simply create various pipelines starting from the raw pdfs, to embedding to retrieval. Here I vary the following element in the pipeline:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Chunking:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;CharacterTextSplitter vs RecursiveTextSplitter&lt;/li&gt; &lt;li&gt;Chuck size (400, 800, 1200)&lt;/li&gt; &lt;li&gt;Chuck overlap (200, 400, 600)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Embedding:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Model (ie. OpenAI vs Cohore)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Retrieval:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Search method: mmr vs similarity&lt;/li&gt; &lt;li&gt;Number of Documents to return [k] (4, 7)&lt;/li&gt; &lt;li&gt;Number of Documents to fetch to pass to MMR algorithm [fetch-k] (20, 40)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Retrieval is tested as follows; at the chunking stage I sample ~10% of the chucks and pass that to an LLM to generate questions. These are then used to test how well the pipeline can retrieve the chucks related to the questions.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Now my problems:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;I consider a single pdf, one document. This document is then chucked, but the document ID is the same for each chuck. Meaning that if a question related to chuck A returns chuck Z; this would be counted as correct. While this would obviously not be correct; I&amp;#39;ve considered changing the relation from a single page in a pdf being considered one document as this is likely more accurate.&lt;/li&gt; &lt;li&gt;The evaluation questions generated vary with the chuck size and method; as the given input to the LLM will be different. So while testing the pipeline, this is strongly affected by the quality of questions the LLM came up with.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Are there people here with experience in testing, or does anyone know any good resources?&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Just_Guide7361&quot;&gt; /u/Just_Guide7361 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1co5cl1/rag_retrieval_evaluation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1co5cl1/rag_retrieval_evaluation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1co5cl1</id><link href="https://www.reddit.com/r/LangChain/comments/1co5cl1/rag_retrieval_evaluation/" /><updated>2024-05-09T19:14:56+00:00</updated><published>2024-05-09T19:14:56+00:00</published><title>RAG Retrieval Evaluation</title></entry><entry><author><name>/u/natheeshkumar</name><uri>https://www.reddit.com/user/natheeshkumar</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This my code&lt;/p&gt; &lt;pre&gt;&lt;code&gt;conversational_rag_chain = RunnableWithMessageHistory( rag_chain, get_session_history, input_messages_key=&amp;quot;input&amp;quot;, history_messages_key=&amp;quot;chat_history&amp;quot;, output_messages_key=&amp;quot;answer&amp;quot;, ) conversational_rag_chain.invoke( {&amp;quot;input&amp;quot;: &amp;quot;I am interested in Screwdrivers, Sockets, Ratchets. Now generate new questions based on past behaviour&amp;quot;}, config={ &amp;quot;configurable&amp;quot;: {&amp;quot;session_id&amp;quot;: &amp;quot;abc123&amp;quot;} }, # constructs a key &amp;quot;abc123&amp;quot; in `store`. )[&amp;quot;answer&amp;quot;] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I want to add this `JsonOutputParser` to above `conversational_rag_chain`&lt;/p&gt; &lt;pre&gt;&lt;code&gt;class ProbingQuestion(BaseModel): Question: str = Field(description=&amp;quot;probing question&amp;quot;) Options: List[str] = Field(description=&amp;quot;list of options for the probing question&amp;quot;) output_parser = JsonOutputParser(pydantic_object=ProbingQuestion) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;So can anyone help this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/natheeshkumar&quot;&gt; /u/natheeshkumar &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cofbkc/how_to_add_jsonoutputparser_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cofbkc/how_to_add_jsonoutputparser_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cofbkc</id><link href="https://www.reddit.com/r/LangChain/comments/1cofbkc/how_to_add_jsonoutputparser_with/" /><updated>2024-05-10T02:52:33+00:00</updated><published>2024-05-10T02:52:33+00:00</published><title>How to add JsonOutputParser with RunnableWithMessageHistory?</title></entry><entry><author><name>/u/easy_breeze5634</name><uri>https://www.reddit.com/user/easy_breeze5634</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a Neo4j graph that&amp;#39;s populated with common category nodes, and sub-nodes. These all have labels and names, other than that there is no data stored inside the properties. I want to find a way to identify related headers for that particular category node, for example &amp;quot;economic&amp;quot;, if a column in one of the CSV files is related to economics then it should be either be added as a new node to that category node or the data inside that cell from the csv be added as a property to an existing node. I&amp;#39;m wondering what everyone also thinks is the best way to set all this up as I am trying to make this Graph as efficient as possible because the plan is to add an LLM on top of it with a chatbot to query to graph for context and return answers. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/easy_breeze5634&quot;&gt; /u/easy_breeze5634 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1code3k/iterating_hundreds_of_csv_file_headers_trying_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1code3k/iterating_hundreds_of_csv_file_headers_trying_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1code3k</id><link href="https://www.reddit.com/r/LangChain/comments/1code3k/iterating_hundreds_of_csv_file_headers_trying_to/" /><updated>2024-05-10T01:11:26+00:00</updated><published>2024-05-10T01:11:26+00:00</published><title>Iterating hundreds of csv file headers, trying to find the best way to identify related headers using NLP or other technique to add data from columns as properties in Graph nodes.</title></entry><entry><author><name>/u/SensitiveStudy520</name><uri>https://www.reddit.com/user/SensitiveStudy520</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cod9zr/langchain_sql_mistral/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/8ABZDWd9r3Ixo9grEHVIAHOHyBW0tLcEXujBylBi4Js.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d969b12e1cfdb941b967d24fef27d9ea4d81da9d&quot; alt=&quot;LangChain SQL &amp;amp; Mistral&quot; title=&quot;LangChain SQL &amp;amp; Mistral&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys,&lt;/p&gt; &lt;p&gt;Recently I am experimenting on using mistral 7b instruct-v0.1 with sql database, and I have try 3 approach, but all of these give me several errors and issues, and I really cannot fix it.&lt;br/&gt; Approach 1 (source=&lt;a href=&quot;https://medium.com/@shivansh.kaushik/talk-to-your-database-using-rag-and-llms-42eb852d2a3c&quot;&gt;Tal to your database using RAG and LLM&lt;/a&gt;)&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/hr1yz5w30izc1.png?width=767&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2de4ee09e1b184434f3c6baf0a7040000987dbed&quot;&gt;https://preview.redd.it/hr1yz5w30izc1.png?width=767&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2de4ee09e1b184434f3c6baf0a7040000987dbed&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/uyas7shgjdzc1.png?width=953&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=61b093e5253e193c1f02d69ba6890566a25858a9&quot;&gt;https://preview.redd.it/uyas7shgjdzc1.png?width=953&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=61b093e5253e193c1f02d69ba6890566a25858a9&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This give me the error as above, but i thought the question is already a string? And it&amp;#39;s so weird to give me 2 SQL Result and answer. &lt;/p&gt; &lt;p&gt;Approach 2 (source is from a youtube)&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/n4vj9z2e0izc1.png?width=930&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3d9ea5d0b76e5ba224f1a55e2abb7b5f130de8d0&quot;&gt;https://preview.redd.it/n4vj9z2e0izc1.png?width=930&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3d9ea5d0b76e5ba224f1a55e2abb7b5f130de8d0&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Approach 3&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/wdc8l03j0izc1.png?width=750&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0dcff653e8367b20ad6b4dcba5742bd4d7585bb9&quot;&gt;https://preview.redd.it/wdc8l03j0izc1.png?width=750&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0dcff653e8367b20ad6b4dcba5742bd4d7585bb9&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This same as approach 1, it gives me 2 different result and answer.&lt;br/&gt; How if i want just only the final answer? How can I get it? print(result[Answer])? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SensitiveStudy520&quot;&gt; /u/SensitiveStudy520 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cod9zr/langchain_sql_mistral/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cod9zr/langchain_sql_mistral/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cod9zr</id><media:thumbnail url="https://external-preview.redd.it/8ABZDWd9r3Ixo9grEHVIAHOHyBW0tLcEXujBylBi4Js.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d969b12e1cfdb941b967d24fef27d9ea4d81da9d" /><link href="https://www.reddit.com/r/LangChain/comments/1cod9zr/langchain_sql_mistral/" /><updated>2024-05-10T01:05:30+00:00</updated><published>2024-05-10T01:05:30+00:00</published><title>LangChain SQL &amp; Mistral</title></entry><entry><author><name>/u/deixhah</name><uri>https://www.reddit.com/user/deixhah</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys, I&amp;#39;m working on a chatbot for our company and we use ChatGPT 4 as an LLM. To keep the costs per request low, I implemented a chat history with only the last 6 messages (3 from user, 3 from bot)&lt;/p&gt; &lt;p&gt;The problem now is, that sometimes people have inputs that the bot can&amp;#39;t answer well, as the messages are already gone in his memory.&lt;/p&gt; &lt;p&gt;Is there any good way to fix this? Is it possible to use vectorsearch for memory? Or does this heavily increase the latency?&lt;/p&gt; &lt;p&gt;What is the best way to go, what are you guys using?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/deixhah&quot;&gt; /u/deixhah &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1coaa4f/vectorsearch_for_chat_history/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1coaa4f/vectorsearch_for_chat_history/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1coaa4f</id><link href="https://www.reddit.com/r/LangChain/comments/1coaa4f/vectorsearch_for_chat_history/" /><updated>2024-05-09T22:43:56+00:00</updated><published>2024-05-09T22:43:56+00:00</published><title>Vectorsearch for chat history?</title></entry><entry><author><name>/u/chaitu9701</name><uri>https://www.reddit.com/user/chaitu9701</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;My org has this usecase to build a rag to answer questions. In rag works great given that I given it a lot of instructions(prompts). One demand that rag isn&amp;#39;t able to fullfill is to never mention document reference in the response.&lt;/p&gt; &lt;p&gt;Eg. 1) The document does not mention how to ... 2) you can view the steps on page 60 in the document.&lt;/p&gt; &lt;p&gt;Any prompt suggestions to overcome this particular scenario. The rag should never share the source of its response &lt;/p&gt; &lt;p&gt;My pipeline&lt;/p&gt; &lt;p&gt;1) Pdf Document Langchain &lt;/p&gt; &lt;p&gt;2) Qdrant for retriever&lt;/p&gt; &lt;p&gt;3) Chat gpt3.5 turbo 16k for llm&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/chaitu9701&quot;&gt; /u/chaitu9701 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cnxfnz/rag_response_always_includes_reference_to_document/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cnxfnz/rag_response_always_includes_reference_to_document/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cnxfnz</id><link href="https://www.reddit.com/r/LangChain/comments/1cnxfnz/rag_response_always_includes_reference_to_document/" /><updated>2024-05-09T13:34:29+00:00</updated><published>2024-05-09T13:34:29+00:00</published><title>Rag response always includes reference to document</title></entry><entry><author><name>/u/roaringsky</name><uri>https://www.reddit.com/user/roaringsky</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to improve the quality of retrieval for my RAG application. I have a knowledge base with multiple pdfs and docs, and currently I&amp;#39;m using basic recursive splitter with overlap for creating chunks. This is not the most effective way, and I&amp;#39;m thinking of using semantic or agentic chunking to improve the quality of my chunks.&lt;/p&gt; &lt;p&gt;Furthermore, I&amp;#39;m also thinking to use knowledge-graphs for this usecase. Now I understand how knowledge-graphs work but I&amp;#39;m not sure how I can use them for my usecase.&lt;/p&gt; &lt;p&gt;Firstoff, I would need to define some nodes (which could be my chunked documents itself I believe) but I&amp;#39;m unsure about how to and to what extent create relationships between those nodes. Again, this is my theory, would love to understand if nodes could be something else here.&lt;/p&gt; &lt;p&gt;IF, I decide on nodes being documents, how should I decide parameters for my relationships? Do I need to make LLM calls for this? -- this would incur more cost I as I keep adding documents to my knowledge base.&lt;/p&gt; &lt;p&gt;I&amp;#39;m thinking of extracting key entities from each document, and use those as the basis of relationship but -- for that I would need a model for extraction (which I guess, I could find some standard NLP technique that are not LLM or even SLM based).&lt;/p&gt; &lt;p&gt;Any thoughts on this would be appreciated. Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/roaringsky&quot;&gt; /u/roaringsky &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1codtrj/how_can_i_go_about_creating_knowledge_graphs_from/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1codtrj/how_can_i_go_about_creating_knowledge_graphs_from/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1codtrj</id><link href="https://www.reddit.com/r/LangChain/comments/1codtrj/how_can_i_go_about_creating_knowledge_graphs_from/" /><updated>2024-05-10T01:33:36+00:00</updated><published>2024-05-10T01:33:36+00:00</published><title>How can I go about creating knowledge graphs from chunks of a document?</title></entry><entry><author><name>/u/smthecyclops</name><uri>https://www.reddit.com/user/smthecyclops</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;Currently, I&amp;#39;m using LangChain to develop a ReAct agent to develop evidence-based arguments supporting the user&amp;#39;s input. I&amp;#39;ve successfully developed a Tool that can access data from a web source based on what the model queries. ReAct seems like a sensible pattern for this use case, but the model gets stuck in a loop, repeatedly asking the same query of the tool. I&amp;#39;ve also noticed that the conversation history is not populated.&lt;/p&gt; &lt;p&gt;Here is the code I developed. The &lt;code&gt;search_cse(query)&lt;/code&gt; function just returns the title and text of an article.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from keys import GOOGLE_GEMINI_API_KEY from google_website_scrape import search_cse import langchain from langchain_core.tools import Tool from langchain.agents import initialize_agent, AgentType from langchain_google_genai import ChatGoogleGenerativeAI from langchain.memory import ConversationBufferMemory langchain.debug = True llm = ChatGoogleGenerativeAI( model=&amp;quot;gemini-1.0-pro&amp;quot;, google_api_key=GOOGLE_GEMINI_API_KEY ) tools = [ Tool( name=&amp;quot;cbs_articles&amp;quot;, description=&amp;quot;This tool provides the content of CBS News articles that pertain to the request.&amp;quot;, func=search_cse ) ] PREFIX = &amp;quot;&amp;quot;&amp;quot;You are an agent designed to construct arguments to fulfill the user&amp;#39;s request, specified in the input. You arguments must include evidence from CBS News articles.&amp;quot;&amp;quot;&amp;quot; FORMAT_INSTRUCTIONS = &amp;quot;&amp;quot;&amp;quot;You MUST use the following format: Question, Though, Action, Action Input. This format is explained in further depth below: Question: This should be the input. Thought: You should think about arguments to fulfill the user&amp;#39;s request. Action: Should ALWAYS BE &amp;quot;cbs_articles&amp;quot;. Do NOT use any other action. Action Input: This should be a search term that will give you information pertaining to the argument you are trying to justify. Observation: You should consider how the information you found supports your argument. ... (this Thought/Action/Action Input/Observation can repeat N times) Thought: I now have multiple arguments WITH EVIDENCE to fulfill the user&amp;#39;s request. Final Answer: Here are the arguments WITH EVIDENCE to fulfill the user&amp;#39;s request.&amp;quot;&amp;quot;&amp;quot; SUFFIX = &amp;quot;&amp;quot;&amp;quot;Begin! Input: Justify the following: &amp;quot;{input}&amp;quot; Thought: {agent_scratchpad} Chat History: {chat_history}&amp;quot;&amp;quot;&amp;quot; memory = ConversationBufferMemory(memory_key=&amp;quot;chat_history&amp;quot;, return_messages=True) agent = initialize_agent( agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, tools=tools, llm=llm, agent_kwargs={ &amp;quot;prefix&amp;quot;: PREFIX, &amp;quot;format_instructions&amp;quot;: FORMAT_INSTRUCTIONS, &amp;quot;suffix&amp;quot;: SUFFIX, &amp;quot;input_variables&amp;quot;: [&amp;quot;input&amp;quot;, &amp;quot;agent_scratchpad&amp;quot;, &amp;quot;chat_history&amp;quot;] }, memory=memory, verbose=True, handle_parsing_errors=True, max_iterations=10 ) print(agent.run(&amp;quot;Electric vehicles should not be mandated nationally.&amp;quot;)) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With this code, the model repeatedly asks itself the following.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Question: Electric vehicles should not be mandated nationally. Thought: Electric vehicles are still too expensive for many people. Action: cbs_articles Action Input: Electric vehicles cost Observation: [ARTICLE TITLE &amp;amp; CONTENT] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Please advise me if I&amp;#39;m using the ReAct pattern incorrectly. Thank you for your time.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/smthecyclops&quot;&gt; /u/smthecyclops &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1co86cn/langchain_react_argumentation_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1co86cn/langchain_react_argumentation_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1co86cn</id><link href="https://www.reddit.com/r/LangChain/comments/1co86cn/langchain_react_argumentation_agent/" /><updated>2024-05-09T21:12:43+00:00</updated><published>2024-05-09T21:12:43+00:00</published><title>LangChain ReAct Argumentation Agent</title></entry><entry><author><name>/u/Jean_dta</name><uri>https://www.reddit.com/user/Jean_dta</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have an llm built with langchain, OPENAI and qdrant; in production run well but in my local my app allways return 429 error; I changed 5 times my tokens, I added 50$ more to my OPENAI account; but the issue persist.&lt;/p&gt; &lt;p&gt;Did anyone have this issue ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jean_dta&quot;&gt; /u/Jean_dta &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1co213w/langchain_allways_return_429_error_este_limit/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1co213w/langchain_allways_return_429_error_este_limit/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1co213w</id><link href="https://www.reddit.com/r/LangChain/comments/1co213w/langchain_allways_return_429_error_este_limit/" /><updated>2024-05-09T16:55:33+00:00</updated><published>2024-05-09T16:55:33+00:00</published><title>Langchain allways return 429 error; este limit</title></entry><entry><author><name>/u/powderarc</name><uri>https://www.reddit.com/user/powderarc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey y‚Äôall üôåüèº I‚Äôve been using some prompt management tools (Humanloop and Braintrust Data) for a few of my recent projects. Overall, they‚Äôre powerful tools but I‚Äôve hit a few snags that make me wonder if a better tool can be built. &lt;/p&gt; &lt;p&gt;I&amp;#39;m really interested in hearing about others&amp;#39; experiences with similar tools, so if you‚Äôre willing to share, that would be awesome! ü´∂üèº &lt;/p&gt; &lt;ul&gt; &lt;li&gt;What tool are you using? &lt;/li&gt; &lt;li&gt;How much does it cost you? &lt;/li&gt; &lt;li&gt;What kind of issues have you run into while using this tool?&lt;/li&gt; &lt;li&gt;Are there specific features that you feel are lacking? &lt;/li&gt; &lt;li&gt;If you could build a wish list of features, what would they be? üåü&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/powderarc&quot;&gt; /u/powderarc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1co09cc/limitations_with_existing_prompt_management_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1co09cc/limitations_with_existing_prompt_management_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1co09cc</id><link href="https://www.reddit.com/r/LangChain/comments/1co09cc/limitations_with_existing_prompt_management_tools/" /><updated>2024-05-09T15:39:36+00:00</updated><published>2024-05-09T15:39:36+00:00</published><title>Limitations with existing prompt management tools?</title></entry><entry><author><name>/u/Jean_dta</name><uri>https://www.reddit.com/user/Jean_dta</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I tried to do fine tuning in openai for limit the topics that my model can to speak, but the model runs bad, for example the result has seen like this:&lt;/p&gt; &lt;p&gt;GOOD: good answer BAD: bad answer&lt;/p&gt; &lt;p&gt;Q: Who is Taylor Swift? (GOOD) A: Sorry‚Ä¶.&lt;/p&gt; &lt;p&gt;Q: What is the sincope in life Sciences? (GOOD) A: The sincope is‚Ä¶&lt;/p&gt; &lt;p&gt;Q: Hello (BAD) A: sorry‚Ä¶.&lt;/p&gt; &lt;p&gt;‚Ä¶ I ask for 5 questions about Life Science Q: give me the answer of question Numbers 3 (BAD) A: sorry‚Ä¶.&lt;/p&gt; &lt;p&gt;How can I fix it ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jean_dta&quot;&gt; /u/Jean_dta &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1co28ib/langchain_openai_fine_tuning/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1co28ib/langchain_openai_fine_tuning/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1co28ib</id><link href="https://www.reddit.com/r/LangChain/comments/1co28ib/langchain_openai_fine_tuning/" /><updated>2024-05-09T17:04:07+00:00</updated><published>2024-05-09T17:04:07+00:00</published><title>Langchain openai FINE TUNING</title></entry><entry><author><name>/u/Alarming-East1193</name><uri>https://www.reddit.com/user/Alarming-East1193</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I&amp;#39;m performing prompt engineering for my Phi3-mini-4K-instruct model and I&amp;#39;m using Anything LLM for my front end application.&lt;/p&gt; &lt;p&gt;The thing is i want my model to only answer query from the context data provided (PDFs) and Don&amp;#39;t give any answers from his own knowledge or external source. The prompt I&amp;#39;m giving is:&lt;/p&gt; &lt;p&gt;&amp;quot; &amp;quot; &amp;quot;You are an assistant for question answering tasks. use the following pieces of retrieved context to answer the question. If the answer isn&amp;#39;t present in the knowledge base, refrain from providing an answer based on your own knowledge. Instead of answer to such question, indicate that relevant information isn&amp;#39;t available. Use three sentences maximum to keep the answer concise&amp;quot; &amp;quot; &amp;quot;&lt;/p&gt; &lt;p&gt;After this promopt I&amp;#39;m still getting answers for the questions which are irrelevant and from outside of the knowledge base provided.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Alarming-East1193&quot;&gt; /u/Alarming-East1193 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cntf8t/prompt_engineering_on_phi3mini4kinstruct_model/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cntf8t/prompt_engineering_on_phi3mini4kinstruct_model/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cntf8t</id><link href="https://www.reddit.com/r/LangChain/comments/1cntf8t/prompt_engineering_on_phi3mini4kinstruct_model/" /><updated>2024-05-09T09:54:38+00:00</updated><published>2024-05-09T09:54:38+00:00</published><title>Prompt Engineering on Phi3-mini-4K-instruct Model</title></entry><entry><author><name>/u/Informal-Victory8655</name><uri>https://www.reddit.com/user/Informal-Victory8655</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cnu7zh/hi_guyswhat_is_the_use_of_parameter_k_in/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/6rhoXyDpNWbgMOkDF20HATQNnc_QYPsXlAv9TbixPUY.jpg&quot; alt=&quot;Hi guys,what is the use of parameter K in ConversationEntityMemory?&quot; title=&quot;Hi guys,what is the use of parameter K in ConversationEntityMemory?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://api.python.langchain.com/en/latest/memory/langchain.memory.entity.ConversationEntityMemory.html&quot;&gt;https://api.python.langchain.com/en/latest/memory/langchain.memory.entity.ConversationEntityMemory.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/ufmg5yvirdzc1.png?width=488&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec24354784b8f84a445c4965f6064b9ed0cd838a&quot;&gt;https://preview.redd.it/ufmg5yvirdzc1.png?width=488&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec24354784b8f84a445c4965f6064b9ed0cd838a&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Informal-Victory8655&quot;&gt; /u/Informal-Victory8655 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cnu7zh/hi_guyswhat_is_the_use_of_parameter_k_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cnu7zh/hi_guyswhat_is_the_use_of_parameter_k_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cnu7zh</id><media:thumbnail url="https://b.thumbs.redditmedia.com/6rhoXyDpNWbgMOkDF20HATQNnc_QYPsXlAv9TbixPUY.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1cnu7zh/hi_guyswhat_is_the_use_of_parameter_k_in/" /><updated>2024-05-09T10:46:02+00:00</updated><published>2024-05-09T10:46:02+00:00</published><title>Hi guys,what is the use of parameter K in ConversationEntityMemory?</title></entry><entry><author><name>/u/MoronSlayer42</name><uri>https://www.reddit.com/user/MoronSlayer42</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Building an LLM app and using Unstructured for parsing data. From the vector store, have can I create a conversational agent that has 2 tools for intent classification? I want to create an agent so that according to user query in my application, the backend either returns a conversational output (chat) + shows sources or for some other type of user queries it returns only documents (no chat) akin to a generic Google search. After I create these two tools, I also want additional tools for the agent to recognize whether the user query is a simple greeting or whether there is any abusive language in the query. Any approaches, suggestions or examples would be helpful.&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MoronSlayer42&quot;&gt; /u/MoronSlayer42 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cnqsxj/langchain_agents_tools_for_intent_classification/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cnqsxj/langchain_agents_tools_for_intent_classification/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cnqsxj</id><link href="https://www.reddit.com/r/LangChain/comments/1cnqsxj/langchain_agents_tools_for_intent_classification/" /><updated>2024-05-09T06:47:15+00:00</updated><published>2024-05-09T06:47:15+00:00</published><title>Langchain agents - tools for intent classification</title></entry><entry><author><name>/u/Putrid_Spinach3961</name><uri>https://www.reddit.com/user/Putrid_Spinach3961</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have access to gpt 4 models in azure openai platform, can i convert react 18.2.0 code to typescript 4.9.5 using langchain and azure openai gpt 4 model. I know langchain is not necessary for conversion, but the data cut off for gpt 4 model is 2021 and the latest version might not be used for train the gpt4 model. So do i have any option to use any langchain tool like chains or agent for this conversion as the model might need external agent support.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Putrid_Spinach3961&quot;&gt; /u/Putrid_Spinach3961 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cnslbe/react_to_typescript/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cnslbe/react_to_typescript/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cnslbe</id><link href="https://www.reddit.com/r/LangChain/comments/1cnslbe/react_to_typescript/" /><updated>2024-05-09T08:55:47+00:00</updated><published>2024-05-09T08:55:47+00:00</published><title>React to Typescript</title></entry><entry><author><name>/u/Omervx</name><uri>https://www.reddit.com/user/Omervx</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cntvmi/having_a_hard_time_with_templates/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/o8AUCLRdlCnANPZeJBedQZzE7o4EKpgnQNYkyDtKBP8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=74efa463daa026a2d0c19f410b6af492e5d26877&quot; alt=&quot;Having a hard time with templates &quot; title=&quot;Having a hard time with templates &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, I&amp;#39;m diving into LangChain and AI for the first time, so please bear with me as I navigate through this learning curve. &lt;/p&gt; &lt;p&gt;I&amp;#39;ve managed to create a small CLI bot with memory, and you can check out the GitHub link here: [GitHub Link] &lt;a href=&quot;https://github.com/oovaa/ChatPDF/blob/main/exper%2Fcommandr.js&quot;&gt;https://github.com/oovaa/ChatPDF/blob/main/exper%2Fcommandr.js&lt;/a&gt;. &lt;/p&gt; &lt;p&gt;However, I&amp;#39;m encountering an issue where the bot interprets my name input as a command rather than part of the conversation. It seems to struggle with understanding the context of the conversation. I&amp;#39;d really appreciate some guidance on how to fix this. Thanks in advance for any help you can provide!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Omervx&quot;&gt; /u/Omervx &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/oovaa/ChatPDF/blob/main/exper%2Fcommandr.js&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cntvmi/having_a_hard_time_with_templates/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cntvmi</id><media:thumbnail url="https://external-preview.redd.it/o8AUCLRdlCnANPZeJBedQZzE7o4EKpgnQNYkyDtKBP8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=74efa463daa026a2d0c19f410b6af492e5d26877" /><link href="https://www.reddit.com/r/LangChain/comments/1cntvmi/having_a_hard_time_with_templates/" /><updated>2024-05-09T10:23:58+00:00</updated><published>2024-05-09T10:23:58+00:00</published><title>Having a hard time with templates</title></entry><entry><author><name>/u/MediocreMolasses9542</name><uri>https://www.reddit.com/user/MediocreMolasses9542</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cn4pyt/i_made_a_tool_that_allows_you_to_searchchat_with/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/NDNhdDhxcmxnN3pjMW2L8kqVelOF3uY9ZoVdnni9DgED4Czo_rSma0qXHZfi.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=973474be24330b917d0e3a16cac97b40fe56f481&quot; alt=&quot;I made a tool that allows you to search/chat with the LangChain codebase&quot; title=&quot;I made a tool that allows you to search/chat with the LangChain codebase&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MediocreMolasses9542&quot;&gt; /u/MediocreMolasses9542 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/axiobrrlg7zc1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cn4pyt/i_made_a_tool_that_allows_you_to_searchchat_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cn4pyt</id><media:thumbnail url="https://external-preview.redd.it/NDNhdDhxcmxnN3pjMW2L8kqVelOF3uY9ZoVdnni9DgED4Czo_rSma0qXHZfi.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=973474be24330b917d0e3a16cac97b40fe56f481" /><link href="https://www.reddit.com/r/LangChain/comments/1cn4pyt/i_made_a_tool_that_allows_you_to_searchchat_with/" /><updated>2024-05-08T13:35:26+00:00</updated><published>2024-05-08T13:35:26+00:00</published><title>I made a tool that allows you to search/chat with the LangChain codebase</title></entry><entry><author><name>/u/pikaLuffy</name><uri>https://www.reddit.com/user/pikaLuffy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;To my fellow experts, I am having trouble to extract tables from PDF. I know there are some packages out there that claim to do the job, but I can‚Äôt seem to get good results from it. Moreover, my work laptop kinda restrict on installation of softwares and the most I can do is download open source library package. Wondering if there are any straightforward ways on how to do that ? Or I have to a rite the code from scratch to process the tables but there seem to be many types of tables I need to consider. &lt;/p&gt; &lt;p&gt;Here are the packages I tried and the reasons why they didn‚Äôt work. &lt;/p&gt; &lt;ol&gt; &lt;li&gt;Pymupdf- messy table formatting, can misinterpret title of the page as column headers&lt;/li&gt; &lt;li&gt;Tabula/pdfminer- same performance as Pymupdf &lt;/li&gt; &lt;li&gt;Camelot- I can‚Äôt seem to get it to work given that it needs to download Ghostscript and tkinter, which require admin privilege which is blocked in my work laptop. &lt;/li&gt; &lt;li&gt;Unstructured- complicated setup as require a lot of dependencies and they are hard to set up &lt;/li&gt; &lt;li&gt;Llamaparse from llama: need cloud api key which is blocked &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I tried converting pdf to html but can‚Äôt seem to identify the tables very well. &lt;/p&gt; &lt;p&gt;Please help a beginner ü•∫&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pikaLuffy&quot;&gt; /u/pikaLuffy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cn0z11/extract_tables_from_pdf_for_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cn0z11/extract_tables_from_pdf_for_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cn0z11</id><link href="https://www.reddit.com/r/LangChain/comments/1cn0z11/extract_tables_from_pdf_for_rag/" /><updated>2024-05-08T10:10:38+00:00</updated><published>2024-05-08T10:10:38+00:00</published><title>Extract tables from PDF for RAG</title></entry><entry><author><name>/u/xandie985</name><uri>https://www.reddit.com/user/xandie985</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;During runtime, I can see, what chain is being executed. I need that information being displayed for further steps. Do you know how can I access the output text while the code is being executed?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/xandie985&quot;&gt; /u/xandie985 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cncubh/how_can_i_access_the_output_while_the_code_is/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cncubh/how_can_i_access_the_output_while_the_code_is/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cncubh</id><link href="https://www.reddit.com/r/LangChain/comments/1cncubh/how_can_i_access_the_output_while_the_code_is/" /><updated>2024-05-08T19:17:00+00:00</updated><published>2024-05-08T19:17:00+00:00</published><title>How can I access the output while the code is running?</title></entry><entry><author><name>/u/Different_Star9899</name><uri>https://www.reddit.com/user/Different_Star9899</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So, I made an information extraction system where basically, when I upload a technical data sheet of a construction material through streamlit, the LLM generates a text string in .csv format containing the attributes of the material that I defined to extract through the prompts (which are already embedded so it&amp;#39;s not a Q&amp;amp;A system). And I linked the response with Gspread so that the string is automatically exported to google sheets in correct order. &lt;/p&gt; &lt;p&gt;I tested and the prototype is working as intended but the problem is with the evaluation of the system. Since it&amp;#39;s part of a thesis project, I have to demonstrate how well the proposed system is performing based on certain metrics, but I am finding difficulty in looking for a quantitively evaluated method that suits this use case scenario. What I want to do is to compare the performances of different LLMs that are being used for the generation as well as assessing the retrieval portion of the system.&lt;/p&gt; &lt;p&gt;Obviously, I&amp;#39;m not well-versed in this area so any help is appreciated. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Different_Star9899&quot;&gt; /u/Different_Star9899 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cn6lau/evaluation_for_rag_for_extraction_and_restricted/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cn6lau/evaluation_for_rag_for_extraction_and_restricted/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cn6lau</id><link href="https://www.reddit.com/r/LangChain/comments/1cn6lau/evaluation_for_rag_for_extraction_and_restricted/" /><updated>2024-05-08T14:56:25+00:00</updated><published>2024-05-08T14:56:25+00:00</published><title>Evaluation for RAG for extraction and restricted responses</title></entry></feed>