<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-04-29T09:58:12+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/kk17702</name><uri>https://www.reddit.com/user/kk17702</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I created a game called Reverse-Akinator where the user will ask questions to find out the person, that has been randomly selected from a CSV file. At low level, it is a history-aware RAG application where the content is derived from their respective Wikipedia page. I am currently using Groq API for query answering, Voyage&amp;#39;s voayage-lite-02-instruct for embeddings and Chroma for vector store. It would really be helpful if you guys can post your opinion on this project and any way I can improve this further functionally. I used streamlit as UI.&lt;br/&gt; &lt;a href=&quot;https://github.com/karthickk17/Reverse-Akinator&quot;&gt;Github Repo&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kk17702&quot;&gt; /u/kk17702 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cftzk1/reverseakinator_a_rag_experiment/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cftzk1/reverseakinator_a_rag_experiment/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cftzk1</id><link href="https://www.reddit.com/r/LangChain/comments/1cftzk1/reverseakinator_a_rag_experiment/" /><updated>2024-04-29T08:30:32+00:00</updated><published>2024-04-29T08:30:32+00:00</published><title>Reverse-Akinator (A RAG experiment)</title></entry><entry><author><name>/u/xtremx12</name><uri>https://www.reddit.com/user/xtremx12</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys, I would like to get your help regarding my case. I have been working as a software testing engineer for almost 12 years. I have a solid Python and JS background. I found that the LLM is very interesting for me. I checked a lot of tutorials about building my own RAG using langchain or lamaindex. I liked it and I found the potential of jobs is start raising in the market. &lt;/p&gt; &lt;p&gt;I&amp;#39;m thinking about start shifting to this new field but I&amp;#39;m not sure how can I cut the gap btwn me and the required skills for these positions. &lt;/p&gt; &lt;p&gt;What should I really know to be able to build a solid portfolio? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/xtremx12&quot;&gt; /u/xtremx12 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfuc06/switch_from_the_testing_field_to_data_engineer/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfuc06/switch_from_the_testing_field_to_data_engineer/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cfuc06</id><link href="https://www.reddit.com/r/LangChain/comments/1cfuc06/switch_from_the_testing_field_to_data_engineer/" /><updated>2024-04-29T08:54:56+00:00</updated><published>2024-04-29T08:54:56+00:00</published><title>switch from the Testing field to Data engineer</title></entry><entry><author><name>/u/Mysterious-Dog8554</name><uri>https://www.reddit.com/user/Mysterious-Dog8554</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to create a tool to rewrite text based on content and style guidelines (ex: use this word instead of this, reading level, etc.). Is there a way to do this easily with Langchain / ex give it some docs of all the vocabulary it should use and a list of style rules?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mysterious-Dog8554&quot;&gt; /u/Mysterious-Dog8554 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfkcbj/using_langchain_to_create_a_writingstyle_guide/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfkcbj/using_langchain_to_create_a_writingstyle_guide/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cfkcbj</id><link href="https://www.reddit.com/r/LangChain/comments/1cfkcbj/using_langchain_to_create_a_writingstyle_guide/" /><updated>2024-04-28T23:25:04+00:00</updated><published>2024-04-28T23:25:04+00:00</published><title>Using Langchain to create a writing/style guide</title></entry><entry><author><name>/u/DancingDorritos</name><uri>https://www.reddit.com/user/DancingDorritos</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfha4g/langchain_with_azure_openai_gpt4/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/d9e3rud6daxc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2fd6fe6d165ce79c6f8d81269c251168e8a484e6&quot; alt=&quot;Langchain with Azure OpenAI gpt4&quot; title=&quot;Langchain with Azure OpenAI gpt4&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’ve been recently trying to get (title) working on a simple python file - just by following the docs - however no matter what YouTube video or documentation I follow, it seems I always get that the error shown in the attached photo. &lt;/p&gt; &lt;p&gt;I’m confused what to do - there must definitely be a way to use langchain with gpt 4 Azure OpenAI. &lt;/p&gt; &lt;p&gt;Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DancingDorritos&quot;&gt; /u/DancingDorritos &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/d9e3rud6daxc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfha4g/langchain_with_azure_openai_gpt4/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cfha4g</id><media:thumbnail url="https://preview.redd.it/d9e3rud6daxc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2fd6fe6d165ce79c6f8d81269c251168e8a484e6" /><link href="https://www.reddit.com/r/LangChain/comments/1cfha4g/langchain_with_azure_openai_gpt4/" /><updated>2024-04-28T21:11:57+00:00</updated><published>2024-04-28T21:11:57+00:00</published><title>Langchain with Azure OpenAI gpt4</title></entry><entry><author><name>/u/Brave-Guide-7470</name><uri>https://www.reddit.com/user/Brave-Guide-7470</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, I tested this app called talkdai/dialog on Github, and it allowed me to deploy a RAG with my customized content in just some few minutes and a Docker-compose file.&lt;/p&gt; &lt;p&gt;It&amp;#39;s totally based on langchain right now, and with a toml file with my prompt and model settings, I was able to deploy it online using caddy and a simple PGVector instance.&lt;/p&gt; &lt;p&gt;Is there any other application that does that?&lt;/p&gt; &lt;p&gt;Here is the link for the source code: &lt;a href=&quot;https://github.com/talkdai/dialog&quot;&gt;https://github.com/talkdai/dialog&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Brave-Guide-7470&quot;&gt; /u/Brave-Guide-7470 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf7q6y/langchain_wrapper_for_easy_rag_deployments/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf7q6y/langchain_wrapper_for_easy_rag_deployments/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cf7q6y</id><link href="https://www.reddit.com/r/LangChain/comments/1cf7q6y/langchain_wrapper_for_easy_rag_deployments/" /><updated>2024-04-28T14:30:22+00:00</updated><published>2024-04-28T14:30:22+00:00</published><title>LangChain Wrapper for easy RAG Deployments</title></entry><entry><author><name>/u/EvidenceBulky6808</name><uri>https://www.reddit.com/user/EvidenceBulky6808</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;would like to use Tokenizer on Huggingface when using LlamaCpp in langchain_community.llms. (Tokenizer on Huggingface for Korean models) However, LlamaCpp says that there are no parameters for tokenizer and it has been sent to model_kwaggs.&lt;br/&gt; Is there any good way? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EvidenceBulky6808&quot;&gt; /u/EvidenceBulky6808 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfqkvt/how_to_use_huggingface_autotokenizer_in_llamacpp/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfqkvt/how_to_use_huggingface_autotokenizer_in_llamacpp/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cfqkvt</id><link href="https://www.reddit.com/r/LangChain/comments/1cfqkvt/how_to_use_huggingface_autotokenizer_in_llamacpp/" /><updated>2024-04-29T04:46:56+00:00</updated><published>2024-04-29T04:46:56+00:00</published><title>How to use Huggingface AutoTokenizer in llamacpp, LangChain?</title></entry><entry><author><name>/u/Relevant-Ad9432</name><uri>https://www.reddit.com/user/Relevant-Ad9432</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I recently tried to make a chatbot, and it was really frustrating to have chatgpt not work (idk why but it just couldn&amp;#39;t answer langchain questions , maybe the training cutoff date) , the docs are not so well arranged... And even if I do somehow get the code to work, it does not perform very well bcz I don&amp;#39;t know much in the first place, I have a theoretical understanding of ML, but idk what are the diff kind of chains, retrievers, agents... I just find it to be a lot of things which are scattered all over the place&lt;/p&gt; &lt;p&gt;So, can someone pls recommend me a course on langchain which consolidates all the different techniques (chains, agents, vectordb etc.) And goes a bit in depth for everything, like how does this chain work or the diff methods of querying to the vectordb... Also feel free to recommend courses other than langchain, it&amp;#39;s just langchain is the only LLM framework I know... &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Relevant-Ad9432&quot;&gt; /u/Relevant-Ad9432 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf5fse/recommend_me_some_courses_for_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf5fse/recommend_me_some_courses_for_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cf5fse</id><link href="https://www.reddit.com/r/LangChain/comments/1cf5fse/recommend_me_some_courses_for_llm/" /><updated>2024-04-28T12:38:17+00:00</updated><published>2024-04-28T12:38:17+00:00</published><title>Recommend me some courses for LLM</title></entry><entry><author><name>/u/jim_andr</name><uri>https://www.reddit.com/user/jim_andr</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jim_andr&quot;&gt; /u/jim_andr &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfbqf9/has_langchain_become_mature_for_production/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfbqf9/has_langchain_become_mature_for_production/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cfbqf9</id><link href="https://www.reddit.com/r/LangChain/comments/1cfbqf9/has_langchain_become_mature_for_production/" /><updated>2024-04-28T17:24:07+00:00</updated><published>2024-04-28T17:24:07+00:00</published><title>Has langchain become mature for production environments?</title></entry><entry><author><name>/u/reds99devil</name><uri>https://www.reddit.com/user/reds99devil</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am working on a small project where i have pdf files and .md files. I am reading md files using TextLoader to separate on &amp;quot;#&amp;quot; and it works well. How do i read pdf files, should i read all of them using a common loader ? is there a way to do it separately?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/reds99devil&quot;&gt; /u/reds99devil &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfkr6u/reading_data_from_multiple_datatypes/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cfkr6u/reading_data_from_multiple_datatypes/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cfkr6u</id><link href="https://www.reddit.com/r/LangChain/comments/1cfkr6u/reading_data_from_multiple_datatypes/" /><updated>2024-04-28T23:44:32+00:00</updated><published>2024-04-28T23:44:32+00:00</published><title>Reading data from multiple datatypes</title></entry><entry><author><name>/u/Aggravating-Floor-38</name><uri>https://www.reddit.com/user/Aggravating-Floor-38</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, need advice on techniques that really elevate rag from naive to an advanced system. I&amp;#39;ve built a rag system that scrapes data from the internet and uses that as context. I&amp;#39;ve worked a bit on chunking strategy and worked extensively on cleaning strategy for the scraped data, query expansion and rewriting, but haven&amp;#39;t done much else. I don&amp;#39;t think I can work on the metadata extraction aspect because I&amp;#39;m using local llms and using them for summaries and QA pairs of the entire scraped db would take too long to do in real time. Also since my systems Open Domain, would fine-tuning the embedding model be useful? Would really appreciate input on that. What other things do you think could be worked on (impressive flashy stuff lol)&lt;/p&gt; &lt;p&gt;I was thinking hybrid search but then I&amp;#39;m also hearing knowledge graphs are great? idk. Saw a paper that just came out last month about context-tuning for retrieval in rag - but can&amp;#39;t find any implementations or discourse around that. Lot of ramble sorry but yeah basically what else can I do to really elevate my RAG system - so far I&amp;#39;m thinking better parsing - processing tables etc., self-rag seems really useful so maybe incorporate that?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Aggravating-Floor-38&quot;&gt; /u/Aggravating-Floor-38 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf97bh/leveling_up_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf97bh/leveling_up_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cf97bh</id><link href="https://www.reddit.com/r/LangChain/comments/1cf97bh/leveling_up_rag/" /><updated>2024-04-28T15:36:08+00:00</updated><published>2024-04-28T15:36:08+00:00</published><title>Leveling up RAG</title></entry><entry><author><name>/u/Distinct-Target7503</name><uri>https://www.reddit.com/user/Distinct-Target7503</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone... &lt;/p&gt; &lt;p&gt;I build an advanced RAG pipeline, and that include an agent that should get data from web, opening links from web search results... Anyway, I&amp;#39;ve zero past experience with web scraping, and my html knowledge is really basic. I&amp;#39;m going mad trying to extract the main text from web pages without lot of noise from tag, headers and other UI elements. As temporary solution, I added an llm agent &amp;quot;in the middle&amp;quot;, using it to clean the scraped text... But that&amp;#39;s slow, expensive (using cloud providers) and fondamentally inefficient. &lt;/p&gt; &lt;p&gt;Someone can give me some tips/help? There is some library, repo or framework that may help me? &lt;/p&gt; &lt;p&gt;Any kind of replay will be really appreciate! &lt;/p&gt; &lt;p&gt;Thanks in advance for your time. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Distinct-Target7503&quot;&gt; /u/Distinct-Target7503 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf2dwc/what_web_scraper_for_web_search_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf2dwc/what_web_scraper_for_web_search_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cf2dwc</id><link href="https://www.reddit.com/r/LangChain/comments/1cf2dwc/what_web_scraper_for_web_search_agent/" /><updated>2024-04-28T09:28:27+00:00</updated><published>2024-04-28T09:28:27+00:00</published><title>What web scraper for web search agent?</title></entry><entry><author><name>/u/djang_odude</name><uri>https://www.reddit.com/user/djang_odude</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/@sreedeep200/how-langchain-and-chatgpt-plugins-are-getting-attacked-by-this-bug-9a47807b66a3&quot;&gt;https://medium.com/@sreedeep200/how-langchain-and-chatgpt-plugins-are-getting-attacked-by-this-bug-9a47807b66a3&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/djang_odude&quot;&gt; /u/djang_odude &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf9wl3/how_langchain_and_chatgpt_plugins_are_getting/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cf9wl3/how_langchain_and_chatgpt_plugins_are_getting/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cf9wl3</id><link href="https://www.reddit.com/r/LangChain/comments/1cf9wl3/how_langchain_and_chatgpt_plugins_are_getting/" /><updated>2024-04-28T16:06:13+00:00</updated><published>2024-04-28T16:06:13+00:00</published><title>How LangChain and ChatGPT plugins are getting attacked by this bug</title></entry><entry><author><name>/u/acageinsearchofabird</name><uri>https://www.reddit.com/user/acageinsearchofabird</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Specifically, legal documents.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/acageinsearchofabird&quot;&gt; /u/acageinsearchofabird &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceztk1/has_anyone_utilized_agents_for_document/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceztk1/has_anyone_utilized_agents_for_document/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ceztk1</id><link href="https://www.reddit.com/r/LangChain/comments/1ceztk1/has_anyone_utilized_agents_for_document/" /><updated>2024-04-28T06:35:41+00:00</updated><published>2024-04-28T06:35:41+00:00</published><title>Has anyone utilized agents for document summarization and information extraction?</title></entry><entry><author><name>/u/AccomplishedLion6322</name><uri>https://www.reddit.com/user/AccomplishedLion6322</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for a part-time LLM engineer to build some AI agent workflows. It&amp;#39;s remote.&lt;/p&gt; &lt;p&gt;Most job boards don&amp;#39;t seem to have this category yet. And the person I&amp;#39;d want wouldn&amp;#39;t need to have tons of AI or software engineering experience anyway. They just need to be technical-enough, a fan of GenAI, and familiar with LLM tooling.&lt;/p&gt; &lt;p&gt;Any good ideas on where to find them?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AccomplishedLion6322&quot;&gt; /u/AccomplishedLion6322 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cejzmq/where_to_hire_llm_engineers_who_know_tools_like/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cejzmq/where_to_hire_llm_engineers_who_know_tools_like/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cejzmq</id><link href="https://www.reddit.com/r/LangChain/comments/1cejzmq/where_to_hire_llm_engineers_who_know_tools_like/" /><updated>2024-04-27T17:31:42+00:00</updated><published>2024-04-27T17:31:42+00:00</published><title>Where to hire LLM engineers who know tools like LangChain? Most job board don't distinguish LLM engineers from typical AI or software engineers</title></entry><entry><author><name>/u/Visual-Librarian6601</name><uri>https://www.reddit.com/user/Visual-Librarian6601</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi I am writing a Nodejs library that uses LLM to process documents. I plan to support LLMs in OpenAI, Groq, Ollama. Is it a good practice to directly to use Langchain or Llama Index in my npm library and introduce it as a dependency?&lt;/p&gt; &lt;p&gt;Yes? (the code will be simpler and supporting multiple LLMs out of the box) today I do use Langchain in my bigger project that includes the code I want to split into this library.&lt;/p&gt; &lt;p&gt;Or shall I use separate LLM APIs like OpenAi’s directly. Or maybe try Llama Index&lt;/p&gt; &lt;p&gt;Any feedback is welcome 🙏 &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Visual-Librarian6601&quot;&gt; /u/Visual-Librarian6601 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceyzjy/use_langchain_vs_individual_llm_api_in_an_npm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceyzjy/use_langchain_vs_individual_llm_api_in_an_npm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ceyzjy</id><link href="https://www.reddit.com/r/LangChain/comments/1ceyzjy/use_langchain_vs_individual_llm_api_in_an_npm/" /><updated>2024-04-28T05:42:26+00:00</updated><published>2024-04-28T05:42:26+00:00</published><title>Use Langchain vs individual LLM API in an npm library</title></entry><entry><author><name>/u/Calm-Number5851</name><uri>https://www.reddit.com/user/Calm-Number5851</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;Large Language Models&lt;/strong&gt;, or LLMs, are advanced AI systems that enhance text prediction to an exceptional level — imagine the autocorrect &amp;amp; text prediction on your phone, but far more sophisticated.&lt;/p&gt; &lt;p&gt;When you type &amp;quot;I am going to the...&amp;quot;, your phone might suggest words like &amp;quot;store&amp;quot; or &amp;quot;gym.&amp;quot;, based on the words you wrote before. LLMs operate similarly, but on a much larger scale, using vast amounts of text to predict and generate language accurately.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The Core Pillars of LLMs are:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Transformer Models&lt;/strong&gt; - the backbone of most LLMs, these models process data by breaking down input text into smaller parts (tokens) and analyzing the relationships between them. This helps the model understand and generate language based on the context provided.Just like our brain uses neurons to process and relay information, transformer models use tokens to process and generate language, making sense of the input based on context.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Training&lt;/strong&gt; - LLMs learn by consuming vast amounts of text data, from websites like Wikipedia to books and articles. This training allows them to understand language patterns and context, and, as a result, generate better text.It’s just like reading hundreds of books to enhance your knowledge and master a subject, we feed LLMs with text data from diverse sources like Wikipedia and various books to help them learn, though with a small caveat — LLMs can do this anywhere from 100-1000 times &lt;em&gt;faster&lt;/em&gt; than us.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Fine-tuning&lt;/strong&gt; - after their initial training, LLMs can be fine-tuned with specific data sets to perform tasks like translation, content generation, or even coding.With fine-tuning, you’re giving your little helper a specific role &amp;amp; legend to fill — for example, &amp;quot;Sir Code-a-lot”, who, after his rigorous initial training, is now sharpening the specific skills needed to slay the mighty dragons in the C++ Language.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;And if you want to see how different your autocorrect &amp;amp; text prediction on your phone is from actual Large Language Models – then here’s a cool visual showing the sheer scale of the various GPT LLMs Essentially, LLMs predict what comes next, depending on the context &amp;amp; your input. If you’re a programmer and you’re writing code in Python, and use an LLM-powered code editor, the model understands every line of code you’ve written and suggests the next one accurately!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The History of LLMs &amp;amp; Transformers&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The evolution of LLMs (&lt;strong&gt;Large Language Models&lt;/strong&gt;) began with the introduction of the Transformer model by Google at NeurIPS 2017. &lt;/p&gt; &lt;p&gt;This model introduced a new approach called &amp;quot;attention mechanisms&amp;quot; that improves how machines understand the context within text. Basically, a Transformer allows the model to focus on different parts of the input data at different times, improving its ability to generate accurate and contextually appropriate responses.&lt;/p&gt; &lt;p&gt;This model led to significant developments such as BERT and GPT models. GPT models, starting from GPT-1 to the latest iterations like GPT-3.5 and GPT-4, have significantly advanced in capabilities, achieving tasks that range from simple text generation to complex decision-making and problem-solving tasks.&lt;/p&gt; &lt;p&gt;And you know what’s the best part about LLMs becoming mainstream? &lt;/p&gt; &lt;p&gt;Nearly every SaaS company is leveraging them by building apps to solve the problems we creators &amp;amp; entrepreneurs face daily – responding to emails, scheduling meetings, finding time for family and leisure, data entry, everything you could imagine — there’s an LLM-based tool for it now.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm-Number5851&quot;&gt; /u/Calm-Number5851 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cff5pa/llms_or_what_even_are_those/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cff5pa/llms_or_what_even_are_those/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cff5pa</id><link href="https://www.reddit.com/r/LangChain/comments/1cff5pa/llms_or_what_even_are_those/" /><updated>2024-04-28T19:45:37+00:00</updated><published>2024-04-28T19:45:37+00:00</published><title>LLMs Or What Even Are Those?</title></entry><entry><author><name>/u/Sea_Application1815</name><uri>https://www.reddit.com/user/Sea_Application1815</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I keep getting this error when using LangSmith:&lt;br/&gt; HTTPError: [Errno 403 Client Error: Forbidden for url: &lt;a href=&quot;https://api.smith.langchain.com/datasets%5C&quot;&gt;https://api.smith.langchain.com/datasets\&lt;/a&gt;] {&amp;quot;detail&amp;quot;:&amp;quot;Forbidden&amp;quot;}&lt;/p&gt; &lt;p&gt;This was working fine just yesterday :(&lt;/p&gt; &lt;pre&gt;&lt;code&gt;os.environ[&amp;#39;LANGCHAIN_TRACING_V2&amp;#39;] = &amp;#39;true&amp;#39; os.environ[&amp;quot;LANGCHAIN_ENDPOINT&amp;quot;] = &amp;quot;https://api.smith.langchain.com&amp;quot; os.environ[&amp;quot;LANGCHAIN_API_KEY&amp;quot;] = os.getenv(&amp;quot;LANGCHAIN_API_KEY&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I have accessed the api_keys.&lt;/p&gt; &lt;p&gt;How do I fix this? Can someone please help?&lt;/p&gt; &lt;p&gt;Edit: I am also importing&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langsmith import Client client = Client() &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sea_Application1815&quot;&gt; /u/Sea_Application1815 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cennxi/langchain_client_connection_error/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cennxi/langchain_client_connection_error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cennxi</id><link href="https://www.reddit.com/r/LangChain/comments/1cennxi/langchain_client_connection_error/" /><updated>2024-04-27T20:08:39+00:00</updated><published>2024-04-27T20:08:39+00:00</published><title>LangChain client connection error</title></entry><entry><author><name>/u/ava69_open</name><uri>https://www.reddit.com/user/ava69_open</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, our small engineering team is exploring RAG for querying our massive internal document system. It&amp;#39;s exciting, but also a little overwhelming with all the choices - LLMs, embedding models, vector databases, hyperparameters... you name it!&lt;/p&gt; &lt;p&gt;Here&amp;#39;s what we&amp;#39;re thinking:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Manually create a test set of 10-20 custom Q&amp;amp;As (should we allow multiple answer options?).&lt;/li&gt; &lt;li&gt;Automate deployment of various combinations: different LLMs, hyperparameters, embedding models, etc.&lt;/li&gt; &lt;li&gt;Compare the generated answers to our gold standard answers (thinking ROUGE score for evaluation).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Does this approach sound reasonable? Are there any tools or frameworks out there that can streamline this process for a small team like ours? Any advice would be greatly appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ava69_open&quot;&gt; /u/ava69_open &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8z9h/diving_into_rag_with_a_small_team/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8z9h/diving_into_rag_with_a_small_team/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce8z9h</id><link href="https://www.reddit.com/r/LangChain/comments/1ce8z9h/diving_into_rag_with_a_small_team/" /><updated>2024-04-27T07:47:07+00:00</updated><published>2024-04-27T07:47:07+00:00</published><title>Diving into RAG with a Small Team</title></entry><entry><author><name>/u/Calm-Number5851</name><uri>https://www.reddit.com/user/Calm-Number5851</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cemgtd/microsoft_launches_tiny_ai_model_phi3/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/rrnQmZ9aRteVTnRSbSR6JHNFl-AMLM7WDd2nxsP19ew.jpg&quot; alt=&quot;Microsoft Launches Tiny AI Model Phi-3 &quot; title=&quot;Microsoft Launches Tiny AI Model Phi-3 &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Microsoft announced its smallest AI model yet, Phi-3. This model, measuring just 3.8 billion parameters, was learned from ‘bedtime stories’ created by other LLMs. Thanks to innovations in learning, the company says this family outperforms the same and next-size models on a range of tests assessing language, programming, and math abilities.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/dav6udi2m2xc1.jpg?width=2000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=cc3538181ff7ad3a69064991c7b0dff507eb7ee6&quot;&gt;https://preview.redd.it/dav6udi2m2xc1.jpg?width=2000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=cc3538181ff7ad3a69064991c7b0dff507eb7ee6&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The new model is available in the Microsoft Azure AI Model Catalog and on Hugging Face, as well as Ollama, a lightweight framework for running models on a local machine. Microsoft says it will also be available as an NVIDIA NIM microservice with a standard API interface that can be deployed anywhere.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm-Number5851&quot;&gt; /u/Calm-Number5851 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cemgtd/microsoft_launches_tiny_ai_model_phi3/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cemgtd/microsoft_launches_tiny_ai_model_phi3/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cemgtd</id><media:thumbnail url="https://b.thumbs.redditmedia.com/rrnQmZ9aRteVTnRSbSR6JHNFl-AMLM7WDd2nxsP19ew.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1cemgtd/microsoft_launches_tiny_ai_model_phi3/" /><updated>2024-04-27T19:16:47+00:00</updated><published>2024-04-27T19:16:47+00:00</published><title>Microsoft Launches Tiny AI Model Phi-3</title></entry><entry><author><name>/u/Familyinalicante</name><uri>https://www.reddit.com/user/Familyinalicante</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am trying to fire out how to create tool for agent to work with Simple rest API (build with Fast API, no auth). I am just learning and couldn&amp;#39;t find practical implementation. I&amp;#39;ve read about using API chain but My api have 4 endpoints. It&amp;#39;s really basic one &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Familyinalicante&quot;&gt; /u/Familyinalicante &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceonep/agent_tool_to_work_with_rest_api/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ceonep/agent_tool_to_work_with_rest_api/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ceonep</id><link href="https://www.reddit.com/r/LangChain/comments/1ceonep/agent_tool_to_work_with_rest_api/" /><updated>2024-04-27T20:51:42+00:00</updated><published>2024-04-27T20:51:42+00:00</published><title>Agent tool to work with rest API</title></entry><entry><author><name>/u/madwzdri</name><uri>https://www.reddit.com/user/madwzdri</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Are there any libraries that can allow me to create a shareable versions of rag documents using links. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I am looking to create a system that will allow me to share a document using links with an LLM trained using RAG. How would you go about this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/madwzdri&quot;&gt; /u/madwzdri &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cefdw6/sharing_rag_enhanced_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cefdw6/sharing_rag_enhanced_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cefdw6</id><link href="https://www.reddit.com/r/LangChain/comments/1cefdw6/sharing_rag_enhanced_documents/" /><updated>2024-04-27T14:09:11+00:00</updated><published>2024-04-27T14:09:11+00:00</published><title>Sharing RAG enhanced documents</title></entry><entry><author><name>/u/QueRoub</name><uri>https://www.reddit.com/user/QueRoub</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have built a RAG application and I am getting back the source file from which the LLM answered a question.&lt;/p&gt; &lt;p&gt;My issue is that a document is always retrieved but the LLM might not give an answer based on that.&lt;/p&gt; &lt;p&gt;I would like to capture this case when I call the chain. &lt;/p&gt; &lt;p&gt;Is that possible?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/QueRoub&quot;&gt; /u/QueRoub &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9jnl/capture_case_where_llm_did_not_find_any_answer_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9jnl/capture_case_where_llm_did_not_find_any_answer_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce9jnl</id><link href="https://www.reddit.com/r/LangChain/comments/1ce9jnl/capture_case_where_llm_did_not_find_any_answer_in/" /><updated>2024-04-27T08:24:37+00:00</updated><published>2024-04-27T08:24:37+00:00</published><title>Capture case where LLM did not find any answer in context</title></entry><entry><author><name>/u/QueRoub</name><uri>https://www.reddit.com/user/QueRoub</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a way to get back similarity scores from retrievers?&lt;/p&gt; &lt;p&gt;If not, do you know any reliable function that computes similarity score between user&amp;#39;s query and retrieved chunks?&lt;/p&gt; &lt;p&gt;My issue is that I am working with non-English documents and many custom similarity score computation functions don&amp;#39;t work very accurately. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/QueRoub&quot;&gt; /u/QueRoub &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9fh1/can_you_get_back_similarity_scores_from_retrievers/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9fh1/can_you_get_back_similarity_scores_from_retrievers/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce9fh1</id><link href="https://www.reddit.com/r/LangChain/comments/1ce9fh1/can_you_get_back_similarity_scores_from_retrievers/" /><updated>2024-04-27T08:16:50+00:00</updated><published>2024-04-27T08:16:50+00:00</published><title>Can you get back similarity scores from retrievers?</title></entry><entry><author><name>/u/prime_danger</name><uri>https://www.reddit.com/user/prime_danger</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a complex documentation and multiple requirements. I ask a question about a requirement which itself has requirements from the same document. Kindly advice on what should I use and how do I build?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/prime_danger&quot;&gt; /u/prime_danger &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8lzd/how_to_build_an_agent_that_goes_back_and_forth/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8lzd/how_to_build_an_agent_that_goes_back_and_forth/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce8lzd</id><link href="https://www.reddit.com/r/LangChain/comments/1ce8lzd/how_to_build_an_agent_that_goes_back_and_forth/" /><updated>2024-04-27T07:22:24+00:00</updated><published>2024-04-27T07:22:24+00:00</published><title>How to build an agent that goes back and forth into the vector db</title></entry><entry><author><name>/u/Diligent_Eye1248</name><uri>https://www.reddit.com/user/Diligent_Eye1248</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://dly.to/emJTz7UM5hG&quot;&gt;Learn&lt;/a&gt; how to build an anime character generator using LangChain and OpenAI. No HTML or CSS required, just use Streamlit to create a simple web interface. Activate the virtual environment, install the necessary libraries, and run the code. Get creative and generate unique anime character names with different themes, along with wise, dramatic, or humorous quotes. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Diligent_Eye1248&quot;&gt; /u/Diligent_Eye1248 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce7m2u/building_an_anime_character_generator_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce7m2u/building_an_anime_character_generator_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce7m2u</id><link href="https://www.reddit.com/r/LangChain/comments/1ce7m2u/building_an_anime_character_generator_with/" /><updated>2024-04-27T06:18:58+00:00</updated><published>2024-04-27T06:18:58+00:00</published><title>Building an Anime Character Generator with LangChain and OpenAI</title></entry></feed>