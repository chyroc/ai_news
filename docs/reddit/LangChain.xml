<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-06-27T12:49:13+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Sevyten</name><uri>https://www.reddit.com/user/Sevyten</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys!&lt;/p&gt; &lt;p&gt;Just wanted to give you all a heads up about a live workshop we&amp;#39;re hosting tonight. We&amp;#39;ll be showing how to build an AI-powered tool similar to GitHub Copilot using &lt;a href=&quot;http://superduperdb.com&quot;&gt;SuperDuperDB&amp;#39;s&lt;/a&gt; latest release (v0.2). ðŸš€&lt;/p&gt; &lt;p&gt;ðŸŽ¥ Today (27/06/2024) at 9 PM CET&lt;br/&gt; ðŸ”— &lt;a href=&quot;https://www.youtube.com/watch?v=JgavM6QDmxQ&quot;&gt;https://www.youtube.com/watch?v=JgavM6QDmxQ&lt;/a&gt;&lt;/p&gt; &lt;h1&gt;What to Expect:&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;AI and Databases:&lt;/strong&gt; How to integrate AI models directly with your database.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Vector Search &amp;amp; Model Chaining:&lt;/strong&gt; Learn about vector search and setting up workflows by chaining models and APIs.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Real-time AI Outputs:&lt;/strong&gt; Implementing real-time AI outputs as new data arrives.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you&amp;#39;re into AI, databases, or just curious about how it all works, this session is for you. &lt;/p&gt; &lt;p&gt;Feel free to drop any questions or comments below. Excited to see what you all think!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sevyten&quot;&gt; /u/Sevyten &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpnjdx/build_your_own_github_copilot_with_superduperdb/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpnjdx/build_your_own_github_copilot_with_superduperdb/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpnjdx</id><link href="https://www.reddit.com/r/LangChain/comments/1dpnjdx/build_your_own_github_copilot_with_superduperdb/" /><updated>2024-06-27T09:57:36+00:00</updated><published>2024-06-27T09:57:36+00:00</published><title>Build Your Own GitHub Copilot with SuperDuperDB: Live Workshop</title></entry><entry><author><name>/u/coolcloud</name><uri>https://www.reddit.com/user/coolcloud</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all,&lt;/p&gt; &lt;p&gt;We&amp;#39;ve spent a lot of time building new techniques for parsing and searching PDFs. They&amp;#39;ve lead to a significant improvement in our RAG search and I wanted to share what we&amp;#39;ve learned.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Some examples:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Table - SEC Docs are notoriously hard for PDF -&amp;gt; tables. We tried the top results on google &amp;amp; some opensource thins not a single one succeeded on this table. &lt;/p&gt; &lt;p&gt;Couple examples of who we looked at:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;ilovepdf&lt;/li&gt; &lt;li&gt;Adobe&lt;/li&gt; &lt;li&gt;Gonitro&lt;/li&gt; &lt;li&gt;PDFtables&lt;/li&gt; &lt;li&gt;OCR 2 Edit&lt;/li&gt; &lt;li&gt;microsoft/table-transformer-structure-recognition&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Results - our result (can be accurately converted into CSV,MD,JSON)&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/5wju5gedmy8d1.png?width=1035&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a336bd0e1af14760fbb5ca4291284c99edaa27e&quot;&gt;https://preview.redd.it/5wju5gedmy8d1.png?width=1035&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a336bd0e1af14760fbb5ca4291284c99edaa27e&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Example: identifying headers, paragraphs, lists/list items (purple), and ignoring the &amp;quot;junk&amp;quot; at the top aka the table of contents in the header.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/ix7747bjmy8d1.png?width=1018&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ea0b65ae6a35581d955da282353ff63509602a38&quot;&gt;https://preview.redd.it/ix7747bjmy8d1.png?width=1018&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ea0b65ae6a35581d955da282353ff63509602a38&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Why did we do this?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;W ran into a bunch of issues with existing approaches that boils down to one thing: hallucinations often happen because the chunk doesn&amp;#39;t provide enough information.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;chunking by word count doesn&amp;#39;t work. It often chunks mid-paragraph or sentence.&lt;/li&gt; &lt;li&gt;Chunking by sentence or paragraph doesn&amp;#39;t work. If the answer spans 2-3 paragraphs, you still are SOL.&lt;/li&gt; &lt;li&gt;Semantic chunking is better but still fail quite often on lists or &amp;quot;somewhat&amp;quot; different pieces of info.&lt;/li&gt; &lt;li&gt;LLM&amp;#39;s deal better with structured/semi-structured data, i.e. knowing what you&amp;#39;re sending it is a header, paragraph list etc., makes the model perform better.&lt;/li&gt; &lt;li&gt;Headers often aren&amp;#39;t included because they&amp;#39;re too far away from the relevant vector, although often times headers contain important information.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;What are we doing different?&lt;/strong&gt; &lt;/p&gt; &lt;p&gt;We are dynamically generating chunks when a search happens, sending headers &amp;amp; sub-headers to the LLM along with the chunk/chunks that were relevant to the search.&lt;/p&gt; &lt;p&gt;Example of how this is helpful: you have 7 documents that talk about how to reset a device, and the header says the device name, but it isn&amp;#39;t talked about the paragraphs. The 7 chunks that talked about how to reset a device would come back, but the LLM wouldn&amp;#39;t know which one was relevant to which product. That is, unless the chunk happened to include both the paragraphs and the headers, which often times in our experience, it doesn&amp;#39;t.&lt;/p&gt; &lt;p&gt;This is a simplified version of what our structure looks like:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;{ &amp;quot;type&amp;quot;: &amp;quot;Root&amp;quot;, &amp;quot;children&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;Header&amp;quot;, &amp;quot;text&amp;quot;: &amp;quot;How to reset an iphone&amp;quot;, &amp;quot;children&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;Header&amp;quot;, &amp;quot;text&amp;quot;: &amp;quot;iphone 10 reset&amp;quot;, &amp;quot;children&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;Paragraph&amp;quot;, &amp;quot;text&amp;quot;: &amp;quot;Example Paragraph.&amp;quot; }, { &amp;quot;type&amp;quot;: &amp;quot;List&amp;quot;, &amp;quot;children&amp;quot;: [ &amp;quot;Item 1&amp;quot;, &amp;quot;Item 2&amp;quot;, &amp;quot;Item 3&amp;quot; ] } ] }, { &amp;quot;type&amp;quot;: &amp;quot;Header&amp;quot;, &amp;quot;text&amp;quot;: &amp;quot;iphone 11 reset&amp;quot;, &amp;quot;children&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;Paragraph&amp;quot;, &amp;quot;text&amp;quot;: &amp;quot;Example Paragraph 2&amp;quot; }, { &amp;quot;type&amp;quot;: &amp;quot;Table&amp;quot;, &amp;quot;children&amp;quot;: [ { &amp;quot;type&amp;quot;: &amp;quot;TableCell&amp;quot;, &amp;quot;row&amp;quot;: 0, &amp;quot;col&amp;quot;: 0, &amp;quot;text&amp;quot;: &amp;quot;Column 1&amp;quot;}, { &amp;quot;type&amp;quot;: &amp;quot;TableCell&amp;quot;, &amp;quot;row&amp;quot;: 0, &amp;quot;col&amp;quot;: 1, &amp;quot;text&amp;quot;: &amp;quot;Column 2&amp;quot;}, { &amp;quot;type&amp;quot;: &amp;quot;TableCell&amp;quot;, &amp;quot;row&amp;quot;: 0, &amp;quot;col&amp;quot;: 2, &amp;quot;text&amp;quot;: &amp;quot;Column 3&amp;quot;}, { &amp;quot;type&amp;quot;: &amp;quot;TableCell&amp;quot;, &amp;quot;row&amp;quot;: 1, &amp;quot;col&amp;quot;: 0, &amp;quot;text&amp;quot;: &amp;quot;Row 1, Cell 1&amp;quot;}, { &amp;quot;type&amp;quot;: &amp;quot;TableCell&amp;quot;, &amp;quot;row&amp;quot;: 1, &amp;quot;col&amp;quot;: 1, &amp;quot;text&amp;quot;: &amp;quot;Row 1, Cell 2&amp;quot;}, { &amp;quot;type&amp;quot;: &amp;quot;TableCell&amp;quot;, &amp;quot;row&amp;quot;: 1, &amp;quot;col&amp;quot;: 2, &amp;quot;text&amp;quot;: &amp;quot;Row 1, Cell 3&amp;quot;} ] } ] } ] } ] } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;How do we get PDF&amp;#39;s into this format?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;At a high level, we are identifying different portions of PDF&amp;#39;s based on PDF metadata and heuristics. This helps solve three problems:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;OCR can often mis-identify letters/numbers, or entirely crop out words. &lt;/li&gt; &lt;li&gt;Most other companies are trying to use OCR/ML models to identify layout elements, which seems to work decent on data it&amp;#39;s seen before but fails pretty hard unexpectedly. When it fails, it&amp;#39;s a black box. For example, Microsoft released a paper a few days ago saying they trained a model on over 500M documents and still fails on a bunch of use cases that we have working&lt;/li&gt; &lt;li&gt;We can look at layout, font analysis etc. throughout the entire doc allowing us to understand the &amp;quot;structure&amp;quot; of the document more. We&amp;#39;ll talk about this more when looking at font classes&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;How?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;First, we extract tables. We use a small OCR model to identify bounding boxes, then we do use white space analysis to find cells. This is the only portion of OCR we use (we&amp;#39;re looking at doing line analysis but have punted on that thus far.) We have found OCR to poorly identify cells on more complex tables, and often turn a 4 into a 5 or a 8 into a 2 etc.&lt;/p&gt; &lt;p&gt;When we find a table, we find characters that we believe to be a cell based on distance between each other, trying to read the table as a human would. An example would be 1345 would be a &amp;quot;cell&amp;quot; or text block, where 1 345 would be two text blocks due to the distance between them. A re-occurring theme is white space can get you pretty far.&lt;/p&gt; &lt;p&gt;Second, we extract character data from the PDF:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Fonts&lt;/strong&gt;: Information about the fonts used in the document, including the font name, type (e.g., TrueType, Type 1), and embedded font files.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Character Positions:&lt;/strong&gt; The exact bounding box of each character on the page.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Character Color:&lt;/strong&gt; PDFs usually give this correctly, and when it&amp;#39;s wrong it&amp;#39;s still good enough&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;PDFs provide a other metadata, but we found them to either be inaccurate or not necessary:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Content Streams:&lt;/strong&gt; Sequences of instructions that describe the content of the page, including text, images, and vector graphics. We found these to be surprisingly inaccurate. Newline characters inserted in the middle of words, characters and words placed out of order, and whitespace is handled really inconsistently (more below)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Annotations:&lt;/strong&gt; Information about interactive elements such as links, form fields, and comments. There are useful details here that we may use in the future, but, again, a lot of PDF tools generate these incorrectly.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Third, we strip out all space, newline, and other invisible characters. We do whitespace analysis to build words from individual characters. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;After extracting PDF metadata:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;We extract out character locations, font sizes, and fonts. We then do multiple passes of whitespace analysis and clustering algorithms to find groups, then try to identify what category they fall into based on heuristics. We used to rely more heavily on clustering (DBScan specifically), but found that simpler whitespace analysis often outperformed it. &lt;/p&gt; &lt;ul&gt; &lt;li&gt;If you look at a PDF and see only a handful of characters, let&amp;#39;s say 1% that are font 32, color blue, and each time they&amp;#39;re identified together it&amp;#39;s only 2-3 words it&amp;#39;s likely a header. &lt;/li&gt; &lt;li&gt;Now you see 2% are font 28, red, it&amp;#39;s probably a sub-header. (That is if the font spans multiple pages.) If it instead is only in a single location, it&amp;#39;s most likely something important in the text that the author wants us to &amp;#39;flag&amp;#39;. &lt;/li&gt; &lt;li&gt;This makes font analysis across the document important, and another reason we stay away from OCR&lt;/li&gt; &lt;li&gt;If, the document is 80% font 12, black. It&amp;#39;s probably &amp;#39;normal text.&amp;#39; Normal text needs to be categorized into two different formats, one is paragraphs, the other is bullet points/lists. &lt;/li&gt; &lt;li&gt;For bullet points we look primarily at the white space, identifying that there&amp;#39;s a significant amount of white space, often follow by a bullet point, number, or dash. &lt;/li&gt; &lt;li&gt;For paragraphs, we text together in a &amp;#39;normal&amp;#39; format without bullet points, traditionally spanning a majority of the document.&lt;/li&gt; &lt;li&gt;Junk detection. A lot of PDF&amp;#39;s have junk in them. An example would be a header that&amp;#39;s at the top of every single document, or a footer on every document saying who wrote it, the page number etc. This junk otherwise is sent to the chunking algorithm meaning you can often have random information mid-paragraph. We generate character ngram vectors and cluster then based on L1 distance (rather than cosine). That lets us find variations like &amp;quot;Page 1&amp;quot;, &amp;quot;Page 2&amp;quot;, etc. If those appear in roughly the same location on more than 20-35% of pages, it&amp;#39;s likely just repeat junk.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The product is still in beta so if you&amp;#39;re actively trying to solve this, or a similar problem, we&amp;#39;re letting people use it for free, in exchange for feedback.&lt;/p&gt; &lt;p&gt;Have additional questions? Shoot!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/coolcloud&quot;&gt; /u/coolcloud &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpbc4g/how_we_chunk_turning_pdfs_into_hierarchical/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpbc4g/how_we_chunk_turning_pdfs_into_hierarchical/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpbc4g</id><link href="https://www.reddit.com/r/LangChain/comments/1dpbc4g/how_we_chunk_turning_pdfs_into_hierarchical/" /><updated>2024-06-26T22:21:08+00:00</updated><published>2024-06-26T22:21:08+00:00</published><title>How we Chunk - turning PDF's into hierarchical structure for RAG</title></entry><entry><author><name>/u/harshit_nariya</name><uri>https://www.reddit.com/user/harshit_nariya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/harshit_nariya&quot;&gt; /u/harshit_nariya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/AnyBodyCanAI/comments/1dpkjvq/we_built_an_opensource_lowcode_multiagent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpo9li/we_built_an_opensource_lowcode_multiagent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpo9li</id><link href="https://www.reddit.com/r/LangChain/comments/1dpo9li/we_built_an_opensource_lowcode_multiagent/" /><updated>2024-06-27T10:45:04+00:00</updated><published>2024-06-27T10:45:04+00:00</published><title>We built an open-source low-code multi-agent automation framework</title></entry><entry><author><name>/u/ms-atomicbomb</name><uri>https://www.reddit.com/user/ms-atomicbomb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m hiring a fully-remote Agentic Software Developers to build, test and refine our agents, as well as the infrastructure around them. We&amp;#39;re a stealth-mode start up backed top VCs. Please feel free to reach out to me here or via Discord (@thebirthdaygirl) and I&amp;#39;d love to chat! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ms-atomicbomb&quot;&gt; /u/ms-atomicbomb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpl6ks/hiring_fullyremote_agentic_software_developers/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpl6ks/hiring_fullyremote_agentic_software_developers/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpl6ks</id><link href="https://www.reddit.com/r/LangChain/comments/1dpl6ks/hiring_fullyremote_agentic_software_developers/" /><updated>2024-06-27T07:08:04+00:00</updated><published>2024-06-27T07:08:04+00:00</published><title>Hiring fully-remote Agentic Software Developers!</title></entry><entry><author><name>/u/d2clon</name><uri>https://www.reddit.com/user/d2clon</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, people. I am a veteran programmer who is new to AI and its business use cases.&lt;/p&gt; &lt;p&gt;I am fascinated by it, and I am now working on a small prototype for a client. It is an out-of-the-book RAG case:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;~1.5K 1-page PDFs with product specs.&lt;/li&gt; &lt;li&gt;Build a chatbot to ask questions about the products.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In our team, we are making great progress in the basic setup. The PDFs are indexed in a VectorDB and we are able to use GPT4 to interact with the VectorDB data and generate human friendly answers.&lt;/p&gt; &lt;p&gt;But there is a lot to improve about the generated recomendations, conclusions, filtering, best results, ...&lt;/p&gt; &lt;p&gt;All the tutorials and documentation we are seeing end up here, in the basic setup. And don&amp;#39;t go further in the details and improvements needed to go to &amp;quot;production&amp;quot; level. Further more, I have seen that many people on this community and others are mentioning their dissapointment with the actual state of the technology and their abandom of building a RAG architecture.&lt;/p&gt; &lt;p&gt;I just want a confirmation that it is possible. That some of you have managed to build a RAG architecture that is used satisfactorily in production. Is this the case? :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/d2clon&quot;&gt; /u/d2clon &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dp7p9j/are_there_any_rag_successful_real_production_use/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dp7p9j/are_there_any_rag_successful_real_production_use/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dp7p9j</id><link href="https://www.reddit.com/r/LangChain/comments/1dp7p9j/are_there_any_rag_successful_real_production_use/" /><updated>2024-06-26T19:47:52+00:00</updated><published>2024-06-26T19:47:52+00:00</published><title>Are there any RAG successful real production use cases out there?</title></entry><entry><author><name>/u/MajorTuttle</name><uri>https://www.reddit.com/user/MajorTuttle</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Caveat: I am very new to using langchain.&lt;/p&gt; &lt;p&gt;Langsmith seems like an excellent product for enterprise and large-scale production, but beyond my needs and pricing, and seems not an easy way to export data.&lt;/p&gt; &lt;p&gt;I just want to be able to capture what is going on under the hood -- including all LLM API call inputs/outputs -- mostly to better understand how the implemented patterns (structured outputs, tool calling, etc) are done in practice. Ideally either as a data-structure for me to persist or directly to a file (JSON or JSONL or similar I can peruse and process).&lt;/p&gt; &lt;p&gt;Is there an easy way to do this?&lt;/p&gt; &lt;p&gt;Its not clear to me if the chain design just makes it challenging to implement observability (and why langsmith is needed), or if its somewhat intentionally not made clear or well-documented as langsmith and langserve are the profit centers.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MajorTuttle&quot;&gt; /u/MajorTuttle &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpjf0d/trace_to_datastructure_or_file_instead_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpjf0d/trace_to_datastructure_or_file_instead_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpjf0d</id><link href="https://www.reddit.com/r/LangChain/comments/1dpjf0d/trace_to_datastructure_or_file_instead_of/" /><updated>2024-06-27T05:12:12+00:00</updated><published>2024-06-27T05:12:12+00:00</published><title>Trace to data-structure or file instead of langsmith?</title></entry><entry><author><name>/u/link2ani</name><uri>https://www.reddit.com/user/link2ani</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/link2ani&quot;&gt; /u/link2ani &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpprkp/anyone_building_rag_app_in_javascript_what_stack/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpprkp/anyone_building_rag_app_in_javascript_what_stack/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpprkp</id><link href="https://www.reddit.com/r/LangChain/comments/1dpprkp/anyone_building_rag_app_in_javascript_what_stack/" /><updated>2024-06-27T12:10:55+00:00</updated><published>2024-06-27T12:10:55+00:00</published><title>anyone building RAG app in javascript? what stack are you using?</title></entry><entry><author><name>/u/Specialist-Cloud-448</name><uri>https://www.reddit.com/user/Specialist-Cloud-448</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have data stored in my &lt;strong&gt;DynamoDB&lt;/strong&gt; which is frequently updated through back-end services. Now I want to create a PG vector based &lt;strong&gt;AuroraDB vector database&lt;/strong&gt; for storing &lt;strong&gt;embeddings&lt;/strong&gt;, which I want to be automatically updated whenever there is the change in the DynamoDB.&lt;/p&gt; &lt;p&gt;I thought about using the &lt;strong&gt;EventBridge&lt;/strong&gt; but need more suggestion on that.&lt;/p&gt; &lt;p&gt;My aim is to create the new embeddings everytime there is the change (Upsert) in the DynamoDB and store them in the PG Vector Database. So that I can perform the RAG on &lt;strong&gt;latest embeddings&lt;/strong&gt; to so the answer from LLM must be context aware.&lt;/p&gt; &lt;p&gt;In the phase of architectural designing and ideation of this feature.&lt;/p&gt; &lt;p&gt;Any suggestions are welcomed .&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Specialist-Cloud-448&quot;&gt; /u/Specialist-Cloud-448 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpphgh/data_ingestion_for_the_rag_from_dynamo_db_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpphgh/data_ingestion_for_the_rag_from_dynamo_db_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpphgh</id><link href="https://www.reddit.com/r/LangChain/comments/1dpphgh/data_ingestion_for_the_rag_from_dynamo_db_to/" /><updated>2024-06-27T11:56:30+00:00</updated><published>2024-06-27T11:56:30+00:00</published><title>Data Ingestion for the RAG from Dynamo DB to AuroraDB with pgVector to store embeddings</title></entry><entry><author><name>/u/byrocuy</name><uri>https://www.reddit.com/user/byrocuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I am currently developing a chatbot using LangGraph, and I&amp;#39;m facing some challenges with managing state for multiple users. Specifically, I&amp;#39;m dealing with the following constraints and setup:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The state is limited only to last 10-15 messages due to the structure of API I am interacting with.&lt;/li&gt; &lt;li&gt;All the chat history will be stored in a MySQL database. I do it by storing each input and response manually to the db, as the checkpointer implementation in MySQL is not supported yet.&lt;/li&gt; &lt;li&gt;The messages will be stored in the database with the corresponding user ID. For now the chat history in the database has no function in the chatbot flow. It only serve for the frontend to load previous interaction when user open the chatbot. &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If I understand correctly, the state is stored in the runtime and shared across multiple users, right? I think this might lead to a memory problem if I don&amp;#39;t implement some way of handler or even if I limit the previous messages for each user it will lead to a problem.&lt;/p&gt; &lt;p&gt;My idea to handle this is as follows: - Store the chat history (user ID and message) in the database. - When a new query comes in, load the last 10 last messages from the database for the appropriate user ID. - Append this history with the new query and pass it to the chatbot.&lt;/p&gt; &lt;p&gt;How does my idea sound? Are there any potential pitfalls or improvements you would suggest? I&amp;#39;m open to any suggestions and feedback.&lt;/p&gt; &lt;p&gt;Thanks in advance for your help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/byrocuy&quot;&gt; /u/byrocuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpgr6p/how_to_manage_state_in_langgraph_for_multiple/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpgr6p/how_to_manage_state_in_langgraph_for_multiple/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpgr6p</id><link href="https://www.reddit.com/r/LangChain/comments/1dpgr6p/how_to_manage_state_in_langgraph_for_multiple/" /><updated>2024-06-27T02:42:53+00:00</updated><published>2024-06-27T02:42:53+00:00</published><title>How to Manage State in LangGraph for Multiple Users?</title></entry><entry><author><name>/u/sujihai</name><uri>https://www.reddit.com/user/sujihai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am currently working on integrating several components into a comprehensive chat application using LangServe and LangChain. Below, I detail the components involved and the specific issues I&amp;#39;m encountering. Any guidance or suggestions would be greatly appreciated.&lt;/p&gt; &lt;h1&gt;Components and Setup:&lt;/h1&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;History Aware Retriever and Question Answer Chain&lt;/strong&gt;: &lt;ul&gt; &lt;li&gt;I&amp;#39;ve created a chain that consists of a history-aware retriever and a question-answer chain.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&amp;#8203;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;contextualize_q_system_prompt = &amp;quot;&amp;quot;&amp;quot;Given a chat history and the latest user question \ which might reference context in the chat history, formulate a standalone question \ which can be understood without the chat history. Do NOT answer the question, \ just reformulate it if needed and otherwise return it as is.&amp;quot;&amp;quot;&amp;quot; contextualize_q_prompt = ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, contextualize_q_system_prompt), MessagesPlaceholder(&amp;quot;chat_history&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;), ] ) history_aware_retriever = create_history_aware_retriever( llm, retriever, contextualize_q_prompt ) ### Answer question ### qa_system_prompt = &amp;quot;&amp;quot;&amp;quot;You are an assistant for question-answering tasks. \ Use the following pieces of retrieved context to answer the question. \ If you don&amp;#39;t know the answer, just say that you don&amp;#39;t know. \ Use three sentences maximum and keep the answer concise.\ {context}&amp;quot;&amp;quot;&amp;quot; qa_prompt = ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, qa_system_prompt), MessagesPlaceholder(&amp;quot;chat_history&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;), ] ) question_answer_chain = create_stuff_documents_chain(llm, qa_prompt) rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain) &lt;/code&gt;&lt;/pre&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Message History Implementation&lt;/strong&gt;: &lt;ul&gt; &lt;li&gt;The application incorporates &lt;code&gt;RedisChatMessageHistory&lt;/code&gt; along with &lt;code&gt;RunnableWithMessageHistory&lt;/code&gt;. The intention is to leverage Redis for managing chat message history, tracking conversations by User ID and Conversation ID.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;LangGraph Integration&lt;/strong&gt;: &lt;ul&gt; &lt;li&gt;I&amp;#39;m attempting to integrate this setup into LangGraph. However, I&amp;#39;m facing challenges because LangGraph documentation suggests using Checkpoints with SQLite, and it&amp;#39;s unclear how to integrate RedisChatMessageHistory which is essential for my application.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt; &lt;h1&gt;Issues:&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Integration with LangGraph&lt;/strong&gt;: How can I integrate &lt;code&gt;RedisChatMessageHistory&lt;/code&gt; within LangGraph, given that LangGraph primarily supports SQLite for Checkpoints?&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Consistent Message History&lt;/strong&gt;: I need to ensure that message history capabilities are maintained across the entire application, allowing tracking of conversations by User ID and Conversation ID.&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Resources:&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;For the retrieval chain setup, please refer to the LangChain documentation on question answering with chat history: &lt;a href=&quot;https://python.langchain.com/v0.1/docs/use_cases/question_answering/chat_history/#tying-it-together&quot;&gt;LangChain QA with Chat History&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;For details on managing persistent chat with user IDs and conversation IDs, see this example from LangServe: &lt;a href=&quot;https://github.com/langchain-ai/langserve/blob/main/examples/chat_with_persistence_and_user/server.py&quot;&gt;LangServe Chat with Persistence&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Request:&lt;/h1&gt; &lt;p&gt;I am seeking advice or examples on how to properly integrate RedisChatMessageHistory with LangGraph in a manner that maintains full functionality of the message history features. Any insights or pointers towards documentation or similar implementations would be incredibly helpful.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sujihai&quot;&gt; /u/sujihai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dposfd/integration_issues_with_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dposfd/integration_issues_with_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dposfd</id><link href="https://www.reddit.com/r/LangChain/comments/1dposfd/integration_issues_with_langgraph/" /><updated>2024-06-27T11:16:17+00:00</updated><published>2024-06-27T11:16:17+00:00</published><title>Integration Issues with LangGraph, RedisChatMessageHistory, and RunnableWithMessageHistory</title></entry><entry><author><name>/u/Early_Low8914</name><uri>https://www.reddit.com/user/Early_Low8914</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;When calling the retriever directly, I get a response which includes the content + metadata.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;retriever = documents.as_retriever(search_kwargs={&amp;quot;k&amp;quot;: 1}) retriever.get_relevant_documents(&amp;quot;foo&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The response:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;[Document(page_content=&amp;#39;foo&amp;#39;, metadata={&amp;#39;tenant_id&amp;#39;: &amp;#39;0d122190-b761-43f7-9ea3-f1842bbe1c4d&amp;#39;, &amp;#39;page&amp;#39;: 7})] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When i wrap the retriever with the utiliy function provided by langchain: &amp;quot;create_retriever_tool&amp;quot;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;tool: Tool = create_retriever_tool(documents.as_retriever(search_kwargs={ &amp;quot;k&amp;quot;: 6}), name=&amp;quot;search_documents&amp;quot;, description=&amp;quot;Search documents&amp;quot;) tool.invoke(&amp;quot;foo&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The response:&lt;/p&gt; &lt;p&gt;&amp;#39;foo&amp;#39;&lt;/p&gt; &lt;p&gt;So in this case, the metadata part is completely missing. I understand that I could use a prompt_template which includes the metadata:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;document_prompt = PromptTemplate.from_template( &amp;quot;Document chunk metadata: tenant_id: {tenant_id}...\n&amp;quot; &amp;quot;Document chunk content: {page_content}. &amp;quot; ) tool: Tool = create_retriever_tool(documents.as_retriever(search_kwargs={ &amp;quot;k&amp;quot;: 6}), name=&amp;quot;search_documents&amp;quot;, description=&amp;quot;Search documents&amp;quot;, document_prompt=document_prompt) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and this works but the output from directly calling retriever.get_relevant_documents(&amp;quot;foo&amp;quot;) is a document array which makes it easier to work with.&lt;/p&gt; &lt;p&gt;I would like to have the exact same output from the response of calling the tool. How can this be achieved? Is the only solution to create a custom tool function instead of using the utility function?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Early_Low8914&quot;&gt; /u/Early_Low8914 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpntgo/how_to_get_a_structured_response_from_create/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpntgo/how_to_get_a_structured_response_from_create/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpntgo</id><link href="https://www.reddit.com/r/LangChain/comments/1dpntgo/how_to_get_a_structured_response_from_create/" /><updated>2024-06-27T10:16:00+00:00</updated><published>2024-06-27T10:16:00+00:00</published><title>How to get a structured response from &quot;create_retriever_tool&quot;?</title></entry><entry><author><name>/u/WesEd178</name><uri>https://www.reddit.com/user/WesEd178</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello I am using create_sql_agent to query a SQL server database. The problem is for some reason the agent does not know that it has to use SQL server dialect from the beginning and also does not know the column names.&lt;/p&gt; &lt;p&gt;Is there a way to provide this initial context to the prompt?&lt;/p&gt; &lt;p&gt;This is my code: llm = ChatOpenAI(model=&amp;quot;gpt-3.5-turbo-0125&amp;quot;, temperature=0) toolkit = SQLDatabaseToolkit(db=db, llm=llm) agent_executor = create_sql_agent( llm=llm, toolkit=toolkit, verbose=True, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, )&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/WesEd178&quot;&gt; /u/WesEd178 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpbl5e/add_context_to_create_sql_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpbl5e/add_context_to_create_sql_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpbl5e</id><link href="https://www.reddit.com/r/LangChain/comments/1dpbl5e/add_context_to_create_sql_agent/" /><updated>2024-06-26T22:32:10+00:00</updated><published>2024-06-26T22:32:10+00:00</published><title>Add context to create_sql_agent</title></entry><entry><author><name>/u/fizzbyte</name><uri>https://www.reddit.com/user/fizzbyte</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How are people versioning their RAG pipelines? &lt;/p&gt; &lt;p&gt;I&amp;#39;ve found that with context which changes/needs frequent updates, we need some type of versioning strategy. &lt;/p&gt; &lt;p&gt;Has anyone else run into this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/fizzbyte&quot;&gt; /u/fizzbyte &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dp9m83/versioning_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dp9m83/versioning_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dp9m83</id><link href="https://www.reddit.com/r/LangChain/comments/1dp9m83/versioning_rag/" /><updated>2024-06-26T21:08:28+00:00</updated><published>2024-06-26T21:08:28+00:00</published><title>Versioning RAG</title></entry><entry><author><name>/u/Pokedrive123</name><uri>https://www.reddit.com/user/Pokedrive123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So I have a doubt, I figured out how to get responses back in a certain format using the Json output parsers. I want to know how I can map a response to an intent. Like I want to create an AI Agent. So if the query is &amp;quot;hey I wanna change my password I think I forgot it&amp;quot; it should map it to a task &amp;quot;reset password&amp;quot;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Pokedrive123&quot;&gt; /u/Pokedrive123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpcfh2/how_do_i_map_a_user_query_and_response_with_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpcfh2/how_do_i_map_a_user_query_and_response_with_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dpcfh2</id><link href="https://www.reddit.com/r/LangChain/comments/1dpcfh2/how_do_i_map_a_user_query_and_response_with_a/" /><updated>2024-06-26T23:09:48+00:00</updated><published>2024-06-26T23:09:48+00:00</published><title>How do I map a user query and response with a certain set of predefined tasks using output parsers?</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dozoeg/use_vannaai_for_texttosql_much_more_reliable_than/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/pwyRXfL2Ycu4z8g64OAgl3-QdCbQ5hpoAQFAUL8tfcY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1176c8ca4c10ea82cf4ba1098828274d2c6158fd&quot; alt=&quot;Use Vanna.ai for text-to-SQL much more reliable than othe r orchestration solutions, here is how to use it for Claude Sonnet 3.5 &quot; title=&quot;Use Vanna.ai for text-to-SQL much more reliable than othe r orchestration solutions, here is how to use it for Claude Sonnet 3.5 &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://arslanshahid-1997.medium.com/build-a-text-to-sql-chatbot-with-claude-sonnet-3-5-621a5bf9f922&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dozoeg/use_vannaai_for_texttosql_much_more_reliable_than/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dozoeg</id><media:thumbnail url="https://external-preview.redd.it/pwyRXfL2Ycu4z8g64OAgl3-QdCbQ5hpoAQFAUL8tfcY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1176c8ca4c10ea82cf4ba1098828274d2c6158fd" /><link href="https://www.reddit.com/r/LangChain/comments/1dozoeg/use_vannaai_for_texttosql_much_more_reliable_than/" /><updated>2024-06-26T14:15:53+00:00</updated><published>2024-06-26T14:15:53+00:00</published><title>Use Vanna.ai for text-to-SQL much more reliable than othe r orchestration solutions, here is how to use it for Claude Sonnet 3.5</title></entry><entry><author><name>/u/MercuriusExMachina</name><uri>https://www.reddit.com/user/MercuriusExMachina</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1doyeb0/how_to_have_secondary_agent_ask_for/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/ga4yvvma2x8d1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=521034eb3eff55cc204c99790c4263bb19f756eb&quot; alt=&quot;How to have secondary agent ask for clarifications from the primary agent?&quot; title=&quot;How to have secondary agent ask for clarifications from the primary agent?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MercuriusExMachina&quot;&gt; /u/MercuriusExMachina &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/ga4yvvma2x8d1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1doyeb0/how_to_have_secondary_agent_ask_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1doyeb0</id><media:thumbnail url="https://preview.redd.it/ga4yvvma2x8d1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=521034eb3eff55cc204c99790c4263bb19f756eb" /><link href="https://www.reddit.com/r/LangChain/comments/1doyeb0/how_to_have_secondary_agent_ask_for/" /><updated>2024-06-26T13:17:27+00:00</updated><published>2024-06-26T13:17:27+00:00</published><title>How to have secondary agent ask for clarifications from the primary agent?</title></entry><entry><author><name>/u/alex6011</name><uri>https://www.reddit.com/user/alex6011</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I&amp;#39;m building a RAG app with Langchain.js. It&amp;#39;s my first time using LLM framework, thus first time using Langchain too. I&amp;#39;m currently using the Recursive URL Loader integration to recursively fetch data from websites. And, behave as I wanted, but I have some issue with websites using modern frontend frameworks. So, I tried the Playwright Langchain integration (I&amp;#39;m a bit familiar with Playwright), and it&amp;#39;s work on the desired websites, but as you guess, it only works on one page. So my question is there is an integration that do both? Handling JS and recursively browse the website, or how can I combine the two to achieve my goal? I&amp;#39;m open to alternative solution using Puppeteer or even Python example.&lt;/p&gt; &lt;p&gt;This is how I use the Recursive URL Loader:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import { RecursiveUrlLoader } from &amp;#39;@langchain/community/document_loaders/web/recursive_url&amp;#39;; import { compile } from &amp;#39;html-to-text&amp;#39;; export async function loadWebsite(url: string, excludeDirs?: string[]) { const compiledConvert = compile({ wordwrap: 130 }); // returns (text: string) =&amp;gt; string; const loader = new RecursiveUrlLoader(url, { extractor: compiledConvert, maxDepth: 1, excludeDirs, preventOutside: true, }); return loader.load(); } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And, this is my Playwright attempt:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import { PlaywrightWebBaseLoader } from &amp;#39;@langchain/community/document_loaders/web/playwright&amp;#39;; import { MozillaReadabilityTransformer } from &amp;#39;@langchain/community/document_transformers/mozilla_readability&amp;#39;; import { RunnableSequence } from &amp;#39;@langchain/core/runnables&amp;#39;; import { RecursiveCharacterTextSplitter } from &amp;#39;@langchain/textsplitters&amp;#39;; export async function loadWebsite(url: string) { const loader = new PlaywrightWebBaseLoader(url, { launchOptions: { chromiumSandbox: false, }, }); const documents = await loader.load(); const transformChain = RunnableSequence.from([ RecursiveCharacterTextSplitter.fromLanguage(&amp;#39;html&amp;#39;), new MozillaReadabilityTransformer(), ]); return transformChain.invoke(documents); } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Thanks for reading! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/alex6011&quot;&gt; /u/alex6011 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1doudja/how_to_use_recursive_url_loader_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1doudja/how_to_use_recursive_url_loader_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1doudja</id><link href="https://www.reddit.com/r/LangChain/comments/1doudja/how_to_use_recursive_url_loader_with/" /><updated>2024-06-26T09:24:56+00:00</updated><published>2024-06-26T09:24:56+00:00</published><title>How to use Recursive URL Loader with Playwright/Puppeteer?</title></entry><entry><author><name>/u/Electrical_Art_1518</name><uri>https://www.reddit.com/user/Electrical_Art_1518</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m creating a chatbot using the OpenAI Assistant API and considering LangChain. Should I use it?&lt;/p&gt; &lt;p&gt;What are the pros and cons?&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Electrical_Art_1518&quot;&gt; /u/Electrical_Art_1518 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dosb9q/should_i_use_langchain_for_building_a_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dosb9q/should_i_use_langchain_for_building_a_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dosb9q</id><link href="https://www.reddit.com/r/LangChain/comments/1dosb9q/should_i_use_langchain_for_building_a_chatbot/" /><updated>2024-06-26T06:57:51+00:00</updated><published>2024-06-26T06:57:51+00:00</published><title>Should I Use LangChain for Building a Chatbot with OpenAI Assistant API?</title></entry><entry><author><name>/u/harshit_nariya</name><uri>https://www.reddit.com/user/harshit_nariya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/harshit_nariya&quot;&gt; /u/harshit_nariya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/AnyBodyCanAI/comments/1dovwah/which_llm_better_for_code_generation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dovx5a/which_llm_better_for_code_generation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dovx5a</id><link href="https://www.reddit.com/r/LangChain/comments/1dovx5a/which_llm_better_for_code_generation/" /><updated>2024-06-26T11:06:36+00:00</updated><published>2024-06-26T11:06:36+00:00</published><title>which llm better for code generation?</title></entry><entry><author><name>/u/ztide_ad</name><uri>https://www.reddit.com/user/ztide_ad</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So, I want to automate the form-filling section. For example, here I am taking Redmine. that is basically a chatbot that will interact with the user and change values in afield according to the input given by the user. for now, I have planned to create a text-to-JSON chatbot using some free open-source LLM that will help the user change the fields by changing the natural language entered by the user to JSON format, which will be sent to execute, and the user can see the fields be changed accordingly. &lt;/p&gt; &lt;p&gt;so, how can I implement something like this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ztide_ad&quot;&gt; /u/ztide_ad &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dovvd2/how_to_automate_form_filling_using_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dovvd2/how_to_automate_form_filling_using_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dovvd2</id><link href="https://www.reddit.com/r/LangChain/comments/1dovvd2/how_to_automate_form_filling_using_llm/" /><updated>2024-06-26T11:03:43+00:00</updated><published>2024-06-26T11:03:43+00:00</published><title>How to automate form filling using LLM ?</title></entry><entry><author><name>/u/harshit_nariya</name><uri>https://www.reddit.com/user/harshit_nariya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/harshit_nariya&quot;&gt; /u/harshit_nariya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/AnyBodyCanAI/comments/1dovayv/how_do_i_evaluate_the_performance_of_different/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dovcxm/how_do_i_evaluate_the_performance_of_different/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dovcxm</id><link href="https://www.reddit.com/r/LangChain/comments/1dovcxm/how_do_i_evaluate_the_performance_of_different/" /><updated>2024-06-26T10:31:32+00:00</updated><published>2024-06-26T10:31:32+00:00</published><title>How do I evaluate the performance of different embedding algorithms in RAG?</title></entry><entry><author><name>/u/trj_flash75</name><uri>https://www.reddit.com/user/trj_flash75</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been working on RAG and LLM, and I&amp;#39;ve developed something I think you&amp;#39;ll find useful: BeyondLLM.&lt;/p&gt; &lt;p&gt;It&amp;#39;s a tool I&amp;#39;ve created to simplify the process of building advanced AI applications. With just a few lines of code, you can dive into Retrieval-Augmented Generation and Large Language Models. Plus, it&amp;#39;s open source!&lt;/p&gt; &lt;p&gt;Now, here&amp;#39;s the latest update: BeyondLLM now includes additional features:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Fine Tune Embeddings: Customize your model&amp;#39;s embeddings for improved performance.&lt;/li&gt; &lt;li&gt;Observability: Easily monitor your model&amp;#39;s performance.&lt;/li&gt; &lt;li&gt;Groq LLM: Experience faster inference times for low latency applications.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you&amp;#39;re interested, you can check out BeyondLLM on GitHub: &lt;a href=&quot;https://github.com/aiplanethub/beyondllm/&quot;&gt;BeyondLLM GitHub&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/trj_flash75&quot;&gt; /u/trj_flash75 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dowgnt/evaluating_open_source_llm_for_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dowgnt/evaluating_open_source_llm_for_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dowgnt</id><link href="https://www.reddit.com/r/LangChain/comments/1dowgnt/evaluating_open_source_llm_for_rag/" /><updated>2024-06-26T11:38:09+00:00</updated><published>2024-06-26T11:38:09+00:00</published><title>Evaluating Open Source LLM for RAG</title></entry><entry><author><name>/u/Danidre</name><uri>https://www.reddit.com/user/Danidre</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;h1&gt;Preamble&lt;/h1&gt; &lt;p&gt;What I&amp;#39;ve realized through blogs and experience, is that it is best to have different agents for different purposes. E.G.: one agent for docs RAG, one agent for API calls, one agent for SQL queries.&lt;/p&gt; &lt;p&gt;These agents, by themselves, work quite fine when used in a conversational sense. You can prompt the agent for API calls to reply with follow-up questions to obtain the remaining required parameters for the specific request to be made, based on the user request, and then execute the tool call (fetch request).&lt;/p&gt; &lt;p&gt;Similarly, the agent for docs RAG can send a response, and the user can follow up with a vague question. The LLM will have the context to know what they&amp;#39;re referring to.&lt;/p&gt; &lt;h1&gt;Problem&lt;/h1&gt; &lt;p&gt;But how can we merge these three together? I know there are different design patterns such as Hierarchy, and Supervisor. Supervisor sounds like the better approach for this use case: creating a 3th supervisor agent that takes the user request and delegates it to one of the 3 specialized agents. However, these only seem to work when each request perform the action and respond completely in one invocation.&lt;/p&gt; &lt;p&gt;If the supervisor agent delegates to the API calling agent, and that agent responds with a follow-up question for more information, it goes back up the hierarchy to the supervisor agent and the follow-up question is returned as the response to the user. So if the user then sends more information, of course the invocation starts back at the supervisor agent.&lt;/p&gt; &lt;p&gt;How does it keep track of the last sub-agent invoked, whether a user response is to answer a follow-up question, re-invoke the previous agent, whether the user response deviated and required a new agent to be invoked, etc? I have a few ideas, let me know which ones you guys have experienced?&lt;/p&gt; &lt;h1&gt;Ideas&lt;/h1&gt; &lt;h1&gt;Manual Tracking&lt;/h1&gt; &lt;p&gt;Rather than a 4th agent, the user message is first passed to an LLM with definitions of the types of agents. It&amp;#39;s job is to respond with the name of the agent most likely to handle this request. That agent is then invoked. The last agent called, as well as it&amp;#39;s last response is stored. Follow up user messages call this LLM again with definitions of the type of agents, the message, the last agent invoked, and the last message it replied. The LLM will use this context to determine if it should call that same agent again with the new user message, or another agent instead.&lt;/p&gt; &lt;h1&gt;Supervisor Agent with Agent Named as Messages State&lt;/h1&gt; &lt;p&gt;Each sub-agent will have its own isolated messages list, however the supervisor agent will track messages by the name of the agent, to determine who best to delegate the request to. However, it will only track the last response from each invoked agent.&lt;/p&gt; &lt;h1&gt;Example Conversation:&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;User: Hi Agent: Hi, how can I help you today? User: What is the purpose of this company? Agent: *delegates to RAG agent User: What is the purpose of this company? RAG Agent: *tool calls RAG search Tool: ...company purpose...categories... RAG Agent: This company manages categories.... Agent: This company manages categories.... User: I want to create another category Agent: *delegates to API agent User: I want to create another category API Agent: What is the category name and how many stars? Agent: What is the category name and how many stars? User: Name it Category 5 Agent: *delegates to API agent User: Name it Category 5 API Agent: How many stars (1-5)? Agent: How many stars (1-5)? User: 5 Agent: *delegates to API agent User: 5 API Agent: *tool call endpoint with required params Tool: success API Agent: You have successfully created Category 5. Agent: You have successfully created Category 5. User: How many categories have been created today Agent: *delegates to SQL Agent User: How many categories have been created today SQL Agent: *tool calls sql query generation Tool: select count(1) from categories... SQL Agent: *tool calls sql query execution Tool: (8) SQL Agent: 8 categories have been created today. Agent: 8 categories have been created today. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The history for each agent may be as follows:&lt;/p&gt; &lt;p&gt;RAG Agent:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;User: What is the purpose of this company? Agent: *tool calls RAG search Tool: ...company purpose...categories... Agent: This company manages categories.... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;API Agent:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;User: I want to create another category Agent: What is the category name and how many stars? User: Name it Category 5 Agent: How many stars (1-5)? User: 5 Agent: *tool call endpoint with required params Tool: success Agent: You have successfully created Category 5. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;SQL Agent:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;User: How many categories have been created today SQL Agent: *tool calls sql query generation Tool: select count(1) from categories... SQL Agent: *tool calls sql query execution Tool: (8) SQL Agent: 8 categories have been created today. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Supervisor Agent:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;System: You are a supervisor Agent with the following assistants: RAG Agent helps when.... API Agent helps when.... SQL Agent helps when.... At different times during the conversation, your assistants may interject to respond to the user based on their specialty. Whenever the user responds, based on the history, determine which one of your assistants should respond next. User: Hi Agent: Hi, how can I help you today? User: What is the purpose of this company? RAG Agent: This company manages categories.... User: I want to create another category API Agent: What is the category name and how many stars? User: Name it Category 5 API Agent: How many stars (1-5)? User: 5 API Agent: You have successfully created Category 5. User: How many categories have been created today SQL Agent: 8 categories have been created today. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Perhaps like this, it can better determine who to delegate future responses to. This by itself already seems a bit more complex than seen developed so far. However, there are still things to consider, such as when the user changes their mind, how would delegation work?&lt;/p&gt; &lt;h1&gt;Example Conversation:&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;User: Hi Agent: Hi, how can I help you today? User: What is the purpose of this company? Agent: *delegates to RAG agent User: What is the purpose of this company? RAG Agent: *tool calls RAG search Tool: ...company purpose...categories... RAG Agent: This company manages categories.... Agent: This company manages categories.... User: I want to create another category Agent: *delegates to API agent User: I want to create another category API Agent: What is the category name and how many stars? Agent: What is the category name and how many stars? User: How many categories have been created today? &amp;lt;-- new request, not meant to be the category name Agent: *delegates to SQL Agent User: How many categories have been created today? SQL Agent: *tool calls sql query generation Tool: select count(1) from categories... SQL Agent: *tool calls sql query execution Tool: (9) SQL Agent: 9 categories have been created today. Agent: 9 categories have been created today. User: Okay. I want to create a sub-category. Agent: *delegates to API agent User: Okay. I want to create a sub-category. API Agent: I&amp;#39;m sorry, you cannot create sub-categories. Agent: I&amp;#39;m sorry, you cannot create sub-categories. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The history for each agent may be as follows:&lt;/p&gt; &lt;p&gt;RAG Agent:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;User: What is the purpose of this company? Agent: *tool calls RAG search Tool: ...company purpose...categories... Agent: This company manages categories.... &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;API Agent:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;User: I want to create another category Agent: What is the category name and how many stars? User: Okay. I want to create a sub-category. &amp;lt;-- somehow it knows this is meant as a new request, and not part of the category name as above Agent: I&amp;#39;m sorry, you cannot create sub-categories. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;SQL Agent:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;User: How many categories have been created today? Agent: *tool calls sql query generation Tool: select count(1) from categories... Agent: *tool calls sql query execution Tool: (9) Agent: 9 categories have been created today. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Supervisor Agent:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;System: You are a supervisor Agent with the following assistants: RAG Agent helps when.... API Agent helps when.... SQL Agent helps when.... At different times during the conversation, your assistants may interject to respond to the user based on their specialty. Whenever the user responds, based on the history, determine which one of your assistants should respond next. User: Hi Agent: Hi, how can I help you today? User: What is the purpose of this company? RAG Agent: This company manages categories.... User: I want to create another category API Agent: What is the category name and how many stars? User: How many categories have been created today? &amp;lt;-- new request, not meant to be the category name. somehow it knows to delegate to SQL Agent instead SQL Agent: 9 categories have been created today. User: Okay. I want to create a sub-category. API Agent: I&amp;#39;m sorry, you cannot create sub-categories. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To solve this, maybe there should be an additional step that re-crafts the user prompt before delegating it to each sub-agent?&lt;/p&gt; &lt;p&gt;Does anyone have experiences with these in LangGraph?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Danidre&quot;&gt; /u/Danidre &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dogdy8/multiagent_conversational_graph_designs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dogdy8/multiagent_conversational_graph_designs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dogdy8</id><link href="https://www.reddit.com/r/LangChain/comments/1dogdy8/multiagent_conversational_graph_designs/" /><updated>2024-06-25T20:47:49+00:00</updated><published>2024-06-25T20:47:49+00:00</published><title>Multi-Agent Conversational Graph Designs</title></entry><entry><author><name>/u/Lost-Season-4196</name><uri>https://www.reddit.com/user/Lost-Season-4196</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to host my app on AWS with multiple GPUs. I tried Llama-Index, but they do not support multi-GPU setups as far as I know. How can I run Hugging Face models on multiple GPUs?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Lost-Season-4196&quot;&gt; /u/Lost-Season-4196 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1doszle/multi_gpu_support/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1doszle/multi_gpu_support/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1doszle</id><link href="https://www.reddit.com/r/LangChain/comments/1doszle/multi_gpu_support/" /><updated>2024-06-26T07:45:04+00:00</updated><published>2024-06-26T07:45:04+00:00</published><title>Multi GPU support</title></entry><entry><author><name>/u/Mission_Rain7133</name><uri>https://www.reddit.com/user/Mission_Rain7133</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Anyone knows if LangGraph integrates with Bedrock and what are the capabilties. I am quite new to this and I was following the langChain youtube series on LangGraph and they used a lot of OpenAI Functions so I wanted to know if it was possible to do the same with Bedrock models?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mission_Rain7133&quot;&gt; /u/Mission_Rain7133 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dosz4u/langgraph_integration_with_bedrock/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dosz4u/langgraph_integration_with_bedrock/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dosz4u</id><link href="https://www.reddit.com/r/LangChain/comments/1dosz4u/langgraph_integration_with_bedrock/" /><updated>2024-06-26T07:44:13+00:00</updated><published>2024-06-26T07:44:13+00:00</published><title>LangGraph integration with bedrock</title></entry></feed>