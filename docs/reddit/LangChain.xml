<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-26T03:02:53+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/gswithai</name><uri>https://www.reddit.com/user/gswithai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi there! As you may know I often post here about my latest &lt;a href=&quot;https://www.gettingstarted.ai/tag/langchain&quot;&gt;LangChain tutorials and articles&lt;/a&gt;. I was recently introduced to Embedchain, a Python library built on top of LangChain that takes care of your RAG needs in a few lines of Python code. It basically does all of the following for you right out-of-the-box:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Sets up local Chroma DB&lt;/li&gt; &lt;li&gt;Takes in data source (URL, YouTube, PDF, etc…)&lt;/li&gt; &lt;li&gt;Makes chunks out of the data&lt;/li&gt; &lt;li&gt;Converts the chunks to embeddings&lt;/li&gt; &lt;li&gt;Stores the embeddings on the vector database&lt;/li&gt; &lt;li&gt;Performs similarity search&lt;/li&gt; &lt;li&gt;Query a large language model&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Long story short, I took it for a spin and &lt;a href=&quot;https://www.gettingstarted.ai/what-is-the-difference-between-embedchain-and-langchain/&quot;&gt;wrote about it here&lt;/a&gt; specifically, comparing it with LangChain.&lt;/p&gt; &lt;p&gt;If you‘re looking for a tool that lets you build a RAG app quickly, give it a try. You may find it suitable for your use case.&lt;/p&gt; &lt;p&gt;Let me know what you think!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gswithai&quot;&gt; /u/gswithai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fhmbv/langchain_is_awesome_but_have_you_tried_embedchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fhmbv/langchain_is_awesome_but_have_you_tried_embedchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19fhmbv</id><link href="https://www.reddit.com/r/LangChain/comments/19fhmbv/langchain_is_awesome_but_have_you_tried_embedchain/" /><updated>2024-01-25T19:31:24+00:00</updated><published>2024-01-25T19:31:24+00:00</published><title>LangChain is awesome, but have you tried Embedchain?</title></entry><entry><author><name>/u/whir_of_invention</name><uri>https://www.reddit.com/user/whir_of_invention</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on a project that involves querying a database using natural language, and I&amp;#39;m trying to decide between using Langchain SQL and the GPT-4 SQL function. From my understanding, Langchain SQL specializes in converting natural language into SQL queries, which seems ideal for direct database interaction. On the other hand, gpt4 can also generate sqls directly with function calling. So it seems there is no need to use Langchain anymore.&lt;/p&gt; &lt;p&gt;I&amp;#39;d appreciate insights or experiences from anyone who has used either Langchain SQL or GPT-4 for similar purposes.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/whir_of_invention&quot;&gt; /u/whir_of_invention &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ffzyk/choosing_between_langchain_sql_and_gpt4_sql/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ffzyk/choosing_between_langchain_sql_and_gpt4_sql/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ffzyk</id><link href="https://www.reddit.com/r/LangChain/comments/19ffzyk/choosing_between_langchain_sql_and_gpt4_sql/" /><updated>2024-01-25T18:22:45+00:00</updated><published>2024-01-25T18:22:45+00:00</published><title>Choosing Between Langchain SQL and GPT-4 SQL Function</title></entry><entry><author><name>/u/3RiversAINexus</name><uri>https://www.reddit.com/user/3RiversAINexus</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for the best LLM currently for agentic behavior in langchain. By best, I mean the most consistent with the least parsing errors.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/3RiversAINexus&quot;&gt; /u/3RiversAINexus &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fnp1g/what_is_the_best_local_llm_for_agentic_behavior/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fnp1g/what_is_the_best_local_llm_for_agentic_behavior/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19fnp1g</id><link href="https://www.reddit.com/r/LangChain/comments/19fnp1g/what_is_the_best_local_llm_for_agentic_behavior/" /><updated>2024-01-25T23:57:00+00:00</updated><published>2024-01-25T23:57:00+00:00</published><title>What is the best local LLM for agentic behavior?</title></entry><entry><author><name>/u/romeinday1</name><uri>https://www.reddit.com/user/romeinday1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let us say we have a simple spec like this below:&lt;/p&gt; &lt;p&gt;set my_property to 1, when condition1 is met&lt;/p&gt; &lt;p&gt;set my_property to 2, when condition2 is met&lt;/p&gt; &lt;p&gt;set my_property to 3, when condition3 and condition33 are both met&lt;/p&gt; &lt;p&gt;set my_property to 4, when condition4 is met&lt;/p&gt; &lt;p&gt;Then this is python code below:&lt;/p&gt; &lt;p&gt;if condition1:&lt;/p&gt; &lt;p&gt;my_property to 1&lt;/p&gt; &lt;p&gt;elif condition2:&lt;/p&gt; &lt;p&gt;my_property to -2929 # people making error here&lt;/p&gt; &lt;p&gt;elif condition3 and condition33:&lt;/p&gt; &lt;p&gt;my_property to 3&lt;/p&gt; &lt;p&gt;elif ...&lt;/p&gt; &lt;p&gt;This is an extremely simple example. I am wondering if langchain or other popular LLM library can somehow help us engineers achieve this to make our lives easier. I know langchain can somehow compare two similar (let us say earning report pdf) but not sure if it can help, even just a little bit, to spot any mistaken typo between spec and implementation?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/romeinday1&quot;&gt; /u/romeinday1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fma04/anyway_to_compare_a_spec_word_or_excel_with_its/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fma04/anyway_to_compare_a_spec_word_or_excel_with_its/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19fma04</id><link href="https://www.reddit.com/r/LangChain/comments/19fma04/anyway_to_compare_a_spec_word_or_excel_with_its/" /><updated>2024-01-25T22:53:36+00:00</updated><published>2024-01-25T22:53:36+00:00</published><title>Anyway to compare a spec (word or excel) with its programming implementation for any gap/error</title></entry><entry><author><name>/u/throwawayrandomvowel</name><uri>https://www.reddit.com/user/throwawayrandomvowel</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on a project like this for another dataset, but I don&amp;#39;t see why I can&amp;#39;t apply it to my own repo. I love using GPT for coding productivity, but one of the limitations is in api-type environments with multiple files and dependencies flying around - it&amp;#39;s difficult to share all the relevant information to your agent or chatbot. &lt;/p&gt; &lt;p&gt;Is there anything like this currently available? This isn&amp;#39;t exactly rocket scient to start. If not, I&amp;#39;ll start working on it&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/throwawayrandomvowel&quot;&gt; /u/throwawayrandomvowel &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fgnin/ragd_repo_and_multiagent_chatbot_for_advanced/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fgnin/ragd_repo_and_multiagent_chatbot_for_advanced/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19fgnin</id><link href="https://www.reddit.com/r/LangChain/comments/19fgnin/ragd_repo_and_multiagent_chatbot_for_advanced/" /><updated>2024-01-25T18:50:52+00:00</updated><published>2024-01-25T18:50:52+00:00</published><title>RAG'd Repo and multi-agent chatbot for advanced codebase support?</title></entry><entry><author><name>/u/Gullible-Being-8595</name><uri>https://www.reddit.com/user/Gullible-Being-8595</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am working on a project where I want to use LLMs (GPT4) to summarize the data from a website. First, I want to scrap all the data from the all the links available in that website and then I want to use GPT4 to summarize the data. I can get the summarization part done easily but how can I build a scrapper which can scrap the data from a website. For example;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;If the website is a restaurant website then I would want to go over all the links in that site. It will be an iterative process and somehow I need to keep the already visited/scrapped links so that I shouldn&amp;#39;t scrap it again. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Is there any framework or already built library/API available for this purpose?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Gullible-Being-8595&quot;&gt; /u/Gullible-Being-8595 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fadp1/advance_scrapping_with_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fadp1/advance_scrapping_with_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19fadp1</id><link href="https://www.reddit.com/r/LangChain/comments/19fadp1/advance_scrapping_with_llm/" /><updated>2024-01-25T14:19:16+00:00</updated><published>2024-01-25T14:19:16+00:00</published><title>Advance Scrapping with LLM</title></entry><entry><author><name>/u/Javierrrrrrrrrrrrrrr</name><uri>https://www.reddit.com/user/Javierrrrrrrrrrrrrrr</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been testing langserve with llama2, Mistral and falcon 7b. I&amp;#39;m struggling with concurrence problems when sending concurrent request to langchain (only one request is processed, the other error 500, weird output for the only successful reques). I&amp;#39;ve tested those models concurrence outside langserve (with async calls) also failing. So, it&amp;#39;s not a langserve problem, the models are not handling concurrence (even with things like vllm for model loading).&lt;/p&gt; &lt;p&gt;Somebody else has faced a similar issue?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Javierrrrrrrrrrrrrrr&quot;&gt; /u/Javierrrrrrrrrrrrrrr &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fkd55/model_concurrence/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fkd55/model_concurrence/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19fkd55</id><link href="https://www.reddit.com/r/LangChain/comments/19fkd55/model_concurrence/" /><updated>2024-01-25T21:27:41+00:00</updated><published>2024-01-25T21:27:41+00:00</published><title>Model concurrence</title></entry><entry><author><name>/u/Sad_Reporter910</name><uri>https://www.reddit.com/user/Sad_Reporter910</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;System Prompt with ConversationalRetrievalChain: I am a newb playing with open-ai, chat-gpt, and langchain. Using open-ai api&amp;#39;s directly, I am able to set a system prompt to prepare the llm to respond to all all my interactions with the initial system prompt instructions. Now I am using langchain&amp;#39;s ConversationalRetrievalChain to try to interact with custom content. I have it working, but I would like to give the underlying llm (gpt-4) a system prompt as I do using the open-ai api&amp;#39;s directly. How can I do this? e.g. &amp;quot;You are a helpful sale agent named Joe that works for ACME CO. Try to respond with links to products sold by ACME CO&amp;quot;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sad_Reporter910&quot;&gt; /u/Sad_Reporter910 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fgxzb/how_do_i_get_conversationalretrievalchain_to_use/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19fgxzb/how_do_i_get_conversationalretrievalchain_to_use/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19fgxzb</id><link href="https://www.reddit.com/r/LangChain/comments/19fgxzb/how_do_i_get_conversationalretrievalchain_to_use/" /><updated>2024-01-25T19:03:06+00:00</updated><published>2024-01-25T19:03:06+00:00</published><title>How do I get ConversationalRetrievalChain to use a System Prompt?</title></entry><entry><author><name>/u/Capable_Juice98</name><uri>https://www.reddit.com/user/Capable_Juice98</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Recently I&amp;#39;ve been working on rags using langachain. I also started a course on RAGs in deeplearning.ai, where they discussed advanced rag techniques, like sentence window retrieval and automerging retrieval But the course is mainly in llama index I&amp;#39;m wondering if I can do some advanced retrieval in Langchain without api key&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Capable_Juice98&quot;&gt; /u/Capable_Juice98 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19f5sqj/advanced_rags_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19f5sqj/advanced_rags_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19f5sqj</id><link href="https://www.reddit.com/r/LangChain/comments/19f5sqj/advanced_rags_in_langchain/" /><updated>2024-01-25T09:49:39+00:00</updated><published>2024-01-25T09:49:39+00:00</published><title>Advanced Rags in Langchain</title></entry><entry><author><name>/u/Fr4nkWh1te</name><uri>https://www.reddit.com/user/Fr4nkWh1te</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What&amp;#39;s the best Langchain.js text splitter to handle a JSX string like the following and maintain context of the text content?&lt;/p&gt; &lt;p&gt;The information we mostly care about is the user-readable text. However, JSX tags sometimes also contain relevant information (like the &lt;code&gt;alt&lt;/code&gt; prop of the &lt;code&gt;Image&lt;/code&gt;) so I don&amp;#39;t want to just remove them. However, I&amp;#39;m removing all &lt;code&gt;className&lt;/code&gt; props from the string (via regex) to make the text less verbose.&lt;/p&gt; &lt;p&gt;``` export const metadata: Metadata = { title: &amp;quot;Home Page&amp;quot;, };&lt;/p&gt; &lt;p&gt;export default function Home() { return ( &amp;lt;div&amp;gt; &amp;lt;div&amp;gt; &amp;lt;div&amp;gt; &amp;lt;h1&amp;gt; Hi, I&amp;#39;m Florian 👋 &amp;lt;/h1&amp;gt; &amp;lt;p&amp;gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;Image src={me} alt=&amp;quot;A photo of me&amp;quot; height={350} /&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;p&amp;gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; ); } ```&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fr4nkWh1te&quot;&gt; /u/Fr4nkWh1te &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19f4ub6/text_splitter_for_jsxreact_code_to_keep/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19f4ub6/text_splitter_for_jsxreact_code_to_keep/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19f4ub6</id><link href="https://www.reddit.com/r/LangChain/comments/19f4ub6/text_splitter_for_jsxreact_code_to_keep/" /><updated>2024-01-25T08:37:45+00:00</updated><published>2024-01-25T08:37:45+00:00</published><title>Text splitter for JSX/React code to keep informational context?</title></entry><entry><author><name>/u/flowerescape</name><uri>https://www.reddit.com/user/flowerescape</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can y’all recommend a good tutorial that will get me from start to finish for a RAG app I’m trying to make using LangChain JS?&lt;/p&gt; &lt;p&gt;I don’t wanna become a guru, just trying to get something on production asap. It needs to have memory.&lt;/p&gt; &lt;p&gt;Much appreciated 🙏🏻&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/flowerescape&quot;&gt; /u/flowerescape &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ewodj/whats_the_best_langchain_js_tutorial_on_youtube/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ewodj/whats_the_best_langchain_js_tutorial_on_youtube/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ewodj</id><link href="https://www.reddit.com/r/LangChain/comments/19ewodj/whats_the_best_langchain_js_tutorial_on_youtube/" /><updated>2024-01-25T00:55:58+00:00</updated><published>2024-01-25T00:55:58+00:00</published><title>What’s the best LangChain (JS) tutorial on YouTube</title></entry><entry><author><name>/u/dragon_4789</name><uri>https://www.reddit.com/user/dragon_4789</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m wondering if anyone has successfully added bounding box or coordinate values to each chunk of a PDF using CharacterTextSplitter or Recursive methods. I&amp;#39;m specifically interested in extracting the coordinates and storing them in metadata within a vector store.&lt;/p&gt; &lt;p&gt;My ultimate goal is to be able to query similar chunks and precisely highlight the corresponding text in the PDF from which it was extracted.&lt;/p&gt; &lt;p&gt;If there&amp;#39;s already a solution or tool available for this purpose, could you kindly direct me to the right resources or provide some guidance?&lt;/p&gt; &lt;p&gt;Thank you in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dragon_4789&quot;&gt; /u/dragon_4789 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19f101u/seeking_assistance_with_textsplitter_adding/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19f101u/seeking_assistance_with_textsplitter_adding/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19f101u</id><link href="https://www.reddit.com/r/LangChain/comments/19f101u/seeking_assistance_with_textsplitter_adding/" /><updated>2024-01-25T04:33:56+00:00</updated><published>2024-01-25T04:33:56+00:00</published><title>Seeking Assistance with TextSplitter: Adding Bounding Box or Coordinate Values to PDF Chunks</title></entry><entry><author><name>/u/NefariousnessSad2208</name><uri>https://www.reddit.com/user/NefariousnessSad2208</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m developing an application using a large language model (LLM) and am in need of a robust core agent platform that supports multi-modal agent capabilities. Currently, I&amp;#39;m utilizing LLM for intent recognition and named entity recognition, and then I do backend workflow orchestration without LLM or Agents. My goal is to transition to an agent framework for enhanced flexibility. I&amp;#39;m looking for frameworks that are resilient against prompt injection and easier to with open-source LLMs. &lt;/p&gt; &lt;p&gt;So far, I&amp;#39;ve considered:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;LangChain Agents (I have experience with it)&lt;/li&gt; &lt;li&gt;LLaMaIndex Agents&lt;/li&gt; &lt;li&gt;HayStack Agents&lt;/li&gt; &lt;li&gt;AutoGen&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Do you:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Recommend any additional frameworks that are worth exploring for agent orchestration? &lt;/li&gt; &lt;li&gt;Have a preferred framework in this context?&lt;/li&gt; &lt;li&gt;have experience with these framework and want to share feedback?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/NefariousnessSad2208&quot;&gt; /u/NefariousnessSad2208 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eqmgk/agent_platform_for_multimodal_agent_capabilities/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eqmgk/agent_platform_for_multimodal_agent_capabilities/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19eqmgk</id><link href="https://www.reddit.com/r/LangChain/comments/19eqmgk/agent_platform_for_multimodal_agent_capabilities/" /><updated>2024-01-24T20:38:39+00:00</updated><published>2024-01-24T20:38:39+00:00</published><title>agent platform for multi-modal agent capabilities</title></entry><entry><author><name>/u/Fr4nkWh1te</name><uri>https://www.reddit.com/user/Fr4nkWh1te</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to build a &lt;strong&gt;chatbot&lt;/strong&gt; that has access to &lt;strong&gt;all pages&lt;/strong&gt; in my website&amp;#39;s GitHub repository. &lt;/p&gt; &lt;p&gt;The &lt;a href=&quot;https://js.langchain.com/docs/integrations/document_loaders/web_loaders/github#usage&quot;&gt;GitHubRepoLoader&lt;/a&gt; makes it easy to fetch all pages and turn them into documents. But I would also like to &lt;strong&gt;strip these documents of all the React code&lt;/strong&gt; and keep only the user-readable information.&lt;/p&gt; &lt;p&gt;I tried Langchain.js&amp;#39;s &lt;a href=&quot;https://js.langchain.com/docs/integrations/document_transformers/html-to-text&quot;&gt;html-to-text&lt;/a&gt; converter but that didn&amp;#39;t work. I also found &lt;a href=&quot;https://www.npmjs.com/package/react-to-text&quot;&gt;react-to-text&lt;/a&gt; but this one expects an actual React component as its argument. I have the full file as a string.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fr4nkWh1te&quot;&gt; /u/Fr4nkWh1te &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ehc9w/reactjsx_to_text_parser/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ehc9w/reactjsx_to_text_parser/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ehc9w</id><link href="https://www.reddit.com/r/LangChain/comments/19ehc9w/reactjsx_to_text_parser/" /><updated>2024-01-24T13:41:10+00:00</updated><published>2024-01-24T13:41:10+00:00</published><title>React/JSX to text parser?</title></entry><entry><author><name>/u/jaxolingo</name><uri>https://www.reddit.com/user/jaxolingo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I&amp;#39;ve been using agents with autogen and crew, and now langgraph, mostly for learning and small/mid scale programs. The more I use them the more I&amp;#39;m confused about the purpose of the agent framework in general.&lt;/p&gt; &lt;p&gt;The scenarios I&amp;#39;ve tested: read input, execute web search, summaries, return to user. Most other usecases also follow a sequential iteration of steps. For these usecases, there is no need to include any sort of agents, it can be done through normal python scripts. Same goes for other usecases&lt;/p&gt; &lt;p&gt;I&amp;#39;m trying to think about what does agents let us do that we could not do with just scripts with some logic. Sure, the LLM As OS is a fantastic idea, but in a production setting I&amp;#39;m sticking to my scripts rather than hoping the LLM will decide which tool to use everytime...&lt;/p&gt; &lt;p&gt;I&amp;#39;m interested to learn the actual usecases and potential of using agents too execute tasks, so please do let me know&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jaxolingo&quot;&gt; /u/jaxolingo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ecbnb/purpose_of_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ecbnb/purpose_of_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ecbnb</id><link href="https://www.reddit.com/r/LangChain/comments/19ecbnb/purpose_of_agents/" /><updated>2024-01-24T08:20:30+00:00</updated><published>2024-01-24T08:20:30+00:00</published><title>Purpose of Agents</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, &lt;/p&gt; &lt;p&gt;I have setup FastAPI with Llama.cpp and Langchain. Now I want to enable streaming in the FastAPI responses. Streaming works with Llama.cpp in my terminal, but I wasn&amp;#39;t able to implement it with a FastAPI response. See this Stackoverflow-Question (for code etc.): &lt;a href=&quot;https://stackoverflow.com/questions/77867894/streaming-local-llm-with-fastapi-llama-cpp-and-langchain?noredirect=1#comment137276485_77867894&quot;&gt;https://stackoverflow.com/questions/77867894/streaming-local-llm-with-fastapi-llama-cpp-and-langchain?noredirect=1#comment137276485_77867894&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Most tutorials focused on enabling streaming with an OpenAI model, but I am using a local LLM (quantized Mistral) with llama.cpp. I think I have to modify the Callbackhandler, but no tutorial worked.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Does anyone know how I can make Streaming working? I have a project deadline on Friday and unitl then I have to make it work...&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19enjxr/streaming_local_llm_with_fastapi_llamacpp_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19enjxr/streaming_local_llm_with_fastapi_llamacpp_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19enjxr</id><link href="https://www.reddit.com/r/LangChain/comments/19enjxr/streaming_local_llm_with_fastapi_llamacpp_and/" /><updated>2024-01-24T18:35:17+00:00</updated><published>2024-01-24T18:35:17+00:00</published><title>Streaming local LLM with FastAPI, Llama.cpp and Langchain</title></entry><entry><author><name>/u/Fr4nkWh1te</name><uri>https://www.reddit.com/user/Fr4nkWh1te</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am building a website with an integrated chatbot. How would you load the page info into documents? I want to make my code reusable for future projects.&lt;/p&gt; &lt;p&gt;Right now I&amp;#39;m using the &lt;a href=&quot;https://js.langchain.com/docs/integrations/document_loaders/web_loaders/github&quot;&gt;GitHubRepoLoader&lt;/a&gt; to turn the pages into documents, but this requires the code to be available in a GitHub repository. This is not great for local development (because we don&amp;#39;t have the latest data).&lt;/p&gt; &lt;p&gt;Would you load the pages from the file system instead? Or is there a better solution?&lt;/p&gt; &lt;p&gt;Any classes/helpers you can point me to? I&amp;#39;m using Langchain.js.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fr4nkWh1te&quot;&gt; /u/Fr4nkWh1te &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19elb7z/loader_for_website_pages_offline_nextjsreact/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19elb7z/loader_for_website_pages_offline_nextjsreact/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19elb7z</id><link href="https://www.reddit.com/r/LangChain/comments/19elb7z/loader_for_website_pages_offline_nextjsreact/" /><updated>2024-01-24T16:38:35+00:00</updated><published>2024-01-24T16:38:35+00:00</published><title>Loader for website pages (offline) (Next.js/React)</title></entry><entry><author><name>/u/hamnarif</name><uri>https://www.reddit.com/user/hamnarif</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’ve used these commands to install it in VSCode &lt;/p&gt; &lt;p&gt;export CUDACXX=&amp;quot;/mnt/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.3/bin/nvcc.exe&amp;quot; export CMAKE_ARGS=&amp;quot;-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all-major -DCUDAToolkit_ROOT=C:\Program Files\NVIDIA GP export FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir --force-reinstall --upgrade&lt;/p&gt; &lt;p&gt;Successfully installed but it’s still not accessing gpu. I’ve nvidia GeForce RTC 3070 Ti &lt;/p&gt; &lt;p&gt;How do I know how many n_gpu_layers to set&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hamnarif&quot;&gt; /u/hamnarif &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eco2b/has_anyone_used_llamacpp_python_with_gpu_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eco2b/has_anyone_used_llamacpp_python_with_gpu_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19eco2b</id><link href="https://www.reddit.com/r/LangChain/comments/19eco2b/has_anyone_used_llamacpp_python_with_gpu_in/" /><updated>2024-01-24T08:46:11+00:00</updated><published>2024-01-24T08:46:11+00:00</published><title>Has anyone used Llama.cpp python with gpu in vscode to load local llm. Does it even work with VSCode or do I’ve to install visual studio community edition?</title></entry><entry><author><name>/u/Zestyclose-Bid-487</name><uri>https://www.reddit.com/user/Zestyclose-Bid-487</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;it has a collab notebook, blog links &amp;amp; all code&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zestyclose-Bid-487&quot;&gt; /u/Zestyclose-Bid-487 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ehe5m/best_resources_to_learn_to_advanced_rag_topics/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ehe5m/best_resources_to_learn_to_advanced_rag_topics/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ehe5m</id><link href="https://www.reddit.com/r/LangChain/comments/19ehe5m/best_resources_to_learn_to_advanced_rag_topics/" /><updated>2024-01-24T13:43:48+00:00</updated><published>2024-01-24T13:43:48+00:00</published><title>Best resources to learn to advanced RAG topics &amp; and to end projects</title></entry><entry><author><name>/u/Gon_Buruwa</name><uri>https://www.reddit.com/user/Gon_Buruwa</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey! I&amp;#39;ve been working with a vast vector database containing thousands of text documents, each spanning an average of 10-12 pages (sometimes even up to 50 pages). I&amp;#39;ve noticed that when querying the data and citing sources, the system currently cites only the individual chunks rather than the entire document. Has anyone found an efficient way to attribute the entire document, complete with a proper title, instead of just the chunks?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Gon_Buruwa&quot;&gt; /u/Gon_Buruwa &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e8ylz/optimizing_source_citations_for_comprehensive/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e8ylz/optimizing_source_citations_for_comprehensive/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19e8ylz</id><link href="https://www.reddit.com/r/LangChain/comments/19e8ylz/optimizing_source_citations_for_comprehensive/" /><updated>2024-01-24T04:48:15+00:00</updated><published>2024-01-24T04:48:15+00:00</published><title>Optimizing Source Citations for Comprehensive References: How to attribute Documents Instead of Chunks?</title></entry><entry><author><name>/u/Adam-Schroeder</name><uri>https://www.reddit.com/user/Adam-Schroeder</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eaixd/create_ai_chatbots_for_websites_in_python/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/f_5VVWhKW_bpNQG8yIoNnXdTsFuLk7mlnMGL2VRdGnM.jpg&quot; alt=&quot;Create AI Chatbots for Websites in Python - EmbedChain Dash&quot; title=&quot;Create AI Chatbots for Websites in Python - EmbedChain Dash&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Everyone,&lt;br/&gt; A few days ago, I created this free video tutorial on how to build an AI Chatbot in Python. I use the EmbedChain (built on top of LangChain) and Dash libraries, as I show how to train and interact with your bot. Hope you find it helpful. &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/tmOmTBEdNrE&quot;&gt;https://youtu.be/tmOmTBEdNrE&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/t2ebobt8zbec1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b2dcd9f2a930da35f2862b368a535d30ad885825&quot;&gt;https://preview.redd.it/t2ebobt8zbec1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b2dcd9f2a930da35f2862b368a535d30ad885825&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Adam-Schroeder&quot;&gt; /u/Adam-Schroeder &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eaixd/create_ai_chatbots_for_websites_in_python/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eaixd/create_ai_chatbots_for_websites_in_python/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19eaixd</id><media:thumbnail url="https://b.thumbs.redditmedia.com/f_5VVWhKW_bpNQG8yIoNnXdTsFuLk7mlnMGL2VRdGnM.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/19eaixd/create_ai_chatbots_for_websites_in_python/" /><updated>2024-01-24T06:19:29+00:00</updated><published>2024-01-24T06:19:29+00:00</published><title>Create AI Chatbots for Websites in Python - EmbedChain Dash</title></entry><entry><author><name>/u/the_snow_princess</name><uri>https://www.reddit.com/user/the_snow_princess</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dp7e2/awesome_list_of_ai_agents_and_agentbuilding/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/amFtcWVvdHg1N2VjMVsrKOVaRlL6CSzyiPBSRcju48PidCE7SUNuW3Vur3do.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e62e5d6e5fecb8bb694c9fa2a2cb9a94e428c0e4&quot; alt=&quot;Awesome list of AI agents and agent-building frameworks&quot; title=&quot;Awesome list of AI agents and agent-building frameworks&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/the_snow_princess&quot;&gt; /u/the_snow_princess &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/x8gio2o9v6ec1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dp7e2/awesome_list_of_ai_agents_and_agentbuilding/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19dp7e2</id><media:thumbnail url="https://external-preview.redd.it/amFtcWVvdHg1N2VjMVsrKOVaRlL6CSzyiPBSRcju48PidCE7SUNuW3Vur3do.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e62e5d6e5fecb8bb694c9fa2a2cb9a94e428c0e4" /><link href="https://www.reddit.com/r/LangChain/comments/19dp7e2/awesome_list_of_ai_agents_and_agentbuilding/" /><updated>2024-01-23T14:07:31+00:00</updated><published>2024-01-23T14:07:31+00:00</published><title>Awesome list of AI agents and agent-building frameworks</title></entry><entry><author><name>/u/Critical_Pop_2216</name><uri>https://www.reddit.com/user/Critical_Pop_2216</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I am looking for the cheapest way possible to process sensitive documents using Mistral&amp;#39;s 8x7b model. It probably should be self-hosted to ensure the nothing from the document leaks. I&amp;#39;ve found that many APIs are vague about what information is stored. I have a budget around $100 a month to deploy this model, and to lower the cost it would be ok to only deploy it during the work day around ~160 hours a month. Any help would be appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Critical_Pop_2216&quot;&gt; /u/Critical_Pop_2216 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e7zga/processing_sensitive_info_with_mistral_for_cheap/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e7zga/processing_sensitive_info_with_mistral_for_cheap/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19e7zga</id><link href="https://www.reddit.com/r/LangChain/comments/19e7zga/processing_sensitive_info_with_mistral_for_cheap/" /><updated>2024-01-24T03:55:29+00:00</updated><published>2024-01-24T03:55:29+00:00</published><title>Processing sensitive info with Mistral for cheap</title></entry><entry><author><name>/u/fancypigollo</name><uri>https://www.reddit.com/user/fancypigollo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e5ir7/future_of_nlp_and_llms_chris_manning_stanford/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/MEJbeXJfv7_J1XfMubk4lFohPs9G6cM15TgeICfNphk.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6fbdb05b21a1af6537ce1177458bece843b1ae53&quot; alt=&quot;Future of NLP and LLMs - Chris Manning Stanford CoreNLP&quot; title=&quot;Future of NLP and LLMs - Chris Manning Stanford CoreNLP&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/fancypigollo&quot;&gt; /u/fancypigollo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/xk01kx_klOE?si=I5EEkHpuZCFqyQAz&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e5ir7/future_of_nlp_and_llms_chris_manning_stanford/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19e5ir7</id><media:thumbnail url="https://external-preview.redd.it/MEJbeXJfv7_J1XfMubk4lFohPs9G6cM15TgeICfNphk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6fbdb05b21a1af6537ce1177458bece843b1ae53" /><link href="https://www.reddit.com/r/LangChain/comments/19e5ir7/future_of_nlp_and_llms_chris_manning_stanford/" /><updated>2024-01-24T01:54:00+00:00</updated><published>2024-01-24T01:54:00+00:00</published><title>Future of NLP and LLMs - Chris Manning Stanford CoreNLP</title></entry><entry><author><name>/u/rkubc</name><uri>https://www.reddit.com/user/rkubc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello Reddit Community,&lt;/p&gt; &lt;p&gt;I am currently working on a Document Information extractor project using LangChain within a Docker environment. The project involves integrating OpenAI embeddings with FAISS for document search. While everything works fine locally, I run into an SSL certificate verification error when I attempt to run the same code in Docker. The error is as follows:&lt;/p&gt; &lt;p&gt;Error&lt;/p&gt; &lt;pre&gt;&lt;code&gt;MaxRetryError: HTTPSConnectionPool(host=&amp;#39;openai.blob.core.windows.net&amp;#39;, port=443): Max retries exceeded with url: /embeddings/... (Caused by SSLError(SSLCertVerificationError(1, &amp;#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)&amp;#39;))) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This error occurs at the following line of code:&lt;/p&gt; &lt;p&gt;Python code&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docsearch = FAISS.from_documents(documents, OpenAIEmbeddings()) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The Docker container seems unable to verify the SSL certificate presented by the OpenAI server. I&amp;#39;ve ensured my internet connection is stable, and there are no issues with SSL certificates when running the code outside of Docker.&lt;/p&gt; &lt;p&gt;Has anyone encountered a similar issue or have any suggestions on what might be going wrong with SSL verification in Docker? What steps can I take to resolve this SSLCertVerificationError within the Docker environment?&lt;/p&gt; &lt;p&gt;Any insights or advice would be greatly appreciated. Thank you for your help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rkubc&quot;&gt; /u/rkubc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e8txp/sslcertverificationerror_in_docker_when/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e8txp/sslcertverificationerror_in_docker_when/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19e8txp</id><link href="https://www.reddit.com/r/LangChain/comments/19e8txp/sslcertverificationerror_in_docker_when/" /><updated>2024-01-24T04:41:10+00:00</updated><published>2024-01-24T04:41:10+00:00</published><title>SSLCertVerificationError in Docker When Integrating OpenAI Embeddings with FAISS for LangChain</title></entry></feed>