<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-07-02T06:47:01+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/maniac_runner</name><uri>https://www.reddit.com/user/maniac_runner</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtcuy7/guide_pdf_checkbox_and_radio_button_extraction/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/x8DTkNS8a7_4qR6b2OBqRcQ1aDflD3BoKmpf6YLiY1g.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4b269f9d896a63bf5bd3496277b35476e4c51860&quot; alt=&quot;[Guide] PDF checkbox and radio button extraction with LLMWhisperer, Langchain, and Pydantic&quot; title=&quot;[Guide] PDF checkbox and radio button extraction with LLMWhisperer, Langchain, and Pydantic&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/maniac_runner&quot;&gt; /u/maniac_runner &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=dC7EhnEIdDA&amp;amp;ab_channel=Unstract&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtcuy7/guide_pdf_checkbox_and_radio_button_extraction/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dtcuy7</id><media:thumbnail url="https://external-preview.redd.it/x8DTkNS8a7_4qR6b2OBqRcQ1aDflD3BoKmpf6YLiY1g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4b269f9d896a63bf5bd3496277b35476e4c51860" /><link href="https://www.reddit.com/r/LangChain/comments/1dtcuy7/guide_pdf_checkbox_and_radio_button_extraction/" /><updated>2024-07-02T04:07:20+00:00</updated><published>2024-07-02T04:07:20+00:00</published><title>[Guide] PDF checkbox and radio button extraction with LLMWhisperer, Langchain, and Pydantic</title></entry><entry><author><name>/u/goddamnit_1</name><uri>https://www.reddit.com/user/goddamnit_1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsych9/built_a_pr_agent_with_langchain_and_3_other/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/6Mc008Ca21IsXkVQZ7BC8S65PYZTOpW1i6vv0a-gFXU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4cca14bc297de8f853bc85571e118ec44c6fcd00&quot; alt=&quot;Built a PR Agent with Langchain and 3 other frameworks - A Comparison&quot; title=&quot;Built a PR Agent with Langchain and 3 other frameworks - A Comparison&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The goal was to create an agent that would:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Monitor a GitHub repository for new PRs&lt;/li&gt; &lt;li&gt;Perform a code review on each PR&lt;/li&gt; &lt;li&gt;Post a summary of the review to a Slack channel&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/0yf542afwx9d1.png?width=1442&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=791bd8618af7c67f8e20d928705639366bea065b&quot;&gt;https://preview.redd.it/0yf542afwx9d1.png?width=1442&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=791bd8618af7c67f8e20d928705639366bea065b&lt;/a&gt;&lt;/p&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th align=&quot;left&quot;&gt;Framework&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;Why langchain is better&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;Why it can be better&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;CrewAI&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;Langchain provides a more comprehensive toolkit for building various AI applications, including but not limited to multi-agent scenarios.&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;CrewAI may be easier to get started with for specific multi-agent tasks&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;Llama Index&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;Langchain offers more general-purpose capabilities&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;For projects primarily focused on data indexing and retrieval, llama index is better&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;Autogen&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;Langchain provides more structured components for building AI applications&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;For projects requiring highly dynamic multi-agent interactions, Autogen&amp;#39;s specialized focus might provide a more intuitive framework&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;The agent works great!&lt;/p&gt; &lt;p&gt;here&amp;#39;s the link for the project: &lt;a href=&quot;https://git.new/pr-agent-langchain&quot;&gt;https://git.new/pr-agent-langchain&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/goddamnit_1&quot;&gt; /u/goddamnit_1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsych9/built_a_pr_agent_with_langchain_and_3_other/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsych9/built_a_pr_agent_with_langchain_and_3_other/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dsych9</id><media:thumbnail url="https://external-preview.redd.it/6Mc008Ca21IsXkVQZ7BC8S65PYZTOpW1i6vv0a-gFXU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4cca14bc297de8f853bc85571e118ec44c6fcd00" /><link href="https://www.reddit.com/r/LangChain/comments/1dsych9/built_a_pr_agent_with_langchain_and_3_other/" /><updated>2024-07-01T17:11:32+00:00</updated><published>2024-07-01T17:11:32+00:00</published><title>Built a PR Agent with Langchain and 3 other frameworks - A Comparison</title></entry><entry><author><name>/u/No-Speed3625</name><uri>https://www.reddit.com/user/No-Speed3625</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a PromptTemplate with three inputs: cause, symptom, and action. My LLM should use the inputs to produce a &amp;quot;theme&amp;quot; it gathers from the inputs. However, I am getting an error because the chain.invoke method expects one input instead of multiple.&lt;/p&gt; &lt;p&gt;This is the error that is thrown: ValueError: Invalid input type &amp;lt;class &amp;#39;dict&amp;#39;&amp;gt;. Must be a PromptValue, str, or list of BaseMessages.&lt;/p&gt; &lt;p&gt;All the examples of invoking a chain in the langchain documentation only have one input. What am I supposed to do when my prompt template contains three inputs?&lt;/p&gt; &lt;p&gt;For reference, this is the code:&lt;/p&gt; &lt;p&gt;&lt;code&gt;llm = AzureChatOpenAI()&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;prompt_template = PromptTemplate(&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;input_variables=[&amp;quot;cause&amp;quot;, &amp;quot;symptom&amp;quot;, &amp;quot;action&amp;quot;],&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;template=&amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Root Cause:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;{cause}&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Complaint Symptom:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;{symptom}&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Corrective Action:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;{action}&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Based on the information provided above, generate a concise &amp;quot;Failure Theme&amp;quot; encapulating the reason for the failure.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Failure Theme:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;chain = llm | prompt_template | StrOutputParser()&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;root_cause = df.iloc[0][&amp;#39;Root Cause&amp;#39;]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;complaint_symptom = df.iloc[0][&amp;#39;Complaint Symptom&amp;#39;]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;corrective_action = df.iloc[0][&amp;#39;Corrective Action&amp;#39;]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;chain.invoke({&amp;quot;cause&amp;quot;: root_cause, &amp;quot;symptom&amp;quot;: complaint_symptom, &amp;quot;action&amp;quot;: corrective_action})&lt;/code&gt;&lt;/p&gt; &lt;p&gt; &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No-Speed3625&quot;&gt; /u/No-Speed3625 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dt57k9/how_to_invoke_runnablesequence_chain_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dt57k9/how_to_invoke_runnablesequence_chain_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dt57k9</id><link href="https://www.reddit.com/r/LangChain/comments/1dt57k9/how_to_invoke_runnablesequence_chain_with/" /><updated>2024-07-01T21:54:25+00:00</updated><published>2024-07-01T21:54:25+00:00</published><title>How to Invoke RunnableSequence chain with multiple inputs</title></entry><entry><author><name>/u/northwolf56</name><uri>https://www.reddit.com/user/northwolf56</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I made a TL;DR video about using our browser extension to run your chat agents alongside any web page or app! Visually design your LangChain RAG + Agents app, add a chat UI to it and use it instantly, all from your browser. No code!&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/5-QV3lVI8uo&quot;&gt;https://youtu.be/5-QV3lVI8uo&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/northwolf56&quot;&gt; /u/northwolf56 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dswds9/chat_with_any_webpage_or_application_using_visual/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dswds9/chat_with_any_webpage_or_application_using_visual/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dswds9</id><link href="https://www.reddit.com/r/LangChain/comments/1dswds9/chat_with_any_webpage_or_application_using_visual/" /><updated>2024-07-01T15:52:00+00:00</updated><published>2024-07-01T15:52:00+00:00</published><title>Chat With Any WebPage or Application using Visual Agents &amp; LangChain</title></entry><entry><author><name>/u/i_am_innovative</name><uri>https://www.reddit.com/user/i_am_innovative</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;i asked react agent about last name of johnny it&amp;#39;s not showing in it&amp;#39;s final output why ? I think I have found the table that contains the name &amp;quot;JOHNNY&amp;quot;. It&amp;#39;s the &amp;quot;actor&amp;quot; table. Now, I need to write a query to retrieve the last name of the actor with the first name &amp;quot;JOHNNY&amp;quot;. Action: sql_db_query_checker Action Input: SELECT last_name FROM actor WHERE first_name = &amp;#39;JOHNNY&amp;#39;SELECT last_name FROM actor WHERE first_name = &amp;#39;JOHNNY&amp;#39;Action: sql_db_query Action Input: SELECT last_name FROM actor WHERE first_name = &amp;#39;JOHNNY&amp;#39;[(&amp;#39;LOLLOBRIGIDA&amp;#39;,), (&amp;#39;CAGE&amp;#39;,)]I now know the final answer Final Answer: The last name of JOHNNY is not found in the database, but there are actors with the last names LOLLOBRIGIDA and CAGE who have first names that are not JOHNNY. It&amp;#39;s possible that the actor with the first name JOHNNY does not exist in the database. &amp;gt; Finished chain. &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/i_am_innovative&quot;&gt; /u/i_am_innovative &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsyf46/whats_wrong_with_langchain_react_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsyf46/whats_wrong_with_langchain_react_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dsyf46</id><link href="https://www.reddit.com/r/LangChain/comments/1dsyf46/whats_wrong_with_langchain_react_agent/" /><updated>2024-07-01T17:14:38+00:00</updated><published>2024-07-01T17:14:38+00:00</published><title>What's wrong with Langchain React Agent</title></entry><entry><author><name>/u/harshit_nariya</name><uri>https://www.reddit.com/user/harshit_nariya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/genai-agents-unleashed/generate-powerpoint-presentation-with-openai-the-future-of-slide-decks-ce1a7c928986&quot;&gt;https://medium.com/genai-agents-unleashed/generate-powerpoint-presentation-with-openai-the-future-of-slide-decks-ce1a7c928986&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/harshit_nariya&quot;&gt; /u/harshit_nariya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dt0zzz/automate_slide_decks_and_presentations/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dt0zzz/automate_slide_decks_and_presentations/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dt0zzz</id><link href="https://www.reddit.com/r/LangChain/comments/1dt0zzz/automate_slide_decks_and_presentations/" /><updated>2024-07-01T18:59:51+00:00</updated><published>2024-07-01T18:59:51+00:00</published><title>Automate Slide decks and presentations</title></entry><entry><author><name>/u/TableauforViz</name><uri>https://www.reddit.com/user/TableauforViz</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a huge schema in the neo4j database.&lt;/p&gt; &lt;p&gt;I&amp;#39;m using the LangChain function to generate a cypher query&lt;/p&gt; &lt;p&gt;chain = GraphCypherQAChain.from_llm( ChatOpenAI(temperature=0), graph=graph, verbose=True )&lt;/p&gt; &lt;p&gt;chain.invoke(query)&lt;/p&gt; &lt;p&gt;It&amp;#39;s returning an error saying that the model supports 16k tokens and I&amp;#39;m passing 15M+ tokens&lt;/p&gt; &lt;p&gt;How can I limit these tokens? I tried setting ChatOpenAI(temperature=0, max_tokens=1000) and it&amp;#39;s still giving the same error.&lt;/p&gt; &lt;p&gt;I think it&amp;#39;s passing the whole schema at once, how can I set a limit on that?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TableauforViz&quot;&gt; /u/TableauforViz &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dt089d/how_to_generate_cypher_query_using_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dt089d/how_to_generate_cypher_query_using_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dt089d</id><link href="https://www.reddit.com/r/LangChain/comments/1dt089d/how_to_generate_cypher_query_using_llm/" /><updated>2024-07-01T18:28:35+00:00</updated><published>2024-07-01T18:28:35+00:00</published><title>How to generate Cypher Query using LLM?</title></entry><entry><author><name>/u/Lost-Season-4196</name><uri>https://www.reddit.com/user/Lost-Season-4196</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I made a RAG app that basically answers user questions based on provided data, it works fine on GPU and a single GPU. I want to deploy it on multiple GPUs (4 T4s) but I always get CUDA out of Memory error on pipeline.&lt;/p&gt; &lt;p&gt;I tried using &amp;quot;auto&amp;quot; keyword too but Langchain does not let me use it as keyword.&lt;/p&gt; &lt;p&gt;I used Langchain as main framework, my code looks like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline, HuggingFaceEmbeddings MODEL_NAME=&amp;quot;mistralai/Mistral-7B-Instruct-v0.3&amp;quot; pipe = HuggingFacePipeline.from_model_id( model_id=MODEL_NAME, device=0, model_kwargs={&amp;quot;torch_dtype&amp;quot;:torch.float16}, task=&amp;quot;text-generation&amp;quot;) llm = ChatHuggingFace(llm=pipe) embedding = HuggingFaceEmbeddings(model_name=MODEL_NAME, model_kwargs={&amp;quot;device&amp;quot;:&amp;quot;cuda:1&amp;quot;}, multi_process=True, ) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Lost-Season-4196&quot;&gt; /u/Lost-Season-4196 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dszxdk/rag_app_on_multiple_gpus/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dszxdk/rag_app_on_multiple_gpus/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dszxdk</id><link href="https://www.reddit.com/r/LangChain/comments/1dszxdk/rag_app_on_multiple_gpus/" /><updated>2024-07-01T18:16:25+00:00</updated><published>2024-07-01T18:16:25+00:00</published><title>RAG app on multiple GPUs</title></entry><entry><author><name>/u/ravediamond000</name><uri>https://www.reddit.com/user/ravediamond000</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;Here&amp;#39;s a cool post that shows how to integrate multiple AWS Bedrock LLMs in your LangChain apps and choosing which one used with only one configuration parameter.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the link: &lt;a href=&quot;https://www.metadocs.co/2024/04/11/handle-multiple-llm-models-in-langchain-and-aws-bedrock-seamlessly/&quot;&gt;link&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Have a nice read.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ravediamond000&quot;&gt; /u/ravediamond000 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsrfca/integrate_multiple_aws_bedrock_llms_seamlessly/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsrfca/integrate_multiple_aws_bedrock_llms_seamlessly/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dsrfca</id><link href="https://www.reddit.com/r/LangChain/comments/1dsrfca/integrate_multiple_aws_bedrock_llms_seamlessly/" /><updated>2024-07-01T12:11:22+00:00</updated><published>2024-07-01T12:11:22+00:00</published><title>Integrate multiple AWS bedrock LLMs seamlessly with Langchain</title></entry><entry><author><name>/u/bubble_h13</name><uri>https://www.reddit.com/user/bubble_h13</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I haven&amp;#39;t seen the sample in Langchain 0.2, so I just referenced &lt;a href=&quot;https://python.langchain.com/v0.1/docs/use_cases/tool_use/multiple_tools/&quot;&gt;v0.1&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I use local model with &amp;quot;taide-7b-a.2-q4_k_m.gguf&amp;quot;, so there are some different&lt;/p&gt; &lt;pre&gt;&lt;code&gt; llm = ChatLlamaCpp( model_path= str(model_path), n_gpu_layers=100, n_batch=512, n_ctx=2048, f16_kv=True, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=True, ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;after invoking the question, I can&amp;#39;t get the tools information. like&lt;/p&gt; &lt;pre&gt;&lt;code&gt;[{&amp;#39;name&amp;#39;: &amp;#39;multiply&amp;#39;, &amp;#39;args&amp;#39;: {&amp;#39;first_int&amp;#39;: 23, &amp;#39;second_int&amp;#39;: 7}, &amp;#39;id&amp;#39;: &amp;#39;toolu_01Wf8kUs36kxRKLDL8vs7G8q&amp;#39;, &amp;#39;output&amp;#39;: 161}] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Can anyone tell me what&amp;#39;s wrong? here&amp;#39;s the code&lt;/p&gt; &lt;pre&gt;&lt;code&gt; tools = [multiply, exponentiate, add] llm_with_tools = llm.bind_tools(tools) def call_tools(msg: AIMessage) -&amp;gt; Runnable: &amp;quot;&amp;quot;&amp;quot;Simple tool calling helper.&amp;quot;&amp;quot;&amp;quot; tool_map = {tool.name: tool for tool in tools} tool_calls = msg.tool_calls.copy() for tool_call in tool_calls: tool_call[&amp;quot;output&amp;quot;] = tool_map[tool_call[&amp;quot;name&amp;quot;]].invoke(tool_call[&amp;quot;args&amp;quot;]) return tool_calls chain = llm_with_tools | call_tools chain.invoke(&amp;quot;23 times 7&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bubble_h13&quot;&gt; /u/bubble_h13 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsvy6s/choosing_multitool_in_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsvy6s/choosing_multitool_in_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dsvy6s</id><link href="https://www.reddit.com/r/LangChain/comments/1dsvy6s/choosing_multitool_in_agent/" /><updated>2024-07-01T15:33:49+00:00</updated><published>2024-07-01T15:33:49+00:00</published><title>choosing multi-tool in agent</title></entry><entry><author><name>/u/MoronSlayer42</name><uri>https://www.reddit.com/user/MoronSlayer42</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Using astream, the response from the LLM has words that are split for example the word &amp;quot;hippopotamus&amp;quot; comes as 2 chunks &amp;quot;hippo&amp;quot; and &amp;quot;potamus&amp;quot;. When creating an app, how to recognize and combine the 2 split parts into a single word for front-end?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MoronSlayer42&quot;&gt; /u/MoronSlayer42 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsvmg8/streaming_responses_have_words_split/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsvmg8/streaming_responses_have_words_split/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dsvmg8</id><link href="https://www.reddit.com/r/LangChain/comments/1dsvmg8/streaming_responses_have_words_split/" /><updated>2024-07-01T15:20:47+00:00</updated><published>2024-07-01T15:20:47+00:00</published><title>Streaming responses have words split</title></entry><entry><author><name>/u/Equivalent_Noise3560</name><uri>https://www.reddit.com/user/Equivalent_Noise3560</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dso9pj/custom_functions_with_runnablelambda_in_langchain/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/2347JJ6JbmR5WGmdxSM3iu0OnGohPD3MltcLei8lmx8.jpg?width=108&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7a4559964a97155995aa6f0c96a36eebba24728a&quot; alt=&quot;Custom Functions with RunnableLambda in LangChain JS&quot; title=&quot;Custom Functions with RunnableLambda in LangChain JS&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Made a short post about how to make Custom Functions with RunnableLambda in LangChain JS:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.js-craft.io/blog/custom-functions-runnablelambda-langchain-js/&quot;&gt;https://www.js-craft.io/blog/custom-functions-runnablelambda-langchain-js/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/9v8pcoekfv9d1.png?width=1474&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8dfa8bb8a5efb6b1873e1ee70fba90cd43f2e4ff&quot;&gt;https://preview.redd.it/9v8pcoekfv9d1.png?width=1474&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8dfa8bb8a5efb6b1873e1ee70fba90cd43f2e4ff&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Equivalent_Noise3560&quot;&gt; /u/Equivalent_Noise3560 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dso9pj/custom_functions_with_runnablelambda_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dso9pj/custom_functions_with_runnablelambda_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dso9pj</id><media:thumbnail url="https://external-preview.redd.it/2347JJ6JbmR5WGmdxSM3iu0OnGohPD3MltcLei8lmx8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a4559964a97155995aa6f0c96a36eebba24728a" /><link href="https://www.reddit.com/r/LangChain/comments/1dso9pj/custom_functions_with_runnablelambda_in_langchain/" /><updated>2024-07-01T08:52:49+00:00</updated><published>2024-07-01T08:52:49+00:00</published><title>Custom Functions with RunnableLambda in LangChain JS</title></entry><entry><author><name>/u/OpenInvestigator3235</name><uri>https://www.reddit.com/user/OpenInvestigator3235</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want help with how to go about an idea.&lt;/p&gt; &lt;p&gt;I currently need to build a ‘virtual assistant’ chatbot at work.&lt;/p&gt; &lt;p&gt;For the POC, I am using LangChain, LangGraph, and Chainlit for the UI. &lt;/p&gt; &lt;p&gt;I want through the chatbot based LLM app to be able to access the following: 1. RAG 2. Web Search 3. Normal Conversational Chat&lt;/p&gt; &lt;p&gt;For the persona of the chatbot, I know I can just set that in the context prompt of the system message.&lt;/p&gt; &lt;p&gt;But for the Agent capabilities, I have a simple corrective RAG agent graph made in LangGraph.&lt;/p&gt; &lt;p&gt;My questions are: 1. How do I current the capabilities of the agent graph made to my basic langchain chainlit app? 2. Do I need to make another conversational agent that can be routed to for normal chatbot capabilities or no? 3. How do I make Web Searching with Tavily an ability? 4. What will the final architecture look like?&lt;/p&gt; &lt;p&gt;I really appreciate any input you have.&lt;/p&gt; &lt;p&gt;If anyone is kind enough to give me 10 mins of their time on a discord call, I would REALLY REALLY appreciate it!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OpenInvestigator3235&quot;&gt; /u/OpenInvestigator3235 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsr8tf/agent_routing_inquiry/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsr8tf/agent_routing_inquiry/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dsr8tf</id><link href="https://www.reddit.com/r/LangChain/comments/1dsr8tf/agent_routing_inquiry/" /><updated>2024-07-01T12:01:33+00:00</updated><published>2024-07-01T12:01:33+00:00</published><title>Agent Routing Inquiry</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am using Langgraph and now I want to clear the state if a user presses the button: &amp;quot;Clear Chat History&amp;quot;. &lt;/p&gt; &lt;p&gt;How can I clear the state of my Graph or set it to the default values?&lt;/p&gt; &lt;p&gt;I can view the state like this: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;config ={ &amp;quot;configurable&amp;quot;: {&amp;quot;thread_id&amp;quot;: &amp;quot;user_id19999&amp;quot;}, #here specific user_ids or conversation_ids can be inserted if needed &amp;#39;callbacks&amp;#39;: [langfuse_handler] #if you are not using Langfuse, use &amp;#39;ConsoleCallbackHandler&amp;#39; for &amp;#39;callbacks&amp;#39; } app.get_state(config).values &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Which gives me this output:&lt;/p&gt; &lt;p&gt;{&amp;#39;question&amp;#39;: &amp;#39;Wie war mein Name?&amp;#39;,&lt;br/&gt; &amp;#39;raw_docs&amp;#39;: [],&lt;br/&gt; &amp;#39;generation&amp;#39;: AIMessage(content=&amp;#39;Es tut mir leid, aber zu Ihrer Frage nach meinem Namen konnten keine Inhalte in Confluence gefunden werden. Ich antworte Ihnen gerne, dass mein Name AnswerBot lautet. Bitte beachten Sie, dass diese Antwort nicht anhand von Confluence-Kontextinformationen generiert wurde und ich die Richtigkeit der Antwort nicht sicherstellen kann. Es kann hilfreich sein, die Frage klarer zu formulieren, damit Informationen dazu besser gefunden werden können.&amp;#39;, response_metadata={&amp;#39;finish_reason&amp;#39;: &amp;#39;stop&amp;#39;}, id=&amp;#39;run-6e24ee0f-bbe6-4d8f-99c2-3f816555ffe4&amp;#39;),&lt;br/&gt; &amp;#39;messages&amp;#39;: [HumanMessage(content=&amp;#39;Wie war mein Name?&amp;#39;, id=&amp;#39;2b259646-0465-4b86-80d5-332f005083ab&amp;#39;)],&lt;br/&gt; &amp;#39;is_smalltalk&amp;#39;: &amp;#39;False&amp;#39;,}&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsr14k/clear_state_in_langgraph_to_delete_chat_history/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsr14k/clear_state_in_langgraph_to_delete_chat_history/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dsr14k</id><link href="https://www.reddit.com/r/LangChain/comments/1dsr14k/clear_state_in_langgraph_to_delete_chat_history/" /><updated>2024-07-01T11:49:46+00:00</updated><published>2024-07-01T11:49:46+00:00</published><title>Clear State in Langgraph to delete chat history</title></entry><entry><author><name>/u/AffectionateChain907</name><uri>https://www.reddit.com/user/AffectionateChain907</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsmk86/decreasing_the_response_time_in_multiagent/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/Trr0hIVGArLk1jDefnLU165NUCuypW9tm7AD1E8osbM.jpg&quot; alt=&quot;Decreasing the response time in Multi-Agent Workflow of LangGraph using Ollama - Llama 3 model&quot; title=&quot;Decreasing the response time in Multi-Agent Workflow of LangGraph using Ollama - Llama 3 model&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So recently I was testing out the Multi-Agent Workflow of langchain with some budget constraints and hence I decided to use Llama 3 model from Ollama. &lt;/p&gt; &lt;p&gt;I am following the supervisor structure as shown in their tutorials. The role of the supervisor is to simply redirect the query to one particular agent and that particular agent then handles the extraction of some special attributes from the user query.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/nsib0o7btu9d1.png?width=1934&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=96b120524949e1af997b82b3df221b9824ce1d8d&quot;&gt;Multi-Agent Workflow Schema Diagram&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Now what&amp;#39;s happening is that when I run these agents (without langraph) on a individual script level for 5 user queries, the first query takes around 20 seconds to generate the response and then the subsequent 4 queries give response like within 3 seconds. &lt;/p&gt; &lt;p&gt;But when I connect the supervisor to the agents using LangGraph, and I test it for the same 5 queries, each query takes &amp;gt; 100 seconds to yield the final output. &lt;/p&gt; &lt;p&gt;My hardware specs are pretty decent i believe and should not be a hardware issue :-&lt;/p&gt; &lt;p&gt;RAM- 16GB, PROCESSOR - RYZEN 9, GPU - 4GB RTX 3050&lt;/p&gt; &lt;p&gt;Is this happening most likely due to a code level issue or something related to my ollama server settings like number of models running parallelly? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AffectionateChain907&quot;&gt; /u/AffectionateChain907 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsmk86/decreasing_the_response_time_in_multiagent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsmk86/decreasing_the_response_time_in_multiagent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dsmk86</id><media:thumbnail url="https://b.thumbs.redditmedia.com/Trr0hIVGArLk1jDefnLU165NUCuypW9tm7AD1E8osbM.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1dsmk86/decreasing_the_response_time_in_multiagent/" /><updated>2024-07-01T06:55:03+00:00</updated><published>2024-07-01T06:55:03+00:00</published><title>Decreasing the response time in Multi-Agent Workflow of LangGraph using Ollama - Llama 3 model</title></entry><entry><author><name>/u/ramkitvprk</name><uri>https://www.reddit.com/user/ramkitvprk</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi All,&lt;br/&gt; any resources or reference , I can get to convert the SAS scripts into HIve SQL using LLMs? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ramkitvprk&quot;&gt; /u/ramkitvprk &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsl8ne/sas_to_hive_sql_conversions_using_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsl8ne/sas_to_hive_sql_conversions_using_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dsl8ne</id><link href="https://www.reddit.com/r/LangChain/comments/1dsl8ne/sas_to_hive_sql_conversions_using_llm/" /><updated>2024-07-01T05:27:30+00:00</updated><published>2024-07-01T05:27:30+00:00</published><title>SAS to Hive sql conversions using LLM</title></entry><entry><author><name>/u/UpvoteBeast</name><uri>https://www.reddit.com/user/UpvoteBeast</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Question is self explanatory! Im looking for a workbench or way to evaluate different LLMs. For example giving score to answers, comparing prompts, giving good answer samples, etc etc&lt;/p&gt; &lt;p&gt;If it can show me the runs, the better so i can compare.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpvoteBeast&quot;&gt; /u/UpvoteBeast &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsgbif/evaluate_different_llms_or_flows/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dsgbif/evaluate_different_llms_or_flows/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dsgbif</id><link href="https://www.reddit.com/r/LangChain/comments/1dsgbif/evaluate_different_llms_or_flows/" /><updated>2024-07-01T00:50:30+00:00</updated><published>2024-07-01T00:50:30+00:00</published><title>Evaluate different LLMs or flows</title></entry><entry><author><name>/u/westernspion</name><uri>https://www.reddit.com/user/westernspion</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello there,&lt;/p&gt; &lt;p&gt;What practical applications for langchain based agents have you been having success with?&lt;/p&gt; &lt;p&gt;Of particular interests, what foundational models have you been seeing perform best as agents? What size of datasets do you have it reasoning through?&lt;/p&gt; &lt;p&gt;I’ve been building agents and chains for the past year. My lingering impression is that I won’t get agents involved in any real time chat use cases for performance reasons. I have been sticking to static lcel based chains but they are nowhere near as capable. Tried streaming events back and updating the UI with backend status but - that isn’t actually fixing anything &lt;/p&gt; &lt;p&gt;Sincerely, $corporate_employee &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/westernspion&quot;&gt; /u/westernspion &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds2f62/agents_as_a_practical_solution/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds2f62/agents_as_a_practical_solution/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds2f62</id><link href="https://www.reddit.com/r/LangChain/comments/1ds2f62/agents_as_a_practical_solution/" /><updated>2024-06-30T14:14:05+00:00</updated><published>2024-06-30T14:14:05+00:00</published><title>Agents as a practical solution</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds0vq6/building_autoanalyst_a_data_analytics_ai_agentic/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=176a74000cbddae2ae4411428019bc4d3d1ed768&quot; alt=&quot;Building “Auto-Analyst” — A data analytics AI agentic system&quot; title=&quot;Building “Auto-Analyst” — A data analytics AI agentic system&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://medium.com/firebird-technologies/building-auto-analyst-a-data-analytics-ai-agentic-system-3ac2573dcaf0&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds0vq6/building_autoanalyst_a_data_analytics_ai_agentic/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ds0vq6</id><media:thumbnail url="https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=176a74000cbddae2ae4411428019bc4d3d1ed768" /><link href="https://www.reddit.com/r/LangChain/comments/1ds0vq6/building_autoanalyst_a_data_analytics_ai_agentic/" /><updated>2024-06-30T12:56:15+00:00</updated><published>2024-06-30T12:56:15+00:00</published><title>Building “Auto-Analyst” — A data analytics AI agentic system</title></entry><entry><author><name>/u/Electronic-Letter592</name><uri>https://www.reddit.com/user/Electronic-Letter592</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I need the to extract table content (mainly numbers) from scanned documents. Those numbers are typed, not handwritten. The position and layout of the table can slightly change. What is currently the best open source model for that?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Electronic-Letter592&quot;&gt; /u/Electronic-Letter592 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds4rnu/recommendation_for_table_extraction/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds4rnu/recommendation_for_table_extraction/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds4rnu</id><link href="https://www.reddit.com/r/LangChain/comments/1ds4rnu/recommendation_for_table_extraction/" /><updated>2024-06-30T16:01:08+00:00</updated><published>2024-06-30T16:01:08+00:00</published><title>Recommendation for table extraction</title></entry><entry><author><name>/u/Alarmed-Reporter-230</name><uri>https://www.reddit.com/user/Alarmed-Reporter-230</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;RunnableBranch and RunnableParallel , probably allow to lower api calls costs down, but I fail to see when they are truly needed. What&amp;#39;s your experience with them? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Alarmed-Reporter-230&quot;&gt; /u/Alarmed-Reporter-230 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds3ih5/when_to_use_runnablebranch_and_runnableparallel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds3ih5/when_to_use_runnablebranch_and_runnableparallel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds3ih5</id><link href="https://www.reddit.com/r/LangChain/comments/1ds3ih5/when_to_use_runnablebranch_and_runnableparallel/" /><updated>2024-06-30T15:04:01+00:00</updated><published>2024-06-30T15:04:01+00:00</published><title>When to use RunnableBranch and RunnableParallel</title></entry><entry><author><name>/u/Not-That-rpg</name><uri>https://www.reddit.com/user/Not-That-rpg</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Was writing some code that wanted to print the model string for a model without having a specific model. Unfortunately, &lt;code&gt;BaseChatModel&lt;/code&gt; does not have a &lt;code&gt;model&lt;/code&gt; property. Tried the set of alternatives used in my code at present, &lt;code&gt;Union[ChatOpenAI, ChatLiteLLM, ChatAnthropic]&lt;/code&gt; and &lt;code&gt;ChatOpenAI&lt;/code&gt; has no &lt;code&gt;model&lt;/code&gt; property. This kind of thing hurts langchain&amp;#39;s ability to paper over the differences between LLMs, which is its key strength.&lt;/p&gt; &lt;p&gt;I suggest a refactoring that promotes &lt;code&gt;model&lt;/code&gt; up to the &lt;code&gt;BaseChatModel&lt;/code&gt; and does something about &lt;code&gt;model&lt;/code&gt; vs. &lt;code&gt;model_name&lt;/code&gt; to make the latter both clearer in terms of its meaning (or simply an alias to the former, as it is in &lt;code&gt;ChatAnthropic&lt;/code&gt; (see below). The following in &lt;code&gt;ChatLiteLLM&lt;/code&gt; is not at all helpful:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;model_name: Optional[str] = None &amp;quot;&amp;quot;&amp;quot;Model name to use.&amp;quot;&amp;quot;&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As opposed to model name not to use?&lt;/p&gt; &lt;p&gt;&lt;code&gt;ChatAnthropic&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;model: str = Field(alias=&amp;quot;model_name&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It&amp;#39;s ok if &lt;code&gt;model_name&lt;/code&gt; is just and alias for backwards compatibility, but on &lt;code&gt;ChatLiteLLM&lt;/code&gt; the fact that it&amp;#39;s &lt;code&gt;Optional&lt;/code&gt; means that it might not be defined, which foils that purpose.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Not-That-rpg&quot;&gt; /u/Not-That-rpg &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds40ke/chat_model_class_orthogonality_suggestion/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds40ke/chat_model_class_orthogonality_suggestion/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds40ke</id><link href="https://www.reddit.com/r/LangChain/comments/1ds40ke/chat_model_class_orthogonality_suggestion/" /><updated>2024-06-30T15:26:37+00:00</updated><published>2024-06-30T15:26:37+00:00</published><title>Chat Model Class orthogonality suggestion</title></entry><entry><author><name>/u/RoundImpressive3543</name><uri>https://www.reddit.com/user/RoundImpressive3543</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The input is going to be unfilled form images (imagine W2) and I want to fill it with fake relevant data. The current code I have uses a JSON config file containing the location of coordinates where the fake data needs to go and I just write text on those fields with a white background. I use the faker library to generate fake data but I&amp;#39;m looking for something more accurate and relevant. Can I have some suggestions regarding what technologies I need to use to create such a form generator?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RoundImpressive3543&quot;&gt; /u/RoundImpressive3543 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds7h57/automated_document_filling_need_suggestions/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds7h57/automated_document_filling_need_suggestions/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds7h57</id><link href="https://www.reddit.com/r/LangChain/comments/1ds7h57/automated_document_filling_need_suggestions/" /><updated>2024-06-30T18:04:14+00:00</updated><published>2024-06-30T18:04:14+00:00</published><title>Automated document filling - Need Suggestions</title></entry><entry><author><name>/u/shanumas</name><uri>https://www.reddit.com/user/shanumas</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for a solution for this problem. &lt;a href=&quot;https://github.com/langchain-ai/chat-langchain/issues/339&quot;&gt;https://github.com/langchain-ai/chat-langchain/issues/339&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I checked-out chat-langchain from github. I get the error that :&lt;/p&gt; &lt;p&gt;langgraph-api-1 | ValueError: License key is not valid&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/shanumas&quot;&gt; /u/shanumas &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds1qal/langgraph_license_key_is_not_valid/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ds1qal/langgraph_license_key_is_not_valid/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ds1qal</id><link href="https://www.reddit.com/r/LangChain/comments/1ds1qal/langgraph_license_key_is_not_valid/" /><updated>2024-06-30T13:40:06+00:00</updated><published>2024-06-30T13:40:06+00:00</published><title>Langgraph &quot;License key is not valid&quot;</title></entry><entry><author><name>/u/DueHearing1315</name><uri>https://www.reddit.com/user/DueHearing1315</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drrn4a/visualize_where_in_the_world_your_commits_come/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/wxe3e856hm9d1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f5b62e26c83d3b2c6448c13df1c105b4fce0bc51&quot; alt=&quot;Visualize where in the world your commits come from.&quot; title=&quot;Visualize where in the world your commits come from.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DueHearing1315&quot;&gt; /u/DueHearing1315 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/wxe3e856hm9d1.png&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1drrn4a/visualize_where_in_the_world_your_commits_come/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1drrn4a</id><media:thumbnail url="https://preview.redd.it/wxe3e856hm9d1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f5b62e26c83d3b2c6448c13df1c105b4fce0bc51" /><link href="https://www.reddit.com/r/LangChain/comments/1drrn4a/visualize_where_in_the_world_your_commits_come/" /><updated>2024-06-30T02:45:24+00:00</updated><published>2024-06-30T02:45:24+00:00</published><title>Visualize where in the world your commits come from.</title></entry></feed>