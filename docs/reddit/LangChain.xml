<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-06-12T10:59:47+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Disneyskidney</name><uri>https://www.reddit.com/user/Disneyskidney</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on a use case that relies on very robust knowledge graph construction and I wanted to know if any startups/companies/open-source have built either free or paid production ready solutions for the unstructured text to knowledge graph pipeline.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Disneyskidney&quot;&gt; /u/Disneyskidney &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddvywe/production_ready_unstructured_text_to_knowledge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddvywe/production_ready_unstructured_text_to_knowledge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddvywe</id><link href="https://www.reddit.com/r/LangChain/comments/1ddvywe/production_ready_unstructured_text_to_knowledge/" /><updated>2024-06-12T02:29:12+00:00</updated><published>2024-06-12T02:29:12+00:00</published><title>Production Ready Unstructured Text to Knowledge Graph</title></entry><entry><author><name>/u/thewanitz</name><uri>https://www.reddit.com/user/thewanitz</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys!&lt;/p&gt; &lt;p&gt;So I’ve been looking at a lot of tutorials to build a basic RAG search which does the following:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Takes the user query and put it into the state “user_query”&lt;/li&gt; &lt;li&gt;Searches the internet for results. These results are then populated as text in the state “internet_search_results” field with the url and title of the text&lt;/li&gt; &lt;li&gt; Does the same but searches the local database and populates the state “local_search_results” field with the post ID and title of the search results. &lt;/li&gt; &lt;li&gt;Then passes the state with the information above into a summariser function which uses GPT 3.5 to return structured output with the following fields: (i) the text response, (ii) an array of the sources which include the title, the type (web search or local post), and either the url or the post ID. &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I’m at a loss on this as can’t find any good tutorials for this. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thewanitz&quot;&gt; /u/thewanitz &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1de095x/good_tutorials_for_rag_with_structured_state_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1de095x/good_tutorials_for_rag_with_structured_state_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1de095x</id><link href="https://www.reddit.com/r/LangChain/comments/1de095x/good_tutorials_for_rag_with_structured_state_and/" /><updated>2024-06-12T06:48:15+00:00</updated><published>2024-06-12T06:48:15+00:00</published><title>Good Tutorials For RAG with Structured State and Output?</title></entry><entry><author><name>/u/Highlight-Content</name><uri>https://www.reddit.com/user/Highlight-Content</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In this &lt;a href=&quot;https://medium.com/ama-tech-blog/combining-langchain-and-llamaindex-to-build-your-first-agentic-rag-system-6e8e2e7825e7&quot;&gt;Medium article&lt;/a&gt;, the agent has three tools:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&amp;quot;lyft_10k&amp;quot;: &amp;quot;Provides information about Lyft financials for year 2021. &amp;quot;&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&amp;quot;uber_10k&amp;quot;: &amp;quot;Provides information about Uber financials for year 2021. &amp;quot;&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;and&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&amp;#39;DuckDuckGoSearch&amp;#39;: &amp;#39;Use for when you need to perform an internet search to find information that another tool can not provide.&amp;#39;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In one of the test cases, the author queries the agent&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;quot;List me the names of Uber&amp;#39;s board of directors.&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Intuitively, one would assume the agent will invoke the &amp;quot;uber_10k&amp;quot; tool. However, the agent invokes &amp;quot;DuckDuckGoSearch&amp;quot;.&lt;/p&gt; &lt;p&gt;The author explains that:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Since this information is out-of-scope for any of the retriever tools, the agent correctly decided to invoke the external search tool.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;How does the agent know that question is out-of-scope for the &amp;quot;uber_10k&amp;quot; retriever?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Highlight-Content&quot;&gt; /u/Highlight-Content &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddr9hj/how_does_this_langchain_agent_correctly_identify/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddr9hj/how_does_this_langchain_agent_correctly_identify/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddr9hj</id><link href="https://www.reddit.com/r/LangChain/comments/1ddr9hj/how_does_this_langchain_agent_correctly_identify/" /><updated>2024-06-11T22:36:45+00:00</updated><published>2024-06-11T22:36:45+00:00</published><title>How does this LangChain agent correctly identify the tool to use?</title></entry><entry><author><name>/u/Medium_Eggplant795</name><uri>https://www.reddit.com/user/Medium_Eggplant795</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am not a software engineer but an enthusiast of RAG and LLM agents. I wanted to know where is the real bottleneck in building an agent who would build documents based on chat that I am currently having with an LLM based chat interface and embed the chat text using embedding models and store it in vector db for the user to search in later? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Medium_Eggplant795&quot;&gt; /u/Medium_Eggplant795 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddyhkq/question_regarding_limitation_of_agent_use/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddyhkq/question_regarding_limitation_of_agent_use/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddyhkq</id><link href="https://www.reddit.com/r/LangChain/comments/1ddyhkq/question_regarding_limitation_of_agent_use/" /><updated>2024-06-12T04:51:46+00:00</updated><published>2024-06-12T04:51:46+00:00</published><title>Question regarding limitation of agent use</title></entry><entry><author><name>/u/diptanuc</name><uri>https://www.reddit.com/user/diptanuc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks, we built a TypeScript library to improve search results in RAG Applications. If you are building a RAG application on top of vector indexes, re-ranking search results will always improve LLM&amp;#39;s response synthesis. We implemented two commonly used re-ranking techniques - Reciprocal Rank Fusion(RRF) and LLM Based Re-Ranking(using Llama3 from Groq and GPT-4). Hope this is useful to folks building LLM Applications in React/NextJS.&lt;/p&gt; &lt;p&gt;Code - &lt;a href=&quot;https://github.com/tensorlakeai/rerank-ts&quot;&gt;https://github.com/tensorlakeai/rerank-ts&lt;/a&gt; &lt;/p&gt; &lt;p&gt;We were building a consumer application with our open source data framework &lt;a href=&quot;https://github.com/tensorlakeai/indexify&quot;&gt;https://github.com/tensorlakeai/indexify&lt;/a&gt; and were not able to find a good re-ranking library in TypeScript. So we decided to build one, and it works really well to re-rank ~100 results. We get latency of around 1 second with Llama3/Groq. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/diptanuc&quot;&gt; /u/diptanuc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddhd9t/rerankts_typescript_library_for_improving_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddhd9t/rerankts_typescript_library_for_improving_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddhd9t</id><link href="https://www.reddit.com/r/LangChain/comments/1ddhd9t/rerankts_typescript_library_for_improving_search/" /><updated>2024-06-11T15:46:38+00:00</updated><published>2024-06-11T15:46:38+00:00</published><title>rerank-ts: TypeScript Library for Improving Search Results in RAG Applications</title></entry><entry><author><name>/u/Fit_Influence_1576</name><uri>https://www.reddit.com/user/Fit_Influence_1576</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’m looking for a chatbot frontend with citations, that utilizes a fast api/langserve backend. Anyone have good suggestions? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fit_Influence_1576&quot;&gt; /u/Fit_Influence_1576 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddm4a1/full_stack_starter/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddm4a1/full_stack_starter/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddm4a1</id><link href="https://www.reddit.com/r/LangChain/comments/1ddm4a1/full_stack_starter/" /><updated>2024-06-11T19:01:34+00:00</updated><published>2024-06-11T19:01:34+00:00</published><title>Full stack starter</title></entry><entry><author><name>/u/youniss_k</name><uri>https://www.reddit.com/user/youniss_k</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Using langchain sometimes feels like gambling with costs to me. I never really know how much my requests would actually cost when I send it. I know there are detailed charts which we should read, but who really does? Instead I wanted to ask if anybody knows of an automated way to calculate costs before sending the requests? For my use case, specifically for OpenAI, but maybe there is another way.&lt;/p&gt; &lt;p&gt;And if there isnt anything like that, maybe this would be an interessting project... Like a package which calculates your LLM costs before the requests, depending on the specific platform you use&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/youniss_k&quot;&gt; /u/youniss_k &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddft47/calculating_llm_costs_before_sending_requests/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddft47/calculating_llm_costs_before_sending_requests/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddft47</id><link href="https://www.reddit.com/r/LangChain/comments/1ddft47/calculating_llm_costs_before_sending_requests/" /><updated>2024-06-11T14:41:50+00:00</updated><published>2024-06-11T14:41:50+00:00</published><title>Calculating LLM costs before sending requests?</title></entry><entry><author><name>/u/ss1seekining</name><uri>https://www.reddit.com/user/ss1seekining</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys I was struggling for quite sometime on how to host Langserve in AWS ECS. So prepared this two repos&lt;/p&gt; &lt;p&gt;1st one creates a VPC &lt;a href=&quot;https://github.com/mathlover777/shared-vpc&quot;&gt;https://github.com/mathlover777/shared-vpc&lt;/a&gt;&lt;/p&gt; &lt;p&gt;2nd one deploys in the same VPC &lt;a href=&quot;https://github.com/mathlover777/langserve-cdk-ecs&quot;&gt;https://github.com/mathlover777/langserve-cdk-ecs&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You can deployment multiple stages in the same VPC also as AWS has a soft limit on number of VPCs.&lt;/p&gt; &lt;p&gt;This does not have autoscale added, as I dont know how to do it myself in ecs, will update when I get time.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ss1seekining&quot;&gt; /u/ss1seekining &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddb6qz/deploying_langserve_in_ecs_with_cdk/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddb6qz/deploying_langserve_in_ecs_with_cdk/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddb6qz</id><link href="https://www.reddit.com/r/LangChain/comments/1ddb6qz/deploying_langserve_in_ecs_with_cdk/" /><updated>2024-06-11T10:50:50+00:00</updated><published>2024-06-11T10:50:50+00:00</published><title>Deploying Langserve in ECS with CDK</title></entry><entry><author><name>/u/Not-That-rpg</name><uri>https://www.reddit.com/user/Not-That-rpg</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Recently when I try to do &lt;code&gt;import langchain_anthropic&lt;/code&gt; I have been getting errors like this: ```&lt;/p&gt; &lt;blockquote&gt; &lt;blockquote&gt; &lt;blockquote&gt; &lt;p&gt;import langchain&lt;em&gt;anthropic Traceback (most recent call last): File &amp;quot;&amp;lt;stdin&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt; File &amp;quot;/usr/local/lib/python3.12/site-packages/langchain_anthropic/&lt;/em&gt;&lt;em&gt;init&lt;/em&gt;&lt;em&gt;.py&amp;quot;, line 1, in &amp;lt;module&amp;gt; from langchain_anthropic.chat_models import ChatAnthropic, ChatAnthropicMessages File &amp;quot;/usr/local/lib/python3.12/site-packages/langchain_anthropic/chat_models.py&amp;quot;, line 26, in &amp;lt;module&amp;gt; from langchain_core.callbacks import ( File &amp;quot;/usr/local/lib/python3.12/site-packages/langchain_core/callbacks/&lt;/em&gt;&lt;em&gt;init&lt;/em&gt;&lt;em&gt;.py&amp;quot;, line 22, in &amp;lt;module&amp;gt; from langchain_core.callbacks.manager import ( File &amp;quot;/usr/local/lib/python3.12/site-packages/langchain_core/callbacks/manager.py&amp;quot;, line 29, in &amp;lt;module&amp;gt; from langsmith.run_helpers import get_run_tree_context File &amp;quot;/usr/local/lib/python3.12/site-packages/langsmith/run_helpers.py&amp;quot;, line 40, in &amp;lt;module&amp;gt; from langsmith import client as ls_client File &amp;quot;/usr/local/lib/python3.12/site-packages/langsmith/client.py&amp;quot;, line 52, in &amp;lt;module&amp;gt; from langsmith import env as ls_env File &amp;quot;/usr/local/lib/python3.12/site-packages/langsmith/env/&lt;/em&gt;&lt;em&gt;init&lt;/em&gt;&lt;em&gt;.py&amp;quot;, line 3, in &amp;lt;module&amp;gt; from langsmith.env._runtime_env import ( File &amp;quot;/usr/local/lib/python3.12/site-packages/langsmith/env/_runtime_env.py&amp;quot;, line 10, in &amp;lt;module&amp;gt; from langsmith.utils import get_docker_compose_command File &amp;quot;/usr/local/lib/python3.12/site-packages/langsmith/utils.py&amp;quot;, line 31, in &amp;lt;module&amp;gt; from langsmith import schemas as ls_schemas File &amp;quot;/usr/local/lib/python3.12/site-packages/langsmith/schemas.py&amp;quot;, line 69, in &amp;lt;module&amp;gt; class Example(ExampleBase): File &amp;quot;/usr/local/lib/python3.12/site-packages/pydantic/v1/main.py&amp;quot;, line 286, in __new&lt;/em&gt;_ cls.&lt;strong&gt;try_update_forward_refs&lt;/strong&gt;() File &amp;quot;/usr/local/lib/python3.12/site-packages/pydantic/v1/main.py&amp;quot;, line 807, in &lt;strong&gt;try_update_forward_refs&lt;/strong&gt; update&lt;em&gt;model_forward_refs(cls, cls.&lt;/em&gt;&lt;em&gt;fields&lt;/em&gt;&lt;em&gt;.values(), cls.&lt;/em&gt;&lt;em&gt;config&lt;/em&gt;&lt;em&gt;.json_encoders, localns, (NameError,)) File &amp;quot;/usr/local/lib/python3.12/site-packages/pydantic/v1/typing.py&amp;quot;, line 554, in update_model_forward_refs update_field_forward_refs(f, globalns=globalns, localns=localns) File &amp;quot;/usr/local/lib/python3.12/site-packages/pydantic/v1/typing.py&amp;quot;, line 520, in update_field_forward_refs field.type&lt;/em&gt; = evaluate&lt;em&gt;forwardref(field.type&lt;/em&gt;, globalns, localns or None) File &amp;quot;/usr/local/lib/python3.12/site-packages/pydantic/v1/typing.py&amp;quot;, line 66, in evaluate&lt;em&gt;forwardref return cast(Any, type&lt;/em&gt;)._evaluate(globalns, localns, set()) TypeError: ForwardRef._evaluate() missing 1 required keyword-only argument: &amp;#39;recursive_guard&amp;#39;&lt;/p&gt; &lt;p&gt;``&lt;code&gt; That smells like maybe there&amp;#39;s an un-captured dependency from the&lt;/code&gt;langchain_anthropic` code onto pydantic or something, but I don&amp;#39;t have any great ideas about how to debug this. Anyone else seen this? Any fix or work-around?&lt;/p&gt; &lt;/blockquote&gt; &lt;/blockquote&gt; &lt;/blockquote&gt; &lt;p&gt;Checking, it looks like I have &lt;code&gt;langchain-anthropic==0.1.13&lt;/code&gt; and &lt;code&gt;langchain==0.1.20&lt;/code&gt; if that helps.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Not-That-rpg&quot;&gt; /u/Not-That-rpg &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddort5/errors_loading_langchain_anthropic/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddort5/errors_loading_langchain_anthropic/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddort5</id><link href="https://www.reddit.com/r/LangChain/comments/1ddort5/errors_loading_langchain_anthropic/" /><updated>2024-06-11T20:50:13+00:00</updated><published>2024-06-11T20:50:13+00:00</published><title>Errors loading `langchain_anthropic`</title></entry><entry><author><name>/u/Gvascons</name><uri>https://www.reddit.com/user/Gvascons</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So, I&amp;#39;m building this simple rag pipeline with langchain and ollama that takes in a PDF document and returns it&amp;#39;s summary as bulletpoints.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;file_path = &amp;quot;paper.pdf&amp;quot; loader = PyPDFLoader(file_path) docs = loader.load() embeddings = (OllamaEmbeddings(model=&amp;#39;llama3&amp;#39;)) text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) splits = text_splitter.split_documents(docs) vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings, persist_directory=&amp;quot;emb&amp;quot;) retriever = as_retriever( embeddings=embeddings, chroma=vectorstore ) prompt_template = &amp;quot;&amp;quot;&amp;quot;Based on the following information and being really specific about it&amp;#39;s data: &amp;#39;{text}&amp;#39;.\n\n Here are the goals, methodology, and conclusions/achievements of the paper, written as bullet points:&amp;quot;&amp;quot;&amp;quot; prompt = PromptTemplate.from_template(prompt_template) llm = Ollama(model=&amp;quot;llama3&amp;quot;) chain = ( retriever | prompt | llm ) result = chain.invoke({}) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The calling of the chain just seems too much like a workaround, since I didn&amp;#39;t have a specific question about the reference document, therefore I just had to use the prompt_template as the instruction to treat the pdf. It just seems like there are a lot of way to get to this same result. Whether to call the llm by it&amp;#39;s default completion object or through it&amp;#39;s chat variation. Whether to use a LLMChain(), a RetrievalQA.from_chain_type() or a simple chain() specifying it&amp;#39;s common parameters etc. Ins&amp;#39;t there a way to standardize this workflow according to your needs?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Gvascons&quot;&gt; /u/Gvascons &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dddjew/multiple_ways_to_get_to_the_same_result_w_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dddjew/multiple_ways_to_get_to_the_same_result_w_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dddjew</id><link href="https://www.reddit.com/r/LangChain/comments/1dddjew/multiple_ways_to_get_to_the_same_result_w_rag/" /><updated>2024-06-11T13:00:58+00:00</updated><published>2024-06-11T13:00:58+00:00</published><title>Multiple ways to get to the same result w/ RAG</title></entry><entry><author><name>/u/Sweaty-Wolf2228</name><uri>https://www.reddit.com/user/Sweaty-Wolf2228</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I use chainlit as UI in my rag system, the first qst passes ok, but when i inser the second one it translated automaticly to english. So How to strictly change translation for all users to a specific language? File xx-XX.json is placed in the translations folder. Deletion of en-US.json doesn&amp;#39;t work (it is generated each time again) &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sweaty-Wolf2228&quot;&gt; /u/Sweaty-Wolf2228 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddfqps/chainlit_translation_in_a_rag_system/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddfqps/chainlit_translation_in_a_rag_system/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddfqps</id><link href="https://www.reddit.com/r/LangChain/comments/1ddfqps/chainlit_translation_in_a_rag_system/" /><updated>2024-06-11T14:39:07+00:00</updated><published>2024-06-11T14:39:07+00:00</published><title>Chainlit translation in a rag system</title></entry><entry><author><name>/u/pantulis</name><uri>https://www.reddit.com/user/pantulis</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, as a learning side project I am trying to have a simple Agent that queries an authenticated external API. Authentication is with a standard Bearer token.&lt;/p&gt; &lt;p&gt;I have two tools, one is called fetch_token that knows how to request a valid access token. And then there is another tool which does the real work and fetches certain value from an external https endpoint using the previously retrieved access token. These are non public APIs and in my tool functions I am using &amp;#39;requests&amp;#39; to programatically access and parse the JSON to extract the relevant values back to the Agent.&lt;/p&gt; &lt;p&gt;So given a user&amp;#39;s query, the Agent must invoke the first tool, fetch the access token and then invoke the second one passing the token as a parameter.&lt;/p&gt; &lt;p&gt;The thing is working, (yay!!), even when the input of the user makes the agent call the second tool repeatedly with different input values (but the same access token).&lt;/p&gt; &lt;p&gt;But my issue is that the agent is terribly slow. I suspect this happens because the bearer token (a quite long and random string, it is 2330 hexadecimal chars) is being passed each time to the LLM (OpenAI, &amp;#39;gpt4-turbo-preview&amp;#39;) and that takes a lot of context and processing for the LLM, which perhaps only be concerned with the fact that the access token is already present, not its value.&lt;/p&gt; &lt;p&gt;So I was thinking of storing the token in the Agent state, but I am not aware of a way that the output of a tool can be stored in the Agent state, and I also suspect that the whole Agent state is what is already being sent to the LLM so this would not defeat the purpose of this hoop.&lt;/p&gt; &lt;p&gt;So I am at a loss, my Agent is roughly working but is very slow! Are there any suggestions, resources or examples for this patterns?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pantulis&quot;&gt; /u/pantulis &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddl2k0/newbie_question_langgraph_and_authenticated_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddl2k0/newbie_question_langgraph_and_authenticated_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddl2k0</id><link href="https://www.reddit.com/r/LangChain/comments/1ddl2k0/newbie_question_langgraph_and_authenticated_tools/" /><updated>2024-06-11T18:19:15+00:00</updated><published>2024-06-11T18:19:15+00:00</published><title>Newbie question: Langgraph and authenticated tools</title></entry><entry><author><name>/u/HotDogDelusions</name><uri>https://www.reddit.com/user/HotDogDelusions</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So this is my first time ever hearing about vector databases - I know very little about them and I&amp;#39;m running into some trouble with a simple rag script I threw together.&lt;/p&gt; &lt;p&gt;I followed one of langchain&amp;#39;s documentation tutorials and was able to get a basic RAG setup going with some text files. Well now I&amp;#39;m trying to expand on it to be something useful - so I currently have ~800 documents totaling to just under 50 MB of data that I want to store in the vector DB. For some reason, the `Chroma.from_documents()` method will hang for a very long period of time (been running for over 10 minutes now) - and I can&amp;#39;t seem to figure out why it&amp;#39;s so slow.&lt;/p&gt; &lt;p&gt;Firstly, this `Chroma.from_documents` method - is what its doing called &amp;quot;indexing&amp;quot;? I keep seeing this term thrown around, not entirely sure what it means.&lt;/p&gt; &lt;p&gt;Second, Is it normal for creating the vector store to take this long with the amount of data I have? I figured 50MB of data and only 800 documents would be pretty trivial, as I&amp;#39;ve seen other posts about people having millions of documents.&lt;/p&gt; &lt;p&gt;Any help would be appreciated.&lt;/p&gt; &lt;p&gt;For reference, here is the relevant code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;loader = DirectoryLoader(&amp;#39;docs2&amp;#39;, glob=&amp;#39;**/*.htm&amp;#39;, loader_cls=BSHTMLLoader, loader_kwargs={&amp;#39;open_encoding&amp;#39;: &amp;#39;utf8&amp;#39;}, show_progress=True, use_multithreading=True) docs = loader.load() text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000) splits = text_splitter.split_documents(docs) model = &amp;#39;Alibaba-NLP/gte-large-en-v1.5&amp;#39; model_kwargs = model_kwargs = {&amp;#39;device&amp;#39;:&amp;#39;cpu&amp;#39;, &amp;#39;trust_remote_code&amp;#39;: True} encode_kwargs = {&amp;#39;normalize_embeddings&amp;#39;: True} embeddings = HuggingFaceEmbeddings( model_name=model, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs ) vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HotDogDelusions&quot;&gt; /u/HotDogDelusions &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddk9b1/chroma_db_taking_extremely_long_time_to_create/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddk9b1/chroma_db_taking_extremely_long_time_to_create/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddk9b1</id><link href="https://www.reddit.com/r/LangChain/comments/1ddk9b1/chroma_db_taking_extremely_long_time_to_create/" /><updated>2024-06-11T17:46:56+00:00</updated><published>2024-06-11T17:46:56+00:00</published><title>Chroma DB taking extremely long time to create.</title></entry><entry><author><name>/u/Informal-Victory8655</name><uri>https://www.reddit.com/user/Informal-Victory8655</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys, I&amp;#39;m working on this project where initially we have 700 csvs to be ingested and build a poc with some ui for querying the csvs database with text and and metadata parameters selected via ui.&lt;/p&gt; &lt;p&gt;Need opinions fro experts on how to approach this project, considering the production use and ingesting more cvs into ai system. &lt;/p&gt; &lt;p&gt;For initial POC, I&amp;#39;m planning to use chromadb and streamlit for UI. Better options?&lt;/p&gt; &lt;p&gt;I can build above RAG, but I&amp;#39;m asking for expert opinions keeping in mind the production use case and scaling to more pdfs &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Informal-Victory8655&quot;&gt; /u/Informal-Victory8655 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dd8ssq/best_way_forward_and_vector_db_for_an_ai_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dd8ssq/best_way_forward_and_vector_db_for_an_ai_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dd8ssq</id><link href="https://www.reddit.com/r/LangChain/comments/1dd8ssq/best_way_forward_and_vector_db_for_an_ai_rag/" /><updated>2024-06-11T08:02:51+00:00</updated><published>2024-06-11T08:02:51+00:00</published><title>Best way forward and vector db for an AI RAG system for CVs ranking using query and some metadata</title></entry><entry><author><name>/u/Yuzunii</name><uri>https://www.reddit.com/user/Yuzunii</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a way to implement multistep operations in LangGraph? Specifically, I&amp;#39;m looking to perform a series of modifications where one step directly influences the next. For instance, I want to first remove the background of an image in the initial node, and then, in a subsequent node, use another tool to search for and replace an object. The key requirement is that the second modification should be applied to the modified image from the first step, not the original image. Can LangGraph handle this type of sequential image processing?&lt;/p&gt; &lt;ul&gt; &lt;li&gt;I have checked langgraph documentation and found no relevant information&lt;/li&gt; &lt;li&gt;I have tried changing and updating the way I have written the prompt to see if it affects&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Any help is greatly appreciated :))&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Yuzunii&quot;&gt; /u/Yuzunii &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddg11m/is_there_a_way_to_add_multistepscontinuation_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddg11m/is_there_a_way_to_add_multistepscontinuation_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddg11m</id><link href="https://www.reddit.com/r/LangChain/comments/1ddg11m/is_there_a_way_to_add_multistepscontinuation_in/" /><updated>2024-06-11T14:51:04+00:00</updated><published>2024-06-11T14:51:04+00:00</published><title>Is there a way to add multisteps/continuation in langgraph?</title></entry><entry><author><name>/u/rtrex12</name><uri>https://www.reddit.com/user/rtrex12</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;For context my vector db research started today from 0 knowledge and I feel absolutely unqualified to be making this decision but here we are.&lt;/p&gt; &lt;p&gt;I have narrowed the search down to Milvus, Qdrant and potentially Weaviate.&lt;/p&gt; &lt;p&gt;I am scoping out a project for a client where we need to store up to 100 million pages. The application is scientific so retrieval precision is a top priority as is search time latency and cost.&lt;/p&gt; &lt;p&gt;It seems:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Milvus seems the most established and easiest to setup. also itis fast but takes up a lot of memory so can get quite expensive.&lt;/li&gt; &lt;li&gt;Qdrant is fast and quite a bit cheaper than Milvus but lacks dynamic sharding &lt;/li&gt; &lt;li&gt;I have seen two conflicting reports one saying Weaviate is incredibly quick with a benchmark of 0.12s for a particular query which took Milvus 0.9s to perform the same and then another where it says it is slow. and it is the cheapest.&lt;/li&gt; &lt;li&gt;PG-vector is not as performant as the dedicated vector stores but are tried and tested part of the ecosystem and anecdotally great to work with &lt;/li&gt; &lt;li&gt;Chroma is not the best for accurate retrieval and I haven&amp;#39;t heard many recommending it as the best except for its usability and ease of integration. &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rtrex12&quot;&gt; /u/rtrex12 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcyc6i/what_vector_db_should_i_choose_for_100m_pages_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcyc6i/what_vector_db_should_i_choose_for_100m_pages_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcyc6i</id><link href="https://www.reddit.com/r/LangChain/comments/1dcyc6i/what_vector_db_should_i_choose_for_100m_pages_of/" /><updated>2024-06-10T22:18:54+00:00</updated><published>2024-06-10T22:18:54+00:00</published><title>What vector db should I choose for 100m pages of text?</title></entry><entry><author><name>/u/conjuncti</name><uri>https://www.reddit.com/user/conjuncti</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;People of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt;, &lt;/p&gt; &lt;p&gt;Like many of you (&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1am3fz8/how_to_recover_document_structure_and_plain_text/&quot;&gt;1&lt;/a&gt;) (&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cn0z11/extract_tables_from_pdf_for_rag/&quot;&gt;2&lt;/a&gt;) (&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/17c7g9b/anyone_worked_on_reading_pdf_with_tables/&quot;&gt;3&lt;/a&gt;), I have been searching for a reasonable way to extract precious tables from pdfs for RAG for quite some time. Despite this seemingly simple problem, I&amp;#39;ve been surprised at just how unsolved this problem is. Despite a ton of options (see below), surprisingly few of them &amp;quot;just work&amp;quot;. Some users have even suggested paid APIs like Mathpix and Adobe Extract.&lt;/p&gt; &lt;p&gt;In an effort to consolidate all the options out there, I&amp;#39;ve made a guide for many existing pdf table extraction options, with links to quickstarts, Colab Notebooks, and github repos. I&amp;#39;ve written &lt;a href=&quot;https://drive.google.com/drive/u/0/folders/114bWRj5H4aE-BA5UKH9S5ol8LC6vhqfR&quot;&gt;colab notebooks&lt;/a&gt; that let you extract tables using methods like pdfplumber, pymupdf, nougat, open-parse, deepdoctection, surya, and unstructured. To be as objective as possible, I&amp;#39;ve also compared the options with the same 3 papers: &lt;a href=&quot;https://arxiv.org/abs/2110.00061&quot;&gt;PubTables-1M (tatr)&lt;/a&gt;, the classic &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;Attention&lt;/a&gt; paper, and a &lt;a href=&quot;http://ccc.chem.pitt.edu/wipf/Web/NMR_Impurities.pdf&quot;&gt;very challenging nmr table&lt;/a&gt;.&lt;/p&gt; &lt;h1&gt;gmft release&lt;/h1&gt; &lt;p&gt;On top of this, I&amp;#39;m thrilled to announce &lt;a href=&quot;https://github.com/conjuncts/gmft&quot;&gt;gmft&lt;/a&gt; (&lt;strong&gt;g&lt;/strong&gt;ive &lt;strong&gt;m&lt;/strong&gt;e the &lt;strong&gt;f&lt;/strong&gt;ormatted &lt;strong&gt;t&lt;/strong&gt;ables), a deep table recognition relying on Microsoft&amp;#39;s TATR. Partially written out of exasperation, it is about an &lt;em&gt;order of magnitude faster&lt;/em&gt; than most deep competitors like nougat, open-parse, unstructured and deepdoctection. It runs on &lt;strong&gt;cpu&lt;/strong&gt; (!) at around 1.381 s/page; it additionally takes ~0.945s for each table converted to df. The reason why it&amp;#39;s so fast is that gmft does not rerun OCR. In many cases, the existing OCR is already good or even better than tesseract or other OCR software, so there is no need for expensive OCR. But gmft still allows for OCR downstream by outputting an image of the cropped table.&lt;/p&gt; &lt;p&gt;I also think gmft&amp;#39;s quality is unparalleled, especially in terms of value alignment to row/column header! It&amp;#39;s easiest to see the results (&lt;a href=&quot;https://colab.research.google.com/drive/1fEqsTdKcO5RNPV_b2v9cB4Y5We9Kv-hR&quot;&gt;colab&lt;/a&gt;) (&lt;a href=&quot;https://github.com/conjuncts/gmft/blob/main/notebooks/bulk_extract.ipynb&quot;&gt;github&lt;/a&gt;) for yourself. I invite the reader to explore all the notebooks to survey your own use cases and compare see each option&amp;#39;s strengths and weaknesses.&lt;/p&gt; &lt;p&gt;Some weaknesses of gmft include no rotated table support (yet), false positives when rotated, and a current lack of support for multi-indexes (multiple row headers). However, gmft&amp;#39;s major strength is alignment. Because of the underlying algorithm, values are usually correctly aligned to their row or column header, even when there are other issues with TATR. This is in contrast with other options like unstructured, open-parse, which may fail first on alignment. Anecdotally, I&amp;#39;ve personally extracted ~4000 pdfs with gmft on cpu, and (barring occassional header issues) the quality is excellent. Again, take a look at &lt;a href=&quot;https://colab.research.google.com/drive/1fEqsTdKcO5RNPV_b2&quot;&gt;this notebook&lt;/a&gt; for the table quality.&lt;/p&gt; &lt;h1&gt;Comparison&lt;/h1&gt; &lt;p&gt;All the quickstarts that I have made/modified are in &lt;a href=&quot;https://drive.google.com/drive/u/0/folders/114bWRj5H4aE-BA5UKH9S5ol8LC6vhqfR&quot;&gt;this google drive folder&lt;/a&gt;; the installations should all work with google colab.&lt;/p&gt; &lt;p&gt;The most up-to-date table of all comparisons is &lt;a href=&quot;https://docs.google.com/spreadsheets/d/12IhxHZbYF71dPl32PQpF_6pg9e9S8f9W4sTHt-B0KTg/edit#gid=0&quot;&gt;here&lt;/a&gt;; my calculations for throughput is &lt;a href=&quot;https://docs.google.com/spreadsheets/d/12IhxHZbYF71dPl32PQpF_6pg9e9S8f9W4sTHt-B0KTg/edit#gid=39227585&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I have undoubtedly missed some options. In particular, I have not had the chance to evaluate paddleocr. As a stopgap, see &lt;a href=&quot;https://medium.com/@malshanCS/automating-table-data-extraction-tools-and-techniques-for-efficiency-a29df313cbda#629d&quot;&gt;this&lt;/a&gt; writeup. If you&amp;#39;d like an option added to the table, please let me know!&lt;/p&gt; &lt;h2&gt;Table&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;https://docs.google.com/spreadsheets/d/12IhxHZbYF71dPl32PQpF_6pg9e9S8f9W4sTHt-B0KTg/edit#gid=0&quot;&gt;See google sheets!&lt;/a&gt; Table is too big for reddit to format.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/conjuncti&quot;&gt; /u/conjuncti &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dclawv/pdf_table_extraction_the_definitive_guide_gmft/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dclawv/pdf_table_extraction_the_definitive_guide_gmft/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dclawv</id><link href="https://www.reddit.com/r/LangChain/comments/1dclawv/pdf_table_extraction_the_definitive_guide_gmft/" /><updated>2024-06-10T13:18:10+00:00</updated><published>2024-06-10T13:18:10+00:00</published><title>PDF Table Extraction, the Definitive Guide (+ gmft release!)</title></entry><entry><author><name>/u/harshit_nariya</name><uri>https://www.reddit.com/user/harshit_nariya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/harshit_nariya&quot;&gt; /u/harshit_nariya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/AnyBodyCanAI/comments/1dd9hj9/can_ai_chatbots_help_airbnb_hosts_win_with_guests/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dd9i93/can_ai_chatbots_help_airbnb_hosts_win_with_guests/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dd9i93</id><link href="https://www.reddit.com/r/LangChain/comments/1dd9i93/can_ai_chatbots_help_airbnb_hosts_win_with_guests/" /><updated>2024-06-11T08:54:51+00:00</updated><published>2024-06-11T08:54:51+00:00</published><title>Can AI Chatbots Help Airbnb Hosts Win with Guests?</title></entry><entry><author><name>/u/tisi3000</name><uri>https://www.reddit.com/user/tisi3000</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcwtxk/build_ai_automation_with_managed_triggers_human/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/xmfqjmle8t5d1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=40e33e68dd5565b3d24efe6ef00069c46a609370&quot; alt=&quot;Build AI automation with managed triggers, human approvals and retries&quot; title=&quot;Build AI automation with managed triggers, human approvals and retries&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/tisi3000&quot;&gt; /u/tisi3000 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/xmfqjmle8t5d1.png&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcwtxk/build_ai_automation_with_managed_triggers_human/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dcwtxk</id><media:thumbnail url="https://preview.redd.it/xmfqjmle8t5d1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=40e33e68dd5565b3d24efe6ef00069c46a609370" /><link href="https://www.reddit.com/r/LangChain/comments/1dcwtxk/build_ai_automation_with_managed_triggers_human/" /><updated>2024-06-10T21:14:57+00:00</updated><published>2024-06-10T21:14:57+00:00</published><title>Build AI automation with managed triggers, human approvals and retries</title></entry><entry><author><name>/u/Aggravating-Lack6666</name><uri>https://www.reddit.com/user/Aggravating-Lack6666</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;I have 2 cases of ambiguity&lt;/strong&gt; &lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Similar names within a table - Eg: constrained_demand, unconstrained_demand&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Same names across different tables. - Sales in both table1 and table 2&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I have built a chatbot using open-ai tools agents , giving it access to SQLDatabaseToolKit. There is prefix, suffix and FewShotPrompt Template to handle multiple different calculations and complexities of SQL queries. Now user can ask multiple queries of the below format .&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;What is the demand for 2024? - there is ambiguity as to if the user is asking constrained demand or unconstrained demand. Assumption that is no &amp;quot;demand&amp;quot; column . Expectation - LLM should figure out such ambiguity without any hardcoding and then ask back the user as to which column he is referring to. Once LLM gets user input, then query with the new info.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;What is the sales for brand1? there is ambiguity as to if the user is asking sales from table1 or table2. Expectation - LLM should figure out such ambiguity without any hardcoding and then ask back the user as to which table he is referring to. Once LLM gets user input, then query with the new info.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Cannot handle this in column description as even if the descriptions are different, we cannot make sense from the question. Need help in how to approach this. TIA!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Aggravating-Lack6666&quot;&gt; /u/Aggravating-Lack6666 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcvnzv/how_to_handle_ambiguous_column_names_when/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcvnzv/how_to_handle_ambiguous_column_names_when/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcvnzv</id><link href="https://www.reddit.com/r/LangChain/comments/1dcvnzv/how_to_handle_ambiguous_column_names_when/" /><updated>2024-06-10T20:27:18+00:00</updated><published>2024-06-10T20:27:18+00:00</published><title>How to handle ambiguous column names when converting Text-to-SQL in SQL Agent?</title></entry><entry><author><name>/u/EidolonAI</name><uri>https://www.reddit.com/user/EidolonAI</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcsu90/how_to_test_genai_applications/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/xvareROY2VMrdr0sCgsYHlMFYQmA9BA6Qu4yI44Xpgo.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=694e656794358d9bbed1855c12904b39dd41c41b&quot; alt=&quot;How to Test GenAI Applications&quot; title=&quot;How to Test GenAI Applications&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EidolonAI&quot;&gt; /u/EidolonAI &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.eidolonai.com/testing_llm_apps&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcsu90/how_to_test_genai_applications/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dcsu90</id><media:thumbnail url="https://external-preview.redd.it/xvareROY2VMrdr0sCgsYHlMFYQmA9BA6Qu4yI44Xpgo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=694e656794358d9bbed1855c12904b39dd41c41b" /><link href="https://www.reddit.com/r/LangChain/comments/1dcsu90/how_to_test_genai_applications/" /><updated>2024-06-10T18:35:15+00:00</updated><published>2024-06-10T18:35:15+00:00</published><title>How to Test GenAI Applications</title></entry><entry><author><name>/u/Strange-Ant-4194</name><uri>https://www.reddit.com/user/Strange-Ant-4194</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;When a single tool is to be used this is the output I get from Llama3 is:{&amp;#39;arguments&amp;#39;: {}, &amp;#39;name&amp;#39;: &amp;#39;check_location&amp;#39;}&lt;/p&gt; &lt;p&gt;The logic I&amp;#39;m using to parse a single tool call is this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from operator import itemgetter def tool_chain(model_output): tool_map = {tool.name: tool for tool in tools} chosen_tool = tool_map[model_output[&amp;quot;name&amp;quot;]] return itemgetter(&amp;quot;arguments&amp;quot;) | chosen_tool &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;How do i modify this for a call to multiple tools. The output from Llama3 is:{&amp;#39;tools&amp;#39;: [{&amp;#39;arguments&amp;#39;: {}, &amp;#39;name&amp;#39;: &amp;#39;check_location&amp;#39;},&lt;br/&gt; {&amp;#39;arguments&amp;#39;: {}, &amp;#39;name&amp;#39;: &amp;#39;check_calendar&amp;#39;}]}&lt;/p&gt; &lt;p&gt;I&amp;#39;m using Llama3, ollama and LangGraph.&lt;/p&gt; &lt;p&gt;Edit: I&amp;#39;ve managed to get an output like this:&lt;/p&gt; &lt;p&gt;&amp;#39;Finished running: grader:&amp;#39;&lt;br/&gt; {&amp;#39;tool1&amp;#39;: {&amp;#39;arguments&amp;#39;: {}, &amp;#39;name&amp;#39;: &amp;#39;check_location&amp;#39;},&lt;br/&gt; &amp;#39;tool2&amp;#39;: {&amp;#39;arguments&amp;#39;: {}, &amp;#39;name&amp;#39;: &amp;#39;check_calendar&amp;#39;}}&lt;/p&gt; &lt;p&gt;How do i parse the above?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Strange-Ant-4194&quot;&gt; /u/Strange-Ant-4194 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dd6poy/how_do_i_parse_a_call_to_multiple_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dd6poy/how_do_i_parse_a_call_to_multiple_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dd6poy</id><link href="https://www.reddit.com/r/LangChain/comments/1dd6poy/how_do_i_parse_a_call_to_multiple_tools/" /><updated>2024-06-11T05:37:14+00:00</updated><published>2024-06-11T05:37:14+00:00</published><title>How do i parse a call to multiple tools</title></entry><entry><author><name>/u/AsvkDasher01</name><uri>https://www.reddit.com/user/AsvkDasher01</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am a beginner so this might be a pretty basic question. I wanted to know if I can use LangChain framework with LLMs other than openai&amp;#39;s GPT. My use case is related to regional languages in India so I was going to use &lt;strong&gt;BharatGPT by&lt;/strong&gt; &lt;a href=&quot;http://CoRover.ai&quot;&gt;&lt;strong&gt;CoRover.ai&lt;/strong&gt;&lt;/a&gt; or &lt;strong&gt;AI4Bharat&lt;/strong&gt; an opensource AI model?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AsvkDasher01&quot;&gt; /u/AsvkDasher01 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dd6poq/can_i_use_langchain_with_indian_opensource_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dd6poq/can_i_use_langchain_with_indian_opensource_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dd6poq</id><link href="https://www.reddit.com/r/LangChain/comments/1dd6poq/can_i_use_langchain_with_indian_opensource_llms/" /><updated>2024-06-11T05:37:14+00:00</updated><published>2024-06-11T05:37:14+00:00</published><title>Can I use LangChain with Indian opensource LLMs?</title></entry><entry><author><name>/u/FewGate7173</name><uri>https://www.reddit.com/user/FewGate7173</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dci0ny/i_built_a_free_notionlike_notebook_connected_your/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/M2ZuNWJqcGF5cDVkMSt7OnYpLebwJQAgLa8HfCmZbYL75AkiXKseS_hNaqFH.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=84f4e719c7e4b06a52770cd239cef12f918201e4&quot; alt=&quot;I built a free Notion-like notebook connected your personal knowledge&quot; title=&quot;I built a free Notion-like notebook connected your personal knowledge&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FewGate7173&quot;&gt; /u/FewGate7173 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/uam6gipayp5d1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dci0ny/i_built_a_free_notionlike_notebook_connected_your/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dci0ny</id><media:thumbnail url="https://external-preview.redd.it/M2ZuNWJqcGF5cDVkMSt7OnYpLebwJQAgLa8HfCmZbYL75AkiXKseS_hNaqFH.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=84f4e719c7e4b06a52770cd239cef12f918201e4" /><link href="https://www.reddit.com/r/LangChain/comments/1dci0ny/i_built_a_free_notionlike_notebook_connected_your/" /><updated>2024-06-10T10:10:22+00:00</updated><published>2024-06-10T10:10:22+00:00</published><title>I built a free Notion-like notebook connected your personal knowledge</title></entry><entry><author><name>/u/onlinebcwhynot</name><uri>https://www.reddit.com/user/onlinebcwhynot</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Here is my project repo: &lt;a href=&quot;https://github.com/saminkhan1/realtor-project&quot;&gt;https://github.com/saminkhan1/realtor-project&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I am building a AI agent using langgraph that talks to a SQL database to get information about real estate data. The questions were:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;What properties are available in New York?&lt;/li&gt; &lt;li&gt;Show me houses with at least 3 bedrooms and 2 bathrooms.&lt;/li&gt; &lt;li&gt;Do you have any properties under $500,000?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;It knew I was looking for houses in NY for the second question, but in the third it didn&amp;#39;t understand I want houses in NY, 3 bed 2 bath and less then 500k it only searched for houses in NY under 500k.&lt;/p&gt; &lt;p&gt;================================ Human Message =================================&lt;/p&gt; &lt;p&gt;What properties are available in New York?&lt;/p&gt; &lt;p&gt;================================== Ai Message ==================================&lt;/p&gt; &lt;p&gt;Here are some properties available in New York:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Price: $175,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 1&lt;/li&gt; &lt;li&gt;Acre Lot: 60&lt;/li&gt; &lt;li&gt;Address: 553526 Berlin, New York, 12022&lt;/li&gt; &lt;li&gt;House Size: 1176 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $425,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 2.02&lt;/li&gt; &lt;li&gt;Address: 263302 Claverack, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1600 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: November 24, 2021&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $225,000 &lt;ul&gt; &lt;li&gt;Beds: 4&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 0.24&lt;/li&gt; &lt;li&gt;Address: 871278 Copake, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1239 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: February 1, 2018&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $419,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 3&lt;/li&gt; &lt;li&gt;Acre Lot: 1.9&lt;/li&gt; &lt;li&gt;Address: 286373 Copake, New York, 12516&lt;/li&gt; &lt;li&gt;House Size: 1800 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Let me know if you need more information or if you have any specific preferences.&lt;/p&gt; &lt;p&gt;================================ Human Message =================================&lt;/p&gt; &lt;p&gt;Show me houses with at least 3 bedrooms and 2 bathrooms.&lt;/p&gt; &lt;p&gt;================================== Ai Message ==================================&lt;/p&gt; &lt;p&gt;Here are houses in New York with at least 3 bedrooms and 2 bathrooms:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Price: $425,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 2.02&lt;/li&gt; &lt;li&gt;Address: 263302 Claverack, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1600 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: November 24, 2021&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $225,000 &lt;ul&gt; &lt;li&gt;Beds: 4&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 0.24&lt;/li&gt; &lt;li&gt;Address: 871278 Copake, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1239 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: February 1, 2018&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $419,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 3&lt;/li&gt; &lt;li&gt;Acre Lot: 1.9&lt;/li&gt; &lt;li&gt;Address: 286373 Copake, New York, 12516&lt;/li&gt; &lt;li&gt;House Size: 1800 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $365,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 2.0&lt;/li&gt; &lt;li&gt;Address: 78544 Copake, New York, 12517&lt;/li&gt; &lt;li&gt;House Size: 1482 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Let me know if you would like more details or if you have any specific preferences.&lt;/p&gt; &lt;p&gt;================================ Human Message =================================&lt;/p&gt; &lt;p&gt;Do you have any properties under $500,000?&lt;/p&gt; &lt;p&gt;================================== Ai Message ==================================&lt;/p&gt; &lt;p&gt;I found some properties in New York under $500,000:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Price: $175,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 1&lt;/li&gt; &lt;li&gt;Acre Lot: 60.0&lt;/li&gt; &lt;li&gt;Address: 553526 Berlin, New York, 12022&lt;/li&gt; &lt;li&gt;House Size: 1176 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $425,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 2.02&lt;/li&gt; &lt;li&gt;Address: 263302 Claverack, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1600 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: November 24, 2021&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $225,000 &lt;ul&gt; &lt;li&gt;Beds: 4&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 0.24&lt;/li&gt; &lt;li&gt;Address: 871278 Copake, New York, 12521&lt;/li&gt; &lt;li&gt;House Size: 1239 sqft&lt;/li&gt; &lt;li&gt;Previous Sold Date: February 1, 2018&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $419,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 3&lt;/li&gt; &lt;li&gt;Acre Lot: 1.9&lt;/li&gt; &lt;li&gt;Address: 286373 Copake, New York, 12516&lt;/li&gt; &lt;li&gt;House Size: 1800 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Price: $365,000 &lt;ul&gt; &lt;li&gt;Beds: 3&lt;/li&gt; &lt;li&gt;Baths: 2&lt;/li&gt; &lt;li&gt;Acre Lot: 2.0&lt;/li&gt; &lt;li&gt;Address: 78544 Copake, New York, 12517&lt;/li&gt; &lt;li&gt;House Size: 1482 sqft&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Let me know if you need more information on any of these properties or if you have any specific preferences.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/onlinebcwhynot&quot;&gt; /u/onlinebcwhynot &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcprk4/how_to_get_ai_agent_to_do_follow_up_questions_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dcprk4/how_to_get_ai_agent_to_do_follow_up_questions_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dcprk4</id><link href="https://www.reddit.com/r/LangChain/comments/1dcprk4/how_to_get_ai_agent_to_do_follow_up_questions_and/" /><updated>2024-06-10T16:29:59+00:00</updated><published>2024-06-10T16:29:59+00:00</published><title>How to get AI Agent to do follow up questions and remember/apply previous request/arguments?</title></entry></feed>