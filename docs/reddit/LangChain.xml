<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-17T03:26:01+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/leamecmy</name><uri>https://www.reddit.com/user/leamecmy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hii community I have a dataset with keys like name,description,why it matters,what to look for. Basically all these contains 1 line information(avg 10 words) ,I want to embedd these dataset using open ai models what are different ways for embedding these dataset . My puropse is when user give some query i can give him top k matched results.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/leamecmy&quot;&gt; /u/leamecmy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctv5au/embeddings_of_certain_dataset/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctv5au/embeddings_of_certain_dataset/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctv5au</id><link href="https://www.reddit.com/r/LangChain/comments/1ctv5au/embeddings_of_certain_dataset/" /><updated>2024-05-17T03:00:26+00:00</updated><published>2024-05-17T03:00:26+00:00</published><title>Embeddings of certain dataset</title></entry><entry><author><name>/u/Beginning_Rock_1906</name><uri>https://www.reddit.com/user/Beginning_Rock_1906</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks, it seems to me that the current sentiment around AI agents is very negative as in that they&amp;#39;re useless but I don&amp;#39;t quite understand why. Could anybody explain to me why this view persists?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Beginning_Rock_1906&quot;&gt; /u/Beginning_Rock_1906 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctfepy/ai_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctfepy/ai_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctfepy</id><link href="https://www.reddit.com/r/LangChain/comments/1ctfepy/ai_agents/" /><updated>2024-05-16T15:19:11+00:00</updated><published>2024-05-16T15:19:11+00:00</published><title>AI Agents</title></entry><entry><author><name>/u/R4Y_animation</name><uri>https://www.reddit.com/user/R4Y_animation</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone! I would like to have some help for a problem i have I want to extract two parameters: date_from: the start of the period date_to: the end of the period&lt;/p&gt; &lt;p&gt;I tried using this &lt;a href=&quot;https://python.langchain.com/v0.1/docs/use_cases/extraction/&quot;&gt;example&lt;/a&gt; but it sometimes misses at simple prompts&lt;/p&gt; &lt;p&gt;What can i add to make it better? Here‚Äôs the &lt;a href=&quot;https://hastebin.skyra.pw/yehokamuqo.py&quot;&gt;code&lt;/a&gt; i made&lt;/p&gt; &lt;p&gt;Basically i want it to get from the user‚Äôs prompt the correct date or period&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/R4Y_animation&quot;&gt; /u/R4Y_animation &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctr9h5/how_to_extract_date_period_from_user_prompt/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctr9h5/how_to_extract_date_period_from_user_prompt/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctr9h5</id><link href="https://www.reddit.com/r/LangChain/comments/1ctr9h5/how_to_extract_date_period_from_user_prompt/" /><updated>2024-05-16T23:37:44+00:00</updated><published>2024-05-16T23:37:44+00:00</published><title>How to extract date period from user prompt</title></entry><entry><author><name>/u/deusebio</name><uri>https://www.reddit.com/user/deusebio</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I‚Äôm trying to set something up where a user can upload a pdf and have it classified based on a resource I converted into a vector database. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/deusebio&quot;&gt; /u/deusebio &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctqz2c/classify_pdf_based_on_separate_rag_database/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctqz2c/classify_pdf_based_on_separate_rag_database/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctqz2c</id><link href="https://www.reddit.com/r/LangChain/comments/1ctqz2c/classify_pdf_based_on_separate_rag_database/" /><updated>2024-05-16T23:23:41+00:00</updated><published>2024-05-16T23:23:41+00:00</published><title>Classify PDF based on separate RAG database</title></entry><entry><author><name>/u/Puzzleheaded_Bee5489</name><uri>https://www.reddit.com/user/Puzzleheaded_Bee5489</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there any way in LangChain where we can get the responses for multiple queries/prompts in LangChain?&lt;/p&gt; &lt;p&gt;Suppose I have a function in python: ```python def function(...): prompt_1 = &amp;quot;...&amp;quot; prompt_2 = &amp;quot;...&amp;quot;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# make these API calls in parallel - use multithreading? response_1 = llm.invoke(prompt_1) reponse_2 = llm.invoke(prompt_2) # rest of the code &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;```&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Puzzleheaded_Bee5489&quot;&gt; /u/Puzzleheaded_Bee5489 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctgq91/sending_multiple_prompts_in_parallel_to_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctgq91/sending_multiple_prompts_in_parallel_to_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctgq91</id><link href="https://www.reddit.com/r/LangChain/comments/1ctgq91/sending_multiple_prompts_in_parallel_to_openai/" /><updated>2024-05-16T16:15:56+00:00</updated><published>2024-05-16T16:15:56+00:00</published><title>Sending multiple prompts in parallel to OpenAI</title></entry><entry><author><name>/u/Responsible-Dog-4134</name><uri>https://www.reddit.com/user/Responsible-Dog-4134</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I‚Äôm working on a project for a client who needs single summaries of games for a game recommender app they‚Äôre creating. I‚Äôve been trying to test out a pipeline of prompts to see what inputs generate the best summaries, but I‚Äôm struggling üòì &lt;/p&gt; &lt;p&gt;It‚Äôs easy to view and edit one prompt at a time, but I need a tool that can handle these more complex, chained prompt scenarios effectively. It feels like there are tools out there that could potentially help, but none seem fully integrated into a seamless prompt management workflow. I want to look across multiple sample output examples (from several sample inputs), and see what‚Äôs working and what‚Äôs not. &lt;/p&gt; &lt;p&gt;Anyone else facing the same struggles? How are you managing more complex prompt scenarios / how are you integrating multiple tools to get the job done? &lt;/p&gt; &lt;p&gt;Maybe it&amp;#39;s just part of the job, but I can&amp;#39;t help but think there&amp;#39;s got to be a better way to manage and streamline this whole process. Any insights or tips would be super helpful! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Responsible-Dog-4134&quot;&gt; /u/Responsible-Dog-4134 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctk5l5/struggling_with_prompt_management_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctk5l5/struggling_with_prompt_management_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctk5l5</id><link href="https://www.reddit.com/r/LangChain/comments/1ctk5l5/struggling_with_prompt_management_tools/" /><updated>2024-05-16T18:37:40+00:00</updated><published>2024-05-16T18:37:40+00:00</published><title>Struggling with prompt management tools</title></entry><entry><author><name>/u/Trick-Asparagus-9260</name><uri>https://www.reddit.com/user/Trick-Asparagus-9260</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for ways to effectively chunk csv/excel files. In a meaningful manner. I looked into loaders but they have unstructuredCSV/Excel Loaders which are nothing but from Unstructured. Is there something in Langchain that I can use to chunk these formats meaningfully for my RAG?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Trick-Asparagus-9260&quot;&gt; /u/Trick-Asparagus-9260 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct97ix/how_to_effectively_chunk_csv_and_xlsx_files_excel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct97ix/how_to_effectively_chunk_csv_and_xlsx_files_excel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ct97ix</id><link href="https://www.reddit.com/r/LangChain/comments/1ct97ix/how_to_effectively_chunk_csv_and_xlsx_files_excel/" /><updated>2024-05-16T09:50:33+00:00</updated><published>2024-05-16T09:50:33+00:00</published><title>How to effectively chunk csv and xlsx files? Excel file can contain text/tables.</title></entry><entry><author><name>/u/BenMan_</name><uri>https://www.reddit.com/user/BenMan_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I‚Äôm trying to figure out if it‚Äôs possible to create a Multi Agent application with LangGraph, where the agents can work in parallel (if needed).&lt;/p&gt; &lt;p&gt;Let‚Äôs say I have three agents (stupid example): 1. Supervisor 2. Agent specialized in tech conferences 3. Agent specialized in medical conferences&lt;/p&gt; &lt;p&gt;Each agent has its own tools.&lt;/p&gt; &lt;p&gt;The user query is ‚ÄúWhat are the main tech conferences and medical conferences in San Francisco in November?‚Äù.&lt;/p&gt; &lt;p&gt;This query can be obviously split in two different questions and each one can be addressed separately: 1. What are the main tech conferences in San Francisco in November? 2. What are the main medical conferences in San Francisco in November?&lt;/p&gt; &lt;p&gt;The Supervisor is able to process the original query, to produce these two questions and to route them separately to the correct Agent.&lt;/p&gt; &lt;p&gt;Is there a way to run these two agents in parallel and to have a fourth Agent (or the supervisor itself) that waits for the two answers and puts all together to produce a single final answer?&lt;/p&gt; &lt;p&gt;Does anyone have experience with such a use case?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BenMan_&quot;&gt; /u/BenMan_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cthrqz/agents_working_in_parallel_with_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cthrqz/agents_working_in_parallel_with_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cthrqz</id><link href="https://www.reddit.com/r/LangChain/comments/1cthrqz/agents_working_in_parallel_with_langgraph/" /><updated>2024-05-16T17:00:08+00:00</updated><published>2024-05-16T17:00:08+00:00</published><title>Agents working in parallel with LangGraph</title></entry><entry><author><name>/u/Zheng_SJ</name><uri>https://www.reddit.com/user/Zheng_SJ</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zheng_SJ&quot;&gt; /u/Zheng_SJ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://pluto-lang.vercel.app/blogs/240515-develop-ai-app-in-new-paradigm&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctga74/bridging_the_last_mile_in_langchain_application/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctga74</id><link href="https://www.reddit.com/r/LangChain/comments/1ctga74/bridging_the_last_mile_in_langchain_application/" /><updated>2024-05-16T15:57:28+00:00</updated><published>2024-05-16T15:57:28+00:00</published><title>Bridging the Last Mile in LangChain Application Development</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Checkout this short video to understand the difference between two major Generative AI packages i.e. LangChain and LlamaIndex and what to use when : &lt;a href=&quot;https://youtu.be/Oy8UZp3potw?si=9mp9M5UrBjR-FX5G&quot;&gt;https://youtu.be/Oy8UZp3potw?si=9mp9M5UrBjR-FX5G&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctgx1l/langchain_vs_llamaindex_differences_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctgx1l/langchain_vs_llamaindex_differences_explained/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctgx1l</id><link href="https://www.reddit.com/r/LangChain/comments/1ctgx1l/langchain_vs_llamaindex_differences_explained/" /><updated>2024-05-16T16:23:58+00:00</updated><published>2024-05-16T16:23:58+00:00</published><title>LangChain vs LlamaIndex differences explained</title></entry><entry><author><name>/u/Longjumping-Buddy501</name><uri>https://www.reddit.com/user/Longjumping-Buddy501</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;After having worked with Anthropic API and Gemini 1.5 Pro &amp;amp; Flash APIs. OpenAI API seems to be the only reliable API service available.&lt;br/&gt; With Anthropic - I am unable to add credits to their console, even after multiple mails to the customer support I have received no resolution. So I finally have to give up hope and just use Open AI.&lt;br/&gt; With Google Gemini - The APIs are absolutely unreliable, you are not sure when the APIs will return an answer and when they will not. I keep encountering error from the API something like: StopCandidateException: finish_reason: RECITATION&lt;br/&gt; So again no point in using Gemini, just switch to Open AI.&lt;/p&gt; &lt;p&gt;Hoping this experience will benefit the community.&lt;/p&gt; &lt;p&gt;Anyone else having these issues.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Longjumping-Buddy501&quot;&gt; /u/Longjumping-Buddy501 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrtc3/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrtc3/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csrtc3</id><link href="https://www.reddit.com/r/LangChain/comments/1csrtc3/open_ai_apis_are_the_only_reliable_apis_in/" /><updated>2024-05-15T18:21:45+00:00</updated><published>2024-05-15T18:21:45+00:00</published><title>Open AI APIs are the only reliable APIs in production</title></entry><entry><author><name>/u/Such-Maintenance9199</name><uri>https://www.reddit.com/user/Such-Maintenance9199</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i need a suggestion on a situation at work.&lt;/p&gt; &lt;p&gt;I am writing code for an application. i have 2 options, that is, either choose an existing python framework that is available in the market or write my own python code.&lt;/p&gt; &lt;p&gt;Existing framework: LangChain, LlamaIndex&lt;/p&gt; &lt;p&gt;Pros:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;used a lot outside in the market. just in case if i want to shift another company. i can easily adapt and can earn more money&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;I can create Agents (AI) with little ease as i dont have to implement everything from scratch (usually research work and strategies are implemented in this framework). implementing features becomes faster&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;as knowledge workers are more aware of this framework - hiring them and getting them to understand the code becomes easy &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Cons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt; So many abstractions in this framework and i fully dont understand it. few months back i tried to use this framework and i couldn&amp;#39;t customize it for our situation. I am worried if i use this and make some progress and later realize that it is not customizable. i will be screwed. lot of work will be wasted.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Own Code:&lt;/p&gt; &lt;p&gt;Pros:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;i can implement all the functionalities by myself. i can design code base and write everything from scratch. this skill is valued in lot of places especially in startups as you have literally implemented lot of things from scratch. this way i can get a hang over the language and my skill improves drastically&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;i get to do research and implement them with my own code.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;i can customize it for my specific scenario&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;the company will have a lot of dependency on me &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Cons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;lot of work&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;development might not be as fast paced as i would have liked it to be.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;i might get stuck and not find any solution as i am the only person available who has knowledge on this in this company.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Any suggestions are appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Such-Maintenance9199&quot;&gt; /u/Such-Maintenance9199 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cstpmx/llm_orchestration_framework_or_own_python_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cstpmx/llm_orchestration_framework_or_own_python_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cstpmx</id><link href="https://www.reddit.com/r/LangChain/comments/1cstpmx/llm_orchestration_framework_or_own_python_code/" /><updated>2024-05-15T19:38:46+00:00</updated><published>2024-05-15T19:38:46+00:00</published><title>LLM Orchestration framework or own python code, which is better?</title></entry><entry><author><name>/u/Longjumping-Buddy501</name><uri>https://www.reddit.com/user/Longjumping-Buddy501</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;After having worked with Anthropic API and Gemini 1.5 Pro &amp;amp; Flash APIs. OpenAI API seems to be the only reliable API service available.&lt;br/&gt; With Anthropic - I am unable to add credits to their console, even after multiple mails to the customer support I have received no resolution. So I finally have to give up hope and just use Open AI.&lt;br/&gt; With Google Gemini - The APIs are absolutely unreliable, you are not sure when the APIs will return an answer and when they will not. I keep encountering error from the API something like: StopCandidateException: finish_reason: RECITATION&lt;br/&gt; So again no point in using Gemini, just switch to Open AI.&lt;/p&gt; &lt;p&gt;Hoping this experience will benefit the community.&lt;/p&gt; &lt;p&gt;Anyone else having these issues.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Longjumping-Buddy501&quot;&gt; /u/Longjumping-Buddy501 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrta9/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrta9/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csrta9</id><link href="https://www.reddit.com/r/LangChain/comments/1csrta9/open_ai_apis_are_the_only_reliable_apis_in/" /><updated>2024-05-15T18:21:41+00:00</updated><published>2024-05-15T18:21:41+00:00</published><title>Open AI APIs are the only reliable APIs in production</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1ct1sja/creating_proxy_server_for_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct1thu/creating_proxy_server_for_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ct1thu</id><link href="https://www.reddit.com/r/LangChain/comments/1ct1thu/creating_proxy_server_for_llms/" /><updated>2024-05-16T01:50:35+00:00</updated><published>2024-05-16T01:50:35+00:00</published><title>Creating proxy server for llms</title></entry><entry><author><name>/u/hesitantelephant</name><uri>https://www.reddit.com/user/hesitantelephant</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;TLDR: I made a platform to make it easy to switch between LLMs, find the best one for your specific needs, analyze their performance, and test different providers in production. Check it out at&lt;/strong&gt; &lt;a href=&quot;https://optimix.app/?lang&quot;&gt;&lt;strong&gt;optimix.app&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Figuring out whether or not you should switch to Llama 3, Gemini 1.5 Flash, or GPT-4o can be hard. And knowing if the prompt change you just made will be good or bad is even harder.&lt;/p&gt; &lt;p&gt;A key focus of Optimix is to make experimentation easy. You can run A/B tests and other experiments to figure out how your changes impacted your core metrics like cost, speed, and user satisfaction. You can also test and compare different models in our playground and make requests through our API.&lt;/p&gt; &lt;p&gt;It also dynamically selects the most suitable model for each request, and helps manage fallbacks for outages and rate limits. Facing an OpenAI outage? Switch to Llama 3. Need superior coding assistance? We can auto switch you to the best one.&lt;/p&gt; &lt;p&gt;I&amp;#39;d love any feedback or suggestions on the platform, and hope this can be helpful for you all with all the new models coming out!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hesitantelephant&quot;&gt; /u/hesitantelephant &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct4m4z/experiment_and_test_the_reliability_of_different/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct4m4z/experiment_and_test_the_reliability_of_different/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ct4m4z</id><link href="https://www.reddit.com/r/LangChain/comments/1ct4m4z/experiment_and_test_the_reliability_of_different/" /><updated>2024-05-16T04:23:44+00:00</updated><published>2024-05-16T04:23:44+00:00</published><title>Experiment and test the reliability of different LLMs in prod and pre-prod!</title></entry><entry><author><name>/u/dominik-reinert-dev</name><uri>https://www.reddit.com/user/dominik-reinert-dev</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am currently working on a project where I need to fill documents (CSV files) according to requirements in a big compendium (800+ pages PDF).&lt;/p&gt; &lt;p&gt;for example:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;context: &lt;ul&gt; &lt;li&gt;the PDF compendium of 800 pages with instructions and detailed legal requirements to be met when implementing infrastructure projects in IT sector&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;CSV file: &lt;ul&gt; &lt;li&gt;a checklist-style CSV file containing the short name of the subject from the PDF compendium and columns to input things to be checked and processed by a person (or in this case: AI)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th align=&quot;left&quot;&gt;Subject&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;Responsible&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;Price&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;Risks&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;A.1.1.&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;Author of this file&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;$20.000&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;If not done, we are doomed&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;ul&gt; &lt;li&gt;Prompt &lt;ul&gt; &lt;li&gt;&amp;quot;I want to add a exchange a router in Building C3.&amp;quot;&lt;/li&gt; &lt;li&gt;&amp;quot;I want to add a gitlab server to our network&amp;quot;&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In both cases, the output should be a CSV file or CSV text .&lt;/p&gt; &lt;p&gt;&lt;strong&gt;These are the models im using (and liking):&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;model: wizardlm2:7b&lt;/li&gt; &lt;li&gt;embedding model: mxbai-embed-large&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;What I have done so far&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;reading in the pdf files&lt;/li&gt; &lt;li&gt;embedding the pdf files&lt;/li&gt; &lt;li&gt;reading in the csv file&lt;/li&gt; &lt;li&gt;embedding the csv file (&amp;lt;- is this correct?)&lt;/li&gt; &lt;li&gt;created a prompt&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;```&lt;br/&gt; Fill the csv file in the context with valuable data found in the embeddings according to the question.&lt;/p&gt; &lt;p&gt;Do not guess, do not add anything. Use only the context.&lt;/p&gt; &lt;p&gt;{context}&lt;/p&gt; &lt;p&gt;Question: {input}&lt;/p&gt; &lt;p&gt;```&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What is not working. AKA: What is my question?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;The output the model is giving me is unstructured and has nothing to do with the CSV file I put into the context.&lt;/p&gt; &lt;p&gt;Is there a way that I can make the AI&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Read in PDFs&lt;/li&gt; &lt;li&gt;Read in CSV&lt;/li&gt; &lt;li&gt;Listen to the prompt&lt;/li&gt; &lt;li&gt;Output a CSV file or (- like text) I gave it with data from the embedded PDFs correctly according to the needs arising from the input prompt&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dominik-reinert-dev&quot;&gt; /u/dominik-reinert-dev &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csts7q/how_can_i_use_langchainjs_to_fill_out_csv_file/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csts7q/how_can_i_use_langchainjs_to_fill_out_csv_file/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csts7q</id><link href="https://www.reddit.com/r/LangChain/comments/1csts7q/how_can_i_use_langchainjs_to_fill_out_csv_file/" /><updated>2024-05-15T19:41:42+00:00</updated><published>2024-05-15T19:41:42+00:00</published><title>How can I use LangChainJs to fill out csv file according to big context and prompt?</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csn64j/chat_with_your_sql_database_using_gpt_4o/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/rYJPoFWIRFemdSrdPxJrRIzP3PsTxlihd_RpHdFeMaU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2b498a1f2ad64e74a06e0e47a4a53ec4a119e9f9&quot; alt=&quot;Chat with your SQL database using GPT 4o &quot; title=&quot;Chat with your SQL database using GPT 4o &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://arslanshahid-1997.medium.com/chat-with-your-sql-database-using-gpt-4o-via-vanna-ai-b87e3296f8dc&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csn64j/chat_with_your_sql_database_using_gpt_4o/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1csn64j</id><media:thumbnail url="https://external-preview.redd.it/rYJPoFWIRFemdSrdPxJrRIzP3PsTxlihd_RpHdFeMaU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b498a1f2ad64e74a06e0e47a4a53ec4a119e9f9" /><link href="https://www.reddit.com/r/LangChain/comments/1csn64j/chat_with_your_sql_database_using_gpt_4o/" /><updated>2024-05-15T15:10:02+00:00</updated><published>2024-05-15T15:10:02+00:00</published><title>Chat with your SQL database using GPT 4o</title></entry><entry><author><name>/u/toubar_</name><uri>https://www.reddit.com/user/toubar_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m sorry for the trivial question, but I&amp;#39;ve been struggling with this and cannot find a solution. &lt;/p&gt; &lt;p&gt;I have a retrieval with a list of questions and answers, and I have a chain defined, but im struggling to properly handle the case in which the question being asked by the user doesn&amp;#39;t exist in my vector store (or even in a simplified system, where a 5 questions and their answers are added in the prompt - without a vectorstore and retrieval) &lt;/p&gt; &lt;p&gt;Thanks a lot in advance :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/toubar_&quot;&gt; /u/toubar_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csohun/need_trivial_help_with_rag_how_do_i/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csohun/need_trivial_help_with_rag_how_do_i/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csohun</id><link href="https://www.reddit.com/r/LangChain/comments/1csohun/need_trivial_help_with_rag_how_do_i/" /><updated>2024-05-15T16:05:30+00:00</updated><published>2024-05-15T16:05:30+00:00</published><title>Need trivial help with RAG: how do I programmatically handle the case in which the Q&amp;A Chain's retrieval found no match for the question being answered?</title></entry><entry><author><name>/u/Not-That-rpg</name><uri>https://www.reddit.com/user/Not-That-rpg</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I hope I do not sound like a jerk here, but ... more and more I feel that these classes are more trouble than they are worth. I&amp;#39;d welcome it if someone made a case for their existence.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the claim: we are (almost?) always better off just working with f-strings and format instead of working with these classes. Here is my rationale:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Concatenation: Most recently, I have been fighting with trying to concatenate various `Message` and `PromptTemplate` classes. Sometimes this works, sometimes it fails at runtime. This is made worse by the fact that static type-checking doesn&amp;#39;t detect this prior to runtime.&lt;/li&gt; &lt;li&gt;Type hints: the above illustrates a problem with these classes that extends beyond them and is pervasive in Langchain. There are a lot of type hints, and there are type failures, but the type hints don&amp;#39;t help. The type specifications are often so loose that type checking tools cannot warn me about errors to come. This is related to another pervasive problem:&lt;/li&gt; &lt;li&gt;The use of opaque objects and loose typing causes many problems in development with Langchain. When I try to write my own code to extend langchain behavior I often find that I have to handle many cases that have the potential to cause errors because of loose typing. For example, anything handling input going into an &lt;code&gt;LLM&lt;/code&gt; or &lt;code&gt;ChatModel&lt;/code&gt; must handle &lt;code&gt;PromptValue&lt;/code&gt;, &lt;code&gt;str&lt;/code&gt;, &lt;code&gt;Sequence&lt;/code&gt; of &lt;code&gt;MessageLikeRepresentation&lt;/code&gt; and &lt;code&gt;dict&lt;/code&gt; s with unknown sets of keys. When I process those &lt;code&gt;Sequence&lt;/code&gt;s I must then deal with &lt;code&gt;BaseMessage&lt;/code&gt;, &lt;code&gt;str&lt;/code&gt;, &lt;code&gt;Tuple[str,str]&lt;/code&gt; and &lt;code&gt;Dict[str, Any]&lt;/code&gt;. I apologize for being cranky, but these type hints seem more aimed at ensuring that type checkers never raise errors, rather than aimed at helping the programmer write correct code. The type checker is a tool, not an oracle to be worshipped.&lt;/li&gt; &lt;li&gt;&lt;code&gt;PromptTemplate&lt;/code&gt;s work extremely poorly when they must accommodate code as template-fillers. The curly braces in code confuse prompt handling no end.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Looping back to the hypothesis: If I try to assemble a prompt in stages by plugging values in over and over, the use of &lt;code&gt;PromptTemplate&lt;/code&gt; and &lt;code&gt;Message&lt;/code&gt; objects makes my life more difficult and costs me hours of debugging. My recent alternative is simply to assemble together ordinary strings, using &lt;code&gt;format&lt;/code&gt; as necessary, until the last minute before they are needed, at which time I wrap them in &lt;code&gt;PromptTemplate.from_template()&lt;/code&gt; so that they can be put in an LCEL chain expression.&lt;/p&gt; &lt;p&gt;IMO this indicates that the layers and layers of complex types and meta-classes are more trouble than they are worth. I&amp;#39;m willing -- indeed hoping! -- that someone will prove me wrong. How does my experience align with that of other langchain users?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Not-That-rpg&quot;&gt; /u/Not-That-rpg &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csmlwe/message_and_prompt_classes_are_they_helpful/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csmlwe/message_and_prompt_classes_are_they_helpful/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csmlwe</id><link href="https://www.reddit.com/r/LangChain/comments/1csmlwe/message_and_prompt_classes_are_they_helpful/" /><updated>2024-05-15T14:46:22+00:00</updated><published>2024-05-15T14:46:22+00:00</published><title>Message and Prompt Classes -- are they helpful?</title></entry><entry><author><name>/u/RaGE_Syria</name><uri>https://www.reddit.com/user/RaGE_Syria</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building an app with Next.js. &lt;/p&gt; &lt;p&gt;Is it possible to have LangChain only give me the context it found from the vector store? I then want to take this context and manually insert it into another part of my app that&amp;#39;s using an llm as a part of the message history (but I don&amp;#39;t want to do this final step in LangChain)&lt;/p&gt; &lt;p&gt;So I don&amp;#39;t want LangChain to give me the final output just the context is found using the vector store and OpenAi embedding model.&lt;/p&gt; &lt;p&gt;I&amp;#39;m still learning sry if this a stupid question. &lt;/p&gt; &lt;p&gt;I&amp;#39;m having issues streaming output from LangChain to the front end and want to use something else I already have setup&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RaGE_Syria&quot;&gt; /u/RaGE_Syria &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csy9ul/can_i_use_langchain_to_only_give_me_the_context/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csy9ul/can_i_use_langchain_to_only_give_me_the_context/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csy9ul</id><link href="https://www.reddit.com/r/LangChain/comments/1csy9ul/can_i_use_langchain_to_only_give_me_the_context/" /><updated>2024-05-15T22:55:25+00:00</updated><published>2024-05-15T22:55:25+00:00</published><title>Can I use LangChain to only give me the context is found from the retrieval?</title></entry><entry><author><name>/u/iclickedca</name><uri>https://www.reddit.com/user/iclickedca</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/iclickedca&quot;&gt; /u/iclickedca &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csvh8w/any_example_of_using_llmbind_tool_i_get_not/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csvh8w/any_example_of_using_llmbind_tool_i_get_not/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csvh8w</id><link href="https://www.reddit.com/r/LangChain/comments/1csvh8w/any_example_of_using_llmbind_tool_i_get_not/" /><updated>2024-05-15T20:52:36+00:00</updated><published>2024-05-15T20:52:36+00:00</published><title>Any example of using llm.bind_tool ? i get not implemented error - want to run tools w GPT-4o</title></entry><entry><author><name>/u/ggStrift</name><uri>https://www.reddit.com/user/ggStrift</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ggStrift&quot;&gt; /u/ggStrift &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://blog.meilisearch.com/langchain-semantic-search-tutorial/?utm_campaign=social&amp;amp;utm_source=reddit&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csok7u/a_stepbystep_tutorial_to_building_semantic_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csok7u</id><link href="https://www.reddit.com/r/LangChain/comments/1csok7u/a_stepbystep_tutorial_to_building_semantic_search/" /><updated>2024-05-15T16:08:13+00:00</updated><published>2024-05-15T16:08:13+00:00</published><title>A step-by-step tutorial to building semantic search with LangChain</title></entry><entry><author><name>/u/Glittering-Bear5748</name><uri>https://www.reddit.com/user/Glittering-Bear5748</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;issue: I am build RAG chat bot and my model is taking server time zone when i ask what is current date and time how fix it ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering-Bear5748&quot;&gt; /u/Glittering-Bear5748 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csobxi/llm_model_with_timezone_issue/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csobxi/llm_model_with_timezone_issue/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csobxi</id><link href="https://www.reddit.com/r/LangChain/comments/1csobxi/llm_model_with_timezone_issue/" /><updated>2024-05-15T15:59:13+00:00</updated><published>2024-05-15T15:59:13+00:00</published><title>LLM model with timezone issue</title></entry><entry><author><name>/u/deixhah</name><uri>https://www.reddit.com/user/deixhah</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I use Dall-E as a tool for my langchain agent but the quality of the images are so low compared to the images from the ChatGPT Interface.&lt;/p&gt; &lt;p&gt;Is there a way to fix this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/deixhah&quot;&gt; /u/deixhah &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csmium/dalle_api_low_quality_images/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csmium/dalle_api_low_quality_images/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csmium</id><link href="https://www.reddit.com/r/LangChain/comments/1csmium/dalle_api_low_quality_images/" /><updated>2024-05-15T14:42:54+00:00</updated><published>2024-05-15T14:42:54+00:00</published><title>Dall-E Api low quality images</title></entry><entry><author><name>/u/UpskillingDS17</name><uri>https://www.reddit.com/user/UpskillingDS17</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I have to do a POC and below are the steps or direction how to implement using Langchain and Snowflake DB and LLM ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî 1. User will enter the Transformation Logic sheet where every row will have the logic how the values inside the Source Table are mapped/modified to Target Table. 2. User will also have access to Target Table to check whether the SQL query generation using Transformation logic correctly mapped the values to Target table or not.&lt;/p&gt; &lt;p&gt;I have tried using excel sheet and a basic table in ChatGPT and I was able to accomplish upto good level. I want to know how to implement in python and is there any good LLM for such text-sql conversion. Many thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpskillingDS17&quot;&gt; /u/UpskillingDS17 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csjz1h/texttosql_conversion_for_etl_testing_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csjz1h/texttosql_conversion_for_etl_testing_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csjz1h</id><link href="https://www.reddit.com/r/LangChain/comments/1csjz1h/texttosql_conversion_for_etl_testing_using/" /><updated>2024-05-15T12:48:05+00:00</updated><published>2024-05-15T12:48:05+00:00</published><title>Text-to-SQL conversion for ETL testing using Snowflake</title></entry></feed>