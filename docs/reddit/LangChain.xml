<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-07-22T09:09:35+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This tutorial explains how to use GraphRAG using JSON file and LangChain. This involves 1. Converting json to text 2. Create Knowledge Graph 3. Create GraphQA chain&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/wXTs3cmZuJA?si=dnwTo6BHbK8WgGEF&quot;&gt;https://youtu.be/wXTs3cmZuJA?si=dnwTo6BHbK8WgGEF&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e967n3/graphrag_using_json_and_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e967n3/graphrag_using_json_and_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e967n3</id><link href="https://www.reddit.com/r/LangChain/comments/1e967n3/graphrag_using_json_and_langchain/" /><updated>2024-07-22T05:11:53+00:00</updated><published>2024-07-22T05:11:53+00:00</published><title>GraphRAG using JSON and LangChain</title></entry><entry><author><name>/u/behitek</name><uri>https://www.reddit.com/user/behitek</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;🚀 Exciting News! 🚀&lt;/p&gt; &lt;p&gt;Just published my latest blog post on the Behitek blog: &amp;quot;RAG in Production: Best Practices for Robust and Scalable Systems&amp;quot; 🌟&lt;/p&gt; &lt;p&gt;In this article, I explore how to effectively implement Retrieval-Augmented Generation (RAG) models in production environments. From reducing hallucinations to maintaining document hierarchy and optimizing chunking strategies, this guide covers all you need to know for robust and efficient RAG deployments.&lt;/p&gt; &lt;p&gt;Check it out and share your thoughts or experiences! I&amp;#39;d love to hear your feedback and any additional tips you might have. 👇&lt;/p&gt; &lt;p&gt;🔗 &lt;a href=&quot;https://behitek.com/blog/2024/07/18/rag-in-production&quot;&gt;https://behitek.com/blog/2024/07/18/rag-in-production&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/behitek&quot;&gt; /u/behitek &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8oct1/rag_in_production_best_practices_for_robust_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8oct1/rag_in_production_best_practices_for_robust_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e8oct1</id><link href="https://www.reddit.com/r/LangChain/comments/1e8oct1/rag_in_production_best_practices_for_robust_and/" /><updated>2024-07-21T15:05:36+00:00</updated><published>2024-07-21T15:05:36+00:00</published><title>RAG in Production: Best Practices for Robust and Scalable Systems</title></entry><entry><author><name>/u/Alert_Monitor4490</name><uri>https://www.reddit.com/user/Alert_Monitor4490</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am an intern and I&amp;#39;m trying to create a RAG app for my company so it will be easier for them to get access to their test test data. But when I look at how frequently things change in the RAG world, like modules moving from langchain to langchain_community, and calls being changed. Do you guys think it&amp;#39;s a good idea I go ahead with it? Cos if I leave and there is an update or anything like that no one apart from me can do it. So in the end it becomes useless a few months after. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Alert_Monitor4490&quot;&gt; /u/Alert_Monitor4490 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e95do2/updates_on_rag_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e95do2/updates_on_rag_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e95do2</id><link href="https://www.reddit.com/r/LangChain/comments/1e95do2/updates_on_rag_app/" /><updated>2024-07-22T04:20:30+00:00</updated><published>2024-07-22T04:20:30+00:00</published><title>Updates on RAG app</title></entry><entry><author><name>/u/The_Wolfiee</name><uri>https://www.reddit.com/user/The_Wolfiee</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to build an LLM powered evaluation application using LangChain where human users answer a set of pre-defined questions and an LLM checks the correctness of the answers and assign a percentage of how correct the answer is and how the answers can be improved. Assume that correct answers are stored in a database&lt;/p&gt; &lt;p&gt;Can someone provide a guide or a tutorial for this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/The_Wolfiee&quot;&gt; /u/The_Wolfiee &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e96ndq/llm_that_evaluates_human_answers/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e96ndq/llm_that_evaluates_human_answers/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e96ndq</id><link href="https://www.reddit.com/r/LangChain/comments/1e96ndq/llm_that_evaluates_human_answers/" /><updated>2024-07-22T05:40:06+00:00</updated><published>2024-07-22T05:40:06+00:00</published><title>LLM that evaluates human answers</title></entry><entry><author><name>/u/ashishjadon</name><uri>https://www.reddit.com/user/ashishjadon</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m developing a mental health assessment tool using LangChain and OpenAI. The goal is to analyze user inputs and answer predefined questions about their mental state based solely on the information explicitly stated in their input.&lt;/p&gt; &lt;p&gt;My current implementation uses a ChatPromptTemplate with system and human messages, followed by a ChatOpenAI model and JsonOutputParser. However, I&amp;#39;m getting mixed results. The model sometimes infers information not explicitly stated in the input.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s a simplified version of my questions.json. There are around 30 questions in my json.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;[ { &amp;quot;name&amp;quot;: &amp;quot;Age&amp;quot;, &amp;quot;question_text&amp;quot;: &amp;quot;Select your age group:&amp;quot;, &amp;quot;displayOptions&amp;quot;: [ &amp;quot;12 to 21&amp;quot;, &amp;quot;21 to 30&amp;quot;, &amp;quot;30 to 50&amp;quot;, &amp;quot;60 and above&amp;quot; ] }, { &amp;quot;name&amp;quot;: &amp;quot;Gender&amp;quot;, &amp;quot;question_text&amp;quot;: &amp;quot;Select your gender:&amp;quot;, &amp;quot;displayOptions&amp;quot;: [ &amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Others&amp;quot; ] }, { &amp;quot;name&amp;quot;: &amp;quot;StressRecently&amp;quot;, &amp;quot;question_text&amp;quot;: &amp;quot;Have you been stressed about something recently?&amp;quot;, &amp;quot;displayOptions&amp;quot;: [ &amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot; ] }, ] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Sample user input is: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;I&amp;#39;m 32 year old guy.i&amp;#39;ve been working 10-12 hours in office although i am working from home. I&amp;#39;ve trouble sleeping. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;the response i&amp;#39;m getting is &lt;/p&gt; &lt;pre&gt;&lt;code&gt;{ &amp;quot;analysis&amp;quot;: { &amp;quot;AbnormalDailyActivity&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;AbnormalDisinterested&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;AbnormalDistraction&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;AbnormalEating&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;AbnormalMindMaking&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;AbnormalWeightGain&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;Age&amp;quot;: &amp;quot;30 to 50&amp;quot;, &amp;quot;ChronicHealth&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;CurrentChallenges&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;CurrentSituation&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;Employment&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;EnergyLevel&amp;quot;: &amp;quot;Yes&amp;quot;, &amp;quot;EngageActivities&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;EnjoyNormalDay&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;Gender&amp;quot;: &amp;quot;Male&amp;quot;, &amp;quot;GoodHealth&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;ServiceType&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;Staylocation&amp;quot;: &amp;quot;Home or at relatives&amp;quot;, &amp;quot;StressAge&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;StressLoss&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;StressRecently&amp;quot;: &amp;quot;Yes&amp;quot;, &amp;quot;StressShared1&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;WellBeingHealth&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;WellBeingNormal&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;WellBeingSatisfy&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;WorklifeBalance&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;Workstress&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;lackofMotivation&amp;quot;: &amp;quot;Yes&amp;quot; }, &amp;quot;response_time&amp;quot;: &amp;quot;3.45 seconds&amp;quot; } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;now the issue is that i am getting and answer for StressRecently as Yes but the user&amp;#39;s input doesn&amp;#39;t has anything related to the stress. I&amp;#39;ve tried to change the prompt as per my requirement but the LLM is inferring the data from the user&amp;#39;s input. I need it to answer only those questions which are explicitly mentioned in the user&amp;#39;s input. &lt;/p&gt; &lt;p&gt;here&amp;#39;s the code i am using for my prompting. &lt;/p&gt; &lt;pre&gt;&lt;code&gt;system_template = &amp;#39;&amp;#39;&amp;#39;You are a highly precise mental health assessment assistant. Your role is to analyze user inputs and respond to a set of predefined questions about their mental state and well-being. Follow these strict guidelines: 1. Only use information explicitly stated in the user&amp;#39;s input. 2. DO NOT make inferences, assumptions, or guesses about unstated information. 3. Respond with &amp;quot;Unknown&amp;quot; for any question that cannot be directly answered from the given information. 4. Be extremely cautious: it&amp;#39;s better to answer &amp;quot;Unknown&amp;quot; than to potentially provide incorrect information. 5. Focus solely on the content of the user&amp;#39;s statement, not on interpreting or diagnosing their condition. 6. DO NOT interpret or diagnose. Only report what is directly stated. Remember, this is a critical assessment tool dealing with real patients&amp;#39; mental health. Accuracy and caution are paramount. &amp;#39;&amp;#39;&amp;#39; human_template = &amp;#39;&amp;#39;&amp;#39;Carefully read the following user input: User&amp;#39;s statement: {text} Based solely on this input, provide answers to the following questions. Use &amp;quot;Unknown&amp;quot; for any question that cannot be answered with absolute certainty based on the explicit content of the user&amp;#39;s statement. Questions: {questions} While answering the questions, use the question_text field to answer the question. don;t rely on just the name field. Provide your answers in JSON format. Include all questions, using &amp;quot;Unknown&amp;quot; for any that cannot be confidently answered based solely on the given information.&amp;#39;&amp;#39;&amp;#39; prompt_template = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, system_template), (&amp;quot;human&amp;quot;, human_template) ]) chain = prompt_template | model | parser def analyze_situation( text ): start_time = time.time() result = chain.invoke({ &amp;quot;questions&amp;quot;: json.dumps(questions_json, indent =2), &amp;quot;text&amp;quot;: text }) end_time = time.time() elapsed_time = end_time - start_time return result, elapsed_time &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Can i get any pointers or guidance on &lt;/p&gt; &lt;ul&gt; &lt;li&gt;How to improve my prompt to ensure the model only uses explicitly stated information?&lt;br/&gt;&lt;/li&gt; &lt;li&gt;Are there better LangChain components or techniques I should consider for this task? &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;As a LangChain novice, any guidance on best practices would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashishjadon&quot;&gt; /u/ashishjadon &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e95iug/need_some_help_to_optimize_the_performance_of_my/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e95iug/need_some_help_to_optimize_the_performance_of_my/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e95iug</id><link href="https://www.reddit.com/r/LangChain/comments/1e95iug/need_some_help_to_optimize_the_performance_of_my/" /><updated>2024-07-22T04:29:23+00:00</updated><published>2024-07-22T04:29:23+00:00</published><title>Need some help to optimize the performance of my first ever langchain application.</title></entry><entry><author><name>/u/Big_Barracuda_6753</name><uri>https://www.reddit.com/user/Big_Barracuda_6753</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e98vyl/how_to_format_llm_output_of_my_streamlit/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/g-dMiYCR2OS6-PNY2p-lUpTbZDE26MwKXMddl3H-dDA.jpg&quot; alt=&quot;How to format LLM output of my Streamlit + Langchain app like ChatGPT does ?&quot; title=&quot;How to format LLM output of my Streamlit + Langchain app like ChatGPT does ?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi , I&amp;#39;m developing a PDFRAG app . &lt;/p&gt; &lt;p&gt;Currently , I&amp;#39;m able to upload a PDF , ask questions from it , the response is streamed back to me .&lt;/p&gt; &lt;p&gt;This is working fine . &lt;/p&gt; &lt;p&gt;Now , I want ChatGPT like functionality where the title of the response is larger in font size and bold and the subtitle / the text is smaller in font size and normal in style .&lt;/p&gt; &lt;p&gt;This is my app response to a query where I ask the model to generate a title and subtitle .&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/bhqvd9av21ed1.png?width=920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e14a9fd323bc8829c4646b8200bc9492ae69ce17&quot;&gt;https://preview.redd.it/bhqvd9av21ed1.png?width=920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e14a9fd323bc8829c4646b8200bc9492ae69ce17&lt;/a&gt;&lt;/p&gt; &lt;p&gt;And this is AIPDF&amp;#39;s response .&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/im1ktz4b31ed1.png?width=641&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9de639f58d9200b1dacf671253f774474c6039f7&quot;&gt;https://preview.redd.it/im1ktz4b31ed1.png?width=641&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9de639f58d9200b1dacf671253f774474c6039f7&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I want my response like AIPDF .&lt;/p&gt; &lt;p&gt;What do I need to do ? I&amp;#39;m using Langchain and Streamlit to develop my application .&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Big_Barracuda_6753&quot;&gt; /u/Big_Barracuda_6753 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e98vyl/how_to_format_llm_output_of_my_streamlit/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e98vyl/how_to_format_llm_output_of_my_streamlit/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1e98vyl</id><media:thumbnail url="https://b.thumbs.redditmedia.com/g-dMiYCR2OS6-PNY2p-lUpTbZDE26MwKXMddl3H-dDA.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1e98vyl/how_to_format_llm_output_of_my_streamlit/" /><updated>2024-07-22T08:11:53+00:00</updated><published>2024-07-22T08:11:53+00:00</published><title>How to format LLM output of my Streamlit + Langchain app like ChatGPT does ?</title></entry><entry><author><name>/u/BigYesterday2785</name><uri>https://www.reddit.com/user/BigYesterday2785</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am deciding between different vector databases to add. &lt;/p&gt; &lt;p&gt;I would prefer a vector database which could already give me confidence score. &lt;/p&gt; &lt;p&gt;So that when the chunk is found, there is also similarity score (confidence score) provided, and I do not have to implement it manually later on. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BigYesterday2785&quot;&gt; /u/BigYesterday2785 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e98owl/which_vector_database_already_provides_confidence/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e98owl/which_vector_database_already_provides_confidence/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e98owl</id><link href="https://www.reddit.com/r/LangChain/comments/1e98owl/which_vector_database_already_provides_confidence/" /><updated>2024-07-22T07:58:36+00:00</updated><published>2024-07-22T07:58:36+00:00</published><title>Which Vector Database already provides confidence scoring to us?</title></entry><entry><author><name>/u/Timetofly123</name><uri>https://www.reddit.com/user/Timetofly123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e96uvu/pandas_dataframe_agent_strange_issue/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/qe45holue0ed1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=669963387996cc10b1afc7c6efea6adc6972f880&quot; alt=&quot;Pandas DataFrame Agent - strange issue &quot; title=&quot;Pandas DataFrame Agent - strange issue &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve created a DataFrame agent and sent in the simple question &amp;quot;how many rows are there in the DataFrame?&amp;quot;.&lt;/p&gt; &lt;p&gt;I can see the action input is correct:&lt;/p&gt; &lt;p&gt;df.shape[0]&lt;/p&gt; &lt;p&gt;However it looks like it&amp;#39;s struggling with assigning a value to Observation? I&amp;#39;ve added a photo of the issue (sorry it&amp;#39;s not a screenshot).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Timetofly123&quot;&gt; /u/Timetofly123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/qe45holue0ed1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e96uvu/pandas_dataframe_agent_strange_issue/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1e96uvu</id><media:thumbnail url="https://preview.redd.it/qe45holue0ed1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=669963387996cc10b1afc7c6efea6adc6972f880" /><link href="https://www.reddit.com/r/LangChain/comments/1e96uvu/pandas_dataframe_agent_strange_issue/" /><updated>2024-07-22T05:53:49+00:00</updated><published>2024-07-22T05:53:49+00:00</published><title>Pandas DataFrame Agent - strange issue</title></entry><entry><author><name>/u/Repulsive-Bedroom883</name><uri>https://www.reddit.com/user/Repulsive-Bedroom883</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Reddit community,&lt;/p&gt; &lt;p&gt;I wanted to share something I&amp;#39;ve been passionately working on recently. I&amp;#39;ve developed an AI Therapist—an innovative solution aimed at making emotional support accessible to everyone, right at your fingertips.&lt;/p&gt; &lt;p&gt;What does it do?&lt;/p&gt; &lt;p&gt;Imagine having a therapist available anytime, anywhere, simply by calling. This AI Therapist isn&amp;#39;t just about conversation; it&amp;#39;s designed to understand your emotions through your voice and provide personalized support. Whether you&amp;#39;re dealing with stress, seeking advice, or in need of a friendly ear, it&amp;#39;s here to listen and engage with empathy.&lt;/p&gt; &lt;p&gt;Why is this important?&lt;/p&gt; &lt;p&gt;Traditional therapy can be costly and inaccessible to many. Recognizing this, I&amp;#39;ve created this AI Therapist to break down barriers and ensure everyone can access the emotional support they deserve.&lt;/p&gt; &lt;p&gt;Privacy and Accessibility&lt;/p&gt; &lt;p&gt;Privacy is paramount. No data is shared, no voice recordings are kept, and everything is deleted after each session. Your confidentiality and emotional well-being are prioritized.&lt;/p&gt; &lt;p&gt;Join the Beta Stage&lt;/p&gt; &lt;p&gt;Currently, the AI Therapist is in its beta stage, evolving with feedback. I&amp;#39;m eager to hear your thoughts on features you find most beneficial. Whether it&amp;#39;s enhancing emotional understanding, adding new forms of support, or refining its responsiveness, your input will shape its development.&lt;/p&gt; &lt;p&gt;Let&amp;#39;s make therapy more accessible and supportive for everyone.&lt;/p&gt; &lt;p&gt;If you&amp;#39;re interested in trying it out or have questions, feel free to reach out! Together, we can make a positive impact on mental health care.&lt;/p&gt; &lt;p&gt;Looking forward to your thoughts!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Repulsive-Bedroom883&quot;&gt; /u/Repulsive-Bedroom883 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8tbyr/creating_an_ai_therapist_that_you_can_talk_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8tbyr/creating_an_ai_therapist_that_you_can_talk_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e8tbyr</id><link href="https://www.reddit.com/r/LangChain/comments/1e8tbyr/creating_an_ai_therapist_that_you_can_talk_to/" /><updated>2024-07-21T18:43:11+00:00</updated><published>2024-07-21T18:43:11+00:00</published><title>Creating an AI Therapist That You Can Talk To Anytime, Anywhere</title></entry><entry><author><name>/u/Hungry_Neat_8080</name><uri>https://www.reddit.com/user/Hungry_Neat_8080</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;how to make my chain learn to classify tabular data? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Hungry_Neat_8080&quot;&gt; /u/Hungry_Neat_8080 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e92zuz/classification/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e92zuz/classification/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e92zuz</id><link href="https://www.reddit.com/r/LangChain/comments/1e92zuz/classification/" /><updated>2024-07-22T02:10:21+00:00</updated><published>2024-07-22T02:10:21+00:00</published><title>classification</title></entry><entry><author><name>/u/DifficultNerve6992</name><uri>https://www.reddit.com/user/DifficultNerve6992</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8ymoy/boost_your_ai_agents_exposure_join_specialized_ai/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/rTJ4tFhBzaY549T6e3XDhX26g3UqETDgVZDRuQioxvk.jpg?width=216&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=44f47b1b426caed17ab16352854c6851eff7ca82&quot; alt=&quot;Boost Your AI Agent's Exposure: Join Specialized AI Agent Directory!&quot; title=&quot;Boost Your AI Agent's Exposure: Join Specialized AI Agent Directory!&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey AI Agent builder,&lt;/p&gt; &lt;p&gt;If you&amp;#39;re working on an AI agent, consider adding it to specialized and free &lt;a href=&quot;https://aiagentsdirectory.com/&quot;&gt;AI Agent Directory&lt;/a&gt;! It’s a fantastic way to gain extra exposure and benefit from an SEO backlink to your project. Our directory is tailored specifically for AI agents, providing a platform to showcase your work to a broader audience.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/1vkgq0ga8ydd1.png?width=1594&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d7af1c74646bbd7ba3948dd2e5edd3b7a337a10b&quot;&gt;https://preview.redd.it/1vkgq0ga8ydd1.png?width=1594&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d7af1c74646bbd7ba3948dd2e5edd3b7a337a10b&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DifficultNerve6992&quot;&gt; /u/DifficultNerve6992 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8ymoy/boost_your_ai_agents_exposure_join_specialized_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8ymoy/boost_your_ai_agents_exposure_join_specialized_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1e8ymoy</id><media:thumbnail url="https://external-preview.redd.it/rTJ4tFhBzaY549T6e3XDhX26g3UqETDgVZDRuQioxvk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=44f47b1b426caed17ab16352854c6851eff7ca82" /><link href="https://www.reddit.com/r/LangChain/comments/1e8ymoy/boost_your_ai_agents_exposure_join_specialized_ai/" /><updated>2024-07-21T22:36:40+00:00</updated><published>2024-07-21T22:36:40+00:00</published><title>Boost Your AI Agent's Exposure: Join Specialized AI Agent Directory!</title></entry><entry><author><name>/u/justsayno_to_biggovt</name><uri>https://www.reddit.com/user/justsayno_to_biggovt</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been looking for examples of llm used to determine format of unknown format data to write code to ingest it into a common known standard format. It seems like something RAG would be useful for. Maybe make it part of a pipeline as the first step in a data analytics process...thoughts? Recommendations?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/justsayno_to_biggovt&quot;&gt; /u/justsayno_to_biggovt &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8szox/data_ingest/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8szox/data_ingest/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e8szox</id><link href="https://www.reddit.com/r/LangChain/comments/1e8szox/data_ingest/" /><updated>2024-07-21T18:28:28+00:00</updated><published>2024-07-21T18:28:28+00:00</published><title>Data ingest</title></entry><entry><author><name>/u/BigYesterday2785</name><uri>https://www.reddit.com/user/BigYesterday2785</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have &lt;strong&gt;100 pages PDF&lt;/strong&gt; data stores in vector database.&lt;/p&gt; &lt;p&gt;Now i ask it questions but I do not know if the &lt;strong&gt;answer is correct or not&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I want to implement scoring, in 5 categories, where AI tells me, how Confidence it is in the response which is received.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Confidence&lt;/li&gt; &lt;li&gt;Somewhat Confident&lt;/li&gt; &lt;li&gt;Medium Confident&lt;/li&gt; &lt;li&gt;Low Confidence&lt;/li&gt; &lt;li&gt;Very low Confidence&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;How can I do it ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BigYesterday2785&quot;&gt; /u/BigYesterday2785 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8izci/how_to_find_confidence_score_from_the_ai_responses/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8izci/how_to_find_confidence_score_from_the_ai_responses/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e8izci</id><link href="https://www.reddit.com/r/LangChain/comments/1e8izci/how_to_find_confidence_score_from_the_ai_responses/" /><updated>2024-07-21T10:06:13+00:00</updated><published>2024-07-21T10:06:13+00:00</published><title>how to find confidence score from the AI responses</title></entry><entry><author><name>/u/thedabking123</name><uri>https://www.reddit.com/user/thedabking123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;For the life of me I can&amp;#39;t figure out why the below won&amp;#39;t work given the instructions &lt;a href=&quot;https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-system-prompt/&quot;&gt;here&lt;/a&gt;: &lt;/p&gt; &lt;p&gt;Code in Jupyter Notebook:&lt;/p&gt; &lt;p&gt;&lt;code&gt;agent_executor = create_react_agent(llm, tools, state_modifier=system_message, checkpointer=memory)&lt;/code&gt; &lt;/p&gt; &lt;p&gt;&lt;code&gt;from IPython.display import Image, display&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;display(Image(agent_executor.get_graph().draw_mermaid_png()))&lt;/code&gt; &lt;/p&gt; &lt;p&gt;-----Error---:&lt;br/&gt; {&lt;br/&gt; &amp;quot;name&amp;quot;: &amp;quot;TypeError&amp;quot;,&lt;br/&gt; &amp;quot;message&amp;quot;: &amp;quot;create_react_agent() got an unexpected keyword argument &amp;#39;state_modifier&amp;#39;&amp;quot;,&lt;br/&gt; &amp;quot;stack&amp;quot;: &amp;quot;---------------------------------------------------------------------------&lt;br/&gt; TypeError Traceback (most recent call last)&lt;br/&gt; ~\\AppData\\Local\\Temp\\ipykernel_844\\2897566165.py in &amp;lt;module&amp;gt;&lt;br/&gt; 1 from typing import Literal&lt;br/&gt; 2&lt;br/&gt; ----&amp;gt; 3 agent_executor = create_react_agent(llm, tools, state_modifier=system_message, checkpointer=memory)&lt;br/&gt; 4&lt;br/&gt; 5 from IPython.display import Image, display &lt;/p&gt; &lt;p&gt;TypeError: create_react_agent() got an unexpected keyword argument &amp;#39;state_modifier&amp;#39;&amp;quot;&lt;br/&gt; } &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thedabking123&quot;&gt; /u/thedabking123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8q4l9/dont_know_why_im_getting_an_unexpected_keyword/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8q4l9/dont_know_why_im_getting_an_unexpected_keyword/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e8q4l9</id><link href="https://www.reddit.com/r/LangChain/comments/1e8q4l9/dont_know_why_im_getting_an_unexpected_keyword/" /><updated>2024-07-21T16:24:05+00:00</updated><published>2024-07-21T16:24:05+00:00</published><title>Don't know why I'm getting an unexpected keyword argument error?</title></entry><entry><author><name>/u/andrewshvv</name><uri>https://www.reddit.com/user/andrewshvv</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, I was working on GPT-dependent field generation for my side project. The idea is to have a tree of field dependencies, execute the leaf dependencies in parallel, and pass the context to the upper dependency layers. Then I realized that Langchain exists... Does it have something similar?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://gist.github.com/andrewshvv/952eb4547560783fb86b7ad8156216c6&quot;&gt;https://gist.github.com/andrewshvv/952eb4547560783fb86b7ad8156216c6&lt;/a&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;class StringGenerator extends BaseGenerator { async before(_: Context, __: Output, runner: GPTRunner): Promise&amp;lt;void&amp;gt; { runner.add({ role: &amp;#39;system&amp;#39;, content: &amp;#39;Initially you are given empty string, write only final value&amp;#39; }); } @field(&amp;#39;d&amp;#39;, [&amp;#39;a&amp;#39;]) async handler_some_field_d(_: Context, data: Output, runner: GPTRunner): Promise&amp;lt;void&amp;gt; { runner.add({ role: &amp;#39;user&amp;#39;, content: &amp;#39;Add letter D to string, what is final string?&amp;#39; }); const completion = await runner.run(); data[&amp;#39;should_be_bcad&amp;#39;] = completion.content; } @field(&amp;#39;a&amp;#39;, [&amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;]) async handler_some_field_a(_: Context, data: Output, runner: GPTRunner): Promise&amp;lt;void&amp;gt; { runner.add({ role: &amp;#39;user&amp;#39;, content: &amp;#39;Add letter A to string, what is final string?&amp;#39; }); const completion = await runner.run(); data[&amp;#39;should_be_bca&amp;#39;] = completion.content; } @field(&amp;#39;c&amp;#39;) async handler_some_field_c(_: Context, data: Output, runner: GPTRunner): Promise&amp;lt;void&amp;gt; { runner.add({ role: &amp;#39;user&amp;#39;, content: &amp;#39;Add letter C to string, what is final string?&amp;#39; }); const completion = await runner.run(); data[&amp;#39;should_be_c&amp;#39;] = completion.content; } @field(&amp;#39;b&amp;#39;) async handler_some_field_b(_: Context, data: Output, runner: GPTRunner): Promise&amp;lt;void&amp;gt; { runner.add({ role: &amp;#39;user&amp;#39;, content: &amp;#39;Add letter B to string, what is final string?&amp;#39; }); const completion = await runner.run(); data[&amp;#39;should_be_b&amp;#39;] = completion.content; } async generate(context: Context): Promise&amp;lt;Output&amp;gt; { const data = await super.generate(context); return data; } } // Example usage: const g = new StringGenerator(); const finalData = await g.generate({ &amp;#39;some context&amp;#39;: &amp;#39;context&amp;#39; }); console.log(&amp;#39;Final Data:&amp;#39;, finalData); // Final Data: { // should_be_b: &amp;#39;B&amp;#39;, // should_be_c: &amp;#39;C&amp;#39;, // should_be_bca: &amp;#39;BCA&amp;#39;, // should_be_bcad: &amp;#39;BCAD&amp;#39; // } &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/andrewshvv&quot;&gt; /u/andrewshvv &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8gufz/dependent_field_generation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8gufz/dependent_field_generation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e8gufz</id><link href="https://www.reddit.com/r/LangChain/comments/1e8gufz/dependent_field_generation/" /><updated>2024-07-21T07:29:12+00:00</updated><published>2024-07-21T07:29:12+00:00</published><title>Dependent Field Generation</title></entry><entry><author><name>/u/empirical-sadboy</name><uri>https://www.reddit.com/user/empirical-sadboy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/empirical-sadboy&quot;&gt; /u/empirical-sadboy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/LocalLLaMA/comments/1e84de2/top_enhancements_to_try_once_you_have_a_vanilla/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e84w2n/top_enhancements_to_try_once_you_have_a_vanilla/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e84w2n</id><link href="https://www.reddit.com/r/LangChain/comments/1e84w2n/top_enhancements_to_try_once_you_have_a_vanilla/" /><updated>2024-07-20T20:31:16+00:00</updated><published>2024-07-20T20:31:16+00:00</published><title>Top enhancements to try once you have a vanilla RAG set-up with a text vector database?</title></entry><entry><author><name>/u/Phoenix_20_23</name><uri>https://www.reddit.com/user/Phoenix_20_23</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, I hope you&amp;#39;re all doing well! I’m currently on the lookout for a library that can extract text in paragraph chunks from PDFs. For instance, I need it to pull out the Introduction with all its paragraphs separately, the Conclusion with all its paragraphs separately, and so on, essentially chunking the text by paragraphs. Do you have any suggestions? Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Phoenix_20_23&quot;&gt; /u/Phoenix_20_23 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7cntq/whats_the_best_python_library_for_extracting_text/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7cntq/whats_the_best_python_library_for_extracting_text/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e7cntq</id><link href="https://www.reddit.com/r/LangChain/comments/1e7cntq/whats_the_best_python_library_for_extracting_text/" /><updated>2024-07-19T19:48:44+00:00</updated><published>2024-07-19T19:48:44+00:00</published><title>What’s the Best Python Library for Extracting Text from PDFs?</title></entry><entry><author><name>/u/pvbang</name><uri>https://www.reddit.com/user/pvbang</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m having problems building my system.&lt;/p&gt; &lt;p&gt;Let&amp;#39;s say I have one (or more pdf files), I load, splitters, chunking, clean data,... and then save it to a vector database (qdrant). I can query its data quite well with knowledge questions located somewhere in the files.&lt;/p&gt; &lt;p&gt;But suppose in my data file is a list of about 1000 products distributed on many different pages, is there any way I can solve the question: &amp;quot;How many products are there?&amp;quot; Are not?&lt;/p&gt; &lt;p&gt;Or ask &amp;quot;List all the major and minor headings in the file&amp;quot; and it can answer correctly if there is no table of contents available.&lt;/p&gt; &lt;p&gt;My problem is that I can&amp;#39;t read the whole document when putting it in the context part of LLM, because it&amp;#39;s too long if k is increased in the retrievers part, and I also don&amp;#39;t think it can completely satisfy the context content because Maybe it is still left somewhere in other segments if k is fixed?&lt;/p&gt; &lt;p&gt;If anyone has any ideas or solutions, please help me.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/pvbang&quot;&gt; /u/pvbang &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7pcxp/search_for_data_across_entire_text_files/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7pcxp/search_for_data_across_entire_text_files/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e7pcxp</id><link href="https://www.reddit.com/r/LangChain/comments/1e7pcxp/search_for_data_across_entire_text_files/" /><updated>2024-07-20T06:40:13+00:00</updated><published>2024-07-20T06:40:13+00:00</published><title>Search for data across entire text files</title></entry><entry><author><name>/u/AGI-is-coming</name><uri>https://www.reddit.com/user/AGI-is-coming</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;You&amp;#39;ve probably heard about Mistral&amp;#39;s groundbreaking release of Codestral Mamba, a 7B parameter model. But why all the hype over a 7B model when we have giants like GPT-4? Well, it&amp;#39;s not just about size this time – it&amp;#39;s about architecture. 🔍&lt;/p&gt; &lt;p&gt;The &lt;strong&gt;Transformer Dilemma:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Transformers have been the cornerstone architecture for language models, powering everything from open-source LLMs to chatGPT and Claude.&lt;/p&gt; &lt;p&gt;However, they come with a significant drawback: as context expands, so does processing time (hello, quadratic bottleneck!).&lt;/p&gt; &lt;p&gt;Transformers are undeniably effective, storing every detail from the past for theoretically perfect recall.&lt;/p&gt; &lt;p&gt;On the other hand, traditional RNN (Recurring Neural Networks)– forget a lot, retaining only a small portion in their hidden state and discarding the rest. This makes them highly efficient but less effective since discarded information cannot be retrieved.&lt;/p&gt; &lt;p&gt;Finding the Sweet Spot - &lt;strong&gt;Enter Mamba&lt;/strong&gt; 🐍.&lt;/p&gt; &lt;p&gt;Mamba belongs to a class of models known as State Space Models (SSMs). SSMs excel in understanding and predicting how systems (like cars) evolve based on measurable data.&lt;/p&gt; &lt;p&gt;Notably, Mamba offers comparable performance and scalability to Transformers but crucially eliminates the quadratic bottleneck in the Attention Mechanism.&lt;/p&gt; &lt;p&gt;Language models are good at summarizing text, though some details may be lost. However, summarizing other forms of content, like a two-hour movie, is trickier.&lt;/p&gt; &lt;p&gt;This is where Mamba&amp;#39;s long-term memory comes into play, enabling the model to retain important information.&lt;/p&gt; &lt;p&gt;Why should you care? Mamba could be a game-changer for tasks requiring extensive context, like:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;DNA processing 🧬&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Report writing 📚&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Agents with long-term memory and goals 🤖(Mistral - Codestral Mamba)&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AGI-is-coming&quot;&gt; /u/AGI-is-coming &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e72ayj/attention_isnt_all_you_need/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e72ayj/attention_isnt_all_you_need/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e72ayj</id><link href="https://www.reddit.com/r/LangChain/comments/1e72ayj/attention_isnt_all_you_need/" /><updated>2024-07-19T12:16:45+00:00</updated><published>2024-07-19T12:16:45+00:00</published><title>&quot;Attention Isn’t All You Need&quot;</title></entry><entry><author><name>/u/Either-Ambassador738</name><uri>https://www.reddit.com/user/Either-Ambassador738</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there any way to persists the parent documents in the ParentDocumentRetrieval?&lt;br/&gt; All the tutorials I see use the InMemoryStore, but I&amp;#39;d like to persist the parent documents in a redis database or a mysql database. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Either-Ambassador738&quot;&gt; /u/Either-Ambassador738 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7h5ea/persists_documents_on_parentdocumentretrieval/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7h5ea/persists_documents_on_parentdocumentretrieval/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e7h5ea</id><link href="https://www.reddit.com/r/LangChain/comments/1e7h5ea/persists_documents_on_parentdocumentretrieval/" /><updated>2024-07-19T23:04:23+00:00</updated><published>2024-07-19T23:04:23+00:00</published><title>Persists documents on ParentDocumentRetrieval</title></entry><entry><author><name>/u/Either-Ambassador738</name><uri>https://www.reddit.com/user/Either-Ambassador738</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to bind some functions into a llm, I&amp;#39;m using the ChatOpenAI wrapper to connect to a Ollama llama3 model locally, I have this code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt; options = [&amp;quot;FINISH&amp;quot;] + members function_def = { &amp;quot;name&amp;quot;: &amp;quot;route&amp;quot;, &amp;quot;description&amp;quot;: &amp;quot;Select the next role&amp;quot;, &amp;quot;parameters&amp;quot;: { &amp;quot;title&amp;quot;: &amp;quot;routeSchema&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;object&amp;quot;, &amp;quot;properties&amp;quot;: { &amp;quot;next&amp;quot;: { &amp;quot;title&amp;quot;: &amp;quot;Next&amp;quot;, &amp;quot;anyOf&amp;quot;: [ {&amp;quot;enum&amp;quot;: options}, ], }, }, &amp;quot;required&amp;quot;: [&amp;quot;next&amp;quot;], }, } prompt = ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, system_prompt), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), ( &amp;quot;system&amp;quot;, &amp;quot;Given the conversation above, who should act next?&amp;quot; &amp;quot;Or should we FINISH?: select one of {options} ) ] ).partial(options=str(options), team_members=&amp;#39;,&amp;#39;.join(members)) # Bind the function to the LLM, specify the function call, and parse the output as JSON return ( prompt | llm.bind_functions(functions=[function_def], function_call=&amp;quot;route&amp;quot;) | JsonOutputFunctionsParser() ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is the LLM I&amp;#39;m using:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;llm = ChatOpenAI(base_url=&amp;quot;http://localhost:11434/v1&amp;quot;, model=&amp;quot;llama3&amp;quot;, api_key=&amp;quot;ollama&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;However, I encounter the following issue:&lt;/p&gt; &lt;p&gt;langchain_core.exceptions.OutputParserException: Could not parse function call: &amp;#39;function_call&amp;#39;&lt;/p&gt; &lt;p&gt;Could anyone help me here? Thanks :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Either-Ambassador738&quot;&gt; /u/Either-Ambassador738 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7cvzl/bind_functions_with_ollama_model_from_chatopenai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7cvzl/bind_functions_with_ollama_model_from_chatopenai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e7cvzl</id><link href="https://www.reddit.com/r/LangChain/comments/1e7cvzl/bind_functions_with_ollama_model_from_chatopenai/" /><updated>2024-07-19T19:58:32+00:00</updated><published>2024-07-19T19:58:32+00:00</published><title>Bind functions with Ollama model from ChatOpenAI.</title></entry><entry><author><name>/u/emersoftware</name><uri>https://www.reddit.com/user/emersoftware</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone. Has anyone deployed Langgraph in Google Cloud services? Currently, I&amp;#39;ve created my own method to do it using the Reasoning Engine, but I am a newbie in cloud services. I want to know if there is a better way to do it&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/emersoftware&quot;&gt; /u/emersoftware &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7em5x/deploy_langgraph_in_google_cloud/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7em5x/deploy_langgraph_in_google_cloud/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e7em5x</id><link href="https://www.reddit.com/r/LangChain/comments/1e7em5x/deploy_langgraph_in_google_cloud/" /><updated>2024-07-19T21:12:04+00:00</updated><published>2024-07-19T21:12:04+00:00</published><title>Deploy Langgraph in Google Cloud?</title></entry><entry><author><name>/u/Danidre</name><uri>https://www.reddit.com/user/Danidre</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is LangGraph production-ready?&lt;/p&gt; &lt;p&gt;I am finally seeing more documentation on checkpoint implementations, such as persistence using PostgreSQL, MongoDB, and Redis. Thanks a lot to the LangChain devs for the continued development of this open source tool.&lt;/p&gt; &lt;p&gt;However, I notice that these implementations are mainly phrased as &amp;quot;example&amp;quot; implementations. Does this mean they are not production ready?&lt;/p&gt; &lt;p&gt;Are checkpoints in a stable condition? I have been wanting to add an implementation myself, but chalked it up to be something I&amp;#39;d have to spend considerable time implementing as the specifications is lengthy. However, now I see the code for the core checkpoint usage has been updated recently, and even the implementations have new things like &lt;code&gt;write&lt;/code&gt; and &lt;code&gt;channel&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;There are also other areas (comment sections under the notebooks) where someone states that &lt;code&gt;thread_ts&lt;/code&gt; has been deprecated, and &lt;code&gt;checkpoint_id&lt;/code&gt; is now being used. Yet, the notebook example implementations themselves still use &lt;code&gt;thread_ts&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Finally, the behind the scenes of what is stored is a bit complicated to understand as well, without much explanations nor documentations. And even these base abstractions seem to be changing recently. For example, the checkpointer implementations have some code &amp;quot;for backward compatibility&amp;quot;.&lt;/p&gt; &lt;p&gt;If I were to maintain an implementation for another dialect (MariaDB, SQL Server, etc), changing it at such a dynamic pace would take more away from using LangGraph itself on my projects. Especially when the LangGraph changes are discovered when browsing the git history, rather than the LangGraph blogs or documentations.&lt;/p&gt; &lt;p&gt;Can these be documented? It&amp;#39;s a bit of a magic right now with what is being stored unless one attempts to actually reverse engineer it. Again, I do not have an issue doing that; after all, it is an open source tool. However, with the ever-changing seemingly silent changes, it will make it difficult to keep up.&lt;/p&gt; &lt;p&gt;Is LangGraph stable? Or still in heavy development?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Danidre&quot;&gt; /u/Danidre &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e73gzj/langgraph_stability/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e73gzj/langgraph_stability/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e73gzj</id><link href="https://www.reddit.com/r/LangChain/comments/1e73gzj/langgraph_stability/" /><updated>2024-07-19T13:15:05+00:00</updated><published>2024-07-19T13:15:05+00:00</published><title>LangGraph Stability</title></entry><entry><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone. Has anyone deployed Langgraph in Google Cloud services? Currently, I&amp;#39;ve created my own method to do it using the Reasoning Engine, but I am a newbie in cloud services. I want to know if there is a better way to do it&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7dzzf/deploy_langgraph_on_google_cloud/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e7dzzf/deploy_langgraph_on_google_cloud/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e7dzzf</id><link href="https://www.reddit.com/r/LangChain/comments/1e7dzzf/deploy_langgraph_on_google_cloud/" /><updated>2024-07-19T20:45:39+00:00</updated><published>2024-07-19T20:45:39+00:00</published><title>Deploy Langgraph on Google Cloud?</title></entry><entry><author><name>/u/SnooOranges529</name><uri>https://www.reddit.com/user/SnooOranges529</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e77ye2/using_langchain_runnables_and_running_into/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/muWoC4zg6G4f_3ceYgsRd4fQyXABZEXjrjJTS7EIVeE.jpg&quot; alt=&quot;Using Langchain runnables and running into pydantic errors&quot; title=&quot;Using Langchain runnables and running into pydantic errors&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Y&amp;#39;all,&lt;br/&gt; I encounter this issue with running langchain runnables and it can&amp;#39;t get input_schema. To replicate this using a basic chain. This happens with all the chain, when I look for input_schema it yells with this error for those chain&amp;#39;s inputs.&lt;br/&gt; Any leads on how to resolve this issue?&lt;br/&gt; TIA&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/rwbz1r8b5idd1.png?width=1468&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dcfb12069db3cf22268725f921c36a3c5a09ab27&quot;&gt;https://preview.redd.it/rwbz1r8b5idd1.png?width=1468&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dcfb12069db3cf22268725f921c36a3c5a09ab27&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SnooOranges529&quot;&gt; /u/SnooOranges529 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e77ye2/using_langchain_runnables_and_running_into/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e77ye2/using_langchain_runnables_and_running_into/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1e77ye2</id><media:thumbnail url="https://b.thumbs.redditmedia.com/muWoC4zg6G4f_3ceYgsRd4fQyXABZEXjrjJTS7EIVeE.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1e77ye2/using_langchain_runnables_and_running_into/" /><updated>2024-07-19T16:29:07+00:00</updated><published>2024-07-19T16:29:07+00:00</published><title>Using Langchain runnables and running into pydantic errors</title></entry></feed>