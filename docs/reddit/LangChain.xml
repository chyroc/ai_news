<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-10T23:37:14+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Downtown_Repeat7455</name><uri>https://www.reddit.com/user/Downtown_Repeat7455</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am seeing everywhere saying we are building AI apps but in reality i see only RAG. Or am i missing something here. Is there any apps are being built other than knowledge retrieval?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Downtown_Repeat7455&quot;&gt; /u/Downtown_Repeat7455 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193fppt/what_other_ai_apps_are_being_built/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193fppt/what_other_ai_apps_are_being_built/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_193fppt</id><link href="https://www.reddit.com/r/LangChain/comments/193fppt/what_other_ai_apps_are_being_built/" /><updated>2024-01-10T18:47:13+00:00</updated><published>2024-01-10T18:47:13+00:00</published><title>What other AI apps are being built.</title></entry><entry><author><name>/u/Appropriate_Egg6118</name><uri>https://www.reddit.com/user/Appropriate_Egg6118</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can someone help with template to build RAG Chatbot with low latency..&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Appropriate_Egg6118&quot;&gt; /u/Appropriate_Egg6118 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193iq2l/how_to_decrease_latency_in_rag_chatbots/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193iq2l/how_to_decrease_latency_in_rag_chatbots/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_193iq2l</id><link href="https://www.reddit.com/r/LangChain/comments/193iq2l/how_to_decrease_latency_in_rag_chatbots/" /><updated>2024-01-10T20:47:59+00:00</updated><published>2024-01-10T20:47:59+00:00</published><title>How to decrease latency in RAG chatbots?</title></entry><entry><author><name>/u/Realistic-Setting876</name><uri>https://www.reddit.com/user/Realistic-Setting876</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Does anyone have examples of how to build an agent to perform API actions based on user input in natural language format? I have the spec file and want to use OpenAPI agent.I came across examples but all were using open ai LLM.I want to use Azure endpoint&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Realistic-Setting876&quot;&gt; /u/Realistic-Setting876 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193lbjq/openapi_agent_with_azure_openai_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193lbjq/openapi_agent_with_azure_openai_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_193lbjq</id><link href="https://www.reddit.com/r/LangChain/comments/193lbjq/openapi_agent_with_azure_openai_llm/" /><updated>2024-01-10T22:33:18+00:00</updated><published>2024-01-10T22:33:18+00:00</published><title>OpenAPI agent with Azure OpenAI LLM</title></entry><entry><author><name>/u/mean-short-</name><uri>https://www.reddit.com/user/mean-short-</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1934iac/zeroshotagent_gives_me_observation_invalid_format/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/mgRzCBDz_EzI_c6OeOrSW_F_pe9z2uYc6pZDmJslnLA.jpg&quot; alt=&quot;ZeroShotAgent gives me Observation: Invalid Format: Missing 'Action:' after 'Thought: error&quot; title=&quot;ZeroShotAgent gives me Observation: Invalid Format: Missing 'Action:' after 'Thought: error&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello&lt;br/&gt; I am using ZeroShotAgent passing it specific prefix and suffix as well as :&lt;/p&gt; &lt;p&gt;FORMAT_INSTRUCTIONS_TEMPLATE = &amp;quot;&amp;quot;&amp;quot;Use the following format:&lt;br/&gt; Question: the input question you must answer&lt;br/&gt; Thought: you should always think about what to do&lt;br/&gt; Action: the action to take, should be one of: {tool_names}&lt;br/&gt; Action Input: the input to the action&lt;br/&gt; Observation: the result of the action&lt;br/&gt; ... (this Thought/Action/Action Input/Observation can repeat N times)&lt;br/&gt; Thought: I now know the final answer&lt;br/&gt; Final Answer: the final answer to the original input question&lt;br/&gt; Please respect the order of the steps Thought/Action/Action Input/Observation&lt;br/&gt; &amp;quot;&amp;quot;&amp;quot;&lt;/p&gt; &lt;p&gt;I am getting this error &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/zv4fn1hi1lbc1.png?width=698&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=06cefe90e856be26319280946eb168ed88c4c472&quot;&gt;ZeroShot agent error&lt;/a&gt;&lt;/p&gt; &lt;p&gt;What solutions can you suggest and what other agents can I use?&lt;br/&gt; One of the tasks I&amp;#39;m working on is a csv agent, also I want a general solution because later I will be using open source models so no openai functions :/ &lt;/p&gt; &lt;p&gt;Thanks in advance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mean-short-&quot;&gt; /u/mean-short- &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1934iac/zeroshotagent_gives_me_observation_invalid_format/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1934iac/zeroshotagent_gives_me_observation_invalid_format/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1934iac</id><media:thumbnail url="https://b.thumbs.redditmedia.com/mgRzCBDz_EzI_c6OeOrSW_F_pe9z2uYc6pZDmJslnLA.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1934iac/zeroshotagent_gives_me_observation_invalid_format/" /><updated>2024-01-10T09:36:43+00:00</updated><published>2024-01-10T09:36:43+00:00</published><title>ZeroShotAgent gives me Observation: Invalid Format: Missing 'Action:' after 'Thought: error</title></entry><entry><author><name>/u/egoloper</name><uri>https://www.reddit.com/user/egoloper</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19380am/hey_langchain_community_lets_make_document/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/CJYBOlSQbdH6XE3SRaExWIuW1RToc3a_ZoanW6wSMx8.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=88d805e7f119cc60c92965f30a8135a841bde74c&quot; alt=&quot;Hey LangChain community, lets make document_loaders to support BytesIO or an interface for in-memory objects&quot; title=&quot;Hey LangChain community, lets make document_loaders to support BytesIO or an interface for in-memory objects&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/egoloper&quot;&gt; /u/egoloper &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/langchain-ai/langchain/issues/15815&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19380am/hey_langchain_community_lets_make_document/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19380am</id><media:thumbnail url="https://external-preview.redd.it/CJYBOlSQbdH6XE3SRaExWIuW1RToc3a_ZoanW6wSMx8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=88d805e7f119cc60c92965f30a8135a841bde74c" /><link href="https://www.reddit.com/r/LangChain/comments/19380am/hey_langchain_community_lets_make_document/" /><updated>2024-01-10T13:14:28+00:00</updated><published>2024-01-10T13:14:28+00:00</published><title>Hey LangChain community, lets make document_loaders to support BytesIO or an interface for in-memory objects</title></entry><entry><author><name>/u/sarthak_uchiha</name><uri>https://www.reddit.com/user/sarthak_uchiha</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193c79x/not_implemented_error/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/j389hono2nbc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=aa0b6ab930f844cdfb8f52fec7531baa8a0d5b5a&quot; alt=&quot;Not implemented error&quot; title=&quot;Not implemented error&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I was trying to extract data from .html urls but getting this error , any fixes for this ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sarthak_uchiha&quot;&gt; /u/sarthak_uchiha &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/j389hono2nbc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/193c79x/not_implemented_error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_193c79x</id><media:thumbnail url="https://preview.redd.it/j389hono2nbc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=aa0b6ab930f844cdfb8f52fec7531baa8a0d5b5a" /><link href="https://www.reddit.com/r/LangChain/comments/193c79x/not_implemented_error/" /><updated>2024-01-10T16:25:23+00:00</updated><published>2024-01-10T16:25:23+00:00</published><title>Not implemented error</title></entry><entry><author><name>/u/wilyx11</name><uri>https://www.reddit.com/user/wilyx11</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The most likely option is that I got something wrong. &lt;/p&gt; &lt;p&gt;I used Faiis store to do a vector search over 30000 documents, which worked relatively well. I tried to do the same with Langchain and Superbase and the queries take 4x the amount of time to run. Has anyone run into this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/wilyx11&quot;&gt; /u/wilyx11 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192y7se/am_i_tripping_or_is_superbase_super_slow/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192y7se/am_i_tripping_or_is_superbase_super_slow/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_192y7se</id><link href="https://www.reddit.com/r/LangChain/comments/192y7se/am_i_tripping_or_is_superbase_super_slow/" /><updated>2024-01-10T03:19:02+00:00</updated><published>2024-01-10T03:19:02+00:00</published><title>Am I tripping or is SuperBase super slow?</title></entry><entry><author><name>/u/sarthak_uchiha</name><uri>https://www.reddit.com/user/sarthak_uchiha</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1935nsn/not_implemented_error/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/5xyg4y2vflbc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b83cd1676a667399ab571e309a42508fa553e7bc&quot; alt=&quot;Not implemented error&quot; title=&quot;Not implemented error&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Anyone knows any fix for this ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sarthak_uchiha&quot;&gt; /u/sarthak_uchiha &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/5xyg4y2vflbc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1935nsn/not_implemented_error/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1935nsn</id><media:thumbnail url="https://preview.redd.it/5xyg4y2vflbc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b83cd1676a667399ab571e309a42508fa553e7bc" /><link href="https://www.reddit.com/r/LangChain/comments/1935nsn/not_implemented_error/" /><updated>2024-01-10T10:56:09+00:00</updated><published>2024-01-10T10:56:09+00:00</published><title>Not implemented error</title></entry><entry><author><name>/u/foofork</name><uri>https://www.reddit.com/user/foofork</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192ds28/langchain_v010/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/tJ_Y_ThtoNgkhdLSY2LTRnkqAPkmQkGlWROgzJKP4oE.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=714796e21a4c6c882d99f39260075ae7f24dc758&quot; alt=&quot;LangChain v0.1.0&quot; title=&quot;LangChain v0.1.0&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/foofork&quot;&gt; /u/foofork &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://blog.langchain.dev/langchain-v0-1-0/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192ds28/langchain_v010/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_192ds28</id><media:thumbnail url="https://external-preview.redd.it/tJ_Y_ThtoNgkhdLSY2LTRnkqAPkmQkGlWROgzJKP4oE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=714796e21a4c6c882d99f39260075ae7f24dc758" /><link href="https://www.reddit.com/r/LangChain/comments/192ds28/langchain_v010/" /><updated>2024-01-09T12:38:08+00:00</updated><published>2024-01-09T12:38:08+00:00</published><title>LangChain v0.1.0</title></entry><entry><author><name>/u/YourWelcomeOrMine</name><uri>https://www.reddit.com/user/YourWelcomeOrMine</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on creating a chatbot for some long research papers of mine (using RAG). While I&amp;#39;d like the ability to answer both summary questions, e.g. &amp;quot;What&amp;#39;s paper x all about?&amp;quot;, I also want the chatbot to answer specific questions. This need speaks to the usefulness of Agents (I think), but since I don&amp;#39;t need to chain together a bunch of tasks, I&amp;#39;m wondering if LangChain is overkill?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/YourWelcomeOrMine&quot;&gt; /u/YourWelcomeOrMine &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192oom1/is_langchain_neededideal_for_a_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192oom1/is_langchain_neededideal_for_a_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_192oom1</id><link href="https://www.reddit.com/r/LangChain/comments/192oom1/is_langchain_neededideal_for_a_chatbot/" /><updated>2024-01-09T20:28:59+00:00</updated><published>2024-01-09T20:28:59+00:00</published><title>Is LangChain needed/ideal for a chatbot?</title></entry><entry><author><name>/u/Environmental_Win975</name><uri>https://www.reddit.com/user/Environmental_Win975</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;vectorstore_faiss = FAISS.from_documents(&lt;/p&gt; &lt;p&gt;^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt; &lt;p&gt;File &amp;quot;/opt/homebrew/lib/python3.11/site-packages/langchain_core/vectorstores.py&amp;quot;, line 510, in from_documents&lt;/p&gt; &lt;p&gt;return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)&lt;/p&gt; &lt;p&gt;^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&lt;/p&gt; &lt;p&gt;File &amp;quot;/opt/homebrew/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py&amp;quot;, line 915, in from_texts&lt;/p&gt; &lt;p&gt;return cls.__from(&lt;/p&gt; &lt;p&gt;^^^^^^^^^^^&lt;/p&gt; &lt;p&gt;File &amp;quot;/opt/homebrew/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py&amp;quot;, line 874, in __from&lt;/p&gt; &lt;p&gt;index = faiss.IndexFlatL2(len(embeddings[0]))&lt;/p&gt; &lt;p&gt;^^^^^^^^^^^^^^^^^^&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Environmental_Win975&quot;&gt; /u/Environmental_Win975 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192vu2i/getting_error_faiss_call_typeerror_object_of_type/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192vu2i/getting_error_faiss_call_typeerror_object_of_type/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_192vu2i</id><link href="https://www.reddit.com/r/LangChain/comments/192vu2i/getting_error_faiss_call_typeerror_object_of_type/" /><updated>2024-01-10T01:24:35+00:00</updated><published>2024-01-10T01:24:35+00:00</published><title>Getting error FAISS call; [TypeError: object of type 'NoneType' has no len()]</title></entry><entry><author><name>/u/holy_herb</name><uri>https://www.reddit.com/user/holy_herb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone, &lt;/p&gt; &lt;p&gt;A few months ago I was playing around with a bunch of different tools to manage integrations and LLMs. I randomly found a website, where within the UI I was able to:&lt;/p&gt; &lt;p&gt;- Provide a prompt for a complex task (e.g. build app that does XYZ)&lt;/p&gt; &lt;p&gt;- It broke it down into subtasks (e.g. choose data schemas, create frontend...etc)&lt;/p&gt; &lt;p&gt;- It then started working on each subtasks and finding new ones as it completed each one&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I was blown away but then needing to do my research took me somewhere else. I now have time to invest more time in this venture but can&amp;#39;t find it for the life of me. I think it was based on LangChain or AutoGPT but I&amp;#39;ve been searching for hours and can&amp;#39;t find it so trying my luck here :)&lt;/p&gt; &lt;p&gt;Anyone know what this is or uses it?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/holy_herb&quot;&gt; /u/holy_herb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192p8lz/what_llm_orchestration_tool_am_i_thinking_about/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192p8lz/what_llm_orchestration_tool_am_i_thinking_about/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_192p8lz</id><link href="https://www.reddit.com/r/LangChain/comments/192p8lz/what_llm_orchestration_tool_am_i_thinking_about/" /><updated>2024-01-09T20:50:56+00:00</updated><published>2024-01-09T20:50:56+00:00</published><title>What LLM orchestration tool am I thinking about?</title></entry><entry><author><name>/u/abrownie_jr</name><uri>https://www.reddit.com/user/abrownie_jr</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192t5rb/nextjs_langchain_supabase_template_to_build_ai/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/NLTtsU2IxZEBr4_J68TeEl7TeJ8Y4SJh8Gr3iVAxzEg.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7702e881ff398881216e8a978099d40b78cbd8eb&quot; alt=&quot;Nextjs + LangChain + Supabase template to build AI apps&quot; title=&quot;Nextjs + LangChain + Supabase template to build AI apps&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/abrownie_jr&quot;&gt; /u/abrownie_jr &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://templateai.co&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192t5rb/nextjs_langchain_supabase_template_to_build_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_192t5rb</id><media:thumbnail url="https://external-preview.redd.it/NLTtsU2IxZEBr4_J68TeEl7TeJ8Y4SJh8Gr3iVAxzEg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7702e881ff398881216e8a978099d40b78cbd8eb" /><link href="https://www.reddit.com/r/LangChain/comments/192t5rb/nextjs_langchain_supabase_template_to_build_ai/" /><updated>2024-01-09T23:28:06+00:00</updated><published>2024-01-09T23:28:06+00:00</published><title>Nextjs + LangChain + Supabase template to build AI apps</title></entry><entry><author><name>/u/skylight22</name><uri>https://www.reddit.com/user/skylight22</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have the following code, memory does not store the intermediate steps in the tools calling, how can this be achieved? &lt;/p&gt; &lt;pre&gt;&lt;code&gt;def answer_langchain_v2(input, chat_token): memory = ConversationBufferMemory( memory_key=&amp;#39;chat_history&amp;#39;, return_messages=True) azure_open_ai = AzureChatOpenAI( temperature=0, max_tokens=3000, verbose=True, ) tools = [retrieve_benchmarks, search_entities()] prompt = hub.pull(&amp;quot;hwchase17/openai-tools-agent&amp;quot;) agent = create_openai_tools_agent( azure_open_ai, tools, prompt) agent_executor = AgentExecutor( agent=agent, tools=tools, verbose=True, handle_parsing_errors=True, memory=memory ) output = agent_executor.invoke( { &amp;quot;input&amp;quot;: input_schema.format(input=input), } )[&amp;#39;output&amp;#39;] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/skylight22&quot;&gt; /u/skylight22 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192kifr/how_to_make_openai_tools_agent_store_tool_messages/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192kifr/how_to_make_openai_tools_agent_store_tool_messages/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_192kifr</id><link href="https://www.reddit.com/r/LangChain/comments/192kifr/how_to_make_openai_tools_agent_store_tool_messages/" /><updated>2024-01-09T17:42:08+00:00</updated><published>2024-01-09T17:42:08+00:00</published><title>How to make openai tools agent store tool messages</title></entry><entry><author><name>/u/Honest-Worth3677</name><uri>https://www.reddit.com/user/Honest-Worth3677</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192eqy6/why_cannot_you_train_mistral_7b_in_colab/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/l3mjc_n-tsX1idvFHdCA6uS50LoYXp0LRhpi8IsKS74.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=237a2c721035415772aa26843c021e113e6e952a&quot; alt=&quot;Why cannot you train Mistral 7b in colab ?&quot; title=&quot;Why cannot you train Mistral 7b in colab ?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Honest-Worth3677&quot;&gt; /u/Honest-Worth3677 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Wx4lzT3tFYQ&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192eqy6/why_cannot_you_train_mistral_7b_in_colab/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_192eqy6</id><media:thumbnail url="https://external-preview.redd.it/l3mjc_n-tsX1idvFHdCA6uS50LoYXp0LRhpi8IsKS74.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=237a2c721035415772aa26843c021e113e6e952a" /><link href="https://www.reddit.com/r/LangChain/comments/192eqy6/why_cannot_you_train_mistral_7b_in_colab/" /><updated>2024-01-09T13:30:38+00:00</updated><published>2024-01-09T13:30:38+00:00</published><title>Why cannot you train Mistral 7b in colab ?</title></entry><entry><author><name>/u/etticat</name><uri>https://www.reddit.com/user/etticat</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We&amp;#39;re building a web app, that allows the user to upload PDFs, which we then summarise. &lt;/p&gt; &lt;p&gt;A challenge we have is that people upload very different formats of PDFs. (Word exports, flattened images, scanned documents, ...). &lt;/p&gt; &lt;p&gt;In my head I was thinking of detecting if it has lots of big images (when it&amp;#39;s a scan), then using a vision model over those images, and then summarising the outputs. If there are no images, then just extracting texts (potentially handing tables slightly differently). &lt;/p&gt; &lt;p&gt;What are the best practices on ensuring all the information is extracted? In my head I was thinking of detecting if it has lots of big images (when it&amp;#39;s a scan), then using a vision model over those images, and then summarising the outputs. If there are no images, then just extract texts (potentially handing tables slightly differently). &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/etticat&quot;&gt; /u/etticat &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192epg3/best_practices_for_uploading_pdfs_when_type/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192epg3/best_practices_for_uploading_pdfs_when_type/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_192epg3</id><link href="https://www.reddit.com/r/LangChain/comments/192epg3/best_practices_for_uploading_pdfs_when_type/" /><updated>2024-01-09T13:28:30+00:00</updated><published>2024-01-09T13:28:30+00:00</published><title>Best practices for uploading PDFs when type varies a lot (scanned documents, exports, tables, ...)</title></entry><entry><author><name>/u/thegeekcoderzs</name><uri>https://www.reddit.com/user/thegeekcoderzs</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What is the difference between LangChain and LangSmith? What do you think is the best way to learn this framework?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thegeekcoderzs&quot;&gt; /u/thegeekcoderzs &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192avem/i_just_started_learning/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192avem/i_just_started_learning/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_192avem</id><link href="https://www.reddit.com/r/LangChain/comments/192avem/i_just_started_learning/" /><updated>2024-01-09T09:31:19+00:00</updated><published>2024-01-09T09:31:19+00:00</published><title>I just started learning.</title></entry><entry><author><name>/u/modularmindapp</name><uri>https://www.reddit.com/user/modularmindapp</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192d3wv/unlock_the_power_of_ai_for_content_creation_from/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/YnB0OTNrOHhsZWJjMacSrpqR0h8TTy_LNM2c4VpS-z5i0CzyTYXU-ym9LoZB.png?width=140&amp;amp;height=140&amp;amp;crop=140:140,smart&amp;amp;format=jpg&amp;amp;v=enabled&amp;amp;lthumb=true&amp;amp;s=bcb01cad4a444748c4c97c7e6863862e8975ac5d&quot; alt=&quot;Unlock the power of AI for content creation. From crafting a product description to generating keywords with GPT-4, analyzing with GPT-3.5, to effortlessly creating a newsletter, blog post, and TikTok script using Claude2 ‚ú®&quot; title=&quot;Unlock the power of AI for content creation. From crafting a product description to generating keywords with GPT-4, analyzing with GPT-3.5, to effortlessly creating a newsletter, blog post, and TikTok script using Claude2 ‚ú®&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/modularmindapp&quot;&gt; /u/modularmindapp &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/u3flukivlebc1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/192d3wv/unlock_the_power_of_ai_for_content_creation_from/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_192d3wv</id><media:thumbnail url="https://external-preview.redd.it/YnB0OTNrOHhsZWJjMacSrpqR0h8TTy_LNM2c4VpS-z5i0CzyTYXU-ym9LoZB.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=bcb01cad4a444748c4c97c7e6863862e8975ac5d" /><link href="https://www.reddit.com/r/LangChain/comments/192d3wv/unlock_the_power_of_ai_for_content_creation_from/" /><updated>2024-01-09T11:58:41+00:00</updated><published>2024-01-09T11:58:41+00:00</published><title>Unlock the power of AI for content creation. From crafting a product description to generating keywords with GPT-4, analyzing with GPT-3.5, to effortlessly creating a newsletter, blog post, and TikTok script using Claude2 ‚ú®</title></entry><entry><author><name>/u/function-devs</name><uri>https://www.reddit.com/user/function-devs</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone!&lt;/p&gt; &lt;p&gt;Excited to share this with you.&lt;/p&gt; &lt;p&gt;![image](&lt;a href=&quot;https://github.com/thestriver/ai-for-javascript-course/assets/16709708/95237a88-63e2-48b6-a2c6-fc45ff49fe7b&quot;&gt;https://github.com/thestriver/ai-for-javascript-course/assets/16709708/95237a88-63e2-48b6-a2c6-fc45ff49fe7b&lt;/a&gt;)&lt;/p&gt; &lt;p&gt;I just released an open-source course for Javascript developers who want to build AI applications on GitHub. All 60 pages of them (if you want the PDF format of the primer). (The markdown file is at over 1600 lines right now and growing.) üôÇ&lt;/p&gt; &lt;p&gt;Structured to take Javascript developers from 0-1, I put in everything I know from building AI-powered apps over the past year, and I hope you find it useful too.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/thestriver/ai-for-javascript-course&quot;&gt;Github Link&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Here are some of the topics touched on in the modules:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Introduction to LLMs üß©&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Advanced Prompt Engineering and Optimization ‚úèÔ∏è&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Integrating&lt;/strong&gt; &lt;strong&gt;OpenAI GPT 3.5 and Mistral 7B Instruct v0.2 into JS apps&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Retrieval Augmented Generation üí¨&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Using Vercel AI SDK, Pinecone, and Langchain to build a Research Assistant Tool&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Function Calling&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Building&lt;/strong&gt; 3 *&lt;strong&gt;&lt;em&gt;AI Agents with different levels of complexity ü§ñ&lt;/em&gt;&lt;/strong&gt;*&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Security, Ethics, and Performance in AI Development&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;A relevant project accompanies each course.&lt;/p&gt; &lt;p&gt;I created this course hoping it would be an excellent guide for aspiring AI developers and a valuable resource for the wider JavaScript developer community.&lt;/p&gt; &lt;p&gt;I would love to get your feedback and, of course, would appreciate it if you shared any bugs or mistakes you discover or questions with me.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/function-devs&quot;&gt; /u/function-devs &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191r21r/i_released_a_new_opensource_practical_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191r21r/i_released_a_new_opensource_practical_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_191r21r</id><link href="https://www.reddit.com/r/LangChain/comments/191r21r/i_released_a_new_opensource_practical_ai/" /><updated>2024-01-08T17:47:53+00:00</updated><published>2024-01-08T17:47:53+00:00</published><title>I released a new opensource Practical AI Development for Javascript Developers course! (Heavily uses langchain)</title></entry><entry><author><name>/u/gswithai</name><uri>https://www.reddit.com/user/gswithai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi üëã &lt;/p&gt; &lt;p&gt;I wrote this &lt;a href=&quot;https://www.gettingstarted.ai/everything-you-need-to-know-when-getting-started-with-langchain/&quot;&gt;introductory post&lt;/a&gt; for anyone just getting started with LangChain.&lt;/p&gt; &lt;p&gt;I try to keep it simple while going over important points so you can get started in no time.&lt;/p&gt; &lt;p&gt;If you‚Äôre new to LangChain, you‚Äôll want to &lt;a href=&quot;https://www.gettingstarted.ai/everything-you-need-to-know-when-getting-started-with-langchain/&quot;&gt;read this introductory post&lt;/a&gt; and then dive deeper into more advanced topics as you progress.&lt;/p&gt; &lt;p&gt;Check it out and let me know if you have any questions or feedback.&lt;/p&gt; &lt;p&gt;Cheers!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gswithai&quot;&gt; /u/gswithai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191q3qk/new_to_langchain_start_here/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191q3qk/new_to_langchain_start_here/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_191q3qk</id><link href="https://www.reddit.com/r/LangChain/comments/191q3qk/new_to_langchain_start_here/" /><updated>2024-01-08T17:10:01+00:00</updated><published>2024-01-08T17:10:01+00:00</published><title>New to LangChain? Start here!</title></entry><entry><author><name>/u/30299578815310</name><uri>https://www.reddit.com/user/30299578815310</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I like the tools but I&amp;#39;m not a huge fan of the default agent prompts. Just wondering if anybody has done this? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/30299578815310&quot;&gt; /u/30299578815310 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191sm46/has_anybody_used_langchain_tools_but_totally_used/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191sm46/has_anybody_used_langchain_tools_but_totally_used/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_191sm46</id><link href="https://www.reddit.com/r/LangChain/comments/191sm46/has_anybody_used_langchain_tools_but_totally_used/" /><updated>2024-01-08T18:50:31+00:00</updated><published>2024-01-08T18:50:31+00:00</published><title>has anybody used langchain tools but totally used custom logic for parsing LLM responses and invoking them?</title></entry><entry><author><name>/u/areebmianoor</name><uri>https://www.reddit.com/user/areebmianoor</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi &lt;/p&gt; &lt;p&gt;I&amp;#39;m fairly new to this so pardon the basic question, I poked around this community but couldn&amp;#39;t find the response so some help would be kindly appreciated. Here&amp;#39;s the situation:&lt;/p&gt; &lt;p&gt;I&amp;#39;m using RAG to build an assistant for my employer. Currently I&amp;#39;ve set up a chatbot that uses Langchain, OpenAI embedding, Deeplake as a vector database. And my current setup works well from a demo perspective where I can show the chatbot responding over some code files and giving some value. However, when I combine other data types into the database (after chunking and embedding) such as my companies Confluence documentation, it doesn&amp;#39;t seem to mesh well with the codebase data. I believe i should be doinf this in a way where the vector database has files stored in such a way that makes it clear for the retriever what part of the vector database came from a codebase and what part came from documentation (confluence) and they need to be referenced together but stored seperately to work effienciently. &lt;/p&gt; &lt;p&gt;Moreover i need some kind of an agent setup which can identify whether to respond with context from the codebase&amp;#39;s vector files or from the confluence documentations vector files or an appropriate combination of both (that would be ideal). . &lt;/p&gt; &lt;p&gt;It would also be extremely powerful if I could also somehow add on the companies PDFs, word files, PowerPoint, excel files etc. Into the mix and have it all be part of the same RAG flow. &lt;/p&gt; &lt;p&gt;I would appreciate some guidance from people who have done similar or the knowhow to solve this.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/areebmianoor&quot;&gt; /u/areebmianoor &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191d8td/rag_responding_with_multiple_data_types/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191d8td/rag_responding_with_multiple_data_types/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_191d8td</id><link href="https://www.reddit.com/r/LangChain/comments/191d8td/rag_responding_with_multiple_data_types/" /><updated>2024-01-08T05:09:58+00:00</updated><published>2024-01-08T05:09:58+00:00</published><title>RAG - Responding with multiple data types</title></entry><entry><author><name>/u/InternationalMail954</name><uri>https://www.reddit.com/user/InternationalMail954</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone I&amp;#39;m trying to create a document retrieval app with memory. Currently it will only answer document questions and will not answer successive questions.&lt;br/&gt; For example if I ask for 3*3 it returns correctly but if i ask it to multiply the previous result by 3 it will tell me the document doesn&amp;#39;t have a number it knows to multiply by 3. Any help would be greatly appreciated.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import streamlit as st from langchain.memory.chat_message_histories import StreamlitChatMessageHistory from io import StringIO import pinecone pinecone.init(api_key=&amp;quot;&amp;quot;, environment=&amp;quot;gcp-starter&amp;quot;) from langchain import PromptTemplate from langchain.chat_models import ChatOpenAI from langchain.chains import LLMChain from langchain.chains import ConversationalRetrievalChain from langchain.embeddings import OpenAIEmbeddings from langchain.vectorstores import Pinecone from langchain.text_splitter import RecursiveCharacterTextSplitter from langchain.memory import ConversationBufferMemory from langchain.schema import SystemMessage OPENAI_API_KEY = &amp;quot;&amp;quot; OPENAI_DIMENSION = 1536 embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) st.reupload_file = False vector_store = Pinecone.from_existing_index(&amp;quot;legal-cases&amp;quot;, embedding) index = pinecone.Index(&amp;quot;legal-cases&amp;quot;) def upload_new_file_to_pinecone(text): embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) text_splitter = RecursiveCharacterTextSplitter( chunk_size=100, chunk_overlap=0, length_function=len ) chunks = text_splitter.create_documents([text]) result = Pinecone.from_documents(chunks, embedding, index_name=&amp;quot;legal-cases&amp;quot;) st.title(&amp;quot;üìù File Q&amp;amp;A&amp;quot;) uploaded_file = st.file_uploader(&amp;quot;Upload an article&amp;quot;, type=(&amp;quot;txt&amp;quot;, &amp;quot;md&amp;quot;)) if st.reupload_file: print(&amp;quot;updated file&amp;quot;) # To read file as bytes: bytes_data = uploaded_file.getvalue() # To convert to a string based IO: stringio = StringIO(uploaded_file.getvalue().decode(&amp;quot;utf-8&amp;quot;)) # To read file as string: string_data = stringio.read() index.delete(delete_all=True) upload_new_file_to_pinecone(string_data) from langchain.chains import RetrievalQA from langchain.chat_models import ChatOpenAI k = 3 # user&amp;#39;s question text input widget q = st.text_input(&amp;quot;Ask a question about the content of your file:&amp;quot;) if q: # if the user entered a question and hit enter standard_answer = &amp;quot;&amp;quot; q = f&amp;quot;{q} {standard_answer}&amp;quot; system_message = f&amp;quot;&amp;quot;&amp;quot; You are an assistant which helps to user find answers to his question with internal company data. This data will be provided by a vector db as context. You also help with normal stuff like answering questions or generating text by ignoring this system message. When asked to summarize a specific page only summarize pages which match the page id within the url if appliable. &amp;quot;&amp;quot;&amp;quot; system_message = SystemMessage(content=system_message) memory = ConversationBufferMemory( memory_key=&amp;quot;chat_history&amp;quot;, input_key=&amp;quot;question&amp;quot;, output_key=&amp;quot;answer&amp;quot;, return_messages=True, ) memory.chat_memory.add_message(system_message) llm = ChatOpenAI(model=&amp;quot;gpt-3.5-turbo&amp;quot;, temperature=1, api_key=OPENAI_API_KEY) retriever = vector_store.as_retriever( search_type=&amp;quot;similarity&amp;quot;, search_kwargs={&amp;quot;k&amp;quot;: k} ) chain = ConversationalRetrievalChain.from_llm( llm, retriever=retriever, memory=memory, return_source_documents=True, ) answer = chain({&amp;quot;question&amp;quot; : q})[&amp;quot;chat_history&amp;quot;][-1].content # text area widget for the LLM answer st.text_area(&amp;quot;LLM Answer: &amp;quot;, value=answer) st.divider() # if there&amp;#39;s no chat history in the session state, create it if &amp;quot;history&amp;quot; not in st.session_state: st.session_state.history = &amp;quot;&amp;quot; # the current question and answer value = f&amp;quot;Q: {q} \nA: {answer}&amp;quot; st.session_state.history = ( f&amp;#39;{value} \n {&amp;quot;-&amp;quot; * 100} \n {st.session_state.history}&amp;#39; ) h = st.session_state.history # text area widget for the chat history st.text_area(label=&amp;quot;Chat History&amp;quot;, value=h, key=&amp;quot;history&amp;quot;, height=400) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/InternationalMail954&quot;&gt; /u/InternationalMail954 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191bsyn/can_someone_please_help_me_understand_why_this/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191bsyn/can_someone_please_help_me_understand_why_this/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_191bsyn</id><link href="https://www.reddit.com/r/LangChain/comments/191bsyn/can_someone_please_help_me_understand_why_this/" /><updated>2024-01-08T03:53:36+00:00</updated><published>2024-01-08T03:53:36+00:00</published><title>Can someone please help me understand why this document lookup app can't remember previous questions</title></entry><entry><author><name>/u/SignificantSuit5561</name><uri>https://www.reddit.com/user/SignificantSuit5561</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I&amp;#39;m doing an experiment with langchain and chatgpt to see if I can get chatgpt to make business recommendations based on keywords provided in the prompt. I am using the following code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;loader = TextLoader(&amp;#39;/tmp/training.txt&amp;#39;) index = VectorstoreIndexCreator().from_loaders([loader]) chain = ConversationalRetrievalChain.from_llm( llm=ChatOpenAI(model=&amp;quot;gpt-4&amp;quot;), retriever=index.vectorstore.as_retriever(search_kwargs={&amp;quot;k&amp;quot;: 10}), ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;training.txt is just a text file with a JSON array e.g.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;[ { &amp;quot;name&amp;quot;: &amp;quot;Some Software Shop&amp;quot;, &amp;quot;keywords&amp;quot;: [ &amp;quot;SaaS&amp;quot;, &amp;quot;sales&amp;quot; ], &amp;quot;description&amp;quot;: &amp;quot;...&amp;quot;, } ] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When I prompt with something like &amp;quot;What businesses deal with SaaS?&amp;quot;, it never seems to return the relevant results i.e. those with &amp;quot;SaaS&amp;quot; in the keywords. Moreover, it seems that I always get the same handful of results out of hundreds in the file.&lt;/p&gt; &lt;p&gt;Any thoughts on where I&amp;#39;m going wrong? Thank you.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SignificantSuit5561&quot;&gt; /u/SignificantSuit5561 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191b6is/please_teach_me_how_to_get_relevant_vector_store/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191b6is/please_teach_me_how_to_get_relevant_vector_store/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_191b6is</id><link href="https://www.reddit.com/r/LangChain/comments/191b6is/please_teach_me_how_to_get_relevant_vector_store/" /><updated>2024-01-08T03:21:51+00:00</updated><published>2024-01-08T03:21:51+00:00</published><title>Please teach me how to get relevant vector store results</title></entry><entry><author><name>/u/Appropriate_Egg6118</name><uri>https://www.reddit.com/user/Appropriate_Egg6118</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How to add ouput parser to ConversationalRetrievalQAChain or ConversationChain?&lt;/p&gt; &lt;p&gt;I can able to add outputparser to LLMChain but it&amp;#39;s not working for above conversation chains. &lt;/p&gt; &lt;pre&gt;&lt;code&gt;Code: from langchain.output_parsers import ResponseSchema, StructuredOutputParser from langchain.memory import ConversationBufferMemory from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate from langchain.chat_models import ChatOpenAI from langchain.chains import LLMChain, ConversationalRetrievalChain checker_tmpl = &amp;quot;&amp;quot;&amp;quot; # Task Description: As a customer support representative, your role is to provide accurate and helpful responses to customer inquiries. Use the provided context to understand the customer&amp;#39;s issue and answer their questions directly. Avoid any extraneous information or explanations that are not directly relevant to the customer&amp;#39;s query. {format_instructions} Chat History:\n\n{history} \n\n # Given Context: {context} # Customer&amp;#39;s Question: {question} {human_input} # Your Response: [Please type your answer here, ensuring it is concise, relevant, and directly addresses the customer&amp;#39;s question based on the given context.] &amp;quot;&amp;quot;&amp;quot; checker_response_schemas = [ ResponseSchema( name=&amp;quot;requires_customer_support_contact&amp;quot;, description=&amp;quot;Indicates whether the user needs to contact customer support. Set to True if the context does not sufficiently address the user&amp;#39;s issue and further assistance is needed. Set to False if the provided context is adequate to answer the user&amp;#39;s query.&amp;quot;, type=&amp;quot;boolean&amp;quot; ), ResponseSchema( name=&amp;quot;contextual_answer&amp;quot;, description=&amp;quot;Provides a direct answer to the user&amp;#39;s question, utilizing the given context. The response should be concise, accurate, and specifically tailored to address the query based on the context provided.&amp;quot;, ), ] check_output_parser = StructuredOutputParser.from_response_schemas(checker_response_schemas) resume_checker_prompt = ChatPromptTemplate( messages=[ HumanMessagePromptTemplate.from_template(checker_tmpl) ], input_variables=[&amp;quot;history&amp;quot;,&amp;quot;question&amp;quot;,&amp;quot;context&amp;quot;], partial_variables={&amp;quot;format_instructions&amp;quot;: check_output_parser.get_format_instructions()} ) memory = ConversationBufferMemory( memory_key=&amp;quot;history&amp;quot;, input_key=&amp;quot;human_input&amp;quot; ) llm = ChatOpenAI(model_name=&amp;quot;gpt-3.5-turbo-1106&amp;quot;) chat_chain = LLMChain( llm=llm, prompt=resume_checker_prompt, memory = memory ) # I wanna use below chain with output parser. chain = ConversationalRetrievalChain.from_llm( llm=llm, memory=memory, chain_type=&amp;quot;stuff&amp;quot;, retriever=retriever, return_source_documents=True, get_chat_history=lambda h : h, verbose=False , ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Appropriate_Egg6118&quot;&gt; /u/Appropriate_Egg6118 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191b28p/how_to_use_output_parser_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/191b28p/how_to_use_output_parser_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_191b28p</id><link href="https://www.reddit.com/r/LangChain/comments/191b28p/how_to_use_output_parser_with/" /><updated>2024-01-08T03:16:02+00:00</updated><published>2024-01-08T03:16:02+00:00</published><title>How to use Output parser with ConversationalRetrievalQAChain?</title></entry></feed>