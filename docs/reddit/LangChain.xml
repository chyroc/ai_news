<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-25T03:22:30+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/NefariousnessSad2208</name><uri>https://www.reddit.com/user/NefariousnessSad2208</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m developing an application using a large language model (LLM) and am in need of a robust core agent platform that supports multi-modal agent capabilities. Currently, I&amp;#39;m utilizing LLM for intent recognition and named entity recognition, and then I do backend workflow orchestration without LLM or Agents. My goal is to transition to an agent framework for enhanced flexibility. I&amp;#39;m looking for frameworks that are resilient against prompt injection and easier to with open-source LLMs. &lt;/p&gt; &lt;p&gt;So far, I&amp;#39;ve considered:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;LangChain Agents (I have experience with it)&lt;/li&gt; &lt;li&gt;LLaMaIndex Agents&lt;/li&gt; &lt;li&gt;HayStack Agents&lt;/li&gt; &lt;li&gt;AutoGen&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Do you:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Recommend any additional frameworks that are worth exploring for agent orchestration? &lt;/li&gt; &lt;li&gt;Have a preferred framework in this context?&lt;/li&gt; &lt;li&gt;have experience with these framework and want to share feedback?&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/NefariousnessSad2208&quot;&gt; /u/NefariousnessSad2208 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eqmgk/agent_platform_for_multimodal_agent_capabilities/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eqmgk/agent_platform_for_multimodal_agent_capabilities/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19eqmgk</id><link href="https://www.reddit.com/r/LangChain/comments/19eqmgk/agent_platform_for_multimodal_agent_capabilities/" /><updated>2024-01-24T20:38:39+00:00</updated><published>2024-01-24T20:38:39+00:00</published><title>agent platform for multi-modal agent capabilities</title></entry><entry><author><name>/u/flowerescape</name><uri>https://www.reddit.com/user/flowerescape</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can y‚Äôall recommend a good tutorial that will get me from start to finish for a RAG app I‚Äôm trying to make using LangChain JS?&lt;/p&gt; &lt;p&gt;I don‚Äôt wanna become a guru, just trying to get something on production asap. It needs to have memory.&lt;/p&gt; &lt;p&gt;Much appreciated üôèüèª&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/flowerescape&quot;&gt; /u/flowerescape &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ewodj/whats_the_best_langchain_js_tutorial_on_youtube/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ewodj/whats_the_best_langchain_js_tutorial_on_youtube/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ewodj</id><link href="https://www.reddit.com/r/LangChain/comments/19ewodj/whats_the_best_langchain_js_tutorial_on_youtube/" /><updated>2024-01-25T00:55:58+00:00</updated><published>2024-01-25T00:55:58+00:00</published><title>What‚Äôs the best LangChain (JS) tutorial on YouTube</title></entry><entry><author><name>/u/Fr4nkWh1te</name><uri>https://www.reddit.com/user/Fr4nkWh1te</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to build a &lt;strong&gt;chatbot&lt;/strong&gt; that has access to &lt;strong&gt;all pages&lt;/strong&gt; in my website&amp;#39;s GitHub repository. &lt;/p&gt; &lt;p&gt;The &lt;a href=&quot;https://js.langchain.com/docs/integrations/document_loaders/web_loaders/github#usage&quot;&gt;GitHubRepoLoader&lt;/a&gt; makes it easy to fetch all pages and turn them into documents. But I would also like to &lt;strong&gt;strip these documents of all the React code&lt;/strong&gt; and keep only the user-readable information.&lt;/p&gt; &lt;p&gt;I tried Langchain.js&amp;#39;s &lt;a href=&quot;https://js.langchain.com/docs/integrations/document_transformers/html-to-text&quot;&gt;html-to-text&lt;/a&gt; converter but that didn&amp;#39;t work. I also found &lt;a href=&quot;https://www.npmjs.com/package/react-to-text&quot;&gt;react-to-text&lt;/a&gt; but this one expects an actual React component as its argument. I have the full file as a string.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fr4nkWh1te&quot;&gt; /u/Fr4nkWh1te &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ehc9w/reactjsx_to_text_parser/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ehc9w/reactjsx_to_text_parser/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ehc9w</id><link href="https://www.reddit.com/r/LangChain/comments/19ehc9w/reactjsx_to_text_parser/" /><updated>2024-01-24T13:41:10+00:00</updated><published>2024-01-24T13:41:10+00:00</published><title>React/JSX to text parser?</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, &lt;/p&gt; &lt;p&gt;I have setup FastAPI with Llama.cpp and Langchain. Now I want to enable streaming in the FastAPI responses. Streaming works with Llama.cpp in my terminal, but I wasn&amp;#39;t able to implement it with a FastAPI response. See this Stackoverflow-Question (for code etc.): &lt;a href=&quot;https://stackoverflow.com/questions/77867894/streaming-local-llm-with-fastapi-llama-cpp-and-langchain?noredirect=1#comment137276485_77867894&quot;&gt;https://stackoverflow.com/questions/77867894/streaming-local-llm-with-fastapi-llama-cpp-and-langchain?noredirect=1#comment137276485_77867894&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Most tutorials focused on enabling streaming with an OpenAI model, but I am using a local LLM (quantized Mistral) with llama.cpp. I think I have to modify the Callbackhandler, but no tutorial worked.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Does anyone know how I can make Streaming working? I have a project deadline on Friday and unitl then I have to make it work...&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19enjxr/streaming_local_llm_with_fastapi_llamacpp_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19enjxr/streaming_local_llm_with_fastapi_llamacpp_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19enjxr</id><link href="https://www.reddit.com/r/LangChain/comments/19enjxr/streaming_local_llm_with_fastapi_llamacpp_and/" /><updated>2024-01-24T18:35:17+00:00</updated><published>2024-01-24T18:35:17+00:00</published><title>Streaming local LLM with FastAPI, Llama.cpp and Langchain</title></entry><entry><author><name>/u/jaxolingo</name><uri>https://www.reddit.com/user/jaxolingo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I&amp;#39;ve been using agents with autogen and crew, and now langgraph, mostly for learning and small/mid scale programs. The more I use them the more I&amp;#39;m confused about the purpose of the agent framework in general.&lt;/p&gt; &lt;p&gt;The scenarios I&amp;#39;ve tested: read input, execute web search, summaries, return to user. Most other usecases also follow a sequential iteration of steps. For these usecases, there is no need to include any sort of agents, it can be done through normal python scripts. Same goes for other usecases&lt;/p&gt; &lt;p&gt;I&amp;#39;m trying to think about what does agents let us do that we could not do with just scripts with some logic. Sure, the LLM As OS is a fantastic idea, but in a production setting I&amp;#39;m sticking to my scripts rather than hoping the LLM will decide which tool to use everytime...&lt;/p&gt; &lt;p&gt;I&amp;#39;m interested to learn the actual usecases and potential of using agents too execute tasks, so please do let me know&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jaxolingo&quot;&gt; /u/jaxolingo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ecbnb/purpose_of_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ecbnb/purpose_of_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ecbnb</id><link href="https://www.reddit.com/r/LangChain/comments/19ecbnb/purpose_of_agents/" /><updated>2024-01-24T08:20:30+00:00</updated><published>2024-01-24T08:20:30+00:00</published><title>Purpose of Agents</title></entry><entry><author><name>/u/Fr4nkWh1te</name><uri>https://www.reddit.com/user/Fr4nkWh1te</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am building a website with an integrated chatbot. How would you load the page info into documents? I want to make my code reusable for future projects.&lt;/p&gt; &lt;p&gt;Right now I&amp;#39;m using the &lt;a href=&quot;https://js.langchain.com/docs/integrations/document_loaders/web_loaders/github&quot;&gt;GitHubRepoLoader&lt;/a&gt; to turn the pages into documents, but this requires the code to be available in a GitHub repository. This is not great for local development (because we don&amp;#39;t have the latest data).&lt;/p&gt; &lt;p&gt;Would you load the pages from the file system instead? Or is there a better solution?&lt;/p&gt; &lt;p&gt;Any classes/helpers you can point me to? I&amp;#39;m using Langchain.js.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fr4nkWh1te&quot;&gt; /u/Fr4nkWh1te &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19elb7z/loader_for_website_pages_offline_nextjsreact/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19elb7z/loader_for_website_pages_offline_nextjsreact/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19elb7z</id><link href="https://www.reddit.com/r/LangChain/comments/19elb7z/loader_for_website_pages_offline_nextjsreact/" /><updated>2024-01-24T16:38:35+00:00</updated><published>2024-01-24T16:38:35+00:00</published><title>Loader for website pages (offline) (Next.js/React)</title></entry><entry><author><name>/u/Zestyclose-Bid-487</name><uri>https://www.reddit.com/user/Zestyclose-Bid-487</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;it has a collab notebook, blog links &amp;amp; all code&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zestyclose-Bid-487&quot;&gt; /u/Zestyclose-Bid-487 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ehe5m/best_resources_to_learn_to_advanced_rag_topics/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ehe5m/best_resources_to_learn_to_advanced_rag_topics/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ehe5m</id><link href="https://www.reddit.com/r/LangChain/comments/19ehe5m/best_resources_to_learn_to_advanced_rag_topics/" /><updated>2024-01-24T13:43:48+00:00</updated><published>2024-01-24T13:43:48+00:00</published><title>Best resources to learn to advanced RAG topics &amp; and to end projects</title></entry><entry><author><name>/u/hamnarif</name><uri>https://www.reddit.com/user/hamnarif</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I‚Äôve used these commands to install it in VSCode &lt;/p&gt; &lt;p&gt;export CUDACXX=&amp;quot;/mnt/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.3/bin/nvcc.exe&amp;quot; export CMAKE_ARGS=&amp;quot;-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all-major -DCUDAToolkit_ROOT=C:\Program Files\NVIDIA GP export FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir --force-reinstall --upgrade&lt;/p&gt; &lt;p&gt;Successfully installed but it‚Äôs still not accessing gpu. I‚Äôve nvidia GeForce RTC 3070 Ti &lt;/p&gt; &lt;p&gt;How do I know how many n_gpu_layers to set&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hamnarif&quot;&gt; /u/hamnarif &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eco2b/has_anyone_used_llamacpp_python_with_gpu_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eco2b/has_anyone_used_llamacpp_python_with_gpu_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19eco2b</id><link href="https://www.reddit.com/r/LangChain/comments/19eco2b/has_anyone_used_llamacpp_python_with_gpu_in/" /><updated>2024-01-24T08:46:11+00:00</updated><published>2024-01-24T08:46:11+00:00</published><title>Has anyone used Llama.cpp python with gpu in vscode to load local llm. Does it even work with VSCode or do I‚Äôve to install visual studio community edition?</title></entry><entry><author><name>/u/Gon_Buruwa</name><uri>https://www.reddit.com/user/Gon_Buruwa</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey! I&amp;#39;ve been working with a vast vector database containing thousands of text documents, each spanning an average of 10-12 pages (sometimes even up to 50 pages). I&amp;#39;ve noticed that when querying the data and citing sources, the system currently cites only the individual chunks rather than the entire document. Has anyone found an efficient way to attribute the entire document, complete with a proper title, instead of just the chunks?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Gon_Buruwa&quot;&gt; /u/Gon_Buruwa &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e8ylz/optimizing_source_citations_for_comprehensive/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e8ylz/optimizing_source_citations_for_comprehensive/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19e8ylz</id><link href="https://www.reddit.com/r/LangChain/comments/19e8ylz/optimizing_source_citations_for_comprehensive/" /><updated>2024-01-24T04:48:15+00:00</updated><published>2024-01-24T04:48:15+00:00</published><title>Optimizing Source Citations for Comprehensive References: How to attribute Documents Instead of Chunks?</title></entry><entry><author><name>/u/Adam-Schroeder</name><uri>https://www.reddit.com/user/Adam-Schroeder</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eaixd/create_ai_chatbots_for_websites_in_python/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/f_5VVWhKW_bpNQG8yIoNnXdTsFuLk7mlnMGL2VRdGnM.jpg&quot; alt=&quot;Create AI Chatbots for Websites in Python - EmbedChain Dash&quot; title=&quot;Create AI Chatbots for Websites in Python - EmbedChain Dash&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Everyone,&lt;br/&gt; A few days ago, I created this free video tutorial on how to build an AI Chatbot in Python. I use the EmbedChain (built on top of LangChain) and Dash libraries, as I show how to train and interact with your bot. Hope you find it helpful. &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/tmOmTBEdNrE&quot;&gt;https://youtu.be/tmOmTBEdNrE&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/t2ebobt8zbec1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b2dcd9f2a930da35f2862b368a535d30ad885825&quot;&gt;https://preview.redd.it/t2ebobt8zbec1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b2dcd9f2a930da35f2862b368a535d30ad885825&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Adam-Schroeder&quot;&gt; /u/Adam-Schroeder &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eaixd/create_ai_chatbots_for_websites_in_python/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19eaixd/create_ai_chatbots_for_websites_in_python/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19eaixd</id><media:thumbnail url="https://b.thumbs.redditmedia.com/f_5VVWhKW_bpNQG8yIoNnXdTsFuLk7mlnMGL2VRdGnM.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/19eaixd/create_ai_chatbots_for_websites_in_python/" /><updated>2024-01-24T06:19:29+00:00</updated><published>2024-01-24T06:19:29+00:00</published><title>Create AI Chatbots for Websites in Python - EmbedChain Dash</title></entry><entry><author><name>/u/the_snow_princess</name><uri>https://www.reddit.com/user/the_snow_princess</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dp7e2/awesome_list_of_ai_agents_and_agentbuilding/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/amFtcWVvdHg1N2VjMVsrKOVaRlL6CSzyiPBSRcju48PidCE7SUNuW3Vur3do.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e62e5d6e5fecb8bb694c9fa2a2cb9a94e428c0e4&quot; alt=&quot;Awesome list of AI agents and agent-building frameworks&quot; title=&quot;Awesome list of AI agents and agent-building frameworks&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/the_snow_princess&quot;&gt; /u/the_snow_princess &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/x8gio2o9v6ec1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dp7e2/awesome_list_of_ai_agents_and_agentbuilding/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19dp7e2</id><media:thumbnail url="https://external-preview.redd.it/amFtcWVvdHg1N2VjMVsrKOVaRlL6CSzyiPBSRcju48PidCE7SUNuW3Vur3do.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e62e5d6e5fecb8bb694c9fa2a2cb9a94e428c0e4" /><link href="https://www.reddit.com/r/LangChain/comments/19dp7e2/awesome_list_of_ai_agents_and_agentbuilding/" /><updated>2024-01-23T14:07:31+00:00</updated><published>2024-01-23T14:07:31+00:00</published><title>Awesome list of AI agents and agent-building frameworks</title></entry><entry><author><name>/u/Critical_Pop_2216</name><uri>https://www.reddit.com/user/Critical_Pop_2216</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I am looking for the cheapest way possible to process sensitive documents using Mistral&amp;#39;s 8x7b model. It probably should be self-hosted to ensure the nothing from the document leaks. I&amp;#39;ve found that many APIs are vague about what information is stored. I have a budget around $100 a month to deploy this model, and to lower the cost it would be ok to only deploy it during the work day around ~160 hours a month. Any help would be appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Critical_Pop_2216&quot;&gt; /u/Critical_Pop_2216 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e7zga/processing_sensitive_info_with_mistral_for_cheap/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e7zga/processing_sensitive_info_with_mistral_for_cheap/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19e7zga</id><link href="https://www.reddit.com/r/LangChain/comments/19e7zga/processing_sensitive_info_with_mistral_for_cheap/" /><updated>2024-01-24T03:55:29+00:00</updated><published>2024-01-24T03:55:29+00:00</published><title>Processing sensitive info with Mistral for cheap</title></entry><entry><author><name>/u/fancypigollo</name><uri>https://www.reddit.com/user/fancypigollo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e5ir7/future_of_nlp_and_llms_chris_manning_stanford/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/MEJbeXJfv7_J1XfMubk4lFohPs9G6cM15TgeICfNphk.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6fbdb05b21a1af6537ce1177458bece843b1ae53&quot; alt=&quot;Future of NLP and LLMs - Chris Manning Stanford CoreNLP&quot; title=&quot;Future of NLP and LLMs - Chris Manning Stanford CoreNLP&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/fancypigollo&quot;&gt; /u/fancypigollo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/xk01kx_klOE?si=I5EEkHpuZCFqyQAz&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e5ir7/future_of_nlp_and_llms_chris_manning_stanford/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19e5ir7</id><media:thumbnail url="https://external-preview.redd.it/MEJbeXJfv7_J1XfMubk4lFohPs9G6cM15TgeICfNphk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6fbdb05b21a1af6537ce1177458bece843b1ae53" /><link href="https://www.reddit.com/r/LangChain/comments/19e5ir7/future_of_nlp_and_llms_chris_manning_stanford/" /><updated>2024-01-24T01:54:00+00:00</updated><published>2024-01-24T01:54:00+00:00</published><title>Future of NLP and LLMs - Chris Manning Stanford CoreNLP</title></entry><entry><author><name>/u/rkubc</name><uri>https://www.reddit.com/user/rkubc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello Reddit Community,&lt;/p&gt; &lt;p&gt;I am currently working on a Document Information extractor project using LangChain within a Docker environment. The project involves integrating OpenAI embeddings with FAISS for document search. While everything works fine locally, I run into an SSL certificate verification error when I attempt to run the same code in Docker. The error is as follows:&lt;/p&gt; &lt;p&gt;Error&lt;/p&gt; &lt;pre&gt;&lt;code&gt;MaxRetryError: HTTPSConnectionPool(host=&amp;#39;openai.blob.core.windows.net&amp;#39;, port=443): Max retries exceeded with url: /embeddings/... (Caused by SSLError(SSLCertVerificationError(1, &amp;#39;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)&amp;#39;))) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This error occurs at the following line of code:&lt;/p&gt; &lt;p&gt;Python code&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docsearch = FAISS.from_documents(documents, OpenAIEmbeddings()) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The Docker container seems unable to verify the SSL certificate presented by the OpenAI server. I&amp;#39;ve ensured my internet connection is stable, and there are no issues with SSL certificates when running the code outside of Docker.&lt;/p&gt; &lt;p&gt;Has anyone encountered a similar issue or have any suggestions on what might be going wrong with SSL verification in Docker? What steps can I take to resolve this SSLCertVerificationError within the Docker environment?&lt;/p&gt; &lt;p&gt;Any insights or advice would be greatly appreciated. Thank you for your help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rkubc&quot;&gt; /u/rkubc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e8txp/sslcertverificationerror_in_docker_when/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e8txp/sslcertverificationerror_in_docker_when/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19e8txp</id><link href="https://www.reddit.com/r/LangChain/comments/19e8txp/sslcertverificationerror_in_docker_when/" /><updated>2024-01-24T04:41:10+00:00</updated><published>2024-01-24T04:41:10+00:00</published><title>SSLCertVerificationError in Docker When Integrating OpenAI Embeddings with FAISS for LangChain</title></entry><entry><author><name>/u/DeadPukka</name><uri>https://www.reddit.com/user/DeadPukka</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e86b7/multimodal_content_publishing_apartment/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/ctF-_khju6VxdXy-jf0Z630OrjrTqbnAUeewBRHQozE.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=863a73dc02f9f99c6ac9908cb1a33733503e87c0&quot; alt=&quot;Multimodal Content Publishing: Apartment Inspection Reports with Graphlit and GPT-4 Vision&quot; title=&quot;Multimodal Content Publishing: Apartment Inspection Reports with Graphlit and GPT-4 Vision&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DeadPukka&quot;&gt; /u/DeadPukka &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.graphlit.com/blog/multimodal-content-publishing&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e86b7/multimodal_content_publishing_apartment/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19e86b7</id><media:thumbnail url="https://external-preview.redd.it/ctF-_khju6VxdXy-jf0Z630OrjrTqbnAUeewBRHQozE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=863a73dc02f9f99c6ac9908cb1a33733503e87c0" /><link href="https://www.reddit.com/r/LangChain/comments/19e86b7/multimodal_content_publishing_apartment/" /><updated>2024-01-24T04:05:36+00:00</updated><published>2024-01-24T04:05:36+00:00</published><title>Multimodal Content Publishing: Apartment Inspection Reports with Graphlit and GPT-4 Vision</title></entry><entry><author><name>/u/DBAdvice123</name><uri>https://www.reddit.com/user/DBAdvice123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Saw this webinar that is around building a real-time RAG app on Wikipedia with LangChain.js, Vercel, and Astra DB. Looks interesting and is set to go tomorrow: &lt;a href=&quot;https://dtsx.io/498383Z&quot;&gt;https://dtsx.io/498383Z&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DBAdvice123&quot;&gt; /u/DBAdvice123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dvjtb/wikichat/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dvjtb/wikichat/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dvjtb</id><link href="https://www.reddit.com/r/LangChain/comments/19dvjtb/wikichat/" /><updated>2024-01-23T18:43:33+00:00</updated><published>2024-01-23T18:43:33+00:00</published><title>WikiChat</title></entry><entry><author><name>/u/Revolutionary_Let833</name><uri>https://www.reddit.com/user/Revolutionary_Let833</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m creating a demo for a client - it will involve a web ui, a conversational component and some knowledge retrieval. Any insight into what is the best way to set this up? Whether for an MVP or Production grade software? &lt;/p&gt; &lt;p&gt;I really do like Langchain for its flexibility (no vendor lock-in) but am also open to Assistants API. I&amp;#39;m wondering specifically what is the best &amp;#39;front end&amp;#39; chat interface (Botpress ,Voiceflow, custom JS) and how others are setting up a seamless experience while having chatGPT like power. &lt;/p&gt; &lt;p&gt;Just looking to think about tradeoffs as I plan to design the service.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Revolutionary_Let833&quot;&gt; /u/Revolutionary_Let833 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e0853/creating_demo_conversational_ai_for_client/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19e0853/creating_demo_conversational_ai_for_client/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19e0853</id><link href="https://www.reddit.com/r/LangChain/comments/19e0853/creating_demo_conversational_ai_for_client/" /><updated>2024-01-23T21:56:36+00:00</updated><published>2024-01-23T21:56:36+00:00</published><title>Creating demo conversational AI for Client</title></entry><entry><author><name>/u/Capable_Juice98</name><uri>https://www.reddit.com/user/Capable_Juice98</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Currently, my chatbot can generate answers for current questions using the context (acc to prompt). Now I want to use the conversational part i.e., the chat history part to make it more sensible. How is that possible?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Capable_Juice98&quot;&gt; /u/Capable_Juice98 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dya0n/can_we_use_conversation_history_in_rag_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dya0n/can_we_use_conversation_history_in_rag_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dya0n</id><link href="https://www.reddit.com/r/LangChain/comments/19dya0n/can_we_use_conversation_history_in_rag_chain/" /><updated>2024-01-23T20:36:17+00:00</updated><published>2024-01-23T20:36:17+00:00</published><title>Can we use Conversation History in rag chain?</title></entry><entry><author><name>/u/2BucChuck</name><uri>https://www.reddit.com/user/2BucChuck</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have had to upgrade pinecone-client and dependencies in conjunction with langchain for vectorstores. In doing so ran into a conflict with the imports for pinecone import Pinecone and langchain_community.vectorstores import Pinecone &lt;/p&gt; &lt;p&gt;where the class config appears incompatible now and errors with api_key unexpected on Pinecone client creation unless I remove the langchain import line which of course causes the vectorstore setup to fail. &lt;/p&gt; &lt;p&gt;Running the following versions: Pinecone-client 3.0.1 Langchain 0.1.3 Langchain-community 0.0.14 Langchain-core 0.1.15&lt;/p&gt; &lt;p&gt;Any input greatly appreciated - this update made current chatbot inoperable &lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/2BucChuck&quot;&gt; /u/2BucChuck &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dxzv2/updated_pinecone_client_issue_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dxzv2/updated_pinecone_client_issue_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dxzv2</id><link href="https://www.reddit.com/r/LangChain/comments/19dxzv2/updated_pinecone_client_issue_with_langchain/" /><updated>2024-01-23T20:24:40+00:00</updated><published>2024-01-23T20:24:40+00:00</published><title>Updated Pinecone client issue with Langchain vectorstore</title></entry><entry><author><name>/u/megaeren37</name><uri>https://www.reddit.com/user/megaeren37</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I&amp;#39;m using Elasticsearch to maintain a set of documents. When a user types in a query, I perform a lexical (+semantic) search and output the results. So far I&amp;#39;ve had good success with this approach. However, I now want to perform a post-retrieval re-ranking using Cohere. I&amp;#39;m curious as to how should I paginate the results, or if it&amp;#39;s even possible in the first-place?&lt;br/&gt; Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/megaeren37&quot;&gt; /u/megaeren37 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19du39n/reranking_and_pagination/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19du39n/reranking_and_pagination/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19du39n</id><link href="https://www.reddit.com/r/LangChain/comments/19du39n/reranking_and_pagination/" /><updated>2024-01-23T17:45:09+00:00</updated><published>2024-01-23T17:45:09+00:00</published><title>Re-ranking and pagination</title></entry><entry><author><name>/u/giorgiozer</name><uri>https://www.reddit.com/user/giorgiozer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on embedding some documents (lots of it) and I was debugging my code, running it to check if the AzureOpenEmbeddingAPI works, here&amp;#39;s the code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt; loader = DataFrameLoader(df, page_content_column=&amp;quot;desc_cleaned&amp;quot;) splitter = RecursiveCharacterTextSplitter( chunk_size=1000, chunk_overlap=200 ) splits = splitter.split_documents(loader.load()) vectorstore = Chroma.from_documents(documents=splits, embedding=AzureOpenAIEmbeddings(show_progress_bar=True)) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;So now I got my debugger on, and I&amp;#39;m trying to save the vector store so that I don&amp;#39;t have to sit through the whole thing again, but doing `vectorstore.persist()` does not seem to work, and it does not throw an error either.&lt;/p&gt; &lt;p&gt;Do you guys have an idea on how I could save the store locally?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/giorgiozer&quot;&gt; /u/giorgiozer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dsmf1/help_cant_save_the_chromadb_vector_store/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dsmf1/help_cant_save_the_chromadb_vector_store/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dsmf1</id><link href="https://www.reddit.com/r/LangChain/comments/19dsmf1/help_cant_save_the_chromadb_vector_store/" /><updated>2024-01-23T16:40:28+00:00</updated><published>2024-01-23T16:40:28+00:00</published><title>[HELP] Can't save the chromadb vector store</title></entry><entry><author><name>/u/Money_Mycologist4939</name><uri>https://www.reddit.com/user/Money_Mycologist4939</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How can I build a custom retrieval chatbot chain using the LCEL and not the available default langchain chains?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Money_Mycologist4939&quot;&gt; /u/Money_Mycologist4939 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19drvmj/memory_handling_in_lcel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19drvmj/memory_handling_in_lcel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19drvmj</id><link href="https://www.reddit.com/r/LangChain/comments/19drvmj/memory_handling_in_lcel/" /><updated>2024-01-23T16:09:22+00:00</updated><published>2024-01-23T16:09:22+00:00</published><title>Memory handling in LCEL.</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, &lt;/p&gt; &lt;p&gt;I wanted to find a more clean way to load my PDFs than PyPDF loader and came across &lt;a href=&quot;https://Unstructured.io&quot;&gt;Unstructured.io&lt;/a&gt; wit Langchain. I am loading my PDF like this: &lt;/p&gt; &lt;p&gt;&lt;code&gt;# UnstructuredIO Test&lt;/code&gt;&lt;br/&gt; &lt;code&gt;from langchain_community.document_loaders import UnstructuredFileLoader&lt;/code&gt;&lt;br/&gt; &lt;code&gt;loader = UnstructuredFileLoader(&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;my.pdf&amp;quot;, mode=&amp;quot;elements&amp;quot;&lt;/code&gt;&lt;br/&gt; &lt;code&gt;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;docs = loader.load()&lt;/code&gt;&lt;br/&gt; &lt;code&gt;docs[:5]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Now I figured out that this loads every line of the PDF into a list entry (PDF with 22 pages ended up with 580 entries). But how can I extract the text of whole pages to be able to further use it for RAG?&lt;/p&gt; &lt;p&gt;With only reading on one line each, I think context gets lost.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dk7mc/langchain_unstructuredfileloader_load_pdfs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dk7mc/langchain_unstructuredfileloader_load_pdfs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dk7mc</id><link href="https://www.reddit.com/r/LangChain/comments/19dk7mc/langchain_unstructuredfileloader_load_pdfs/" /><updated>2024-01-23T09:00:42+00:00</updated><published>2024-01-23T09:00:42+00:00</published><title>Langchain UnstructuredFileLoader: Load PDFs</title></entry><entry><author><name>/u/Aggressive_Tea9664</name><uri>https://www.reddit.com/user/Aggressive_Tea9664</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello all, May I know what is the metric used to compute similarity for QDrant Retriever, with a search_type=similarity ? Would it be cosine similarity? L2?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Aggressive_Tea9664&quot;&gt; /u/Aggressive_Tea9664 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dmjn0/qdrant_similarity_search_metric/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dmjn0/qdrant_similarity_search_metric/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dmjn0</id><link href="https://www.reddit.com/r/LangChain/comments/19dmjn0/qdrant_similarity_search_metric/" /><updated>2024-01-23T11:41:46+00:00</updated><published>2024-01-23T11:41:46+00:00</published><title>Qdrant Similarity Search Metric</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I understand that Chunking for RAG is very important for longer texts. But I was wondering why it is common that PDFs also get chunked. &lt;/p&gt; &lt;p&gt;For example, many PDF pages in my use case have less than 2000 characters. When reading in the PDF, the context over pages gets lost anyways, because PyPDFLoader for example stores every page separately. As 2000 chars isn&amp;#39;t that much and I want to get as many context as possible (so maximum 1 page), why should I consider chunking?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dip1l/rag_with_pdfs_why_chunking_and_not_using_whole/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19dip1l/rag_with_pdfs_why_chunking_and_not_using_whole/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19dip1l</id><link href="https://www.reddit.com/r/LangChain/comments/19dip1l/rag_with_pdfs_why_chunking_and_not_using_whole/" /><updated>2024-01-23T07:11:32+00:00</updated><published>2024-01-23T07:11:32+00:00</published><title>RAG with PDFs: Why chunking and not using whole page</title></entry></feed>