<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-04T22:05:20+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for some tried and tested ways to measure and improve my RAGs retrieval strategy.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck3k84</id><link href="https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/" /><updated>2024-05-04T15:57:55+00:00</updated><published>2024-05-04T15:57:55+00:00</published><title>What are some ways to test and improve my RAGs retrieval strategy?</title></entry><entry><author><name>/u/Legionnairesgeek</name><uri>https://www.reddit.com/user/Legionnairesgeek</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am new to LangChain and I am developing a application that uses a Pandas Dataframe as document original a Microsoft Excel sheet. I need it answer questions based on it. &lt;/p&gt; &lt;p&gt;How should I proceed? Should I ditch the DataFrame approach and interface it directly ?&lt;/p&gt; &lt;p&gt;How should I use approach it?&lt;/p&gt; &lt;p&gt;How should I add history as i need to have GUI.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Legionnairesgeek&quot;&gt; /u/Legionnairesgeek &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck54cw/how_should_i_develop_a_rag_chatbot_that_uses_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck54cw/how_should_i_develop_a_rag_chatbot_that_uses_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck54cw</id><link href="https://www.reddit.com/r/LangChain/comments/1ck54cw/how_should_i_develop_a_rag_chatbot_that_uses_a/" /><updated>2024-05-04T17:05:47+00:00</updated><published>2024-05-04T17:05:47+00:00</published><title>How should I develop a RAG ChatBot that uses a Pandas Dataframe as a source?</title></entry><entry><author><name>/u/ToeIntelligent4472</name><uri>https://www.reddit.com/user/ToeIntelligent4472</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Not looking to build my own system per se, just looking for something open source (doesn&amp;#39;t have to use langchain) that can use tools (code interp, web browsing, make google drive files, sending emails, replying to github issues) and perform RAG across all my google drive documents, emails, and code.&lt;/p&gt; &lt;p&gt;Apologies if this is too ambitious or too much to ask for with the current state of things.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ToeIntelligent4472&quot;&gt; /u/ToeIntelligent4472 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckbmf0/is_there_any_agent_that_can_do_rag_across_my/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckbmf0/is_there_any_agent_that_can_do_rag_across_my/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckbmf0</id><link href="https://www.reddit.com/r/LangChain/comments/1ckbmf0/is_there_any_agent_that_can_do_rag_across_my/" /><updated>2024-05-04T21:56:45+00:00</updated><published>2024-05-04T21:56:45+00:00</published><title>Is there any agent that can do RAG across my GDrive, Gmail, &amp; GitHub?</title></entry><entry><author><name>/u/Glittering_Class_333</name><uri>https://www.reddit.com/user/Glittering_Class_333</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am newbie interested in training LLMs on csv dataset that contains text data (few sentences about a product) and numeric data(its ratings). I have around 200k rows and would to like to train an LLM but I am unable to do it. Can anyone here guide me or share any resource which could help me.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering_Class_333&quot;&gt; /u/Glittering_Class_333 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckapb8/how_to_train_an_llm_with_data_that_contains_text/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckapb8/how_to_train_an_llm_with_data_that_contains_text/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckapb8</id><link href="https://www.reddit.com/r/LangChain/comments/1ckapb8/how_to_train_an_llm_with_data_that_contains_text/" /><updated>2024-05-04T21:14:15+00:00</updated><published>2024-05-04T21:14:15+00:00</published><title>How to train an LLM with data that contains text and numeric modality</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for some tried and tested ways to measure and improve my RAGs retrieval strategy.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck3k49</id><link href="https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/" /><updated>2024-05-04T15:57:46+00:00</updated><published>2024-05-04T15:57:46+00:00</published><title>What are some ways to test and improve my RAGs retrieval strategy?</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone used PGVector with HuggingFaceEmbeddings? I&amp;#39;m encountering an error message: &amp;#39;psycopg2.errors.DataException: different vector dimensions 384 and 1536&amp;#39;.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck8mj0/integrating_pgvector_with_hugging_face_embeddings/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck8mj0/integrating_pgvector_with_hugging_face_embeddings/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck8mj0</id><link href="https://www.reddit.com/r/LangChain/comments/1ck8mj0/integrating_pgvector_with_hugging_face_embeddings/" /><updated>2024-05-04T19:40:59+00:00</updated><published>2024-05-04T19:40:59+00:00</published><title>Integrating PGVector with Hugging Face Embeddings: Addressing Dimension Mismatch Errors</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjyiww/generate_powerpoints_using_llama3_a_first_step_in/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/kTSFHuwiwJ0qxPFejuEtCfKnLN42fnt_kIVuZy8HWNM.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b519accc5730b7cdf08908f9c12395c5a9410f79&quot; alt=&quot;Generate PowerPoints using Llama-3 — A first step in automating slide decks&quot; title=&quot;Generate PowerPoints using Llama-3 — A first step in automating slide decks&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://medium.com/firebird-technologies/generate-powerpoints-using-llama-3-a-first-step-in-automating-slide-decks-536f5fcb6e0e&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjyiww/generate_powerpoints_using_llama3_a_first_step_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cjyiww</id><media:thumbnail url="https://external-preview.redd.it/kTSFHuwiwJ0qxPFejuEtCfKnLN42fnt_kIVuZy8HWNM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b519accc5730b7cdf08908f9c12395c5a9410f79" /><link href="https://www.reddit.com/r/LangChain/comments/1cjyiww/generate_powerpoints_using_llama3_a_first_step_in/" /><updated>2024-05-04T11:52:17+00:00</updated><published>2024-05-04T11:52:17+00:00</published><title>Generate PowerPoints using Llama-3 — A first step in automating slide decks</title></entry><entry><author><name>/u/AI_technologies</name><uri>https://www.reddit.com/user/AI_technologies</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt; let’s outline &lt;em&gt;what&lt;/em&gt; VAs even do. As a creator yourself, you balance big projects with smaller, repetitive tasks like answering emails, scheduling meetings &amp;amp; writing smaller pieces of content.&lt;/p&gt; &lt;p&gt;And that’s where your partner in time, your VA comes in — they handle all of the tedious tasks on your behalf, giving you the freedom to concentrate fully on the important things in your life &amp;amp; business.&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Recent stats show Virtual assistants save companies up to 78% in operating costs per year, and the VA market is projected to grow 22.3% annually, reaching $8.6B by 2028 — this is definitely a sector to pay close attention to.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;As the demand for efficiency in our workflows increases, it&amp;#39;s worth knowing the potential of AI assistants, because why wouldn’t you want to get more time back? Here are the core reasons why AI assistants are better than traditional VAs:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Cost-Effectiveness&lt;/strong&gt; – traditional VAs are invaluable but come with recurring costs — salaries, benefits, and more. AI assistants, on the other hand, involve a one-time setup fee and minimal ongoing costs.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;24/7 Availability&lt;/strong&gt; – your business needs don’t stop at 5 PM, and neither does an AI assistant. Unlike human VAs who clock out, AI can work round-the-clock, able to complete any given task at any time.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Consistency &amp;amp; Accuracy&lt;/strong&gt; – AI minimizes human errors in data entry, scheduling, and customer communication, maintaining high consistency in performance.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;blockquote&gt; &lt;p&gt;This reliability is key in managing operations that demand precision, like tailored content creation or responding to an important business email, for example.&lt;/p&gt; &lt;/blockquote&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Adaptability&lt;/strong&gt; – training a new assistant takes time and resources. AI assistants, however, can be quickly trained to manage new tasks, adapting &amp;amp; evolving alongside your business.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Accessibility&lt;/strong&gt; – with numerous AI tools available, starting is as easy as signing up and setting up — no lengthy recruitment or training is required (if you aren’t creating your very own AI assistant, in which case it’s a tad more complex). &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;However, we must mention the main negative of artificial intelligence – it lacks the human aspect, and therefore AI Assistants could &lt;strong&gt;&lt;em&gt;never&lt;/em&gt;&lt;/strong&gt; replace real VAs.&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;The human element is crucial, as it brings empathy, creativity, and intuitive problem-solving to tasks that AI simply can&amp;#39;t replicate, and the best way to get the best of both worlds is to integrate AI tools in your virtual assistant’s workflow — we’ll show you how to turn your VA into a cyborg very soon!&lt;/p&gt; &lt;/blockquote&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AI_technologies&quot;&gt; /u/AI_technologies &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck67xs/why_ai_assistants_can_be_better_than_human_vas/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck67xs/why_ai_assistants_can_be_better_than_human_vas/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck67xs</id><link href="https://www.reddit.com/r/LangChain/comments/1ck67xs/why_ai_assistants_can_be_better_than_human_vas/" /><updated>2024-05-04T17:55:12+00:00</updated><published>2024-05-04T17:55:12+00:00</published><title>Why AI Assistants Can Be Better Than Human VAs</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So far, I&amp;#39;ve been using the OpenAI API to build a RAG application with Langchain. Now, I&amp;#39;m exploring LLama 3/LLama-2 with GPU support. Can anyone suggest a tutorial for this with Langchain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck4sy9/how_to_use_llama_3llama2_model_on_nvidia_gpu/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck4sy9/how_to_use_llama_3llama2_model_on_nvidia_gpu/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck4sy9</id><link href="https://www.reddit.com/r/LangChain/comments/1ck4sy9/how_to_use_llama_3llama2_model_on_nvidia_gpu/" /><updated>2024-05-04T16:51:45+00:00</updated><published>2024-05-04T16:51:45+00:00</published><title>How to use LLama -3/LLama-2 Model on Nvidia GPU?</title></entry><entry><author><name>/u/runrabbit007</name><uri>https://www.reddit.com/user/runrabbit007</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let&amp;#39;s say we have two chain , like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;prompt1 = &amp;quot;some prompts here 1&amp;quot; prompt2 = &amp;quot;some prompts here 2&amp;quot; chain1 = prompt1 | model chain2 = prompt2 | model combine_chain = chain1 | chain2 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;My question is how to add memory to combine_chain with RunnableWithMessageHistory? &lt;/p&gt; &lt;p&gt;The official document just show how to add it in single chain . I tried that way for combine_chain, but it doesn&amp;#39;t work. Because prompt2 always need to pass the parameter of &amp;quot;history&amp;quot; which I don&amp;#39;t how to pass it. （suppose we have history_messages_key=&amp;quot;history&amp;quot;).&lt;/p&gt; &lt;p&gt;I&amp;#39;m stuck on this problem. I will be very thankful to anyone who can help on it. &lt;/p&gt; &lt;p&gt;For reference here, the office document show how to add memory to single chain with RunnableWithMessageHistory: &lt;a href=&quot;https://python.langchain.com/docs/expression_language/how_to/message_history/&quot;&gt;https://python.langchain.com/docs/expression_language/how_to/message_history/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/runrabbit007&quot;&gt; /u/runrabbit007 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck2zy8/how_to_add_memory_to_multi_chain_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck2zy8/how_to_add_memory_to_multi_chain_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck2zy8</id><link href="https://www.reddit.com/r/LangChain/comments/1ck2zy8/how_to_add_memory_to_multi_chain_with/" /><updated>2024-05-04T15:32:39+00:00</updated><published>2024-05-04T15:32:39+00:00</published><title>How to add memory to multi- chain with RunnableWithMessageHistory?</title></entry><entry><author><name>/u/Tiny-Ad-5694</name><uri>https://www.reddit.com/user/Tiny-Ad-5694</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve built a code search tool for anyone using LangChain to search its source code and find LangChain actual use case code examples. This isn&amp;#39;t an AI chat bot;&lt;br/&gt; I built this because when I first used LangChain, I constantly needed to search for and utilize sample code blocks and delve into the LangChain source code for insights into my project&lt;/p&gt; &lt;p&gt;Currently it can only search LangChain related content. Let me know your thoughts&lt;br/&gt; Here is link: &lt;a href=&quot;http://solidsearchportal.azurewebsites.net&quot;&gt;solidsearchportal.azurewebsites.net&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Tiny-Ad-5694&quot;&gt; /u/Tiny-Ad-5694 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjncxr/a_code_search_tool_for_langchain_developer/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjncxr/a_code_search_tool_for_langchain_developer/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjncxr</id><link href="https://www.reddit.com/r/LangChain/comments/1cjncxr/a_code_search_tool_for_langchain_developer/" /><updated>2024-05-04T00:19:34+00:00</updated><published>2024-05-04T00:19:34+00:00</published><title>A code search tool for LangChain developer</title></entry><entry><author><name>/u/furyacer</name><uri>https://www.reddit.com/user/furyacer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A lot of vector dbs are available for RAG and LLM based projects. How will you choose the best one for your use-case? Is there a set of criteria to follow for choosing a specific vector db for your project? Lmk what you think&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/furyacer&quot;&gt; /u/furyacer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjz0lt/vector_dbs_to_use_for_specific_usecase/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjz0lt/vector_dbs_to_use_for_specific_usecase/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjz0lt</id><link href="https://www.reddit.com/r/LangChain/comments/1cjz0lt/vector_dbs_to_use_for_specific_usecase/" /><updated>2024-05-04T12:19:27+00:00</updated><published>2024-05-04T12:19:27+00:00</published><title>Vector dbs to use for specific use-case</title></entry><entry><author><name>/u/Calm_Pea_2428</name><uri>https://www.reddit.com/user/Calm_Pea_2428</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In version 1.5.0 of MyScale, we introduced an upgraded full-text search feature powered by &lt;a href=&quot;https://github.com/quickwit-oss/tantivy&quot;&gt;Tantivy&lt;/a&gt;. Tantivy have lower latency rate and it&amp;#39;s written in Rust. &lt;/p&gt; &lt;p&gt;In the latest update, MyScaleDB now supports:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Supports full-text search&lt;/li&gt; &lt;li&gt;Supports fuzzy and wildcard searches along with rich tokenizers&lt;/li&gt; &lt;li&gt;Utilizes BM25 for relevance scoring similar to Elasticsearch&lt;/li&gt; &lt;li&gt;Query times over 5M rows are 300x faster than ClickHouse&amp;#39;s built-in inverted index&lt;/li&gt; &lt;li&gt;Real-time searching without manual reindexing&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For more detailed explanation, you can read this blog: &lt;a href=&quot;https://myscale.com/blog/text-search-and-hybrid-search-in-myscale/&quot;&gt;Introducing MyScale&amp;#39;s Powerful Full-Text and Hybrid Search Capabilities&lt;/a&gt;&lt;/p&gt; &lt;p&gt;or take a look at these documents: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://myscale.com/docs/en/text-search/&quot;&gt;Full-Text Search in MyScale&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://myscale.com/docs/en/hybrid-search/&quot;&gt;Hybrid Search in MyScale&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm_Pea_2428&quot;&gt; /u/Calm_Pea_2428 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjy7f5/myscaledb_now_supports_fulltext_and_hybrid_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjy7f5/myscaledb_now_supports_fulltext_and_hybrid_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjy7f5</id><link href="https://www.reddit.com/r/LangChain/comments/1cjy7f5/myscaledb_now_supports_fulltext_and_hybrid_search/" /><updated>2024-05-04T11:33:25+00:00</updated><published>2024-05-04T11:33:25+00:00</published><title>MyScaleDB now supports Full-Text and Hybrid Search</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1cjqb4f/llms_cant_play_tictactoe_why_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjqbn4/llms_cant_play_tictactoe_why_explained_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjqbn4</id><link href="https://www.reddit.com/r/LangChain/comments/1cjqbn4/llms_cant_play_tictactoe_why_explained_langgraph/" /><updated>2024-05-04T02:57:15+00:00</updated><published>2024-05-04T02:57:15+00:00</published><title>LLMs can't play tic-tac-toe. Why? Explained (LangGraph experiment)</title></entry><entry><author><name>/u/UpvoteBeast</name><uri>https://www.reddit.com/user/UpvoteBeast</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjr0xy/how_rag_architecture_overcomes_llm_limitations/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/dQl7-TauXBI9Vl5SEA2wORLVhC6T_s1Q4Vhw-WmKfC4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2c756b18e6de96109083b4e4ceab0f2aff65b413&quot; alt=&quot;How RAG Architecture Overcomes LLM Limitations&quot; title=&quot;How RAG Architecture Overcomes LLM Limitations&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpvoteBeast&quot;&gt; /u/UpvoteBeast &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://dly.to/CkHPBlwHuPo&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjr0xy/how_rag_architecture_overcomes_llm_limitations/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cjr0xy</id><media:thumbnail url="https://external-preview.redd.it/dQl7-TauXBI9Vl5SEA2wORLVhC6T_s1Q4Vhw-WmKfC4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c756b18e6de96109083b4e4ceab0f2aff65b413" /><link href="https://www.reddit.com/r/LangChain/comments/1cjr0xy/how_rag_architecture_overcomes_llm_limitations/" /><updated>2024-05-04T03:36:38+00:00</updated><published>2024-05-04T03:36:38+00:00</published><title>How RAG Architecture Overcomes LLM Limitations</title></entry><entry><author><name>/u/JimZerChapirov</name><uri>https://www.reddit.com/user/JimZerChapirov</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj7j7y/using_lowerlevel_tools_makes_better_genai_apps_an/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/uWX5oFoKEnjBx53i5EEmGlw1iSAsf2On7x5mBJCG3ws.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2eb07213afc1aa854d453368c168981164872406&quot; alt=&quot;Using lower-level tools makes better GenAI apps: an alternative to the LangChain way&quot; title=&quot;Using lower-level tools makes better GenAI apps: an alternative to the LangChain way&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/JimZerChapirov&quot;&gt; /u/JimZerChapirov &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtu.be/VSfehUJUWQY&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj7j7y/using_lowerlevel_tools_makes_better_genai_apps_an/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cj7j7y</id><media:thumbnail url="https://external-preview.redd.it/uWX5oFoKEnjBx53i5EEmGlw1iSAsf2On7x5mBJCG3ws.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2eb07213afc1aa854d453368c168981164872406" /><link href="https://www.reddit.com/r/LangChain/comments/1cj7j7y/using_lowerlevel_tools_makes_better_genai_apps_an/" /><updated>2024-05-03T12:32:16+00:00</updated><published>2024-05-03T12:32:16+00:00</published><title>Using lower-level tools makes better GenAI apps: an alternative to the LangChain way</title></entry><entry><author><name>/u/atomacht</name><uri>https://www.reddit.com/user/atomacht</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am working with a Dev on a project and he explained to me that no all OpenAI Chat Models are supported by Langchain, especially not the newer ones (e.g. GPT4-Turbo) when they come out.&lt;/p&gt; &lt;p&gt;I was under the impression that Langchain works with all Chat Models that OpenAI offers via the API.&lt;/p&gt; &lt;p&gt;Can&amp;#39;t find this info in the docs. &lt;/p&gt; &lt;p&gt;Any input from the community is highly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/atomacht&quot;&gt; /u/atomacht &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjt6lt/openai_chat_models/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjt6lt/openai_chat_models/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjt6lt</id><link href="https://www.reddit.com/r/LangChain/comments/1cjt6lt/openai_chat_models/" /><updated>2024-05-04T05:45:02+00:00</updated><published>2024-05-04T05:45:02+00:00</published><title>OpenAI Chat Models</title></entry><entry><author><name>/u/hasteiswaste</name><uri>https://www.reddit.com/user/hasteiswaste</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m more or less completely new to LangChain, but I envision it as the best tool to solve the following task. What I&amp;#39;m trying to create is a script that takes two PDF documents, where one is the application criteria and the other is the application itself, and compares the content to determine what is omitted in one document and addressed in the other. It concerns a fairly extensive application procedure where it would be very useful to have autogenerated insights into what the application lacks.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve attempted to modify the script here with various prompts (&lt;a href=&quot;https://python.langchain.com/docs/integrations/toolkits/document%5C_comparison%5C_toolkit/&quot;&gt;https://python.langchain.com/docs/integrations/toolkits/document\_comparison\_toolkit/&lt;/a&gt;), and while I get somewhat useful responses, none of them manage to list the deficiencies in the application comprehensively. The document outlining the application criteria is structured with points, whereas the application document may have responses that overlap and are arranged in a way that makes it difficult to compare point by point.&lt;/p&gt; &lt;p&gt;Suggestions for approach or how to tackle the challenge would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hasteiswaste&quot;&gt; /u/hasteiswaste &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjkchx/comparing_two_documents_and_finding_the_diff/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjkchx/comparing_two_documents_and_finding_the_diff/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjkchx</id><link href="https://www.reddit.com/r/LangChain/comments/1cjkchx/comparing_two_documents_and_finding_the_diff/" /><updated>2024-05-03T21:57:44+00:00</updated><published>2024-05-03T21:57:44+00:00</published><title>Comparing two documents and finding the diff</title></entry><entry><author><name>/u/Calm-Number5851</name><uri>https://www.reddit.com/user/Calm-Number5851</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m sad to admit it, but the facts answer in the negative: AI devices are useless and unnecessary. At least not right now. I love unusual gadgets, actively follow what&amp;#39;s happening in the AR and VR world, and love testing new form factors. But the problem with AI devices is that our smartphones are very good, and it&amp;#39;s too hard to compete with them for a place in our pockets.&lt;/p&gt; &lt;p&gt;I see it this way: developers should think about how to create a gadget that goes beyond the devices we&amp;#39;re familiar with. Something similar is being done by Apple with the Vision Pro, as well as companies developing AR glasses and lenses. With these devices, we (well, sometimes) see clear advantages over smartphones and understand why we should buy them.&lt;/p&gt; &lt;blockquote&gt; &lt;/blockquote&gt; &lt;p&gt;Let&amp;#39;s wait a bit. Sooner or later, we&amp;#39;ll surely see someone who will change the way we think about AI devices. Again, I just hope so.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm-Number5851&quot;&gt; /u/Calm-Number5851 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjf7q8/ai_devices_will_never_be_useful/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjf7q8/ai_devices_will_never_be_useful/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjf7q8</id><link href="https://www.reddit.com/r/LangChain/comments/1cjf7q8/ai_devices_will_never_be_useful/" /><updated>2024-05-03T18:03:56+00:00</updated><published>2024-05-03T18:03:56+00:00</published><title>AI Devices Will Never be Useful?</title></entry><entry><author><name>/u/Crafty-Investment417</name><uri>https://www.reddit.com/user/Crafty-Investment417</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjszsn/getting_import_error_in_importing_llamaindex/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/9e6q5kg3jcyc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=95f40a7897e9b7696519b615cc6393b2439f6d11&quot; alt=&quot;Getting import error in importing llamaindex vector stores &quot; title=&quot;Getting import error in importing llamaindex vector stores &quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using jupyter notebook anaconda windows python. I am trying to import qdrant vector store and ollama embeddings after installing them in virtual environment but I am getting module not found error. Similar error with other llm embeddings and llms and vector stores. How to resolve this. I am using import functions mentioned in llama index documentation.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Crafty-Investment417&quot;&gt; /u/Crafty-Investment417 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/9e6q5kg3jcyc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjszsn/getting_import_error_in_importing_llamaindex/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cjszsn</id><media:thumbnail url="https://preview.redd.it/9e6q5kg3jcyc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=95f40a7897e9b7696519b615cc6393b2439f6d11" /><link href="https://www.reddit.com/r/LangChain/comments/1cjszsn/getting_import_error_in_importing_llamaindex/" /><updated>2024-05-04T05:32:51+00:00</updated><published>2024-05-04T05:32:51+00:00</published><title>Getting import error in importing llamaindex vector stores</title></entry><entry><author><name>/u/Desperate_Fact_5574</name><uri>https://www.reddit.com/user/Desperate_Fact_5574</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, I am kind of new to the concept of LLM and RAG. I want to make a program that use stored instructions in a document. This will be the data the RAG will use as context for the LLM. What I have read about until now, is that you can do this and then the user can pass a query about the stored document. However, I want to be able to send the text from my documents into the RAG and then let the RAG respond to if the document is correcg based on the instructions as mentioned. &lt;/p&gt; &lt;p&gt;What is the best approach here? Do I just pass the whole text from the document as a query and ask the RAG to decide if the text is correct based on the context?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Desperate_Fact_5574&quot;&gt; /u/Desperate_Fact_5574 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjlflw/passing_text_from_a_document_to_a_rag_to_validate/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjlflw/passing_text_from_a_document_to_a_rag_to_validate/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjlflw</id><link href="https://www.reddit.com/r/LangChain/comments/1cjlflw/passing_text_from_a_document_to_a_rag_to_validate/" /><updated>2024-05-03T22:46:23+00:00</updated><published>2024-05-03T22:46:23+00:00</published><title>Passing text from a document to a RAG to validate document</title></entry><entry><author><name>/u/Designer_Athlete7286</name><uri>https://www.reddit.com/user/Designer_Athlete7286</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve tried to look for this in docs but couldn&amp;#39;t find any examples on how to do so. Is this possible in the first place? &lt;/p&gt; &lt;p&gt;My plan if to deploy a chatbot with tool access including a rag using LangServe. Do I need to make my cahtbot into a runnable chain using LCEL?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Designer_Athlete7286&quot;&gt; /u/Designer_Athlete7286 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjgce9/openai_tool_calling_agent_as_an_lcel_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjgce9/openai_tool_calling_agent_as_an_lcel_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjgce9</id><link href="https://www.reddit.com/r/LangChain/comments/1cjgce9/openai_tool_calling_agent_as_an_lcel_chain/" /><updated>2024-05-03T18:52:14+00:00</updated><published>2024-05-03T18:52:14+00:00</published><title>OpenAI Tool Calling Agent as an LCEL chain?</title></entry><entry><author><name>/u/Only-Requirement619</name><uri>https://www.reddit.com/user/Only-Requirement619</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I came across a gpt in OpenAI called stoic gpt. It’s based off the words of Marcus Ariellius, Seneca and a couple other prominent legends. I wanted to create a similar gpt with the words of some prominent athletes. I know the simple way would be to collect as much data and embed it into a custom gpt, but is there a better way to capture all data including from podcasts, yt etc &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Only-Requirement619&quot;&gt; /u/Only-Requirement619 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjfrvr/embedding_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjfrvr/embedding_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjfrvr</id><link href="https://www.reddit.com/r/LangChain/comments/1cjfrvr/embedding_data/" /><updated>2024-05-03T18:27:49+00:00</updated><published>2024-05-03T18:27:49+00:00</published><title>EMBEDDING data</title></entry><entry><author><name>/u/wiseduckling</name><uri>https://www.reddit.com/user/wiseduckling</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So I have a RAG app that&amp;#39;s working but I need to optimize it. &lt;/p&gt; &lt;p&gt;Right now I take a doc --&amp;gt; chunk it --&amp;gt; summarize chunks --&amp;gt; build page summaries and doc summarize from those chunks --&amp;gt; vectorize everything. &lt;/p&gt; &lt;p&gt;The docs are stored in an S3 bucket and the chunks + their vectors in redis. &lt;/p&gt; &lt;p&gt;I need to reduce the content I m storing in redis as it won&amp;#39;t scale in terms of cost so my plan is to only store the summaries and their vectors for each chunk, page, doc. &lt;/p&gt; &lt;p&gt;My question is then, after identifying the where the relevant content is, where should I pull that content from. Are you guys pulling it directly from PDF docs or storing it in a seperate SQL db somewhere else? I think a db will ultimately be less resource intensive but I m not sure thats the best approach. &lt;/p&gt; &lt;p&gt;db process would be:&lt;br/&gt; Identify where relevant content is through vector search on redis.&lt;br/&gt; Pull rows in the db referenced by redis with the content. &lt;/p&gt; &lt;p&gt;accessing document directly:&lt;/p&gt; &lt;p&gt;Identify relevant content (doc, page, paragraphs)&lt;br/&gt; Get pdf from s3, pull relevant content&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/wiseduckling&quot;&gt; /u/wiseduckling &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj5fbp/where_do_you_pull_your_content_from_for_feeding/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj5fbp/where_do_you_pull_your_content_from_for_feeding/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cj5fbp</id><link href="https://www.reddit.com/r/LangChain/comments/1cj5fbp/where_do_you_pull_your_content_from_for_feeding/" /><updated>2024-05-03T10:35:57+00:00</updated><published>2024-05-03T10:35:57+00:00</published><title>Where do you pull your content from for feeding context in your RAG app?</title></entry><entry><author><name>/u/the-room-is-on-fire</name><uri>https://www.reddit.com/user/the-room-is-on-fire</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’m interested in building a RAG tool for internal company documents, and I intend on using a locally hosted LLM using ollama or LMstudio. From what I can tell, there wouldn’t be any data privacy concerns so long as I’m not using an API key for some LLM, but I’m not completely sure. Would my company’s data be secure?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/the-room-is-on-fire&quot;&gt; /u/the-room-is-on-fire &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj9nbx/langchain_for_data_privacy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cj9nbx/langchain_for_data_privacy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cj9nbx</id><link href="https://www.reddit.com/r/LangChain/comments/1cj9nbx/langchain_for_data_privacy/" /><updated>2024-05-03T14:10:49+00:00</updated><published>2024-05-03T14:10:49+00:00</published><title>Langchain for data privacy?</title></entry></feed>