<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-02-08T22:27:17+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Travolta1984</name><uri>https://www.reddit.com/user/Travolta1984</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a consensus in terms of the quality of the AI response, between keeping the chat history in the memory as is, or summarizing it using ConversationSummaryMemory? &lt;/p&gt; &lt;p&gt;I understand that summarizing past messages will lead to fewer tokens being used, but does it also lead to a drop in the quality of the AI answer in an RAG model, considering that the summary may not necessarily include all the facts of the past messages? &lt;/p&gt; &lt;p&gt;Common sense would say that yes, that may lead to worse answers, but wondering how the community feels about this topic.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Travolta1984&quot;&gt; /u/Travolta1984 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1am5nsd/summarizing_past_messages_in_an_rag_conversation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1am5nsd/summarizing_past_messages_in_an_rag_conversation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1am5nsd</id><link href="https://www.reddit.com/r/LangChain/comments/1am5nsd/summarizing_past_messages_in_an_rag_conversation/" /><updated>2024-02-08T20:40:41+00:00</updated><published>2024-02-08T20:40:41+00:00</published><title>Summarizing past messages in an RAG conversation - is it always recommended?</title></entry><entry><author><name>/u/_dakshesh</name><uri>https://www.reddit.com/user/_dakshesh</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I recently completed a project that involved using the FAISS vector database. I utilized lang-chain for storing embeddings in the vector database, which were generated from PDF files. For the purpose of the project, it was sufficient to store all the information without separating the storage according to users. &lt;/p&gt; &lt;p&gt;What I want to know is - when a user uploads a PDF, can I create an embedding for it and store it in the vector database, allowing me to query the embeddings for &lt;strong&gt;that&lt;/strong&gt; user later on. This ensures that the generated output is accurate and privacy is also maintained. I was wondering, can I do that? If so, how?&lt;/p&gt; &lt;p&gt;I really appreciate any help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/_dakshesh&quot;&gt; /u/_dakshesh &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alq3to/help_needed_with_vector_database/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alq3to/help_needed_with_vector_database/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alq3to</id><link href="https://www.reddit.com/r/LangChain/comments/1alq3to/help_needed_with_vector_database/" /><updated>2024-02-08T07:20:15+00:00</updated><published>2024-02-08T07:20:15+00:00</published><title>Help needed with vector database</title></entry><entry><author><name>/u/Mr_Nrj</name><uri>https://www.reddit.com/user/Mr_Nrj</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am creating a RAG program where I used 20 pdfs which contains lease agreement of different tenants.&lt;/p&gt; &lt;p&gt;I am using langchain framework to work with FAISS and openAI Embeddings.&lt;/p&gt; &lt;p&gt;I am using &lt;code&gt;text-embedding-ada-002&lt;/code&gt; model because I think langchain currently does not support v3 embedding models. I get this error while using v3 models: &lt;code&gt;model not found. Using cl100k_base encoding.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Here&amp;#39;s my process:&lt;/p&gt; &lt;p&gt;- I read the directory containing pdfs (Some pdf are image based, some are textual).&lt;/p&gt; &lt;p&gt;- I use &lt;code&gt;from unstructured.partition.pdf import partition_pdf&lt;/code&gt; to extract data based on title. Below id code block:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;raw_pdf_elements = partition_pdf(filename=pdf_path, # Unstructured first finds embedded image blocks extract_images_in_pdf=True, #Use layout model (YOLOX) to get bounding boxes (for tables) and find titles # Titles are any sub-section of the document infer_table_structure=True, # Post processing to aggregate text once we have the title chunking_strategy=&amp;quot;by_title&amp;quot;, # Chunking params to aggregate text blocks # Attempt to create a new chunk 3800 chars # Attempt to keep chunks &amp;gt; 2000 chars max_characters=4000, new_after_n_chars=3800, combine_text_under_n_chars=2000, image_output_dir_path=path ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;- Then I create documents from the extracted text along with the tenant name in metadata (To get information from specific tenant&amp;#39;s lease agreement when I mention it&amp;#39;s name in the question). 1 pdf at a time.&lt;/p&gt; &lt;p&gt;- After I get document chunks from all pdfs, I create list of all the chunks.&lt;/p&gt; &lt;p&gt;- I create FAISS index for that data.&lt;/p&gt; &lt;p&gt;- Then I perform QnA.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;The problem is the accuracy I get from this is very low. For most of the question, semantic search cannot even find relevant context.&lt;/p&gt; &lt;p&gt;I want to know if the accuracy of RAG is generally lower than the expectations or am I doing something wrong?&lt;/p&gt; &lt;p&gt;What process do you follow for better results?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mr_Nrj&quot;&gt; /u/Mr_Nrj &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alus6s/rag_accuracy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alus6s/rag_accuracy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alus6s</id><link href="https://www.reddit.com/r/LangChain/comments/1alus6s/rag_accuracy/" /><updated>2024-02-08T12:39:08+00:00</updated><published>2024-02-08T12:39:08+00:00</published><title>RAG Accuracy</title></entry><entry><author><name>/u/Johnluhot</name><uri>https://www.reddit.com/user/Johnluhot</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Managing Pinecone deployments is a thing of the past!!! üíÉ&lt;/p&gt; &lt;p&gt;ü•áSome noteworthy features ü•á&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Handles CRUDs for both Pod and Serverless Spec indexes&lt;/li&gt; &lt;li&gt;Deploy multiple indexes at the same time with isolated state management&lt;/li&gt; &lt;li&gt;Adheres to AWS-defined removal policies (DESTROY, SNAPSHOT, etc.)&lt;/li&gt; &lt;li&gt;Creates stack-scoped index names, to avoid name collisions üôå&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;It&amp;#39;s still in beta, so feedback is more than welcome! ü´∂&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/petterle-endeavors/pinecone-db-construct&quot;&gt;Github&lt;/a&gt;&lt;br/&gt; &lt;a href=&quot;https://pypi.org/project/pinecone-db-construct/&quot;&gt;PyPi&lt;/a&gt;&lt;br/&gt; &lt;a href=&quot;https://www.npmjs.com/package/pinecone-db-construct&quot;&gt;NPM&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Johnluhot&quot;&gt; /u/Johnluhot &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aly0xv/i_made_an_opensource_pinecone_db_aws_construct/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aly0xv/i_made_an_opensource_pinecone_db_aws_construct/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aly0xv</id><link href="https://www.reddit.com/r/LangChain/comments/1aly0xv/i_made_an_opensource_pinecone_db_aws_construct/" /><updated>2024-02-08T15:17:53+00:00</updated><published>2024-02-08T15:17:53+00:00</published><title>I Made an Open-Source Pinecone DB AWS Construct üèóÔ∏è</title></entry><entry><author><name>/u/ethicalhack3r</name><uri>https://www.reddit.com/user/ethicalhack3r</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I want to create my own custom document loader, like the IMSDB one for example:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/langchain-ai/langchain/blob/00a09e1b7117f3bde14a44748510fcccc95f9de5/libs/community/langchain_community/document_loaders/imsdb.py#L8&quot;&gt;https://github.com/langchain-ai/langchain/blob/00a09e1b7117f3bde14a44748510fcccc95f9de5/libs/community/langchain_community/document_loaders/imsdb.py#L8&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The main reason I want to do this is to only extract the data I need from a web page, and not the whole thing, to improve accuracy.&lt;/p&gt; &lt;p&gt;If I wrote a script like &lt;a href=&quot;https://imsdb.py&quot;&gt;imsdb.py&lt;/a&gt;, how could I tell my Python script to use it? Maybe there&amp;#39;s already a tutorial for this online? I couldn&amp;#39;t find anytning from a quick search.&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ethicalhack3r&quot;&gt; /u/ethicalhack3r &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alrd96/create_custom_document_loader/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alrd96/create_custom_document_loader/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alrd96</id><link href="https://www.reddit.com/r/LangChain/comments/1alrd96/create_custom_document_loader/" /><updated>2024-02-08T08:51:07+00:00</updated><published>2024-02-08T08:51:07+00:00</published><title>Create Custom Document Loader</title></entry><entry><author><name>/u/WrongdoerSingle4832</name><uri>https://www.reddit.com/user/WrongdoerSingle4832</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/WrongdoerSingle4832&quot;&gt; /u/WrongdoerSingle4832 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aludk3/how_much_gpu_vram_do_i_need_to_finetune_llama_7b/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aludk3/how_much_gpu_vram_do_i_need_to_finetune_llama_7b/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aludk3</id><link href="https://www.reddit.com/r/LangChain/comments/1aludk3/how_much_gpu_vram_do_i_need_to_finetune_llama_7b/" /><updated>2024-02-08T12:15:59+00:00</updated><published>2024-02-08T12:15:59+00:00</published><title>How much GPU vRAM do I need to finetune Llama 7b?</title></entry><entry><author><name>/u/HappyDataGuy</name><uri>https://www.reddit.com/user/HappyDataGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;My question is simple, I am not able to figure out, how to integrate nemo-guardrails in my current RAG applications without completely changing structure. It should return 0 or 1 based on whether user is query is valid or not. how can I get it to this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HappyDataGuy&quot;&gt; /u/HappyDataGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alpm95/how_to_use_nemoguardrails_how_to_know_that_is_not/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alpm95/how_to_use_nemoguardrails_how_to_know_that_is_not/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alpm95</id><link href="https://www.reddit.com/r/LangChain/comments/1alpm95/how_to_use_nemoguardrails_how_to_know_that_is_not/" /><updated>2024-02-08T06:47:31+00:00</updated><published>2024-02-08T06:47:31+00:00</published><title>How to use nemo-guardrails? how to know that is not policy violation and then to pass query to primary LLM?</title></entry><entry><author><name>/u/OnlyBadKarma</name><uri>https://www.reddit.com/user/OnlyBadKarma</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to filter the documents based on the metadata filter. However, I am not sure how to do it using the Langchain Annoy module.&lt;/p&gt; &lt;p&gt;I have a source in metadata, even though I applied the filter it is returning all the docs and not filtering them.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Load the vector db vectordb = Annoy.load_local(PERSIST_DIRECTORY, embeddings=embedding) # Query Annoy docs = vectordb.similarity_search(&amp;quot;how to do X?&amp;quot;, k=2, filter={&amp;quot;source&amp;quot;: &amp;quot;news&amp;quot;}) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OnlyBadKarma&quot;&gt; /u/OnlyBadKarma &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1als4n1/how_to_apply_a_metadata_filter_in_annoy_by_spotify/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1als4n1/how_to_apply_a_metadata_filter_in_annoy_by_spotify/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1als4n1</id><link href="https://www.reddit.com/r/LangChain/comments/1als4n1/how_to_apply_a_metadata_filter_in_annoy_by_spotify/" /><updated>2024-02-08T09:46:22+00:00</updated><published>2024-02-08T09:46:22+00:00</published><title>How to apply a metadata filter in Annoy by Spotify?</title></entry><entry><author><name>/u/AbbreviationsPale867</name><uri>https://www.reddit.com/user/AbbreviationsPale867</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, so I&amp;#39;ve made a new chatPromptTemplate and once I did the first commit to it, I am unable to go back into the artifact playground and modify the prompt. Which is weird cause I can edit my other prompts, for this specific prompt I get &amp;quot; &lt;strong&gt;Message 0 had extra kwargs: additional_kwargs&lt;/strong&gt; &amp;quot; when I hover over the playground button. Any help would be great&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;EDIT: just for reference the prompt im having issue with is &lt;strong&gt;thecodingbarista/documentgenerator&lt;/strong&gt; on the langsmith hub&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AbbreviationsPale867&quot;&gt; /u/AbbreviationsPale867 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alqrzy/langsmith_prompts/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alqrzy/langsmith_prompts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alqrzy</id><link href="https://www.reddit.com/r/LangChain/comments/1alqrzy/langsmith_prompts/" /><updated>2024-02-08T08:07:46+00:00</updated><published>2024-02-08T08:07:46+00:00</published><title>Langsmith prompts</title></entry><entry><author><name>/u/gamesntech</name><uri>https://www.reddit.com/user/gamesntech</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;When generating code-related output from an LLM like python functions, sql queries, etc. a lot of times the LLM wraps the code between triple quotes like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;```python blah ``` &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Is there an output parser or extractor component or anything that can help with extracting these segments and ignoring all the fluff around it?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gamesntech&quot;&gt; /u/gamesntech &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aljkdj/question_about_llm_output_parsing/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aljkdj/question_about_llm_output_parsing/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aljkdj</id><link href="https://www.reddit.com/r/LangChain/comments/1aljkdj/question_about_llm_output_parsing/" /><updated>2024-02-08T01:23:06+00:00</updated><published>2024-02-08T01:23:06+00:00</published><title>Question about LLM output parsing</title></entry><entry><author><name>/u/Environmental_Win975</name><uri>https://www.reddit.com/user/Environmental_Win975</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi All&lt;/p&gt; &lt;p&gt;Question, After creating my vector database of entire 100docs, i want how to this vector database in seperate client progran. How shall I do it? I using aws opensearch servless for vector db&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Environmental_Win975&quot;&gt; /u/Environmental_Win975 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alilwn/opeansearch_vector_db_use_in_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alilwn/opeansearch_vector_db_use_in_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1alilwn</id><link href="https://www.reddit.com/r/LangChain/comments/1alilwn/opeansearch_vector_db_use_in_rag/" /><updated>2024-02-08T00:37:01+00:00</updated><published>2024-02-08T00:37:01+00:00</published><title>Opeansearch vector db use in rag</title></entry><entry><author><name>/u/mofusa16</name><uri>https://www.reddit.com/user/mofusa16</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alpexo/predict_and_parse_method_deprecation_warning_how/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/vbejhbfl3bhc1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5bd31f1c45badb50beea07d0ba434a2b2aa19bce&quot; alt=&quot;predict_and_parse method deprecation warning. How to Solve?&quot; title=&quot;predict_and_parse method deprecation warning. How to Solve?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mofusa16&quot;&gt; /u/mofusa16 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/vbejhbfl3bhc1.png&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1alpexo/predict_and_parse_method_deprecation_warning_how/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1alpexo</id><media:thumbnail url="https://preview.redd.it/vbejhbfl3bhc1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5bd31f1c45badb50beea07d0ba434a2b2aa19bce" /><link href="https://www.reddit.com/r/LangChain/comments/1alpexo/predict_and_parse_method_deprecation_warning_how/" /><updated>2024-02-08T06:34:10+00:00</updated><published>2024-02-08T06:34:10+00:00</published><title>predict_and_parse method deprecation warning. How to Solve?</title></entry><entry><author><name>/u/Many-Historian-3143</name><uri>https://www.reddit.com/user/Many-Historian-3143</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1allnji/extracting_table_using_pdfplumber_but_not/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/E9MQmOOKPQq8mlF486E7NUM2zcae5DznPSEcoyayfNo.jpg&quot; alt=&quot;Extracting Table using PDFPlumber but not extracting Text that has background color&quot; title=&quot;Extracting Table using PDFPlumber but not extracting Text that has background color&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, community,&lt;/p&gt; &lt;p&gt;In the section with a color background, the text is not extracting checked all parameters of main function for extracting text from the table in Python, pddplumber, unstructured. What recommendation do you have?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/2ofmdidh1ahc1.jpg?width=778&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=bc6d1e50cfaeba5dd5e6ca9ce765eb4923973768&quot;&gt;https://preview.redd.it/2ofmdidh1ahc1.jpg?width=778&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=bc6d1e50cfaeba5dd5e6ca9ce765eb4923973768&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Many-Historian-3143&quot;&gt; /u/Many-Historian-3143 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1allnji/extracting_table_using_pdfplumber_but_not/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1allnji/extracting_table_using_pdfplumber_but_not/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1allnji</id><media:thumbnail url="https://b.thumbs.redditmedia.com/E9MQmOOKPQq8mlF486E7NUM2zcae5DznPSEcoyayfNo.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1allnji/extracting_table_using_pdfplumber_but_not/" /><updated>2024-02-08T03:04:14+00:00</updated><published>2024-02-08T03:04:14+00:00</published><title>Extracting Table using PDFPlumber but not extracting Text that has background color</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Checkout my new tutorial on how to build a recommendation system using RAG and LangChain &lt;a href=&quot;https://youtu.be/WW0q8jjsisQ?si=9JI24AIj822N9zJK&quot;&gt;https://youtu.be/WW0q8jjsisQ?si=9JI24AIj822N9zJK&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al7yyt/recommendation_system_using_langchain_and_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al7yyt/recommendation_system_using_langchain_and_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1al7yyt</id><link href="https://www.reddit.com/r/LangChain/comments/1al7yyt/recommendation_system_using_langchain_and_rag/" /><updated>2024-02-07T17:11:24+00:00</updated><published>2024-02-07T17:11:24+00:00</published><title>Recommendation system using LangChain and RAG</title></entry><entry><author><name>/u/OkVegetable2512</name><uri>https://www.reddit.com/user/OkVegetable2512</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys, I have to create a llm based on risk analysis (mainly hara) for my company. The only problem is that the input data is sensitive that‚Äôs why I am steering in the direction of using a locally hosted/offline llm like private gpt or elasticsearch with some kind of ui. Can anybody give me pointers on where to start and how to do it? I am still a student and fairly new to the topic&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OkVegetable2512&quot;&gt; /u/OkVegetable2512 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al25wz/langchain_for_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al25wz/langchain_for_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1al25wz</id><link href="https://www.reddit.com/r/LangChain/comments/1al25wz/langchain_for_llm/" /><updated>2024-02-07T12:48:38+00:00</updated><published>2024-02-07T12:48:38+00:00</published><title>LangChain for llm</title></entry><entry><author><name>/u/BigActivity9282</name><uri>https://www.reddit.com/user/BigActivity9282</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Guys,&lt;/p&gt; &lt;p&gt;Can anyone point me to a resource where we can choose different vector db retriever based on the input question. There is an example on routing to different prompts using runnablelambda. However the input is a dictionary hence it works. My problem is to choose the retriever on run time then pass only the question to the selected retriever at runtime.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BigActivity9282&quot;&gt; /u/BigActivity9282 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al3xwz/langchain_expression_language/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1al3xwz/langchain_expression_language/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1al3xwz</id><link href="https://www.reddit.com/r/LangChain/comments/1al3xwz/langchain_expression_language/" /><updated>2024-02-07T14:17:37+00:00</updated><published>2024-02-07T14:17:37+00:00</published><title>Langchain expression language</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, I just released a tutorial on how to make an agent interact with multiple vector databases with examples and codes. Do check it out&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/cBpdiQ3gljM?si=rfpFmlyGILHlIH4t&quot;&gt;https://youtu.be/cBpdiQ3gljM?si=rfpFmlyGILHlIH4t &lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akroee/multi_document_rag_using_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akroee/multi_document_rag_using_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akroee</id><link href="https://www.reddit.com/r/LangChain/comments/1akroee/multi_document_rag_using_agents/" /><updated>2024-02-07T02:08:43+00:00</updated><published>2024-02-07T02:08:43+00:00</published><title>Multi Document RAG using Agents</title></entry><entry><author><name>/u/deadmalone</name><uri>https://www.reddit.com/user/deadmalone</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, I was testing out things and I made a personal document analyser. I chunked and stored multiple documents in the same index in Pincone. Since the documents have contextual overlap, this improved the quality of the results produced a lot.&lt;/p&gt; &lt;p&gt;For reference I was testing with the Mistral 8x7b model.&lt;/p&gt; &lt;p&gt;What&amp;#39;s your opinion on this??&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/deadmalone&quot;&gt; /u/deadmalone &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akzs8s/multiple_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akzs8s/multiple_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akzs8s</id><link href="https://www.reddit.com/r/LangChain/comments/1akzs8s/multiple_documents/" /><updated>2024-02-07T10:16:52+00:00</updated><published>2024-02-07T10:16:52+00:00</published><title>Multiple Documents</title></entry><entry><author><name>/u/Azyain</name><uri>https://www.reddit.com/user/Azyain</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I have a project to build a chatbot for E-commerce. This chatbot should interact with users and inform them about the products sold on the website. I tried using one agent to handle both interaction and task execution. However, when I only said &amp;quot;Hi,&amp;quot; the bot returned a ValueError, something like &amp;quot;LLM could not parse.&amp;quot; So, in this situation, do I need two agents? One to interact with users for out-of-context questions such as greetings or asking the bot&amp;#39;s name, and the other to handle the thinking process for tasks such as finding today&amp;#39;s discounts or locating gaming accessories? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Azyain&quot;&gt; /u/Azyain &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aktwzi/do_you_really_need_more_than_one_agent_in_your/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aktwzi/do_you_really_need_more_than_one_agent_in_your/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aktwzi</id><link href="https://www.reddit.com/r/LangChain/comments/1aktwzi/do_you_really_need_more_than_one_agent_in_your/" /><updated>2024-02-07T04:00:20+00:00</updated><published>2024-02-07T04:00:20+00:00</published><title>Do you really need more than one agent in your LLM chatbot?</title></entry><entry><author><name>/u/Arajgor</name><uri>https://www.reddit.com/user/Arajgor</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to build PDF chatbot using OpenAI, Langchain and Pinecone.&lt;/p&gt; &lt;p&gt;Here is my code,&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain.document_loaders import PyPDFLoader from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter import uuid loader = PyPDFLoader(&amp;quot;2104.02830.pdf&amp;quot;) data = loader.load() text_splitter = RecursiveCharacterTextSplitter( chunk_size=2000, chunk_overlap=0) texts = text_splitter.split_documents(data) for text in texts: id = uuid.uuid4().hex response = embeddings.embed_query(text.page_content) vectors.append([(id, response, {&amp;quot;page&amp;quot;: text.metadata[&amp;#39;page&amp;#39;], &amp;quot;text&amp;quot;: text.page_content})]) for vector in vectors: index.upsert(vector) query_embedding = embeddings.embed_query(&amp;quot;author of this research paper&amp;quot;) result = index.query(vector=query_embedding , top_k=5, include_metadata=True) print(result[&amp;#39;matches&amp;#39;][0]) [{&amp;#39;id&amp;#39;: &amp;#39;ccd0dac490da4b4b947db97076cdf10d&amp;#39;, &amp;#39;metadata&amp;#39;: {&amp;#39;page&amp;#39;: 5.0, &amp;#39;text&amp;#39;: &amp;#39;novel image dataset for benchmarking machine learning &amp;#39; &amp;#39;al-\n&amp;#39;&amp;#39;gorithms. ArXiv , abs/1708.07747, 2017.\n&amp;#39; &amp;#39;[20] X. Zou, X. Kong, W. Wong, C. Wang, Y . Liu, and Y &amp;#39;&amp;#39;. Cao.\n&amp;#39;&amp;#39;Fashionai: A hierarchical dataset for fashion &amp;#39;&amp;#39;understand-\n&amp;#39;&amp;#39;ing. In 2019 IEEE/CVF Conference on Computer Vision &amp;#39;&amp;#39;and\n&amp;#39;&amp;#39;Pattern Recognition Workshops (CVPRW) , pages 296‚Äì304,\n&amp;#39;&amp;#39;2019.\n&amp;#39;&amp;#39;6&amp;#39;}, &amp;#39;score&amp;#39;: 0.290649086, &amp;#39;values&amp;#39;: []}, &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;It gives me reference links rather than author names.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Arajgor&quot;&gt; /u/Arajgor &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akvy3c/rag_using_pinecone_does_not_give_accurate_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akvy3c/rag_using_pinecone_does_not_give_accurate_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akvy3c</id><link href="https://www.reddit.com/r/LangChain/comments/1akvy3c/rag_using_pinecone_does_not_give_accurate_data/" /><updated>2024-02-07T05:50:30+00:00</updated><published>2024-02-07T05:50:30+00:00</published><title>RAG using pinecone does not give accurate data</title></entry><entry><author><name>/u/williamfzc</name><uri>https://www.reddit.com/user/williamfzc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In the past few months, we&amp;#39;ve experimented with various approaches to enable LLM to comprehend code files. Currently, LLM can grasp the essence of file meanings at a functional level. This understanding is facilitated by providing contextual information such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;File content&lt;/li&gt; &lt;li&gt;File path&lt;/li&gt; &lt;li&gt;Commit message&lt;/li&gt; &lt;li&gt;Issues&lt;/li&gt; &lt;li&gt;...&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;However, the code represents business logic, which often spans multiple/complex categories. This business logic may be entirely unrelated to the contents mentioned in a single code file, posing a significant challenge for LLM to comprehend and classify.&lt;/p&gt; &lt;p&gt;I&amp;#39;m wondering if there are any existing methods or approaches to address this issue. Any insights or suggestions would be greatly appreciated. Thanks in advance :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/williamfzc&quot;&gt; /u/williamfzc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akyazk/is_there_a_existed_way_to_mapping_code_files_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akyazk/is_there_a_existed_way_to_mapping_code_files_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akyazk</id><link href="https://www.reddit.com/r/LangChain/comments/1akyazk/is_there_a_existed_way_to_mapping_code_files_with/" /><updated>2024-02-07T08:27:03+00:00</updated><published>2024-02-07T08:27:03+00:00</published><title>Is there a existed way to mapping code files with real businesses?</title></entry><entry><author><name>/u/ashpreetbedi</name><uri>https://www.reddit.com/user/ashpreetbedi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak94ud/asking_llms_who_are_you_and_who_created_you/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/YVvMvxzowXU43xjPmturLrx4YDFm_6WOx2VRMivKwUU.jpg&quot; alt=&quot;Asking LLMs &amp;quot;Who are you and who created you?&amp;quot; reveals very interesting results&quot; title=&quot;Asking LLMs &amp;quot;Who are you and who created you?&amp;quot; reveals very interesting results&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I asked 6 llms &amp;quot;Who are you and who created you?&amp;quot; &lt;/p&gt; &lt;ul&gt; &lt;li&gt;surprisingly most of them were created by OpenAI üòÇ&lt;/li&gt; &lt;li&gt;Llama and Mixtral were accurate most likely cause they&amp;#39;re trained from scratch&lt;/li&gt; &lt;li&gt;Tinyllama is my favourite&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/j5ohzozrpygc1.png?width=796&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=894cefdfd1d9f3fe402e76917fac705e9ba3c327&quot;&gt;https://preview.redd.it/j5ohzozrpygc1.png?width=796&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=894cefdfd1d9f3fe402e76917fac705e9ba3c327&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/phidatahq/phidata/blob/main/cookbook/ollama/who_are_you.py&quot;&gt;Here&amp;#39;s the code I used for this&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashpreetbedi&quot;&gt; /u/ashpreetbedi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak94ud/asking_llms_who_are_you_and_who_created_you/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak94ud/asking_llms_who_are_you_and_who_created_you/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ak94ud</id><media:thumbnail url="https://b.thumbs.redditmedia.com/YVvMvxzowXU43xjPmturLrx4YDFm_6WOx2VRMivKwUU.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1ak94ud/asking_llms_who_are_you_and_who_created_you/" /><updated>2024-02-06T12:57:14+00:00</updated><published>2024-02-06T12:57:14+00:00</published><title>Asking LLMs &quot;Who are you and who created you?&quot; reveals very interesting results</title></entry><entry><author><name>/u/_micromastery_</name><uri>https://www.reddit.com/user/_micromastery_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all,&lt;/p&gt; &lt;p&gt;I started exploring lang chain recently and was really amazed by its extensibility. I have written my experience as small tutorials and wanted to share the same with the community.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://micromastery.github.io/posts/meet-your-digital-dream-team-revolutionizing-tech-world-with-ai/&quot;&gt;Meet Your Digital Dream Team: Revolutionizing the Tech World with AI &lt;/a&gt; - This is where I explored a python framework called Crew AI which allows creating collaborative AI using langchain tools&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://micromastery.github.io/posts/customizing-llms-with-langchain-text-to-speech/&quot;&gt;Enhancing LLMs with Custom Capabilities: A Guide to Langchain and Text-to-Speech &lt;/a&gt; - This is where I explored creation of custom tools for lang chain. I am using this day to day for creating voiceovers for videos.&lt;/p&gt; &lt;p&gt;Hope you find these useful.&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/_micromastery_&quot;&gt; /u/_micromastery_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akfdm7/langchains_extensibility_is/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akfdm7/langchains_extensibility_is/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akfdm7</id><link href="https://www.reddit.com/r/LangChain/comments/1akfdm7/langchains_extensibility_is/" /><updated>2024-02-06T17:34:42+00:00</updated><published>2024-02-06T17:34:42+00:00</published><title>LangChain's extensibility is ü§Ø</title></entry><entry><author><name>/u/Money_Mycologist4939</name><uri>https://www.reddit.com/user/Money_Mycologist4939</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is quite easy to create a chatbot with langchain LCEL and using the buffer memory, but what if in production I wanna store the history of the conversation in a db and not in the RAM and retrieve it when the user restart the conversation with the chatbot? I cannot find a tuto anywhere. Has anyone already tried to do it??&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Money_Mycologist4939&quot;&gt; /u/Money_Mycologist4939 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak7lzj/langchain_chatbot_in_production/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ak7lzj/langchain_chatbot_in_production/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ak7lzj</id><link href="https://www.reddit.com/r/LangChain/comments/1ak7lzj/langchain_chatbot_in_production/" /><updated>2024-02-06T11:28:19+00:00</updated><published>2024-02-06T11:28:19+00:00</published><title>Langchain Chatbot in production</title></entry><entry><author><name>/u/KoalaPink1999</name><uri>https://www.reddit.com/user/KoalaPink1999</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have specific usecase of extracting structured (logically split) information from documents. Is there any parser that is opensource and does not need any particular API key ?&lt;br/&gt; The snippets would be sent to a RAG. This data would be used for internal usecases, so I would prefer a solution that would work for the same.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/KoalaPink1999&quot;&gt; /u/KoalaPink1999 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akc06q/splitting_documents_pdfshtml_pagestxt_files_into/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1akc06q/splitting_documents_pdfshtml_pagestxt_files_into/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1akc06q</id><link href="https://www.reddit.com/r/LangChain/comments/1akc06q/splitting_documents_pdfshtml_pagestxt_files_into/" /><updated>2024-02-06T15:11:34+00:00</updated><published>2024-02-06T15:11:34+00:00</published><title>Splitting documents (pdfs/html pages/txt files) into snippets with logical flow with Opensource tools</title></entry></feed>