<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-06-16T06:46:01+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/HomunMage</name><uri>https://www.reddit.com/user/HomunMage</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Because langchain/langgraph example and tutorial is sxcking, I beleieve many people agree that. such &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1d4lwt0/am_i_the_only_one_who_feels_langgraph/&quot;&gt;Am I the only one who feels LangGraph documentation and tutorials by lanfchain absolutely sxck?&lt;/a&gt;&lt;/p&gt; &lt;p&gt;for example, all examples are openai related llm interface and hard to convert to local such ollama.&lt;br/&gt; This makes me even a &lt;a href=&quot;https://github.com/HomunMage/AI_Agents/blob/main/LangChain/Hello%20World.py&quot;&gt;simple hello world&lt;/a&gt; need hours to coding it.&lt;/p&gt; &lt;p&gt;That is why I had crate a &lt;a href=&quot;https://github.com/HomunMage/CrewAI-GUI&quot;&gt;GUI for CrewAI&lt;/a&gt; , not a gui for langchain or langgraph. But I think learning langgraph still important.&lt;/p&gt; &lt;p&gt;I want to find or build a langgraph learning group. And also want to build a LangGraph-GUI&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HomunMage&quot;&gt; /u/HomunMage &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgxdvq/any_learning_group_for_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgxdvq/any_learning_group_for_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dgxdvq</id><link href="https://www.reddit.com/r/LangChain/comments/1dgxdvq/any_learning_group_for_langgraph/" /><updated>2024-06-16T02:09:17+00:00</updated><published>2024-06-16T02:09:17+00:00</published><title>Any learning Group for LangGraph?</title></entry><entry><author><name>/u/Nimitzxz</name><uri>https://www.reddit.com/user/Nimitzxz</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been working on a project that aims to enhance job applications using AI. It&amp;#39;s called &lt;a href=&quot;https://github.com/DAVEinside/GenAI_Job_Fit&quot;&gt;GenAI_Job_Fit&lt;/a&gt;, and I would love for you all to check it out. I took inspiration from the Agent-Supervisor example notebook provided.&lt;/p&gt; &lt;p&gt;The system leverages AI to analyze job descriptions and tailor resumes to match job requirements, increasing the chances of getting noticed by recruiters and ATS (Applicant Tracking Systems). Here are some key features:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Automated resume tailoring&lt;/li&gt; &lt;li&gt;Keyword optimization&lt;/li&gt; &lt;li&gt;Compatibility scoring between job descriptions and resumes&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I&amp;#39;d really appreciate it if you could take a look and let me know what you think. I&amp;#39;m particularly interested in any suggestions for improvements or additional features that could make the tool even more useful.&lt;/p&gt; &lt;p&gt;Feel free to fork the repo, open issues, or submit pull requests. Your feedback will be invaluable in making this project better!&lt;/p&gt; &lt;p&gt;Repo Link : &lt;a href=&quot;https://github.com/DAVEinside/GenAI_Job_Fit&quot;&gt;https://github.com/DAVEinside/GenAI_Job_Fit&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Nimitzxz&quot;&gt; /u/Nimitzxz &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgnmjt/aidriven_job_application_enhancement_system/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgnmjt/aidriven_job_application_enhancement_system/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dgnmjt</id><link href="https://www.reddit.com/r/LangChain/comments/1dgnmjt/aidriven_job_application_enhancement_system/" /><updated>2024-06-15T17:57:17+00:00</updated><published>2024-06-15T17:57:17+00:00</published><title>AI-Driven Job Application Enhancement System - Seeking Feedback and Suggestions!</title></entry><entry><author><name>/u/darkziosj</name><uri>https://www.reddit.com/user/darkziosj</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello! Im using the APIchain i use it to get data from an api endpoint, the problem is that the api returns a largue amount of data in json format (i need all the data that the api returns), i will then use a agent to ask questions about that data but since is so massive there&amp;#39;s problems like the token amount or time it takes to analyze, can anyone giveme some tips about what can i do to better the performance or what to do to solve this kind of problem? thanks alot!!!&lt;/p&gt; &lt;p&gt;this is the apiChain im using:&lt;/p&gt; &lt;p&gt;llm = OpenAI(temperature=0)&lt;br/&gt; chain = APIChain.from_llm_and_api_docs(&lt;br/&gt; llm,&lt;br/&gt; open_meteo_docs.OPEN_METEO_DOCS,&lt;br/&gt; verbose=True,&lt;br/&gt; limit_to_domains=[&amp;quot;&lt;a href=&quot;https://api.open-meteo.com/%22%5C&quot;&gt;https://api.open-meteo.com/&amp;quot;\&lt;/a&gt;],&lt;br/&gt; )&lt;br/&gt; chain.run(&lt;br/&gt; &amp;quot;What is the weather like right now in Munich, Germany in degrees Fahrenheit?&amp;quot;&lt;br/&gt; )&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/darkziosj&quot;&gt; /u/darkziosj &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgm1ij/how_to_work_with_large_data_that_is_returned_from/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgm1ij/how_to_work_with_large_data_that_is_returned_from/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dgm1ij</id><link href="https://www.reddit.com/r/LangChain/comments/1dgm1ij/how_to_work_with_large_data_that_is_returned_from/" /><updated>2024-06-15T16:42:29+00:00</updated><published>2024-06-15T16:42:29+00:00</published><title>How to work with large data that is returned from an api?</title></entry><entry><author><name>/u/Perfect_Manner8494</name><uri>https://www.reddit.com/user/Perfect_Manner8494</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i used chromadb with langchain to create embeddings. i used persistent_directory to save those locally and it did but now i am not able to load them. these are the codes&lt;/p&gt; &lt;h1&gt;saving embeddings&lt;/h1&gt; &lt;p&gt;vector_storage=Chroma.from_documents(split,OllamaEmbeddings(model=&amp;quot;nomic-embed-text&amp;quot;), persist_directory=&amp;quot;vector_store&amp;quot;,collection_name=&amp;quot;qna_embeddings&amp;quot;)&lt;/p&gt; &lt;h1&gt;loading embeddings&lt;/h1&gt; &lt;p&gt;vector_store2=Chroma(persist_directory=&amp;quot;vector_store&amp;quot;,embedding_function=OllamaEmbeddings(model=&amp;quot;nomic-embed-text&amp;quot;))&lt;/p&gt; &lt;p&gt;to check i printed the following and it gives 0 as output&lt;/p&gt; &lt;p&gt;print(vector_store2._collection.count())&lt;/p&gt; &lt;p&gt;pls help me &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Perfect_Manner8494&quot;&gt; /u/Perfect_Manner8494 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgpc6w/save_and_load_embeddings/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgpc6w/save_and_load_embeddings/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dgpc6w</id><link href="https://www.reddit.com/r/LangChain/comments/1dgpc6w/save_and_load_embeddings/" /><updated>2024-06-15T19:17:27+00:00</updated><published>2024-06-15T19:17:27+00:00</published><title>save and load embeddings</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgn8l5/improving_performance_for_data_visualization_ai/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/Q6J3m0iBOylgxJPGbdH3ZhbDZVBtgunJRGQdTd5E1bw.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=84ec9c09ce6ecb6530e7a84a850f1b5278517368&quot; alt=&quot;Improving Performance for Data Visualization AI Agent&quot; title=&quot;Improving Performance for Data Visualization AI Agent&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://medium.com/firebird-technologies/improving-performance-for-data-visualization-ai-agent-d677ccb71e81&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgn8l5/improving_performance_for_data_visualization_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dgn8l5</id><media:thumbnail url="https://external-preview.redd.it/Q6J3m0iBOylgxJPGbdH3ZhbDZVBtgunJRGQdTd5E1bw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=84ec9c09ce6ecb6530e7a84a850f1b5278517368" /><link href="https://www.reddit.com/r/LangChain/comments/1dgn8l5/improving_performance_for_data_visualization_ai/" /><updated>2024-06-15T17:38:58+00:00</updated><published>2024-06-15T17:38:58+00:00</published><title>Improving Performance for Data Visualization AI Agent</title></entry><entry><author><name>/u/sarthakai</name><uri>https://www.reddit.com/user/sarthakai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;First, how it works:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;Memory Tuning fine-tunes millions of LoRA adapters (memory experts) on any open-source LLM to ensure accurate fact recall.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;During inference, the model retrieves and integrates the most relevant experts, (a lot like information retrieval). This gives much high accuracy and reduced hallucinations.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;This approach maintains the model&amp;#39;s ability to generalise — while at the same time focusing on zero error for specified facts.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Why is this better than RAG?&lt;/p&gt; &lt;p&gt;RAG shifts probabilities without eliminating errors — while Memory Tuning fully corrects inaccuracies.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/company/lamini-ai/&quot;&gt;Lamini&lt;/a&gt; released their Memory Tuning solution for enterprises with case studies showing amazing accuracy boosts for text-to-sql, labelling, and even recommendation tasks.&lt;/p&gt; &lt;p&gt;Paper: &lt;a href=&quot;https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf&quot;&gt;https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I share high quality AI updates and tutorials daily on my LinkedIn: &lt;a href=&quot;https://www.linkedin.com/in/sarthakrastogi/&quot;&gt;https://www.linkedin.com/in/sarthakrastogi/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;If you like this post and want to stay updated on latest AI research, you can check out: &lt;a href=&quot;https://linktr.ee/sarthakrastogi&quot;&gt;https://linktr.ee/sarthakrastogi&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sarthakai&quot;&gt; /u/sarthakai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgi0vj/whats_memory_tuning_and_how_does_it_give_higher/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgi0vj/whats_memory_tuning_and_how_does_it_give_higher/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dgi0vj</id><link href="https://www.reddit.com/r/LangChain/comments/1dgi0vj/whats_memory_tuning_and_how_does_it_give_higher/" /><updated>2024-06-15T13:30:01+00:00</updated><published>2024-06-15T13:30:01+00:00</published><title>What’s Memory Tuning and how does it give higher accuracy + speed than RAG and prompting?</title></entry><entry><author><name>/u/Sweaty-Minimum5423</name><uri>https://www.reddit.com/user/Sweaty-Minimum5423</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello all, OpenAI assistant should support streaming. But I am not sure why the current OpenAIAssistantV2Runnable do not supports it. Is there a solution to this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sweaty-Minimum5423&quot;&gt; /u/Sweaty-Minimum5423 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgfsmg/streaming_of_openaiassistant_v2/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgfsmg/streaming_of_openaiassistant_v2/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dgfsmg</id><link href="https://www.reddit.com/r/LangChain/comments/1dgfsmg/streaming_of_openaiassistant_v2/" /><updated>2024-06-15T11:23:04+00:00</updated><published>2024-06-15T11:23:04+00:00</published><title>Streaming of OpenAIAssistant v2</title></entry><entry><author><name>/u/filet_mign0n</name><uri>https://www.reddit.com/user/filet_mign0n</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Wondering if anyone here has dealt with passing private information from end user inputs to your LLM, later to interact with an external API? I&amp;#39;m not talking about authentication data per se, just private information (e.g PII) people wouldn&amp;#39;t normally want to share on the internet.&lt;br/&gt; What solution have you come up with to ensure some privacy for your users?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/filet_mign0n&quot;&gt; /u/filet_mign0n &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfyz50/how_to_securely_pass_private_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfyz50/how_to_securely_pass_private_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfyz50</id><link href="https://www.reddit.com/r/LangChain/comments/1dfyz50/how_to_securely_pass_private_data/" /><updated>2024-06-14T19:23:46+00:00</updated><published>2024-06-14T19:23:46+00:00</published><title>How to securely pass private data?</title></entry><entry><author><name>/u/RaeudigerRaffi</name><uri>https://www.reddit.com/user/RaeudigerRaffi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m excited to share an updated open-source resource we’ve been working on—an improved version of the Spider dataset originally published by Yale University for Text2SQL tasks. You can check it out here: &lt;a href=&quot;https://huggingface.co/datasets/RaffaSch121/fixed_spider&quot;&gt;https://huggingface.co/datasets/RaffaSch121/fixed_spider&lt;/a&gt;&lt;/p&gt; &lt;p&gt;During our own model training at &lt;a href=&quot;http://www.turbular.com&quot;&gt;Turbular&lt;/a&gt; we identified several issues in the original dataset. To help the community and give back, we decided to address these problems and release a corrected version. We hope this enhanced dataset will benefit everyone working on Text2SQL and similar projects.&lt;/p&gt; &lt;p&gt;Feel free to download, experiment, and contribute back if you find ways to make it even better!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RaeudigerRaffi&quot;&gt; /u/RaeudigerRaffi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsdbw/improved_text2sql_dataset_now_available_on/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsdbw/improved_text2sql_dataset_now_available_on/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfsdbw</id><link href="https://www.reddit.com/r/LangChain/comments/1dfsdbw/improved_text2sql_dataset_now_available_on/" /><updated>2024-06-14T14:37:24+00:00</updated><published>2024-06-14T14:37:24+00:00</published><title>Improved Text2SQL Dataset Now Available on Huggingface!</title></entry><entry><author><name>/u/FunInformation2332</name><uri>https://www.reddit.com/user/FunInformation2332</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfxwga/evaluating_with_ragas/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/XCOcROHXeB7lrz95uNOAiGKakHooUXoHIPXAQ38I2n0.jpg&quot; alt=&quot;Evaluating with Ragas&quot; title=&quot;Evaluating with Ragas&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve finished my rag job, and performed a evaluation on my rag. results given below&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/pt0khqy10l6d1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4979a08f0e648937407d23feeb494f02a8e793ba&quot;&gt;ragas output&lt;/a&gt;&lt;/p&gt; &lt;p&gt;context_precision is better than good but why the other metrics sucks and how to improve them?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FunInformation2332&quot;&gt; /u/FunInformation2332 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfxwga/evaluating_with_ragas/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfxwga/evaluating_with_ragas/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dfxwga</id><media:thumbnail url="https://a.thumbs.redditmedia.com/XCOcROHXeB7lrz95uNOAiGKakHooUXoHIPXAQ38I2n0.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1dfxwga/evaluating_with_ragas/" /><updated>2024-06-14T18:36:01+00:00</updated><published>2024-06-14T18:36:01+00:00</published><title>Evaluating with Ragas</title></entry><entry><author><name>/u/UnderstandLingAI</name><uri>https://www.reddit.com/user/UnderstandLingAI</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We are in early stages of developing our project so keen feedback. RAG Me Up is a robust layer on top of Langchain designed to make RAG easy and also not prone to simple issues like document re-retrieval, performance for rephrasind and perhaps most importantly: make Langchain work well with Instruct/Chat models&amp;#39; templates.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/AI-Commandos/RAGMeUp&quot;&gt;https://github.com/AI-Commandos/RAGMeUp &lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UnderstandLingAI&quot;&gt; /u/UnderstandLingAI &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfx2di/rag_me_up_rag_for_chat_w_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfx2di/rag_me_up_rag_for_chat_w_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfx2di</id><link href="https://www.reddit.com/r/LangChain/comments/1dfx2di/rag_me_up_rag_for_chat_w_langchain/" /><updated>2024-06-14T18:00:18+00:00</updated><published>2024-06-14T18:00:18+00:00</published><title>RAG Me Up - RAG for chat /w Langchain</title></entry><entry><author><name>/u/MoronSlayer42</name><uri>https://www.reddit.com/user/MoronSlayer42</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have implementing streaming with a chain based runnable which gives token by token output ( word by word), making UI similar to how ChatGPT has its UI. But while implementing the same with an Agent based runnable I see that it gives 3 outputs in order, actions, steps and, output which contains answer. All three come as a whole, one after the other, not word by word.&lt;/p&gt; &lt;p&gt;I want to get word by word streaming for the agent&amp;#39;s final answer.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MoronSlayer42&quot;&gt; /u/MoronSlayer42 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsv2t/streaming_with_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsv2t/streaming_with_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfsv2t</id><link href="https://www.reddit.com/r/LangChain/comments/1dfsv2t/streaming_with_agents/" /><updated>2024-06-14T14:59:04+00:00</updated><published>2024-06-14T14:59:04+00:00</published><title>Streaming with agents</title></entry><entry><author><name>/u/ANil1729</name><uri>https://www.reddit.com/user/ANil1729</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have written an article on how to create a Text to Video AI generator which generates video from a topic by collecting relevant stock videos and stitching them together. &lt;/p&gt; &lt;p&gt;The code is completely open-source and uses free to use tools to generate videos&lt;/p&gt; &lt;p&gt;Link to article :- &lt;a href=&quot;https://medium.com/@anilmatcha/text-to-video-ai-how-to-create-videos-for-free-a-complete-guide-a25c91de50b8&quot;&gt;https://medium.com/@anilmatcha/text-to-video-ai-how-to-create-videos-for-free-a-complete-guide-a25c91de50b8&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ANil1729&quot;&gt; /u/ANil1729 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsc15/a_tutorial_on_creating_video_from_text_using_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsc15/a_tutorial_on_creating_video_from_text_using_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfsc15</id><link href="https://www.reddit.com/r/LangChain/comments/1dfsc15/a_tutorial_on_creating_video_from_text_using_ai/" /><updated>2024-06-14T14:35:53+00:00</updated><published>2024-06-14T14:35:53+00:00</published><title>A tutorial on creating video from text using AI</title></entry><entry><author><name>/u/profsartor</name><uri>https://www.reddit.com/user/profsartor</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;As the title reads, I&amp;#39;m building a side project to chat with my google calendar + assignments from Canvas (learning management system). I&amp;#39;m using GCP to practice working with the cloud. &lt;/p&gt; &lt;p&gt;As of April 2024, Cloud SQL for MySQL now supports vector embeddings. Essentially, I have all of my coursework and assignments in an events table. At first I embedded at the row level but this lost the understanding of columns. Now, I have a new column that is JSON representation of all the relevant columns for my eventual retrieval (event_title, start_time, end_time, tag (Assignment, Discussion, Quiz, Study Times, Personal Events)). In a new column, I&amp;#39;ve successfully embedded all of these JSON&amp;#39;s. What I&amp;#39;ve described above is pretty much the extent of what I&amp;#39;ve done. &lt;/p&gt; &lt;p&gt;My end goal is to develop a streamlit UI to query this vector column in my SQL database. I have a few different paths I can go down, but I&amp;#39;m intentionally keeping this at a high level to hear diverse responses. &lt;/p&gt; &lt;p&gt;Any advice? All thoughts are greatly appreciated. &lt;/p&gt; &lt;p&gt;Cheers&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/profsartor&quot;&gt; /u/profsartor &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsjwl/newbie_seeking_advice_on_side_project_chat_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsjwl/newbie_seeking_advice_on_side_project_chat_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfsjwl</id><link href="https://www.reddit.com/r/LangChain/comments/1dfsjwl/newbie_seeking_advice_on_side_project_chat_with/" /><updated>2024-06-14T14:45:29+00:00</updated><published>2024-06-14T14:45:29+00:00</published><title>Newbie Seeking Advice on Side Project - Chat with Calendar</title></entry><entry><author><name>/u/alcatraz0411</name><uri>https://www.reddit.com/user/alcatraz0411</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all, How do I get the token count for chain.astream_events()&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/alcatraz0411&quot;&gt; /u/alcatraz0411 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfpjpr/token_count_and_cost_for_chainastream_events/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfpjpr/token_count_and_cost_for_chainastream_events/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfpjpr</id><link href="https://www.reddit.com/r/LangChain/comments/1dfpjpr/token_count_and_cost_for_chainastream_events/" /><updated>2024-06-14T12:23:23+00:00</updated><published>2024-06-14T12:23:23+00:00</published><title>Token count and cost for chain.astream_events().</title></entry><entry><author><name>/u/Convhay</name><uri>https://www.reddit.com/user/Convhay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi i am new to the framework of langchain and i want to search for some information in contract documents regarding total m2 area for a partner. The problem is that the main partner contract can have several newer appendices where the old total m2 area in the old original contract is now replaced. Now i only want to extract the new total m2 area. Is there a clever way to sort or filter this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Convhay&quot;&gt; /u/Convhay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfp7xf/ragchain_searching_for_similar_prompts/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfp7xf/ragchain_searching_for_similar_prompts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfp7xf</id><link href="https://www.reddit.com/r/LangChain/comments/1dfp7xf/ragchain_searching_for_similar_prompts/" /><updated>2024-06-14T12:05:06+00:00</updated><published>2024-06-14T12:05:06+00:00</published><title>RAGchain searching for similar prompts</title></entry><entry><author><name>/u/EscapedLaughter</name><uri>https://www.reddit.com/user/EscapedLaughter</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfp2z5/project_compare_top_10_lmsys_models_with_a/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/vrQ98WHCObyIKaUSsC_cjzHZfMprk1y9ugKJTbGEQhc.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4b33690b47fabd60a6ce3e21bdf3b238eaebdb8f&quot; alt=&quot;[Project] Compare Top 10 LMSYS Models with a Universal LLM API Library&quot; title=&quot;[Project] Compare Top 10 LMSYS Models with a Universal LLM API Library&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello Langchain community!&lt;/p&gt; &lt;p&gt;I&amp;#39;m excited to share a project we&amp;#39;ve been working on - an open-source &amp;quot;AI Gateway&amp;quot; library that allows you to access and compare 200+ language models from multiple providers using a simple, unified API.&lt;/p&gt; &lt;p&gt;To showcase the capabilities of this library, I&amp;#39;ve created a Google Colab notebook that demonstrates how you can easily compare the top 10 models from the LMSYS leaderboard with just a few lines of code.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s a snippet:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/lcqhryzx0j6d1.png?width=1822&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cf7d055fa0e79117fed5dd8f8dc37498fe43b9e3&quot;&gt;https://preview.redd.it/lcqhryzx0j6d1.png?width=1822&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cf7d055fa0e79117fed5dd8f8dc37498fe43b9e3&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The library handles all the complexities of authenticating and communicating with different provider APIs behind the scenes, allowing you to focus on experimenting with and comparing the models themselves.&lt;/p&gt; &lt;p&gt;Some key features of the AI Gateway library:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Unified API for accessing 200+ LLMs from OpenAI, Anthropic, Google, Ollama, Cohere, Together AI, and more&lt;/li&gt; &lt;li&gt;Compatible with existing OpenAI client libraries for easy integration&lt;/li&gt; &lt;li&gt;Routing capabilities like fallbacks, load balancing, retries&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I believe this library could be incredibly useful for researchers and developers in the Langchain community who want to easily compare and benchmark different LLMs, or build applications that leverage multiple models.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve put the demo notebook link below, I&amp;#39;d love to get your feedback, suggestions, and contributions:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/Portkey-AI/gateway/blob/main/cookbook/use-cases/LMSYS%20Series/comparing-top10-LMSYS-models-with-Portkey.ipynb&quot;&gt;https://github.com/Portkey-AI/gateway/blob/main/cookbook/use-cases/LMSYS%20Series/comparing-top10-LMSYS-models-with-Portkey.ipynb&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EscapedLaughter&quot;&gt; /u/EscapedLaughter &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfp2z5/project_compare_top_10_lmsys_models_with_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfp2z5/project_compare_top_10_lmsys_models_with_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dfp2z5</id><media:thumbnail url="https://external-preview.redd.it/vrQ98WHCObyIKaUSsC_cjzHZfMprk1y9ugKJTbGEQhc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4b33690b47fabd60a6ce3e21bdf3b238eaebdb8f" /><link href="https://www.reddit.com/r/LangChain/comments/1dfp2z5/project_compare_top_10_lmsys_models_with_a/" /><updated>2024-06-14T11:57:45+00:00</updated><published>2024-06-14T11:57:45+00:00</published><title>[Project] Compare Top 10 LMSYS Models with a Universal LLM API Library</title></entry><entry><author><name>/u/vT_Raven</name><uri>https://www.reddit.com/user/vT_Raven</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, I mean no disrespect to anyone but I am having trouble seeing the appeal of using the lang chain. In my opinion I&amp;#39;am at best a beginner there for my view coulde be too shalow. I am hoping to find an anweser to where my blind spots are and what use cases the lang chain is useful for. For example, if I want to build a rag chatbot. I would use Ollama with Chromadb without any libery except for chromadb and requests. I have to admit that it is nice to try different things with lang chain. It is also easier to handle complex files like PDF. &lt;/p&gt; &lt;p&gt;If some of you say I don&amp;#39;t have enough experience, that&amp;#39;s why I don&amp;#39;t get it, the answer is fair enough for me to take a agaib a look at Lang Chain.&lt;/p&gt; &lt;p&gt;But I have already tried to work with the framework 3 times and it always seems too complex for what I want to achieve. All those time i build an Chatbot that allows to interact with an modell with some litte custmasation over envs. And the last time was a Rag Chatbot that allows me to index Websites to get answers about their content.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/vT_Raven&quot;&gt; /u/vT_Raven &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df95xz/why_should_i_use_lang_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df95xz/why_should_i_use_lang_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1df95xz</id><link href="https://www.reddit.com/r/LangChain/comments/1df95xz/why_should_i_use_lang_chain/" /><updated>2024-06-13T20:41:52+00:00</updated><published>2024-06-13T20:41:52+00:00</published><title>Why should i use lang chain?</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfaquj/run_evaluations_with_langtrace/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/OlQpvPg6C80CPbeQqL74YpdIgrAULdbnNlYTTliAWPg.jpg&quot; alt=&quot;Run Evaluations with Langtrace&quot; title=&quot;Run Evaluations with Langtrace&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all,&lt;/p&gt; &lt;p&gt;Its been a while from me, but just wanted to share that we have added support for running automated evals with Langtrace. As a reminder, Langtrace is an open source LLM application observability and evaluations tool. It is open telemetry compatible so no vendor lock-in. You can also self-host and run Langtrace.&lt;/p&gt; &lt;p&gt;We integrated langtrace with inspect AI (&lt;a href=&quot;https://github.com/UKGovernmentBEIS/inspect%5C_ai&quot;&gt;https://github.com/UKGovernmentBEIS/inspect\_ai&lt;/a&gt;). Inspect is an open source evluations tool from the developers of RStudio - you should definitely check it out. I love it.&lt;br/&gt; With langtrace, you can now&lt;/p&gt; &lt;ul&gt; &lt;li&gt;set up tracing in 2 lines of code&lt;/li&gt; &lt;li&gt;annotate and curate datasets&lt;/li&gt; &lt;li&gt;run evaluations against this dataset using Inspect&lt;/li&gt; &lt;li&gt;view results, compare the outputs against models and understand the performance of your app&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So, you can now establish this feedback loop with langtrace.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/qrwn7r1kte6d1.png?width=2304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3c2d7c82abbb329518b35c133c0e7a0e73a6d53d&quot;&gt;https://preview.redd.it/qrwn7r1kte6d1.png?width=2304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3c2d7c82abbb329518b35c133c0e7a0e73a6d53d&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Shown below are some screenshots:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/t45vq2xute6d1.png?width=3156&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c15fc71499ba5c5ccbf0aa566fc78c82730e209&quot;&gt;https://preview.redd.it/t45vq2xute6d1.png?width=3156&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c15fc71499ba5c5ccbf0aa566fc78c82730e209&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/0gwmyz0xte6d1.png?width=3150&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2713ba619e903d2db227d5922e8e9c7a562fb9b7&quot;&gt;https://preview.redd.it/0gwmyz0xte6d1.png?width=3150&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2713ba619e903d2db227d5922e8e9c7a562fb9b7&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Would love get any feedback. Please do try it out and let me know.&lt;/p&gt; &lt;p&gt;Link: &lt;a href=&quot;https://github.com/Scale3-Labs/langtrace&quot;&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfaquj/run_evaluations_with_langtrace/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfaquj/run_evaluations_with_langtrace/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dfaquj</id><media:thumbnail url="https://b.thumbs.redditmedia.com/OlQpvPg6C80CPbeQqL74YpdIgrAULdbnNlYTTliAWPg.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1dfaquj/run_evaluations_with_langtrace/" /><updated>2024-06-13T21:50:44+00:00</updated><published>2024-06-13T21:50:44+00:00</published><title>Run Evaluations with Langtrace</title></entry><entry><author><name>/u/chaitu9701</name><uri>https://www.reddit.com/user/chaitu9701</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;To set the context we have 4 environments predev, dev, testing and production. Our RAG uses langchain for PDF extraction, qdrant(self hosted on kubernetes) for vectorstore and gpt-3.5-turbo-16k for the llm.&lt;/p&gt; &lt;p&gt;We have built a RAG, which worked well(gave correct answers from PDF) on predev. When we moved it to dev, in the initial days its performance(correctness) was bad and eventually got good without any changes, except for minor document update. Then it moved to testing environment where again the same behaviour. Now it&amp;#39;s in prod and again behaves the same. Facing a lot of backlash from client due to this strange behaviour.&lt;/p&gt; &lt;p&gt;It&amp;#39;s the same document, same gpt, but different qdrant hosted different for different environments.&lt;/p&gt; &lt;p&gt;Did anyone experience similar issue? Can anyone explain why the warmup time.&lt;/p&gt; &lt;p&gt;Any help is greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/chaitu9701&quot;&gt; /u/chaitu9701 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df1wnb/rag_performs_differently_in_different_environments/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df1wnb/rag_performs_differently_in_different_environments/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1df1wnb</id><link href="https://www.reddit.com/r/LangChain/comments/1df1wnb/rag_performs_differently_in_different_environments/" /><updated>2024-06-13T15:35:41+00:00</updated><published>2024-06-13T15:35:41+00:00</published><title>RAG performs differently in different environments</title></entry><entry><author><name>/u/ChallengeOk6437</name><uri>https://www.reddit.com/user/ChallengeOk6437</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build a model to take in 5-10 PDFs and answer questions based on them.&lt;/p&gt; &lt;p&gt;This is my flow ==&amp;gt; LlamaParse-&amp;gt;OpenAI ada embeddings -&amp;gt; FAISS vector store -&amp;gt; multi query retriever -&amp;gt; cohere reranker -&amp;gt; OpenAI gpt4o -&amp;gt; results&lt;/p&gt; &lt;p&gt;I also have a part in my retriever stage where I get citations and chunking is done page wise&lt;/p&gt; &lt;p&gt;The questions I ask take anywhere between 25-50 seconds to get an answer and also I am missing out on information, I have made the retriever send back all relevant pages, not just the top 3 relevant pages&lt;/p&gt; &lt;p&gt;Is there anyway to get this under 20 seconds and extract all relevant chunks with keeping in mind I need citations?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ChallengeOk6437&quot;&gt; /u/ChallengeOk6437 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df0apu/rag_model_too_slow/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df0apu/rag_model_too_slow/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1df0apu</id><link href="https://www.reddit.com/r/LangChain/comments/1df0apu/rag_model_too_slow/" /><updated>2024-06-13T14:26:24+00:00</updated><published>2024-06-13T14:26:24+00:00</published><title>RAG Model TOO SLOW</title></entry><entry><author><name>/u/Glittering-Bear5748</name><uri>https://www.reddit.com/user/Glittering-Bear5748</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello guys&lt;/p&gt; &lt;p&gt;i am creating chat bot with QA retrieval using vector DB and i want to add one more feature that is follow up question along with response to current question&lt;br/&gt; can anybody provide me example how implement it ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering-Bear5748&quot;&gt; /u/Glittering-Bear5748 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df5lc7/suggest_5_followup_question_based_on_previous/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df5lc7/suggest_5_followup_question_based_on_previous/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1df5lc7</id><link href="https://www.reddit.com/r/LangChain/comments/1df5lc7/suggest_5_followup_question_based_on_previous/" /><updated>2024-06-13T18:11:38+00:00</updated><published>2024-06-13T18:11:38+00:00</published><title>suggest 5 follow-up question based on previous asked</title></entry><entry><author><name>/u/milkomeda22</name><uri>https://www.reddit.com/user/milkomeda22</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for recommendations on tools for chemists that can be implemented using LLM and LangChain agents. What useful tools or applications do you think can be created with these technologies? I would appreciate any ideas and suggestions.&lt;/p&gt; &lt;p&gt;Which LLMs do you recommend for laboratory automation solutions, and what data processing life cycles can be implemented by agents?&lt;/p&gt; &lt;p&gt;I&amp;#39;m particularly interested in how to work with the Canonical SMILES format using chatbots and modify it through agents.&lt;/p&gt; &lt;p&gt;I&amp;#39;m exploring this topic as a theoretical preparation for a long-term hackathon focused on the automation of chemical laboratories. All solutions will be &lt;strong&gt;published&lt;/strong&gt; and &lt;strong&gt;open source&lt;/strong&gt; after our team’s presentation.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/milkomeda22&quot;&gt; /u/milkomeda22 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dewg6w/seeking_recommendations_tools_for_chemists_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dewg6w/seeking_recommendations_tools_for_chemists_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dewg6w</id><link href="https://www.reddit.com/r/LangChain/comments/1dewg6w/seeking_recommendations_tools_for_chemists_using/" /><updated>2024-06-13T11:11:53+00:00</updated><published>2024-06-13T11:11:53+00:00</published><title>Seeking Recommendations: Tools for Chemists Using Large Language Models and Agents</title></entry><entry><author><name>/u/Capital_learner</name><uri>https://www.reddit.com/user/Capital_learner</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have to make llm chatbit using open ai on flask. Help me to make this. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Capital_learner&quot;&gt; /u/Capital_learner &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1deh52g/need_help_to_make_langchain_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1deh52g/need_help_to_make_langchain_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1deh52g</id><link href="https://www.reddit.com/r/LangChain/comments/1deh52g/need_help_to_make_langchain_chatbot/" /><updated>2024-06-12T20:48:11+00:00</updated><published>2024-06-12T20:48:11+00:00</published><title>Need Help to make langchain chatbot</title></entry><entry><author><name>/u/Borfecao</name><uri>https://www.reddit.com/user/Borfecao</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on a Supervisor with LangGraph for a company internship. My mentor has asked me to create three Agents: &amp;quot;Question Agent&amp;quot;, &amp;quot;Answer Agent&amp;quot;, and &amp;quot;Summarizer Agent&amp;quot;. The input is a PDF, which I need to split by page and add each page to a vectorial database for later use. Each agent will also save its outputs in the vectorial POSTGRES database. Here&amp;#39;s a rough idea of the structure:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Questions Table&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;id (Primary Key)&lt;/li&gt; &lt;li&gt;question (Text)&lt;/li&gt; &lt;li&gt;embedding (Vector)&lt;/li&gt; &lt;li&gt;document_id (Integer)&lt;/li&gt; &lt;li&gt;page_number (Integer)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Answers Table&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;id (Primary Key)&lt;/li&gt; &lt;li&gt;answer (Text)&lt;/li&gt; &lt;li&gt;embedding (Vector)&lt;/li&gt; &lt;li&gt;document_id (Integer)&lt;/li&gt; &lt;li&gt;page_number (Integer)&lt;/li&gt; &lt;li&gt;question_id (Foreign Key to Questions table)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Summaries Table&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;id (Primary Key)&lt;/li&gt; &lt;li&gt;summary (Text)&lt;/li&gt; &lt;li&gt;embedding (Vector)&lt;/li&gt; &lt;li&gt;document_id (Integer)&lt;/li&gt; &lt;li&gt;page_number (Integer)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Documents Table&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;id (Primary Key)&lt;/li&gt; &lt;li&gt;summary (Text)&lt;/li&gt; &lt;li&gt;document_id (Integer)&lt;/li&gt; &lt;li&gt;number_of_pages (Integer)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The workflow is something like this:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Load the document (sanitize the text, embed it, save in &amp;quot;Documents&amp;quot;)&lt;/li&gt; &lt;li&gt;Make a summary of each page (save in &amp;quot;Summaries&amp;quot;)&lt;/li&gt; &lt;li&gt;Generate questions for each page (save in &amp;quot;Questions&amp;quot;)&lt;/li&gt; &lt;li&gt;Answer all the questions generated by the Question Agent, considering the context of the page (save in &amp;quot;Answers&amp;quot;)&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;My biggest question is:&lt;/strong&gt; what tools and agents should I implement for this? Most resources I&amp;#39;ve found online use tools like Tavily Search and Python REPL, which aren&amp;#39;t really helpful for my case. I need to use the Supervisor since it&amp;#39;s a project requirement, and I&amp;#39;m a bit confused about the implementation details, since this would be very easy to implement with simple chains, and the only solution I could come up with is tooless agents...?&lt;/p&gt; &lt;p&gt;Any advice or pointers would be greatly appreciated! Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Borfecao&quot;&gt; /u/Borfecao &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1deaviw/need_help_implementing_supervisor_with_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1deaviw/need_help_implementing_supervisor_with_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1deaviw</id><link href="https://www.reddit.com/r/LangChain/comments/1deaviw/need_help_implementing_supervisor_with_langgraph/" /><updated>2024-06-12T16:28:31+00:00</updated><published>2024-06-12T16:28:31+00:00</published><title>Need Help Implementing Supervisor with LangGraph</title></entry></feed>