<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-04-27T15:27:51+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/ava69_open</name><uri>https://www.reddit.com/user/ava69_open</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, our small engineering team is exploring RAG for querying our massive internal document system. It&amp;#39;s exciting, but also a little overwhelming with all the choices - LLMs, embedding models, vector databases, hyperparameters... you name it!&lt;/p&gt; &lt;p&gt;Here&amp;#39;s what we&amp;#39;re thinking:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Manually create a test set of 10-20 custom Q&amp;amp;As (should we allow multiple answer options?).&lt;/li&gt; &lt;li&gt;Automate deployment of various combinations: different LLMs, hyperparameters, embedding models, etc.&lt;/li&gt; &lt;li&gt;Compare the generated answers to our gold standard answers (thinking ROUGE score for evaluation).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Does this approach sound reasonable? Are there any tools or frameworks out there that can streamline this process for a small team like ours? Any advice would be greatly appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ava69_open&quot;&gt; /u/ava69_open &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8z9h/diving_into_rag_with_a_small_team/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8z9h/diving_into_rag_with_a_small_team/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce8z9h</id><link href="https://www.reddit.com/r/LangChain/comments/1ce8z9h/diving_into_rag_with_a_small_team/" /><updated>2024-04-27T07:47:07+00:00</updated><published>2024-04-27T07:47:07+00:00</published><title>Diving into RAG with a Small Team</title></entry><entry><author><name>/u/QueRoub</name><uri>https://www.reddit.com/user/QueRoub</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a way to get back similarity scores from retrievers?&lt;/p&gt; &lt;p&gt;If not, do you know any reliable function that computes similarity score between user&amp;#39;s query and retrieved chunks?&lt;/p&gt; &lt;p&gt;My issue is that I am working with non-English documents and many custom similarity score computation functions don&amp;#39;t work very accurately. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/QueRoub&quot;&gt; /u/QueRoub &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9fh1/can_you_get_back_similarity_scores_from_retrievers/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9fh1/can_you_get_back_similarity_scores_from_retrievers/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce9fh1</id><link href="https://www.reddit.com/r/LangChain/comments/1ce9fh1/can_you_get_back_similarity_scores_from_retrievers/" /><updated>2024-04-27T08:16:50+00:00</updated><published>2024-04-27T08:16:50+00:00</published><title>Can you get back similarity scores from retrievers?</title></entry><entry><author><name>/u/madwzdri</name><uri>https://www.reddit.com/user/madwzdri</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Are there any libraries that can allow me to create a shareable versions of rag documents using links. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I am looking to create a system that will allow me to share a document using links with an LLM trained using RAG. How would you go about this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/madwzdri&quot;&gt; /u/madwzdri &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cefdw6/sharing_rag_enhanced_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cefdw6/sharing_rag_enhanced_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cefdw6</id><link href="https://www.reddit.com/r/LangChain/comments/1cefdw6/sharing_rag_enhanced_documents/" /><updated>2024-04-27T14:09:11+00:00</updated><published>2024-04-27T14:09:11+00:00</published><title>Sharing RAG enhanced documents</title></entry><entry><author><name>/u/prime_danger</name><uri>https://www.reddit.com/user/prime_danger</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a complex documentation and multiple requirements. I ask a question about a requirement which itself has requirements from the same document. Kindly advice on what should I use and how do I build?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/prime_danger&quot;&gt; /u/prime_danger &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8lzd/how_to_build_an_agent_that_goes_back_and_forth/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce8lzd/how_to_build_an_agent_that_goes_back_and_forth/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce8lzd</id><link href="https://www.reddit.com/r/LangChain/comments/1ce8lzd/how_to_build_an_agent_that_goes_back_and_forth/" /><updated>2024-04-27T07:22:24+00:00</updated><published>2024-04-27T07:22:24+00:00</published><title>How to build an agent that goes back and forth into the vector db</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/learnmachinelearning/comments/1ce70vu/what_is_llm_jailbreak_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce71lz/what_is_llm_jailbreak_explained/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce71lz</id><link href="https://www.reddit.com/r/LangChain/comments/1ce71lz/what_is_llm_jailbreak_explained/" /><updated>2024-04-27T05:44:12+00:00</updated><published>2024-04-27T05:44:12+00:00</published><title>What is LLM Jailbreak explained</title></entry><entry><author><name>/u/Diligent_Eye1248</name><uri>https://www.reddit.com/user/Diligent_Eye1248</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://dly.to/emJTz7UM5hG&quot;&gt;Learn&lt;/a&gt; how to build an anime character generator using LangChain and OpenAI. No HTML or CSS required, just use Streamlit to create a simple web interface. Activate the virtual environment, install the necessary libraries, and run the code. Get creative and generate unique anime character names with different themes, along with wise, dramatic, or humorous quotes. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Diligent_Eye1248&quot;&gt; /u/Diligent_Eye1248 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce7m2u/building_an_anime_character_generator_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce7m2u/building_an_anime_character_generator_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce7m2u</id><link href="https://www.reddit.com/r/LangChain/comments/1ce7m2u/building_an_anime_character_generator_with/" /><updated>2024-04-27T06:18:58+00:00</updated><published>2024-04-27T06:18:58+00:00</published><title>Building an Anime Character Generator with LangChain and OpenAI</title></entry><entry><author><name>/u/Any_Material_2850</name><uri>https://www.reddit.com/user/Any_Material_2850</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am looking for someone who would be willing to coach me and help me get started in building a bot. Am on a Mac. Is this something that someone would be willing to do?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Any_Material_2850&quot;&gt; /u/Any_Material_2850 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce6ndb/looking_for_a_coach_paid/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce6ndb/looking_for_a_coach_paid/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce6ndb</id><link href="https://www.reddit.com/r/LangChain/comments/1ce6ndb/looking_for_a_coach_paid/" /><updated>2024-04-27T05:20:15+00:00</updated><published>2024-04-27T05:20:15+00:00</published><title>Looking for a coach (paid)</title></entry><entry><author><name>/u/typing_username</name><uri>https://www.reddit.com/user/typing_username</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am building a mock interview bot with langchain js and fireworks ai api.&lt;/p&gt; &lt;p&gt;but getting an continuous output like this in the response:&lt;/p&gt; &lt;p&gt;response &amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;{&amp;quot;response&amp;quot;: &amp;quot;Welcome to the interview for the React Developer position! Can you please tell me a little about yourself and why you&amp;#39;re interested in this role?&amp;quot;, &amp;quot;feedback&amp;quot;: null}&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;{&amp;quot;response&amp;quot;: &amp;quot;What experience do you have with React and its ecosystem, and can you give me an example of a project you&amp;#39;ve worked on that you&amp;#39;re particularly proud of?&amp;quot;, &amp;quot;feedback&amp;quot;: null}&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;{&amp;quot;response&amp;quot;: &amp;quot;How do you handle state management in React applications, and have you used any libraries like Redux or MobX in your previous projects?&amp;quot;, &amp;quot;feedback&amp;quot;: null}&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;{&amp;quot;response&amp;quot;: &amp;quot;Can you explain the concept of a &amp;#39;Higher-Order Component&amp;#39; in React and give an example of how you would use it in a real-world scenario?&amp;quot;, &amp;quot;feedback&amp;quot;: null}&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;{&amp;quot;response&amp;quot;: &amp;quot;How do you optimize the performance of a React application, and what tools or techniques have you used in the past to improve rendering efficiency?&amp;quot;, &amp;quot;feedback&amp;quot;: null}&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&lt;/p&gt; &lt;p&gt;sometimes it is returning the code, Can you tell me how to get a single and correct response? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/typing_username&quot;&gt; /u/typing_username &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce742z/need_help_with_llama_3/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce742z/need_help_with_llama_3/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce742z</id><link href="https://www.reddit.com/r/LangChain/comments/1ce742z/need_help_with_llama_3/" /><updated>2024-04-27T05:48:10+00:00</updated><published>2024-04-27T05:48:10+00:00</published><title>Need Help with Llama 3</title></entry><entry><author><name>/u/RoboCoachTech</name><uri>https://www.reddit.com/user/RoboCoachTech</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;It has been a long time since our last update on &lt;a href=&quot;https://github.com/RoboCoachTechnologies/ROScribe&quot;&gt;ROScribe&lt;/a&gt; (an open source tool for robot integration and software generation using LLM). In our first releases of ROScribe, we autogenerated the entire robot software in ROS (in python) using LLMs and LangChain. Then, later on, we trained ROScribe with all open source repositories available on ROS-index (python or C++) to enable a code-retrieval feature.&lt;/p&gt; &lt;p&gt;The last step was to seamlessly combine these two different methods (Code generation &amp;amp; Code retrieval) to create an ultimate solution that first looks at what codes are available and then only generates code for the parts which aren&amp;#39;t available and tie them together. This problem proved to be more challenging that we thought, and it took us a while to get it done.&lt;/p&gt; &lt;p&gt;It is done now. We made our version 0.1.0 release a few days ago.&lt;/p&gt; &lt;p&gt;Here is a short demo that shows a 2D mapping with Lidar using ROScribe v0.1.0:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=AWnC6s2nK-k&quot;&gt;https://www.youtube.com/watch?v=AWnC6s2nK-k&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I will post more details later. For now you can find extra info in our github:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/RoboCoachTechnologies/ROScribe&quot;&gt;https://github.com/RoboCoachTechnologies/ROScribe&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RoboCoachTech&quot;&gt; /u/RoboCoachTech &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdwvui/code_generation_integrated_with_code_retrieval/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdwvui/code_generation_integrated_with_code_retrieval/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cdwvui</id><link href="https://www.reddit.com/r/LangChain/comments/1cdwvui/code_generation_integrated_with_code_retrieval/" /><updated>2024-04-26T21:17:35+00:00</updated><published>2024-04-26T21:17:35+00:00</published><title>Code generation integrated with code retrieval for robot applications using LangChain</title></entry><entry><author><name>/u/QueRoub</name><uri>https://www.reddit.com/user/QueRoub</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have built a RAG application and I am getting back the source file from which the LLM answered a question.&lt;/p&gt; &lt;p&gt;My issue is that a document is always retrieved but the LLM might not give an answer based on that.&lt;/p&gt; &lt;p&gt;I would like to capture this case when I call the chain. &lt;/p&gt; &lt;p&gt;Is that possible?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/QueRoub&quot;&gt; /u/QueRoub &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9jnl/capture_case_where_llm_did_not_find_any_answer_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ce9jnl/capture_case_where_llm_did_not_find_any_answer_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ce9jnl</id><link href="https://www.reddit.com/r/LangChain/comments/1ce9jnl/capture_case_where_llm_did_not_find_any_answer_in/" /><updated>2024-04-27T08:24:37+00:00</updated><published>2024-04-27T08:24:37+00:00</published><title>Capture case where LLM did not find any answer in context</title></entry><entry><author><name>/u/alimhabidi</name><uri>https://www.reddit.com/user/alimhabidi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdvd9a/book_recommendation_mastering_nlp_from/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/sg4at7g9tvwc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=64377b74227d5d75d0bbf2115c0974c1b8b48b5e&quot; alt=&quot;Book recommendation: Mastering NLP from Foundations to LLMs&quot; title=&quot;Book recommendation: Mastering NLP from Foundations to LLMs&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;üöÄ Exciting News! üöÄ The wait is over ‚≠ê&lt;/p&gt; &lt;p&gt;Mastering NLP from Foundations to LLMs: Apply advanced rule-based techniques to LLMs and solve real-world business problems using Python&lt;/p&gt; &lt;p&gt;Hi everyone, I&amp;#39;m thrilled to share with you all that the much-awaited book authored by leading experts Lior Gazit and Meysam Ghaffari, Ph.D. is finally here! üéâ&lt;/p&gt; &lt;p&gt;Enhance your NLP proficiency with modern frameworks like LangChain, explore mathematical foundations and code samples, and gain expert insights into current and future trends&lt;/p&gt; &lt;p&gt;üí° Dive deep into the fascinating world of Natural Language Processing with this comprehensive guide. Whether you&amp;#39;re just starting out or looking to enhance your skills, this book has got you covered.&lt;/p&gt; &lt;p&gt;üîë Key Features: - Learn how to build Python-driven solutions focusing on NLP, LLMs, RAGs, and GPT. - Master embedding techniques and machine learning principles for real-world applications. - Understand the mathematical foundations of NLP and deep learning designs. - Plus, get a free PDF eBook when you purchase the print or Kindle version!&lt;/p&gt; &lt;p&gt;üìò Book Description: From laying down the groundwork of machine learning to exploring advanced concepts like LLMs, this book takes you on an enlightening journey. Dive into linear algebra, optimization, probability, and statistics ‚Äì all the essentials you need to conquer ML and NLP. And the best part? You&amp;#39;ll find practical Python code samples throughout!&lt;/p&gt; &lt;p&gt;By the end, you&amp;#39;ll be delving into the nitty-gritty of LLMs&amp;#39; theory, design, and applications, alongside expert insights on the future trends in NLP.&lt;/p&gt; &lt;p&gt;Not only this, the book features Expert Insights by Stalwarts from the industry : ‚Ä¢ Xavier (Xavi) Amatriain, VP of Product, Core ML/AI, Google ‚Ä¢ Melanie Garson, Cyber Policy &amp;amp; Tech Geopolitics Lead at Tony Blair Institute for Global Change, and Associate Professor at University College London ‚Ä¢ Nitzan Mekel-Bobrov, Ph.D., CAIO, Ebay ‚Ä¢ David Sontag, Professor at MIT and CEO at Layer Health ‚Ä¢ John Halamka, M.D., M.S., president of the Mayo Clinic Platform&lt;/p&gt; &lt;p&gt;Foreword and Impressions by leading Expert Asha Saxena&lt;/p&gt; &lt;p&gt;üîç What You Will Learn: - Master the mathematical foundations of machine learning and NLP. - Implement advanced techniques for preprocessing text data and analysis. - Design ML-NLP systems in Python. - Model and classify text using traditional and deep learning methods. - Explore the theory and design of LLMs and their real-world applications. - Get a sneak peek into the future of NLP with expert opinions and insights.&lt;/p&gt; &lt;p&gt;üì¢ Don&amp;#39;t miss out on this incredible opportunity to expand your NLP skills! Grab your copy now and embark on an exciting learning journey.&lt;/p&gt; &lt;p&gt;Amazon US &lt;a href=&quot;https://www.amazon.com/Mastering-NLP-Foundations-LLMs-Techniques/dp/1804619183/&quot;&gt;https://www.amazon.com/Mastering-NLP-Foundations-LLMs-Techniques/dp/1804619183/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/alimhabidi&quot;&gt; /u/alimhabidi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/sg4at7g9tvwc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdvd9a/book_recommendation_mastering_nlp_from/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cdvd9a</id><media:thumbnail url="https://preview.redd.it/sg4at7g9tvwc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=64377b74227d5d75d0bbf2115c0974c1b8b48b5e" /><link href="https://www.reddit.com/r/LangChain/comments/1cdvd9a/book_recommendation_mastering_nlp_from/" /><updated>2024-04-26T20:15:23+00:00</updated><published>2024-04-26T20:15:23+00:00</published><title>Book recommendation: Mastering NLP from Foundations to LLMs</title></entry><entry><author><name>/u/QueRoub</name><uri>https://www.reddit.com/user/QueRoub</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Are there any resources about RAG application that uses as knowledge base either excel files or Databases? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/QueRoub&quot;&gt; /u/QueRoub &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdmqk8/any_resources_for_rag_with_excel_files_or/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdmqk8/any_resources_for_rag_with_excel_files_or/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cdmqk8</id><link href="https://www.reddit.com/r/LangChain/comments/1cdmqk8/any_resources_for_rag_with_excel_files_or/" /><updated>2024-04-26T14:23:55+00:00</updated><published>2024-04-26T14:23:55+00:00</published><title>Any resources for RAG with excel files or Databases?</title></entry><entry><author><name>/u/Calm-Number5851</name><uri>https://www.reddit.com/user/Calm-Number5851</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdstt4/make_time_for_family_hack_your_productivity/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/GFWHkLpYs8nwkeJNsP6AIG4bVuIQSQDqq4O1VyQCBAA.jpg&quot; alt=&quot;Make Time For Family, Hack Your Productivity &amp;amp; Goblins?&quot; title=&quot;Make Time For Family, Hack Your Productivity &amp;amp; Goblins?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This post is the awaited part 2 of our last edition ‚Äì ‚ÄúWhat Are LLMs &amp;amp; How They Can Save You 800 Hours This Year‚Äù, which you can read here if you haven‚Äôt already: &lt;/p&gt; &lt;p&gt;we‚Äôll be finishing up on the best LLM-based tools to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Add More Time To Your Day&lt;/strong&gt; ‚Äî the most powerful calendar &amp;amp; time management tools available.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Browse Like You‚Äôre From The Future&lt;/strong&gt; ‚Äî intelligent webpilots that cut your browsing time in half.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Hack Your Productivity&lt;/strong&gt; ‚Äî 4x your productivity using tools that interlink &amp;amp; bring order to your notes.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Can‚Äôt Make Time For Your Family?&lt;/strong&gt;Let‚Äôs be honest, balancing work and life is difficult. Most of us struggle to find the time to spend with our families, for leisure and rest. Fortunately enough, LLM-based calendar tools can efficiently time block your day so that you have time for everything ‚Äì meetings, family, leisure, sleep, and deep work.&lt;br/&gt; These tools can actually show you where your free time really lies, and if you don‚Äôt have any ‚Äî it will create it. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/8ogyz3bnavwc1.jpg?width=1000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4df551684af2f85f1c303630dd0b5d1b33386b60&quot;&gt;https://preview.redd.it/8ogyz3bnavwc1.jpg?width=1000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=4df551684af2f85f1c303630dd0b5d1b33386b60&lt;/a&gt;&lt;/p&gt; &lt;p&gt;These intelligent tools understand your preferences and priorities, helping to arrange your commitments in a way that maximizes efficiency ‚Äî they can handle the back-and-forth of scheduling meetings, suggest optimal times for your appointments based on your habits, and even remind you of important family events.&lt;/p&gt; &lt;p&gt;If you want to be at the top of your game and still make time for friends, family &amp;amp; yourself, you should be using an LLM-based calendar solution.&lt;/p&gt; &lt;p&gt;Let‚Äôs explore the best calendar &amp;amp; time management tools that can give you time to do the things you love, with the people you love!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm-Number5851&quot;&gt; /u/Calm-Number5851 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdstt4/make_time_for_family_hack_your_productivity/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdstt4/make_time_for_family_hack_your_productivity/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cdstt4</id><media:thumbnail url="https://b.thumbs.redditmedia.com/GFWHkLpYs8nwkeJNsP6AIG4bVuIQSQDqq4O1VyQCBAA.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1cdstt4/make_time_for_family_hack_your_productivity/" /><updated>2024-04-26T18:31:49+00:00</updated><published>2024-04-26T18:31:49+00:00</published><title>Make Time For Family, Hack Your Productivity &amp; Goblins?</title></entry><entry><author><name>/u/Just_Guide7361</name><uri>https://www.reddit.com/user/Just_Guide7361</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, I am trying to build a RAG Q&amp;amp;A chain, with memory (chat history). While the invoke function works perfectly fine and allows me to extract the answer, the stream does not. I&amp;#39;ve followed the documentation: &lt;a href=&quot;https://python.langchain.com/docs/use_cases/question_answering/chat_history/#tying-it-together&quot;&gt;https://python.langchain.com/docs/use_cases/question_answering/chat_history/#tying-it-together&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;The only change is as follows:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# This works perfectly fine: conversational_rag_chain.invoke( {&amp;quot;input&amp;quot;: &amp;quot;What is Task Decomposition 2?&amp;quot;}, config={&amp;quot;configurable&amp;quot;: {&amp;quot;session_id&amp;quot;: &amp;quot;abc123&amp;quot;}}, # constructs a key &amp;quot;abc123&amp;quot; in `store`. )[&amp;#39;answer&amp;#39;] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# This does not work - it streams back everything and i can not extract the answer for chuck in conversational_rag_chain.stream( {&amp;quot;input&amp;quot;: &amp;quot;What is Task Decomposition 2?&amp;quot;}, config={&amp;quot;configurable&amp;quot;: {&amp;quot;session_id&amp;quot;: &amp;quot;abc123&amp;quot;}}, # constructs a key &amp;quot;abc123&amp;quot; in `store`. ): print(chuck) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# I have also tried the following but none works; print(chuck[&amp;#39;answer&amp;#39;]) print(chuck.content) print(chuck.content[&amp;#39;answer&amp;#39;]) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Any suggestion or ideas on how to make this work? Seems like very normal behaviour to expect from a stream function?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Just_Guide7361&quot;&gt; /u/Just_Guide7361 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdmey2/how_to_make_streaming_work_with_a_rag_qa_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdmey2/how_to_make_streaming_work_with_a_rag_qa_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cdmey2</id><link href="https://www.reddit.com/r/LangChain/comments/1cdmey2/how_to_make_streaming_work_with_a_rag_qa_chain/" /><updated>2024-04-26T14:10:41+00:00</updated><published>2024-04-26T14:10:41+00:00</published><title>How to make streaming work with a RAG Q&amp;A chain with memory</title></entry><entry><author><name>/u/ava69_open</name><uri>https://www.reddit.com/user/ava69_open</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a way to throw one prompt at all the big LLMs (GPT-3, Bard, you name it) and see their responses side-by-side? I know LangChain might be an option for local development, but I was wondering if there are any existing tools out there.&lt;/p&gt; &lt;p&gt;Imagine the time saved! No more copy-pasting the same prompt across different platforms just to compare answers and check accuracy. Anyone else feeling this struggle?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ava69_open&quot;&gt; /u/ava69_open &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdawva/tool_to_compare_llm_outputs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdawva/tool_to_compare_llm_outputs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cdawva</id><link href="https://www.reddit.com/r/LangChain/comments/1cdawva/tool_to_compare_llm_outputs/" /><updated>2024-04-26T03:09:59+00:00</updated><published>2024-04-26T03:09:59+00:00</published><title>Tool to compare LLM Outputs</title></entry><entry><author><name>/u/mrDalliard2024</name><uri>https://www.reddit.com/user/mrDalliard2024</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello guys, I have been banging my head against the wall for the past few days trying to make this work. Hope you guys can help me. Here&amp;#39;s the setup:&lt;/p&gt; &lt;p&gt;My vectorstore has two collections, one with keywords and another with the actual documents for retrieval. Both collections have page number as metadata, and that&amp;#39;s how they relate to each other. For example, in the keyword store I would have a doc like this:&lt;/p&gt; &lt;p&gt;&lt;code&gt;Document(page_content=&amp;quot;SomeKeyword&amp;quot;, metadata={&amp;#39;pages&amp;#39;: &amp;#39;23, 29&amp;#39;})&lt;/code&gt;&lt;/p&gt; &lt;p&gt;While in the documents store I would have:&lt;/p&gt; &lt;p&gt;&lt;code&gt;Document(page_content=&amp;quot;Lorem ipsum etc etc etc...&amp;quot;, metadata={&amp;#39;page&amp;#39;: 23})&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Then my chain looks basically like this: first we search the keyword store and return the matches. Then we feed this documents into a function that returns a list of relevant page numbers (a `list[int]`). Then we want the search on the document store to be filtered by the list of relevant page numbers, so that we improve accuracy and speed.&lt;/p&gt; &lt;p&gt;I can do this just fine if I manually construct this chain, but if I want to take advantage of LCEL, I can&amp;#39;t find a way to dynamically set this filter on the chain. Here&amp;#39;s what I have:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;user_input = {&amp;quot;question&amp;quot;: &amp;quot;What is unrest?&amp;quot;} keyword_retrieval = RunnableParallel(keywords=itemgetter(&amp;quot;question&amp;quot;) | keywords.as_retriever(search_type=&amp;quot;similarity_score_threshold&amp;quot;, search_kwargs={&amp;quot;score_threshold&amp;quot;: 0.4}),question=itemgetter(&amp;quot;question&amp;quot;), ) page_nums = RunnableParallel(page_nums=itemgetter(&amp;quot;keywords&amp;quot;) | RunnableLambda(get_page_nums),question=itemgetter(&amp;quot;question&amp;quot;), ) docs_retrieval = RunnableParallel(context=itemgetter(&amp;quot;question&amp;quot;) | docs.as_retriever(search_kwargs={&amp;quot;filter&amp;quot;: {&amp;quot;page&amp;quot;: {&amp;quot;$in&amp;quot;: itemgetter(&amp;quot;page_nums&amp;quot;)}}}),question=itemgetter(&amp;quot;question&amp;quot;), ) chain = keyword_retrieval | page_nums | docs_retrieval | prompt | llm &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The above fails with&lt;/p&gt; &lt;pre&gt;&lt;code&gt;.venv\Lib\site-packages\chromadb\api\types.py&amp;quot;, line 364, in validate_where raise ValueError( ValueError: Expected operand value to be an list for operator $in, got operator.itemgetter(&amp;#39;page_nums&amp;#39;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Is there any way to make this work? Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mrDalliard2024&quot;&gt; /u/mrDalliard2024 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdltdd/setting_search_kwargs_dynamically_based_on/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdltdd/setting_search_kwargs_dynamically_based_on/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cdltdd</id><link href="https://www.reddit.com/r/LangChain/comments/1cdltdd/setting_search_kwargs_dynamically_based_on/" /><updated>2024-04-26T13:45:23+00:00</updated><published>2024-04-26T13:45:23+00:00</published><title>Setting search_kwargs dynamically based on previous chain step</title></entry><entry><author><name>/u/ArcuisAlezanzo</name><uri>https://www.reddit.com/user/ArcuisAlezanzo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Anyone can provide good explanations or articles of creating custom agent ? I&amp;#39;m looking for Creating agent using agent class so we can control agent finish and agent action .&lt;/p&gt; &lt;p&gt;Sub question:&lt;/p&gt; &lt;p&gt;How tool calling automatically break complex question into subs questions ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ArcuisAlezanzo&quot;&gt; /u/ArcuisAlezanzo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdi80s/agents_guide/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdi80s/agents_guide/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cdi80s</id><link href="https://www.reddit.com/r/LangChain/comments/1cdi80s/agents_guide/" /><updated>2024-04-26T10:46:57+00:00</updated><published>2024-04-26T10:46:57+00:00</published><title>Agents guide</title></entry><entry><author><name>/u/UpskillingDS17</name><uri>https://www.reddit.com/user/UpskillingDS17</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I have a pdf where some Return in % is under 4 categories such as A, B and so on. When I ask question using Llama3 it is returning the correct answer but it is picking the Return from A rather than knowing from which category the Return should be picked from? How can I make LLM return the output saying which category rather than picking the answer from category A ? Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpskillingDS17&quot;&gt; /u/UpskillingDS17 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdm2tx/how_to_make_llm_return_question_to_be_more/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdm2tx/how_to_make_llm_return_question_to_be_more/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cdm2tx</id><link href="https://www.reddit.com/r/LangChain/comments/1cdm2tx/how_to_make_llm_return_question_to_be_more/" /><updated>2024-04-26T13:57:01+00:00</updated><published>2024-04-26T13:57:01+00:00</published><title>How to make LLM return question to be more specific rather than throwing output?</title></entry><entry><author><name>/u/UpskillingDS17</name><uri>https://www.reddit.com/user/UpskillingDS17</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I was trying RAG using Llama3 and the input prompt is different as compared to other LLMs. How I can know which kind of prompts work best for a specific LLM as prompt used in LLama3 was very different and uses &amp;lt;eos&amp;gt; and etc etc. Is there any template for different LLMs?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpskillingDS17&quot;&gt; /u/UpskillingDS17 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdisrq/how_to_stay_up_to_date_with_prompts_for_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdisrq/how_to_stay_up_to_date_with_prompts_for_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cdisrq</id><link href="https://www.reddit.com/r/LangChain/comments/1cdisrq/how_to_stay_up_to_date_with_prompts_for_llms/" /><updated>2024-04-26T11:19:35+00:00</updated><published>2024-04-26T11:19:35+00:00</published><title>How to stay up to date with prompts for LLMs</title></entry><entry><author><name>/u/ravediamond000</name><uri>https://www.reddit.com/user/ravediamond000</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, &lt;/p&gt; &lt;p&gt;Just wrote and article on two underestimated (and mostly unknown) features of Langchain to create completely configurable chains while still being production ready. This is actually what I use in my own production chains.&lt;br/&gt; Here&amp;#39;s the link: &lt;a href=&quot;https://www.metadocs.co/2024/04/25/two-underestimated-langchain-features-to-create-production-ready-configurable-chains/&quot;&gt;https://www.metadocs.co/2024/04/25/two-underestimated-langchain-features-to-create-production-ready-configurable-chains/&lt;/a&gt; &lt;/p&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ravediamond000&quot;&gt; /u/ravediamond000 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ccxg2l/two_underestimated_langchain_features_to_create/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ccxg2l/two_underestimated_langchain_features_to_create/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ccxg2l</id><link href="https://www.reddit.com/r/LangChain/comments/1ccxg2l/two_underestimated_langchain_features_to_create/" /><updated>2024-04-25T17:47:37+00:00</updated><published>2024-04-25T17:47:37+00:00</published><title>Two underestimated Langchain features to create production-ready configurable chains</title></entry><entry><author><name>/u/sarthak_uchiha</name><uri>https://www.reddit.com/user/sarthak_uchiha</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi guys do anyone know how to convert .msg files to.pdf , msg files may contains IMG in the body , I tried some thing but it was not able to take the IMG in the body, need for a usecase that the whole data gets converted into the pdf including the images &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sarthak_uchiha&quot;&gt; /u/sarthak_uchiha &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdf17a/msg_files_to_pdf/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cdf17a/msg_files_to_pdf/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cdf17a</id><link href="https://www.reddit.com/r/LangChain/comments/1cdf17a/msg_files_to_pdf/" /><updated>2024-04-26T07:08:18+00:00</updated><published>2024-04-26T07:08:18+00:00</published><title>.msg files to .pdf</title></entry><entry><author><name>/u/Any-Demand-2928</name><uri>https://www.reddit.com/user/Any-Demand-2928</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;For those of you who build your frontend UI in React, what library are you using to create the actual chat part of the website? For example, displaying messages, being able to send messages using a chat box, etc...&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Any-Demand-2928&quot;&gt; /u/Any-Demand-2928 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cd31v4/what_react_library_do_you_use_to_build_the_actual/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cd31v4/what_react_library_do_you_use_to_build_the_actual/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cd31v4</id><link href="https://www.reddit.com/r/LangChain/comments/1cd31v4/what_react_library_do_you_use_to_build_the_actual/" /><updated>2024-04-25T21:16:41+00:00</updated><published>2024-04-25T21:16:41+00:00</published><title>What React Library do you use to build the actual Chat Interface?</title></entry><entry><author><name>/u/fokke2508</name><uri>https://www.reddit.com/user/fokke2508</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi All,&lt;/p&gt; &lt;p&gt;I work for a startup that is developing a platform to easily build GenAI-infused applications. As part of our platform, we are starting a community-based building blocks library (sort of like an app store).&lt;/p&gt; &lt;p&gt;We are about to release the community-based components and I would love to fill it up a bit more with great building blocks. Wondering if there are people here that would want to contribute?&lt;/p&gt; &lt;p&gt;I can provide you with the resources to build anything you want, including vector stores, LLMs etc.&lt;br/&gt; The idea is that each building block should help you and others build LLM apps more easily. For example, we might have a building block that provides a specific RAG task or one that converts a PDF into vectors. Could be langchain based but does not have to. &lt;/p&gt; &lt;p&gt;I don&amp;#39;t want to turn this too much into a sales pitch so I&amp;#39;ll stop there, would love to hear if anyone is interested in contributing.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/fokke2508&quot;&gt; /u/fokke2508 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cd1roj/community_created_building_blocks_for_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cd1roj/community_created_building_blocks_for_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cd1roj</id><link href="https://www.reddit.com/r/LangChain/comments/1cd1roj/community_created_building_blocks_for_llms/" /><updated>2024-04-25T20:27:55+00:00</updated><published>2024-04-25T20:27:55+00:00</published><title>Community created building blocks for LLMs</title></entry><entry><author><name>/u/Extreme-Berry7898</name><uri>https://www.reddit.com/user/Extreme-Berry7898</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to use a row from a table to retrieve K rows related to it. One element of each row is a vector, so a row is a vector group. So what I need to do is retrieve the vector group using the vector group. I have no idea how to accomplish this task, can you give me some advice?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Extreme-Berry7898&quot;&gt; /u/Extreme-Berry7898 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cd9ywg/vector_group_based_retrieval/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cd9ywg/vector_group_based_retrieval/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cd9ywg</id><link href="https://www.reddit.com/r/LangChain/comments/1cd9ywg/vector_group_based_retrieval/" /><updated>2024-04-26T02:22:19+00:00</updated><published>2024-04-26T02:22:19+00:00</published><title>Vector group based retrieval</title></entry><entry><author><name>/u/Calm_Pea_2428</name><uri>https://www.reddit.com/user/Calm_Pea_2428</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to ask natural-language questions to collections. For example: for sales collection, ‚ÄúWhats the average quantity sold in the past 3 months?&amp;quot;. I got about 10 collections. About 100K rows each and 25 columns each and this data is updated daily. Apart from mongo, If you have developed this kind of application using any database please add your suggestions. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm_Pea_2428&quot;&gt; /u/Calm_Pea_2428 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ccv7qg/build_a_rag_application_with_large_knowledge_base/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ccv7qg/build_a_rag_application_with_large_knowledge_base/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ccv7qg</id><link href="https://www.reddit.com/r/LangChain/comments/1ccv7qg/build_a_rag_application_with_large_knowledge_base/" /><updated>2024-04-25T15:43:16+00:00</updated><published>2024-04-25T15:43:16+00:00</published><title>Build a RAG application with large knowledge base</title></entry></feed>