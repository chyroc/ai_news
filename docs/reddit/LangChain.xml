<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-02-02T20:10:43+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/ashpreetbedi</name><uri>https://www.reddit.com/user/ashpreetbedi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, I built a chat with PDF using RAG but was struggling to get good results by just prompt stuffing. So I built an advanced PDF AI that uses function calling to intelligently figure out if:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The question needs retrieval from a document or a web search&lt;/li&gt; &lt;li&gt;If it needs retrieval, does it need to search the latest doc, a specific doc or all docs&lt;/li&gt; &lt;li&gt;Produces an answer using the context retrieved&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Give it a spin at: &lt;a href=&quot;https://pdf.aidev.run/&quot;&gt;https://pdf.aidev.run&lt;/a&gt; and let me know what you think. Looking for feedback so I can fix and improve. Here’s the &lt;a href=&quot;https://github.com/phidatahq/ai-cookbook/tree/main/pdf_ai&quot;&gt;code&lt;/a&gt; if you’re interested and I used &lt;a href=&quot;https://github.com/phidatahq/phidata&quot;&gt;phidata&lt;/a&gt; to build this.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://reddit.com/link/1ah1l5f/video/zbz2hm1aq5gc1/player&quot;&gt;https://reddit.com/link/1ah1l5f/video/zbz2hm1aq5gc1/player&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashpreetbedi&quot;&gt; /u/ashpreetbedi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah1l5f/chat_with_pdfs_using_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah1l5f/chat_with_pdfs_using_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah1l5f</id><link href="https://www.reddit.com/r/LangChain/comments/1ah1l5f/chat_with_pdfs_using_function_calling/" /><updated>2024-02-02T11:30:49+00:00</updated><published>2024-02-02T11:30:49+00:00</published><title>Chat with PDFs using function calling</title></entry><entry><author><name>/u/dragon_4789</name><uri>https://www.reddit.com/user/dragon_4789</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been working on a project where I extract information from a large PDF document. I&amp;#39;ve completed the initial steps, including reading the PDF, splitting it into chunks, converting them to embeddings, and storing them in a vector database.&lt;/p&gt; &lt;p&gt;For the next step, I perform a similarity check with a limit of 28. Each chunk has a size of 350, with an overlap of 80. After that, I send these chunks to GPT with a specific question. GPT provides answers, but I&amp;#39;m struggling to determine from which chunk the answer originated.&lt;/p&gt; &lt;p&gt;Is there a way to identify the specific chunk(s) that GPT used to generate the answer? Alternatively, is there a solution to get an array of chunks that may contain the answer out of the 28 available?&lt;/p&gt; &lt;p&gt;Any insights or suggestions on how to achieve this would be greatly appreciated!&lt;/p&gt; &lt;p&gt;Thanks in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/dragon_4789&quot;&gt; /u/dragon_4789 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah5zg3/extracting_answer_source_chunks_from_gpt/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah5zg3/extracting_answer_source_chunks_from_gpt/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah5zg3</id><link href="https://www.reddit.com/r/LangChain/comments/1ah5zg3/extracting_answer_source_chunks_from_gpt/" /><updated>2024-02-02T15:13:34+00:00</updated><published>2024-02-02T15:13:34+00:00</published><title>Extracting Answer Source Chunks from GPT Responses in Langchain</title></entry><entry><author><name>/u/Dramatic-Tutor4352</name><uri>https://www.reddit.com/user/Dramatic-Tutor4352</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, all,&lt;/p&gt; &lt;p&gt;I got embedding and retrieval function based on langchain. &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;code&gt;def embed(source_directory , chunk_size, chunk_overlap, db_name = &amp;quot;faiss&amp;quot;):&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;print(f&amp;quot;Loading documents from {source_directory}&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;documents = load_documents(source_directory)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;# Defining Text Splitter&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;texts = text_splitter.split_documents(documents)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;print(f&amp;quot;Loaded {len(documents)} documents from {source_directory}&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;print(f&amp;quot;Split into {len(texts)} chunks of text (max. {chunk_size} characters each)&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;if db_name.lower() == &amp;quot;chroma&amp;quot;:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;db = Chroma.from_documents(texts, embeddings)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;elif db_name.lower() == &amp;quot;faiss&amp;quot;:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;db = FAISS.from_documents(texts, embeddings)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;else:&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;print(&amp;quot;Only FIASS, Chroma are accepted&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;#return&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;retriever_openai = db.as_retriever(search_kwargs={&amp;quot;k&amp;quot;: 4})&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;# create the chain to answer questions&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;qa_chain_openai = RetrievalQA.from_chain_type(llm=llm,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;chain_type=&amp;quot;stuff&amp;quot;,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;retriever=retriever_openai,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;return_source_documents=True)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;return qa_chain_openai&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;code&gt;QA = embed(&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;source_directory=&amp;#39;/data/home/&amp;#39;,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;chunk_size=1000,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;chunk_overlap=200,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;db_name=&amp;#39;faiss&amp;#39;,&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;Ans=QA(&amp;quot;what is PDX?&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;print(Ans)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;and the results of &amp;#39;print&amp;#39; is&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Loading documents from /data/home/ &lt;/p&gt; &lt;p&gt;Loaded 2 documents from /data/home/&lt;/p&gt; &lt;p&gt;Split into 43 chunks of text (max. 1000 characters each) &lt;/p&gt; &lt;p&gt;{&amp;#39;query&amp;#39;: &amp;#39;what is PDX?&amp;#39;, &amp;#39;result&amp;#39;: &amp;quot;PDX stands for patient-derived xenografts. It is a process where tissues or cells from a patient&amp;#39;s biopsy or tumor excision are implanted into an immunodeficient or humanized mouse. These PDX models can be used to simulate human tumor biology and offer a translational research model for evaluating efficacy.&amp;quot;, &amp;#39;source_documents&amp;#39;: [Document(page_content=&amp;#39;A is committed to developing PDX models to build an in-house PDX repository for \ntesting the efficacy of various preclinical drug candidates. This ongoing effort has the goal of \nhistopathological characterization of PDX tumors after one passage in mice. \n\nThe goal of the current study was to characterize a PDX model from a patient with the diagnosis of \nbladder carcinoma. \n\n2.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;it includes the symble \n.... &lt;/p&gt; &lt;p&gt;I would like to make python print new line instead of \n on screen, how can I do that?&lt;/p&gt; &lt;p&gt;many thanks&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Dramatic-Tutor4352&quot;&gt; /u/Dramatic-Tutor4352 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahc5rf/langchain_output_print_with_format/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ahc5rf/langchain_output_print_with_format/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ahc5rf</id><link href="https://www.reddit.com/r/LangChain/comments/1ahc5rf/langchain_output_print_with_format/" /><updated>2024-02-02T19:36:49+00:00</updated><published>2024-02-02T19:36:49+00:00</published><title>langchain output print with format</title></entry><entry><author><name>/u/eschxr</name><uri>https://www.reddit.com/user/eschxr</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A vast majority of Generative AI solutions are delivered in a chat based user experience. &lt;/p&gt; &lt;p&gt;I&amp;#39;ve created a tutorial on how to quickly adapt an open-source framework to deliver that user experience within 15 minutes. &lt;/p&gt; &lt;p&gt;I hope the community finds this useful!&lt;/p&gt; &lt;p&gt;![&lt;a href=&quot;https://youtu.be/sZ1aJ0zfgmY?si=koLhtl_FO6-y3SC5%5D(https://youtu.be/sZ1aJ0zfgmY?si=koLhtl_FO6-y3SC5)&quot;&gt;https://youtu.be/sZ1aJ0zfgmY?si=koLhtl_FO6-y3SC5](https://youtu.be/sZ1aJ0zfgmY?si=koLhtl_FO6-y3SC5)&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/eschxr&quot;&gt; /u/eschxr &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah55wi/chatgpt_like_ui_for_any_project_within_15_mins/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah55wi/chatgpt_like_ui_for_any_project_within_15_mins/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah55wi</id><link href="https://www.reddit.com/r/LangChain/comments/1ah55wi/chatgpt_like_ui_for_any_project_within_15_mins/" /><updated>2024-02-02T14:37:41+00:00</updated><published>2024-02-02T14:37:41+00:00</published><title>ChatGPT like UI for any project within 15 mins</title></entry><entry><author><name>/u/Various-Squash4836</name><uri>https://www.reddit.com/user/Various-Squash4836</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have lots of documents, they contain procedures to operate a software and it also include images. Now my question is how do i build a custom LLM that would be capable of answering the user with text and also provide the appropriate image from the document&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Various-Squash4836&quot;&gt; /u/Various-Squash4836 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah74n8/document_qa_also_include_images/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah74n8/document_qa_also_include_images/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah74n8</id><link href="https://www.reddit.com/r/LangChain/comments/1ah74n8/document_qa_also_include_images/" /><updated>2024-02-02T16:04:47+00:00</updated><published>2024-02-02T16:04:47+00:00</published><title>Document Q&amp;A, also include images</title></entry><entry><author><name>/u/ContributionFun3037</name><uri>https://www.reddit.com/user/ContributionFun3037</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to implement conversation buffer memory with react, but for some reason it doesn&amp;#39;t work. I followed the docs in langchain i.e &lt;a href=&quot;https://js.langchain.com/docs/modules/memory/types/buffer_window&quot;&gt;Conversation buffer window memory | 🦜️🔗 Langchain&lt;/a&gt; , the code simply doesn&amp;#39;t work.&lt;/p&gt; &lt;p&gt;However using BufferMemory works(I followed the code as given in the docs)&lt;a href=&quot;https://js.langchain.com/docs/modules/memory/types/buffer_window&quot;&gt;Conversation buffer window memory | 🦜️🔗 Langchain&lt;/a&gt; .&lt;/p&gt; &lt;p&gt;My code with BufferWIndow Memory&lt;/p&gt; &lt;pre&gt;&lt;code&gt;const memory = new BufferWindowMemory({ k: 1 }); console.log(memory.chatHistory); try { const chain = new ConversationChain({ llm: model, memory: memory, }); const response = await chain.call({ input: question, }); console.log(response); return { success: true, response }; } catch (error) { console.log(error); } }; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I&amp;#39;m using Gemini API, and I get answers from Gemini, but the memory doesn&amp;#39;t seem to work.Can anybody please tell me what I&amp;quot;m doing wrong?I tried using ChatPromptTemplate as well, but the memory isn&amp;#39;t working at all. Please help!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ContributionFun3037&quot;&gt; /u/ContributionFun3037 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah180z/conversation_memory_not_working_with_react/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah180z/conversation_memory_not_working_with_react/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah180z</id><link href="https://www.reddit.com/r/LangChain/comments/1ah180z/conversation_memory_not_working_with_react/" /><updated>2024-02-02T11:06:56+00:00</updated><published>2024-02-02T11:06:56+00:00</published><title>Conversation Memory not working with react.</title></entry><entry><author><name>/u/phantom69_ftw</name><uri>https://www.reddit.com/user/phantom69_ftw</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agvm60/a_gentle_introduction_to_ai_chat_bot_concepts/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/Tydy7yry658D88ysN1z7n3ImZWhwg7C4Os3zDBdiMCM.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e4f33e5a5c7fac2dee07d795edc43e0b1fdf9680&quot; alt=&quot;A Gentle Introduction to AI Chat Bot Concepts: Basics of Embedding and Vector DBs&quot; title=&quot;A Gentle Introduction to AI Chat Bot Concepts: Basics of Embedding and Vector DBs&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phantom69_ftw&quot;&gt; /u/phantom69_ftw &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.dsdev.in/a-gentle-introduction-to-ai-chat-bot-concepts&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agvm60/a_gentle_introduction_to_ai_chat_bot_concepts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1agvm60</id><media:thumbnail url="https://external-preview.redd.it/Tydy7yry658D88ysN1z7n3ImZWhwg7C4Os3zDBdiMCM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e4f33e5a5c7fac2dee07d795edc43e0b1fdf9680" /><link href="https://www.reddit.com/r/LangChain/comments/1agvm60/a_gentle_introduction_to_ai_chat_bot_concepts/" /><updated>2024-02-02T04:52:13+00:00</updated><published>2024-02-02T04:52:13+00:00</published><title>A Gentle Introduction to AI Chat Bot Concepts: Basics of Embedding and Vector DBs</title></entry><entry><author><name>/u/HappyDataGuy</name><uri>https://www.reddit.com/user/HappyDataGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build a text to sql bot based off of llama-index. The problem is tables have 100s of columns. What llama-index does is put complete create table script of table in model context along with user question to generate sql query and subsequent answer. But if there is need to join multiples tables and they have alot of column its not very efficient and may not even work. How can I solve this problem? Also if some of those columns have enums how can I make the sql bot understand meaning of those enums?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HappyDataGuy&quot;&gt; /u/HappyDataGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agxb0u/how_to_solve_schema_problems_in_texttosql_bot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agxb0u/how_to_solve_schema_problems_in_texttosql_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agxb0u</id><link href="https://www.reddit.com/r/LangChain/comments/1agxb0u/how_to_solve_schema_problems_in_texttosql_bot/" /><updated>2024-02-02T06:32:01+00:00</updated><published>2024-02-02T06:32:01+00:00</published><title>How to solve schema problems in text-to-sql bot?</title></entry><entry><author><name>/u/Available-Dig7628</name><uri>https://www.reddit.com/user/Available-Dig7628</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to go though code of any good rag based chatbot. Can you suggest any open-source project&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Available-Dig7628&quot;&gt; /u/Available-Dig7628 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agfnox/is_there_any_good_rag_based_opensource_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agfnox/is_there_any_good_rag_based_opensource_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agfnox</id><link href="https://www.reddit.com/r/LangChain/comments/1agfnox/is_there_any_good_rag_based_opensource_chatbot/" /><updated>2024-02-01T16:56:50+00:00</updated><published>2024-02-01T16:56:50+00:00</published><title>is there any good rag based open-source chatbot codebase</title></entry><entry><author><name>/u/ronittsainii</name><uri>https://www.reddit.com/user/ronittsainii</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello Everyone I have written a blog on &lt;a href=&quot;https://www.deligence.com/what_is_langchain_ai_app_development_framework_explained/&quot;&gt;What is LangChain?&lt;/a&gt; , please give it a read and let me know your thoughts on the content and relevance, as I am trying to rank it on google. Thanks!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ronittsainii&quot;&gt; /u/ronittsainii &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah071c/what_is_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ah071c/what_is_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ah071c</id><link href="https://www.reddit.com/r/LangChain/comments/1ah071c/what_is_langchain/" /><updated>2024-02-02T09:56:47+00:00</updated><published>2024-02-02T09:56:47+00:00</published><title>What is LangChain?</title></entry><entry><author><name>/u/CincyTriGuy</name><uri>https://www.reddit.com/user/CincyTriGuy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m new to building Gen AI solutions and have been learning in Vertex (I&amp;#39;m a GCP solution architect with an infrastructure focus). I&amp;#39;m even newer to LangChain. But as I&amp;#39;m reading through the LangChain documentation it looks like every Vertex integration is marked deprecated. &lt;/p&gt; &lt;p&gt;Are there any Vertex integrations that aren&amp;#39;t deprecated?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CincyTriGuy&quot;&gt; /u/CincyTriGuy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agoi5b/are_all_the_google_vertex_integrations_deprecated/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agoi5b/are_all_the_google_vertex_integrations_deprecated/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agoi5b</id><link href="https://www.reddit.com/r/LangChain/comments/1agoi5b/are_all_the_google_vertex_integrations_deprecated/" /><updated>2024-02-01T23:06:02+00:00</updated><published>2024-02-01T23:06:02+00:00</published><title>Are all the Google Vertex integrations deprecated?</title></entry><entry><author><name>/u/o3omoomin</name><uri>https://www.reddit.com/user/o3omoomin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The documents may be very long, resulting in errors exceeding tokens per minute&lt;/p&gt; &lt;p&gt;If I ask to translate a long document at the LangChain prompt, how can I do so efficiently?&lt;/p&gt; &lt;p&gt;I even went so far as to separate it into chunks. The current logic is hard-coded to enter prompts one by one from doc[0] to doc[5].&lt;/p&gt; &lt;p&gt;Is there a way to do this efficiently?&lt;/p&gt; &lt;p&gt;I would appreciate it if you could also provide example code.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/o3omoomin&quot;&gt; /u/o3omoomin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agr9yi/how_to_request_translation_of_a_very_long/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agr9yi/how_to_request_translation_of_a_very_long/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agr9yi</id><link href="https://www.reddit.com/r/LangChain/comments/1agr9yi/how_to_request_translation_of_a_very_long/" /><updated>2024-02-02T01:10:30+00:00</updated><published>2024-02-02T01:10:30+00:00</published><title>How to request translation of a very long document to LangChain?</title></entry><entry><author><name>/u/Chemical_Agent_6515</name><uri>https://www.reddit.com/user/Chemical_Agent_6515</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m new to the LLM world, i&amp;#39;m looking for a use case where if i provide the google sheets data, it should give suggestions like what kind of data it is and what insights can be derived from the data.&lt;/p&gt; &lt;p&gt;please help me with the model or a source that helps me&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Chemical_Agent_6515&quot;&gt; /u/Chemical_Agent_6515 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aglqsm/summary_of_the_google_sheets_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aglqsm/summary_of_the_google_sheets_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aglqsm</id><link href="https://www.reddit.com/r/LangChain/comments/1aglqsm/summary_of_the_google_sheets_data/" /><updated>2024-02-01T21:10:16+00:00</updated><published>2024-02-01T21:10:16+00:00</published><title>summary of the google sheets data</title></entry><entry><author><name>/u/AI_ML_preneur</name><uri>https://www.reddit.com/user/AI_ML_preneur</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have build Openai based chatbot that uses Langchain agents - wiki, dolphin, etc. &lt;/p&gt; &lt;p&gt;I am trying to switch to Open source LLM for this chatbot, has anyone used Langchain with LM studio? I was facing some issues using open source LLM from LM Studio for this task. &lt;/p&gt; &lt;p&gt;Questions: Q1. Has anyone successfully used LM Studio with Langchain agents? If so, how? Q2. Can you provide github links for Langchain + LM studio implementations.&lt;/p&gt; &lt;p&gt;TIA&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AI_ML_preneur&quot;&gt; /u/AI_ML_preneur &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agfjcq/langchain_agents_with_lm_studio/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agfjcq/langchain_agents_with_lm_studio/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agfjcq</id><link href="https://www.reddit.com/r/LangChain/comments/1agfjcq/langchain_agents_with_lm_studio/" /><updated>2024-02-01T16:51:43+00:00</updated><published>2024-02-01T16:51:43+00:00</published><title>Langchain agents with LM Studio</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey what been one of the most trendiest and cool apps made using LangChain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag8rpx/what_are_the_coolest_apps_made_on_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag8rpx/what_are_the_coolest_apps_made_on_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag8rpx</id><link href="https://www.reddit.com/r/LangChain/comments/1ag8rpx/what_are_the_coolest_apps_made_on_langchain/" /><updated>2024-02-01T11:22:39+00:00</updated><published>2024-02-01T11:22:39+00:00</published><title>What are the coolest apps made on LangChain?</title></entry><entry><author><name>/u/PollutionNo5879</name><uri>https://www.reddit.com/user/PollutionNo5879</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello Guys,&lt;/p&gt; &lt;p&gt;Can we create indexes in Mongo Atlas DB using pymongo?&lt;/p&gt; &lt;p&gt;It seems all the documentations are only creating manually.&lt;/p&gt; &lt;p&gt;Any help please?&lt;/p&gt; &lt;p&gt;Thanks and regards, Baradwaj Aryasomayajula&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/PollutionNo5879&quot;&gt; /u/PollutionNo5879 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agfuhv/indexes_in_mongodb/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agfuhv/indexes_in_mongodb/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agfuhv</id><link href="https://www.reddit.com/r/LangChain/comments/1agfuhv/indexes_in_mongodb/" /><updated>2024-02-01T17:04:19+00:00</updated><published>2024-02-01T17:04:19+00:00</published><title>Indexes in MongoDB</title></entry><entry><author><name>/u/zeropercentcool68</name><uri>https://www.reddit.com/user/zeropercentcool68</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Now that I’ve graduated past using the standard RecursiveString chunking that LangChain provides. I’m looking to implement something more robust and accurate when chunking large pdfs that have similar styles (tables, images)&lt;/p&gt; &lt;p&gt;I’ve been playing around with Unstructured but have been having a hard time using it consistently. It seems every time I try to recreate something I was working on the previous day in Google Collab, there are dependency issues but I’ve been fixing it as I go.&lt;/p&gt; &lt;p&gt;My main question is, for my use case of a consistent format of my pdfs, what is the best library to chunk the data prior to generate embeddings?&lt;/p&gt; &lt;p&gt;A follow up is, what libraries do you use to ensure when a file is updated, embeddings aren’t created on top of the previous embeddings and the original is removed from the DB and updated with the new embeddings?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zeropercentcool68&quot;&gt; /u/zeropercentcool68 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agj9vr/file_chunking_strategy/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agj9vr/file_chunking_strategy/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agj9vr</id><link href="https://www.reddit.com/r/LangChain/comments/1agj9vr/file_chunking_strategy/" /><updated>2024-02-01T19:27:07+00:00</updated><published>2024-02-01T19:27:07+00:00</published><title>File Chunking Strategy</title></entry><entry><author><name>/u/sarthak_uchiha</name><uri>https://www.reddit.com/user/sarthak_uchiha</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can we get all the chunks from the azure search vector db ? Without doing any similarity search just retrieve all the chunks from the vector db ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sarthak_uchiha&quot;&gt; /u/sarthak_uchiha &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agcymb/azuresearch/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agcymb/azuresearch/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agcymb</id><link href="https://www.reddit.com/r/LangChain/comments/1agcymb/azuresearch/" /><updated>2024-02-01T15:00:55+00:00</updated><published>2024-02-01T15:00:55+00:00</published><title>Azure-search</title></entry><entry><author><name>/u/Striking_Paper5259</name><uri>https://www.reddit.com/user/Striking_Paper5259</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to create an assistant for code completion on private codebase.&lt;/p&gt; &lt;p&gt;i am finding difficult to get correct context from regular embeddings.&lt;/p&gt; &lt;p&gt;is there better way to embed, index and retrieve code efficiently from codebase?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Striking_Paper5259&quot;&gt; /u/Striking_Paper5259 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag8kqg/what_works_best_for_creating_code_completion/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag8kqg/what_works_best_for_creating_code_completion/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag8kqg</id><link href="https://www.reddit.com/r/LangChain/comments/1ag8kqg/what_works_best_for_creating_code_completion/" /><updated>2024-02-01T11:10:00+00:00</updated><published>2024-02-01T11:10:00+00:00</published><title>what works best for creating code completion assistant using RAG over Codebase.</title></entry><entry><author><name>/u/travel-nerd-05</name><uri>https://www.reddit.com/user/travel-nerd-05</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;If I create embeddings of a context, can I pass the embeddings directly to OpenAi and execute the prompt on top of conext without requiring to put the embeddings into vector db and then pull again from there to be sent as a retrieval chain?&lt;/p&gt; &lt;p&gt;Tried to look through but all examples seems to use a vector db.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/travel-nerd-05&quot;&gt; /u/travel-nerd-05 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agayui/can_we_use_langchain_without_vector_db/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1agayui/can_we_use_langchain_without_vector_db/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1agayui</id><link href="https://www.reddit.com/r/LangChain/comments/1agayui/can_we_use_langchain_without_vector_db/" /><updated>2024-02-01T13:27:06+00:00</updated><published>2024-02-01T13:27:06+00:00</published><title>Can we use langchain without vector db?</title></entry><entry><author><name>/u/DonutMysterious</name><uri>https://www.reddit.com/user/DonutMysterious</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;in my company, before we used LLMs, we had a deterministic bot with intent recognition. Examples:&lt;/p&gt; &lt;p&gt;A user asked if our company offers credits cards. If yes, the bot should tell infos about the cards and offer him to order one. If he´s interested, he will get an offer for xyz. The complexity about this system is that there were multiple steps involved in the process, which different paths/routes to take.&lt;/p&gt; &lt;p&gt;In my team, we want to build a new, LLM-based Bot with OpenAI models. The system itself already works pretty good, but we have absolutely no clue how to integrate that behaviour paths into an LLM based system. &lt;/p&gt; &lt;p&gt;The prefered way would be to define the intends and the follow up routes in some kind of yaml file or maybe directly in Code. I am pretty sure, that we are not the only company who want some kind of sales funnel into their Bot. &lt;/p&gt; &lt;p&gt;Does anyone have experience and/or example code or just a suggestion how to tackle this issue?&lt;/p&gt; &lt;p&gt;Thanks :)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DonutMysterious&quot;&gt; /u/DonutMysterious &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ageri4/deterministic_behaviour_in_an_llm_salesfunnel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ageri4/deterministic_behaviour_in_an_llm_salesfunnel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ageri4</id><link href="https://www.reddit.com/r/LangChain/comments/1ageri4/deterministic_behaviour_in_an_llm_salesfunnel/" /><updated>2024-02-01T16:19:16+00:00</updated><published>2024-02-01T16:19:16+00:00</published><title>Deterministic behaviour in an LLM (Salesfunnel)</title></entry><entry><author><name>/u/borrito3179</name><uri>https://www.reddit.com/user/borrito3179</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/borrito3179&quot;&gt; /u/borrito3179 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ChatGPT/comments/1ag67kn/any_custom_gpts_for_crypto_defi/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag6alz/any_custom_gpts_for_crypto_defi/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag6alz</id><link href="https://www.reddit.com/r/LangChain/comments/1ag6alz/any_custom_gpts_for_crypto_defi/" /><updated>2024-02-01T08:28:15+00:00</updated><published>2024-02-01T08:28:15+00:00</published><title>Any custom GPTs for crypto / defi?</title></entry><entry><author><name>/u/minhbtc</name><uri>https://www.reddit.com/user/minhbtc</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/minhbtc&quot;&gt; /u/minhbtc &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/LangChain/comments/1762tkr/a_chatbot_using_langchain_to_integrate_llm_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag5pus/a_chatbot_using_langchain_to_integrate_llm_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag5pus</id><link href="https://www.reddit.com/r/LangChain/comments/1ag5pus/a_chatbot_using_langchain_to_integrate_llm_with/" /><updated>2024-02-01T07:47:42+00:00</updated><published>2024-02-01T07:47:42+00:00</published><title>A Chatbot using Langchain to integrate LLM with MongoDB memory and LangSmith to tracing LLM calls.</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Currently, I am using Chroma DB in production as a vector database. However, I am facing challenges, including delayed responses from the API and potential issues with semantic search, leading to results that do not meet our expectations. Can you suggest a robust database suitable for production, and do you have any additional insights or recommendations based on your expertise?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afkc5g/which_vector_databases_are_widely_used_in_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afkc5g/which_vector_databases_are_widely_used_in_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afkc5g</id><link href="https://www.reddit.com/r/LangChain/comments/1afkc5g/which_vector_databases_are_widely_used_in_the/" /><updated>2024-01-31T15:24:47+00:00</updated><published>2024-01-31T15:24:47+00:00</published><title>Which vector databases are widely used in the industry and are considered suitable for production purposes?</title></entry><entry><author><name>/u/mercuretony</name><uri>https://www.reddit.com/user/mercuretony</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello 👋🏾!&lt;/p&gt; &lt;p&gt;I&amp;#39;m looking forward to build a chatbot that can:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Interact with my class note: indeed, I&amp;#39;m at university and would like to chat with the bot and ask questions about some class notes. &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Requirements: it has to be able to read PDF, docx, word and sometimes HTML files.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;I might be interested in the future to add interaction with my calendar so that I can ask questions about my day.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Requirements: it has to take in account my calendar informations.&lt;/p&gt; &lt;p&gt;Do you think I should use llama index or Langchain.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mercuretony&quot;&gt; /u/mercuretony &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag34dc/help_for_a_project_llama_index_or_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag34dc/help_for_a_project_llama_index_or_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag34dc</id><link href="https://www.reddit.com/r/LangChain/comments/1ag34dc/help_for_a_project_llama_index_or_langchain/" /><updated>2024-02-01T05:05:29+00:00</updated><published>2024-02-01T05:05:29+00:00</published><title>Help for a project! Llama Index or Langchain ?</title></entry></feed>