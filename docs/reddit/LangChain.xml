<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-02-01T07:27:23+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/mercuretony</name><uri>https://www.reddit.com/user/mercuretony</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello üëãüèæ!&lt;/p&gt; &lt;p&gt;I&amp;#39;m looking forward to build a chatbot that can:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Interact with my class note: indeed, I&amp;#39;m at university and would like to chat with the bot and ask questions about some class notes. &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Requirements: it has to be able to read PDF, docx, word and sometimes HTML files.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;I might be interested in the future to add interaction with my calendar so that I can ask questions about my day.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Requirements: it has to take in account my calendar informations.&lt;/p&gt; &lt;p&gt;Do you think I should use llama index or Langchain.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mercuretony&quot;&gt; /u/mercuretony &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag34dc/help_for_a_project_llama_index_or_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag34dc/help_for_a_project_llama_index_or_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ag34dc</id><link href="https://www.reddit.com/r/LangChain/comments/1ag34dc/help_for_a_project_llama_index_or_langchain/" /><updated>2024-02-01T05:05:29+00:00</updated><published>2024-02-01T05:05:29+00:00</published><title>Help for a project! Llama Index or Langchain ?</title></entry><entry><author><name>/u/austin_at_focused</name><uri>https://www.reddit.com/user/austin_at_focused</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag1cy1/chat_with_your_pdfs_an_end_to_end_langchain/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/5DiO8oU-9Phdh4pr4kT6CosZBN3PpI9Y5Bhp2oMIUxE.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=323f40f767d5a97cce6fa9601752f76e918cde05&quot; alt=&quot;Chat With Your PDFs - An End to End LangChain Tutorial - Part 1&quot; title=&quot;Chat With Your PDFs - An End to End LangChain Tutorial - Part 1&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/austin_at_focused&quot;&gt; /u/austin_at_focused &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://youtube.com/watch?v=UwgZmrRAgQ4&amp;amp;si=eC1j7yWuxIGcavVs&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ag1cy1/chat_with_your_pdfs_an_end_to_end_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ag1cy1</id><media:thumbnail url="https://external-preview.redd.it/5DiO8oU-9Phdh4pr4kT6CosZBN3PpI9Y5Bhp2oMIUxE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=323f40f767d5a97cce6fa9601752f76e918cde05" /><link href="https://www.reddit.com/r/LangChain/comments/1ag1cy1/chat_with_your_pdfs_an_end_to_end_langchain/" /><updated>2024-02-01T03:32:40+00:00</updated><published>2024-02-01T03:32:40+00:00</published><title>Chat With Your PDFs - An End to End LangChain Tutorial - Part 1</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Currently, I am using Chroma DB in production as a vector database. However, I am facing challenges, including delayed responses from the API and potential issues with semantic search, leading to results that do not meet our expectations. Can you suggest a robust database suitable for production, and do you have any additional insights or recommendations based on your expertise?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afkc5g/which_vector_databases_are_widely_used_in_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afkc5g/which_vector_databases_are_widely_used_in_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afkc5g</id><link href="https://www.reddit.com/r/LangChain/comments/1afkc5g/which_vector_databases_are_widely_used_in_the/" /><updated>2024-01-31T15:24:47+00:00</updated><published>2024-01-31T15:24:47+00:00</published><title>Which vector databases are widely used in the industry and are considered suitable for production purposes?</title></entry><entry><author><name>/u/DBAdvice123</name><uri>https://www.reddit.com/user/DBAdvice123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Titled &amp;quot;&lt;a href=&quot;https://www.datastax.com/resources/whitepaper/an-llm-agent-reference-architecture-demystifying-llm-based-systems?utm_medium=social_organic&amp;amp;utm_source=reddit&amp;amp;utm_campaign=wp&amp;amp;utm_content=putv&quot;&gt;An LLM Agent Reference Architecture: Demystifying LLM-based Systems&lt;/a&gt;&amp;quot;&lt;/p&gt; &lt;p&gt;The paper gives some design patterns, in-depth architectural examples, and things to keep in mind when architecting LLM-based systems. Worth a read!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DBAdvice123&quot;&gt; /u/DBAdvice123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afmbdu/new_whitepaper_written_by_langchain_datastax/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afmbdu/new_whitepaper_written_by_langchain_datastax/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afmbdu</id><link href="https://www.reddit.com/r/LangChain/comments/1afmbdu/new_whitepaper_written_by_langchain_datastax/" /><updated>2024-01-31T16:49:42+00:00</updated><published>2024-01-31T16:49:42+00:00</published><title>New Whitepaper written by LangChain &amp; DataStax</title></entry><entry><author><name>/u/EconBro95</name><uri>https://www.reddit.com/user/EconBro95</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all,&lt;/p&gt; &lt;p&gt;I am implementing a data system for retrieval and thought to get opinions given how fast the field is moving.&lt;/p&gt; &lt;p&gt;So background, I have a bunch of data in the form of documents, tables (think a lot of csv‚Äôs/excel files), and other text data.&lt;/p&gt; &lt;p&gt;My question relates mainly to the tabular data that I have, the text data I will embed and store in a vector db.&lt;/p&gt; &lt;p&gt;The two approaches possible for the tabular data are:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;More traditional:&lt;/li&gt; &lt;/ol&gt; &lt;ul&gt; &lt;li&gt;Transform into a common structure and pass into a traditional relational database (Postgres, etc).&lt;/li&gt; &lt;li&gt;After that using the metadata from each table with Llama Index: SQLAutoVectorQueryEngine to get the data that I need for each question regarding the data&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Pro‚Äôs:&lt;br/&gt; I can tell exactly what is being queried to get what results and I have more control over the databases themselves and their associated metadata and description.&lt;/p&gt; &lt;p&gt;Con‚Äôs:&lt;br/&gt; A lot harder to scale the structural data portion of this as more data floats in as CSV‚Äôs/xlsx files.&lt;br/&gt; Will there be confusion as to how to use the combination of the text/document data in the vectordb combined with the relational data in the warehouse?&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Knowledge graph and graph DB‚Äôs:&lt;br/&gt; Rather than structure the data for consumption into a Relational database, use Llama Index and unstructured to convert the tabular data into a format capable of being used as a knowledge graph and graph DB.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I BELIEVE that the process for creating such graph‚Äôs is fairly automated by LLama Index and Langchain.&lt;/p&gt; &lt;p&gt;Pro‚Äôs:&lt;br/&gt; Easier to scale.&lt;br/&gt; The relationships might make it easier to pull the relevant data especially given the scale.&lt;/p&gt; &lt;p&gt;Con‚Äôs&lt;br/&gt; I am not sure how well numeric data, the type that is generally stored in relational databases for storage does in a graph DB. Are they able to build relationships easily and accurately?&lt;/p&gt; &lt;p&gt;Would love some thoughts and opinions,&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EconBro95&quot;&gt; /u/EconBro95 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afu4qa/rag_for_structured_data_querying_rd_vs_knowledge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afu4qa/rag_for_structured_data_querying_rd_vs_knowledge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afu4qa</id><link href="https://www.reddit.com/r/LangChain/comments/1afu4qa/rag_for_structured_data_querying_rd_vs_knowledge/" /><updated>2024-01-31T22:04:09+00:00</updated><published>2024-01-31T22:04:09+00:00</published><title>RAG for structured data (querying RD vs. knowledge graph/graph db)</title></entry><entry><author><name>/u/salmenus</name><uri>https://www.reddit.com/user/salmenus</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Reddit! This is about a new &lt;a href=&quot;https://github.com/nluxai/nlux&quot;&gt;open source project&lt;/a&gt; I&amp;#39;m starting for a React JS / Javascript library that makes it &lt;strong&gt;super simple to create conversational AI interfaces&lt;/strong&gt; using LangChain&amp;#39;s &lt;strong&gt;LangServe&lt;/strong&gt;, HuggingFace, or any other LLM.&lt;/p&gt; &lt;p&gt;The project is called NLUX (for &lt;em&gt;Natural Language User Experience&lt;/em&gt;) and you can already start using it to create a web app for your LC backend, or embed LLMs into your web app.&lt;/p&gt; &lt;p&gt;Project Website:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://nlux.ai/&quot;&gt;NLUX.ai&lt;/a&gt; ‚Äî for docs, examples, source code, etc.&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.nlux.ai/examples/langchain-langserve-adapter&quot;&gt;Example here&lt;/a&gt; using LangServe + React JS&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;What you can do with NLUX:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Build AI Chat Interfaces In Minutes&lt;/strong&gt; ‚Äî High quality conversational AI UI in a few lines of code.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Flexible LLM Adapters&lt;/strong&gt; ‚Äî For LangServe, HuggingFace, ChatGPT .. and more coming soon.&lt;/li&gt; &lt;li&gt;An API to &lt;strong&gt;Create Your Own Adapter&lt;/strong&gt; ‚Äî for any LLM or custom backend.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Chatbot Personas&lt;/strong&gt; ‚Äî Configure the bot and user profiles for personalised interactions.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Zero Dependencies&lt;/strong&gt; ‚Äî Lightweight codebase, with zero-dep ! except for LLM front-end libraries.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Give it a try and let me know what you think!&lt;/p&gt; &lt;p&gt;Questions, ideas or feedback? I&amp;#39;m all ears in the comments! üôÇ ‚öõÔ∏è&lt;/p&gt; &lt;p&gt;&lt;em&gt;PS: I‚Äôm may give this post a little promo to get some early adopters. The project is and will always remain free, open source, and self-funded.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;SalmenLead Developer&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/salmenus&quot;&gt; /u/salmenus &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afk4dr/reactjs_langchain_new_js_lib_to_create_frontends/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afk4dr/reactjs_langchain_new_js_lib_to_create_frontends/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afk4dr</id><link href="https://www.reddit.com/r/LangChain/comments/1afk4dr/reactjs_langchain_new_js_lib_to_create_frontends/" /><updated>2024-01-31T15:15:29+00:00</updated><published>2024-01-31T15:15:29+00:00</published><title>ReactJS + LangChain: New JS Lib To Create Frontends Powered by LangServe</title></entry><entry><author><name>/u/ChoicePermission6770</name><uri>https://www.reddit.com/user/ChoicePermission6770</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afox49/langdao_lang/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/f7ngtg3tktfc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=61a66b916cd44d42a335aec4df0bd35e7afbd595&quot; alt=&quot;LangDAO ‚Ä¶ $LANG&quot; title=&quot;LangDAO ‚Ä¶ $LANG&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Last week, I saw a post about LangDAO, something that could be a type of crypto used to compensate contributions in the langchain community. This week, I&amp;#39;m trying to find the posts and threads on X, but I don&amp;#39;t see anything. Any idea what might have happened?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ChoicePermission6770&quot;&gt; /u/ChoicePermission6770 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/f7ngtg3tktfc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afox49/langdao_lang/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1afox49</id><media:thumbnail url="https://preview.redd.it/f7ngtg3tktfc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=61a66b916cd44d42a335aec4df0bd35e7afbd595" /><link href="https://www.reddit.com/r/LangChain/comments/1afox49/langdao_lang/" /><updated>2024-01-31T18:34:09+00:00</updated><published>2024-01-31T18:34:09+00:00</published><title>LangDAO ‚Ä¶ $LANG</title></entry><entry><author><name>/u/OkMeeting8253</name><uri>https://www.reddit.com/user/OkMeeting8253</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a chat history between a client and a coach. I need to create an ability for a coach to quickly recall details from previous conversations. Example: User asks: &amp;quot;remember i told you about mom&amp;quot; Imagine it was two months ago - coach who has multiple clients can&amp;#39;t remember everything, so she need a quick search in a chat history and calls transcripts to get a summary of everything the client has told about her mom.&lt;/p&gt; &lt;p&gt;How would you split and organize chat history and calls transcripts to chunks?&lt;/p&gt; &lt;p&gt;based on what?&lt;/p&gt; &lt;p&gt;when it something that user says it&amp;#39;s seems straight forward. but imagine something like this:&lt;/p&gt; &lt;p&gt;coach: was you close with her? client: yes&lt;/p&gt; &lt;p&gt;so client only says yes, i need somehow keep the ref to the question.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OkMeeting8253&quot;&gt; /u/OkMeeting8253 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afs1kz/how_would_you_organize_a_dialogues_documents_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afs1kz/how_would_you_organize_a_dialogues_documents_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afs1kz</id><link href="https://www.reddit.com/r/LangChain/comments/1afs1kz/how_would_you_organize_a_dialogues_documents_in/" /><updated>2024-01-31T20:39:39+00:00</updated><published>2024-01-31T20:39:39+00:00</published><title>How would you organize a dialogues documents in chunks?</title></entry><entry><author><name>/u/Axiomatic_Inspector_</name><uri>https://www.reddit.com/user/Axiomatic_Inspector_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I just made an AI search engine with Spring Boot and LangChain4J inspired by the project search-with-lepton&lt;/p&gt; &lt;p&gt;If you are interest in it, you can visit it here &lt;a href=&quot;https://github.com/vlinx-io/infinite-search&quot;&gt;https://github.com/vlinx-io/infinite-search&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Axiomatic_Inspector_&quot;&gt; /u/Axiomatic_Inspector_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1affs5p/an_open_source_ai_search_engine/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1affs5p/an_open_source_ai_search_engine/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1affs5p</id><link href="https://www.reddit.com/r/LangChain/comments/1affs5p/an_open_source_ai_search_engine/" /><updated>2024-01-31T11:30:36+00:00</updated><published>2024-01-31T11:30:36+00:00</published><title>An open source AI Search Engine</title></entry><entry><author><name>/u/ashpreetbedi</name><uri>https://www.reddit.com/user/ashpreetbedi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afja1t/building_a_pdf_ai_using_function_calling/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/yR_EBM4rBjE22hpN5-A5fhPvBw6wZRhYGuMrD9XamP0.jpg&quot; alt=&quot;Building a PDF AI using function calling&quot; title=&quot;Building a PDF AI using function calling&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Chat with PDFs is the todo app of AI and i‚Äôve been thinking about building an advanced one using function calling. What do you think of this flow:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;LLM first determines if it needs to search docs or the web for context&lt;/li&gt; &lt;li&gt;Then decides if it needs a specific doc or the latest one&lt;/li&gt; &lt;li&gt;Then decides to search a doc or get context to summarize&lt;/li&gt; &lt;li&gt;Produces an answer using this context&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Using this flow the LLM can search specific docs, summarize, or bring in web context to enhance the answer. Thoughts? &lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/rhni60skesfc1.png?width=1812&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=010b2403811e6729e27a2c1f04f3c407f523ff27&quot;&gt;https://preview.redd.it/rhni60skesfc1.png?width=1812&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=010b2403811e6729e27a2c1f04f3c407f523ff27&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashpreetbedi&quot;&gt; /u/ashpreetbedi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afja1t/building_a_pdf_ai_using_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afja1t/building_a_pdf_ai_using_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1afja1t</id><media:thumbnail url="https://a.thumbs.redditmedia.com/yR_EBM4rBjE22hpN5-A5fhPvBw6wZRhYGuMrD9XamP0.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1afja1t/building_a_pdf_ai_using_function_calling/" /><updated>2024-01-31T14:37:37+00:00</updated><published>2024-01-31T14:37:37+00:00</published><title>Building a PDF AI using function calling</title></entry><entry><author><name>/u/No-Gear-1874</name><uri>https://www.reddit.com/user/No-Gear-1874</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Hey &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; &lt;a href=&quot;/r/LlamaIndex&quot;&gt;r/LlamaIndex&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I&amp;#39;m diving into an exciting venture for a non-profit university project where we aim to build an application generating quizzes from medical course PDFs. The concept is simple: users choose a course in a user-friendly interface, click &amp;quot;Generate,&amp;quot; and watch quiz questions come to life.&lt;/p&gt; &lt;p&gt;However, I&amp;#39;m currently stuck on the most effective strategy for &amp;quot;&lt;strong&gt;chunking&lt;/strong&gt;&amp;quot; and &amp;quot;&lt;strong&gt;retrieving&lt;/strong&gt;&amp;quot; information from the pre-saved PDFs within the application. If you&amp;#39;ve got experience with similar app development or ideas on the best approach, I&amp;#39;d greatly appreciate your input.&lt;/p&gt; &lt;p&gt;I think to use llm and embeddings &lt;/p&gt; &lt;p&gt;Any suggestions, links to helpful resources, or shared experiences would be immensely valuable. This is a non-profit initiative at the university, and your guidance can make a significant impact. Thanks in advance for your invaluable help! üåê‚ú®&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/No-Gear-1874&quot;&gt; /u/No-Gear-1874 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afm8zg/developing_a_quiz_generator_from_medical_course/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afm8zg/developing_a_quiz_generator_from_medical_course/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afm8zg</id><link href="https://www.reddit.com/r/LangChain/comments/1afm8zg/developing_a_quiz_generator_from_medical_course/" /><updated>2024-01-31T16:47:06+00:00</updated><published>2024-01-31T16:47:06+00:00</published><title>Developing a Quiz Generator from Medical Course PDFs</title></entry><entry><author><name>/u/modularmindapp</name><uri>https://www.reddit.com/user/modularmindapp</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afrolj/live_webinar_futureforward_24_dive_into_the/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/eYRqtFhZZg4D2W9wEytd77-hP3CHzsLLkfojUpWZF2s.jpg&quot; alt=&quot;[Live webinar] FutureForward '24 - Dive into the latest advancements&quot; title=&quot;[Live webinar] FutureForward '24 - Dive into the latest advancements&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/modularmindapp&quot;&gt; /u/modularmindapp &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://join.modularmind.app/ff24&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afrolj/live_webinar_futureforward_24_dive_into_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1afrolj</id><media:thumbnail url="https://b.thumbs.redditmedia.com/eYRqtFhZZg4D2W9wEytd77-hP3CHzsLLkfojUpWZF2s.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1afrolj/live_webinar_futureforward_24_dive_into_the/" /><updated>2024-01-31T20:25:15+00:00</updated><published>2024-01-31T20:25:15+00:00</published><title>[Live webinar] FutureForward '24 - Dive into the latest advancements</title></entry><entry><author><name>/u/MareaNeagra</name><uri>https://www.reddit.com/user/MareaNeagra</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi! I am new to this and I do not know how to bypass the limitation of tokens. I should split my prompt in multiple chunks? Is there a method: refine or map-reduce? I have a large prompt and I do not know how to split it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MareaNeagra&quot;&gt; /u/MareaNeagra &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afmn9r/bypass_4096_tokens/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afmn9r/bypass_4096_tokens/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afmn9r</id><link href="https://www.reddit.com/r/LangChain/comments/1afmn9r/bypass_4096_tokens/" /><updated>2024-01-31T17:02:50+00:00</updated><published>2024-01-31T17:02:50+00:00</published><title>Bypass 4096 tokens</title></entry><entry><author><name>/u/YOLOLJJ</name><uri>https://www.reddit.com/user/YOLOLJJ</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using GPT 3.5-Turbo-Instinct and feeding in my dataschema into the prompt. I am creating my SQL query using create_sql_chain and then running the query in the database through JDBC. So far, it is working okay however, if I am looking to push this to production, I need the model to not return anything if it is not confident in its answer or if the query being asked is too vague.&lt;/p&gt; &lt;p&gt;For instance, if I ask my text to sql model &amp;quot;how many rows are there&amp;quot;, it should return back something saying &amp;quot;this query is too vague&amp;quot;. Likewise, if I were to ask it a question such as, &amp;quot;Return the GPA and Networth of Nadir&amp;quot;, how do I get it to do &amp;quot;WHERE LastName = &amp;#39;Nadir&amp;#39; rather than &amp;quot;WHERE FirstName = &amp;#39;Nadir&amp;#39;. I thought that by potentially getting confidence scores I could explore and find a threshold where the human needs to clarify what they meant until the model had a confident enough query&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/YOLOLJJ&quot;&gt; /u/YOLOLJJ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afkz4o/how_to_build_a_text_to_sql_model_that_asks_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afkz4o/how_to_build_a_text_to_sql_model_that_asks_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afkz4o</id><link href="https://www.reddit.com/r/LangChain/comments/1afkz4o/how_to_build_a_text_to_sql_model_that_asks_for/" /><updated>2024-01-31T15:52:38+00:00</updated><published>2024-01-31T15:52:38+00:00</published><title>How to build a Text to SQL Model that asks for more information if the query is too vague</title></entry><entry><author><name>/u/litchiTheGreat</name><uri>https://www.reddit.com/user/litchiTheGreat</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hey, I am new to langhchain and using it in my nodejs application , I have used langchain to successfully split the documents into chunks with recursive vector splitting, I want to add another metadata before embedding it, is langchain suitable for this? I have previously done this manually but it takes a lot of time and i want to try this in the library way. I am looking for something parallel to the ingestingPipeline feature in llamaIndex. would really appricate any guidlelines!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/litchiTheGreat&quot;&gt; /u/litchiTheGreat &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afiba1/metadata_tagging_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afiba1/metadata_tagging_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afiba1</id><link href="https://www.reddit.com/r/LangChain/comments/1afiba1/metadata_tagging_with_langchain/" /><updated>2024-01-31T13:51:45+00:00</updated><published>2024-01-31T13:51:45+00:00</published><title>metadata tagging with langchain,</title></entry><entry><author><name>/u/OnlyBadKarma</name><uri>https://www.reddit.com/user/OnlyBadKarma</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using LangChain QA Retrieval using map-reduce chain. I want to replace/ stuff the documents received through retriever to make my answers better. But I am not able to figure out the way.&lt;/p&gt; &lt;p&gt;&lt;code&gt;question_prompt = PromptTemplate.from_template(&amp;quot;&amp;quot;&amp;quot;Check the summary to tell how it is answering the question. You can just say that it doesn&amp;#39;t answer the question directly.&lt;/code&gt; &lt;/p&gt; &lt;p&gt;&lt;code&gt;{context}&lt;/code&gt; &lt;/p&gt; &lt;p&gt;&lt;code&gt;Original question: {question}&amp;quot;&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;# Loading the Annoy DB from disk.&lt;/code&gt;&lt;br/&gt; &lt;code&gt;vectordb = Annoy.load_local(persist_directory, embeddings=embedding)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;combine_custom_prompt = PromptTemplate.from_template(&amp;quot;&amp;quot;&amp;quot;Out of these summaries. If you don&amp;#39;t know the answer, just say that you don&amp;#39;t know. Don&amp;#39;t try to make up an answer.&lt;/code&gt;&lt;br/&gt; &lt;code&gt;QUESTION IS: {question}&lt;/code&gt;&lt;br/&gt; &lt;code&gt;=========&lt;/code&gt;&lt;br/&gt; &lt;code&gt;{summaries}&lt;/code&gt;&lt;br/&gt; &lt;code&gt;=========&lt;/code&gt;&lt;br/&gt; &lt;code&gt;FINAL ANSWER:&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;&amp;quot;&amp;quot;)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;chain_type_kwargs = {&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;verbose&amp;quot;: True,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;question_prompt&amp;quot;: question_prompt,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;combine_prompt&amp;quot;: combine_custom_prompt,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;combine_document_variable_name&amp;quot;: &amp;quot;summaries&amp;quot;,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;&amp;quot;map_reduce_document_variable_name&amp;quot;: &amp;quot;context&amp;quot;,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;}&lt;/code&gt;&lt;br/&gt; &lt;code&gt;retriever = vectordb.as_retriever(search_kwargs={&amp;quot;k&amp;quot;: 10})&lt;/code&gt;&lt;br/&gt; &lt;code&gt;print(&amp;quot;Type of retriever&amp;quot;, type(retriever))&lt;/code&gt;&lt;br/&gt; &lt;code&gt;refine = RetrievalQA.from_chain_type(llm=OpenAI(),&lt;/code&gt;&lt;br/&gt; &lt;code&gt;chain_type=&amp;quot;map_reduce&amp;quot;,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;return_source_documents=True,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;chain_type_kwargs=chain_type_kwargs,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;retriever=retriever,&lt;/code&gt;&lt;br/&gt; &lt;code&gt;verbose=True)&lt;/code&gt;&lt;br/&gt; &lt;code&gt;print(refine(&amp;quot;Random Question&amp;quot;))&lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/OnlyBadKarma&quot;&gt; /u/OnlyBadKarma &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afe337/how_to_replacestuff_the_content_inside_the/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afe337/how_to_replacestuff_the_content_inside_the/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afe337</id><link href="https://www.reddit.com/r/LangChain/comments/1afe337/how_to_replacestuff_the_content_inside_the/" /><updated>2024-01-31T09:33:24+00:00</updated><published>2024-01-31T09:33:24+00:00</published><title>How to replace/stuff the content inside the document in QAReteriver with a map-reduce chain?</title></entry><entry><author><name>/u/tiagomlopes</name><uri>https://www.reddit.com/user/tiagomlopes</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on enhancing a chatbot&amp;#39;s user experience by integrating dynamic quick replies for instances where certain information is missing for function/tool execution.&lt;/p&gt; &lt;p&gt;For example, consider a function &lt;code&gt;search_movies&lt;/code&gt; that has an optional parameter &lt;code&gt;genre&lt;/code&gt;. When a user writes &amp;quot;I want to watch a movie&amp;quot; without specifying a genre, I&amp;#39;d like the chatbot to present a list of available genres as quick replies in the UI, rather than having the user type out their preference. &lt;/p&gt; &lt;p&gt;The conceptual solution involves:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;pausing the chatbot&amp;#39;s execution from the function and saving its state when additional info is needed.&lt;/li&gt; &lt;li&gt;Once the user picks an option, the chatbot&amp;#39;s state is restored, the relevant function (in this case &lt;code&gt;search_movies&lt;/code&gt;) is invoked with the new input, and the conversation continues.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Some tutorials have similar &amp;quot;pause&amp;quot; functionality to get user inputs, but they only work when the script runs on a terminal. In the scenario above, the code will be behind an API so it&amp;#39;s not possible to keep a connection open waiting for an answer.&lt;/p&gt; &lt;p&gt;Is this approach viable with LangChain? Are there other better approaches?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/tiagomlopes&quot;&gt; /u/tiagomlopes &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afgjex/enhancing_chatbot_ux_with_dynamic_quick_replies/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afgjex/enhancing_chatbot_ux_with_dynamic_quick_replies/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afgjex</id><link href="https://www.reddit.com/r/LangChain/comments/1afgjex/enhancing_chatbot_ux_with_dynamic_quick_replies/" /><updated>2024-01-31T12:17:24+00:00</updated><published>2024-01-31T12:17:24+00:00</published><title>Enhancing Chatbot UX with Dynamic Quick Replies in LangChain - Feasible?</title></entry><entry><author><name>/u/IsseBisse</name><uri>https://www.reddit.com/user/IsseBisse</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m quite new to LangChain, trying it out to see what all the fuzz is about. I recently followed the &lt;a href=&quot;https://python.langchain.com/docs/expression_language/cookbook/memory&quot;&gt;Adding memory cookbook&lt;/a&gt; from the docs. I&amp;#39;m running it inside a simple while loop to provide consecutive inputs to the chain. &lt;/p&gt; &lt;p&gt;Is there any way to update the memory inside the chain? I don&amp;#39;t much care for the &lt;/p&gt; &lt;pre&gt;&lt;code&gt;memory.save_context(inputs, {&amp;quot;output&amp;quot;: response.content}) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;step outside of the chain. That seems to go against the whole point of containing everything LLM related inside the chain. Or am I missing something?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/IsseBisse&quot;&gt; /u/IsseBisse &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afdjc2/cleaner_memory_handling_in_lcel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1afdjc2/cleaner_memory_handling_in_lcel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1afdjc2</id><link href="https://www.reddit.com/r/LangChain/comments/1afdjc2/cleaner_memory_handling_in_lcel/" /><updated>2024-01-31T08:53:55+00:00</updated><published>2024-01-31T08:53:55+00:00</published><title>Cleaner memory handling in LCEL</title></entry><entry><author><name>/u/YannFann</name><uri>https://www.reddit.com/user/YannFann</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am having problems with using the newest version of langchain with Pinecone.&lt;/p&gt; &lt;p&gt;I have conflicting dependencies: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;[...] Directory ‚îú‚îÄ‚î¨ @langchain/pinecone@0.0.1 ‚îÇ ‚îî‚îÄ‚îÄ @pinecone-database/pinecone@2.0.1 deduped ‚îú‚îÄ‚îÄ @pinecone-database/pinecone@2.0.1 ‚îî‚îÄ‚î¨ langchain@0.1.10 ‚îú‚îÄ‚î¨ @langchain/community@0.0.22 ‚îÇ ‚îî‚îÄ‚îÄ @pinecone-database/pinecone@2.0.1 deduped invalid: &amp;quot;^1.1.0&amp;quot; from node_modules/langchain/node_modules/@langchain/community ‚îî‚îÄ‚îÄ @pinecone-database/pinecone@2.0.1 deduped &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As you can see @lanchain/community conflicts with everything.&lt;/p&gt; &lt;p&gt;But i have been looking everywhere to try to figure out how to remove or workaround @langchain/community successfully. &lt;/p&gt; &lt;p&gt;I&amp;#39;m finding it difficult since it is a internal dependency of langchain.&lt;/p&gt; &lt;p&gt;Can&amp;#39;t really think of anywhere else I havent already tried to find a solution.&lt;/p&gt; &lt;p&gt;Anyone here have experience with this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/YannFann&quot;&gt; /u/YannFann &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1af7rrl/i_cant_resolve_some_dependency_issues_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1af7rrl/i_cant_resolve_some_dependency_issues_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1af7rrl</id><link href="https://www.reddit.com/r/LangChain/comments/1af7rrl/i_cant_resolve_some_dependency_issues_with/" /><updated>2024-01-31T03:17:36+00:00</updated><published>2024-01-31T03:17:36+00:00</published><title>I cant resolve some dependency issues with Pinecone</title></entry><entry><author><name>/u/Automatic-Highway-75</name><uri>https://www.reddit.com/user/Automatic-Highway-75</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks, I want to share a side project I‚Äôve been working on during weekends: AutoCoder! üë®‚Äçüíªüë©‚Äçüíª&lt;br/&gt; ü§ñ A description-to-pull-request bot that can answer questions, and make code changes to Github repo through natural language instructions. It‚Äôs powered by LLM function calling and built with&lt;br/&gt; - üß† &lt;a href=&quot;https://github.com/TengHu/ActionWeaver&quot;&gt;ActionWeaver&lt;/a&gt; for function calling orchestration.&lt;br/&gt; - üìö &lt;a href=&quot;https://www.linkedin.com/company/llamaindex/&quot;&gt;LlamaIndex&lt;/a&gt; for RAG, including code chunking and advanced RAG technique like Hypothetical Document Embeddings!&lt;br/&gt; - üõ†Ô∏è &lt;a href=&quot;https://www.langchain.com/langsmith&quot;&gt;LangSmith&lt;/a&gt; for powerful LLM tracing and debugging!&lt;br/&gt; - API toolings from LangChain Community.&lt;br/&gt; It&amp;#39;s incredible what a single developer can leverage existing AI libraries to create something like this in a short time! &lt;/p&gt; &lt;p&gt;Please checkout the codebase below üëá&lt;br/&gt; Github Repo: &lt;a href=&quot;https://github.com/TengHu/AutoCoder&quot;&gt;https://github.com/TengHu/AutoCoder&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Automatic-Highway-75&quot;&gt; /u/Automatic-Highway-75 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aeq95t/autocoder_a_descriptiontopullrequest_coding_bot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aeq95t/autocoder_a_descriptiontopullrequest_coding_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aeq95t</id><link href="https://www.reddit.com/r/LangChain/comments/1aeq95t/autocoder_a_descriptiontopullrequest_coding_bot/" /><updated>2024-01-30T14:55:43+00:00</updated><published>2024-01-30T14:55:43+00:00</published><title>AutoCoder: A description-to-pull-request coding bot built with ActionWeaver, LlamaIndex and LangChain/LangSmith</title></entry><entry><author><name>/u/stoicbats_</name><uri>https://www.reddit.com/user/stoicbats_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I am currently tackling a project that involves a list of various brand names within a specific domain. For instance:&lt;/p&gt; &lt;p&gt;&lt;code&gt;domain_names = [&amp;#39;xyz&amp;#39;, &amp;#39;yza&amp;#39;, &amp;#39;tra&amp;#39;, &amp;#39;world&amp;#39;]&lt;/code&gt;&lt;/p&gt; &lt;p&gt;My goal is to develop a search s capable of analyzing word similarity. Specifically, the system should accept a word and return the top &amp;#39;k&amp;#39; words that are most similar to it. I have experimented with OpenAI embeddings, particularly the latest Embedding Version 3 (3072 dimensions), but the results have been unsatisfactory.&lt;/p&gt; &lt;p&gt;Could someone suggest the most effective approaches for searching word-level similarities ?In the era of GPT, Would it be advisable to train my own Word2Vec model?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/stoicbats_&quot;&gt; /u/stoicbats_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aevsuu/in_the_era_of_gpt_building_an_effective_word/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aevsuu/in_the_era_of_gpt_building_an_effective_word/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aevsuu</id><link href="https://www.reddit.com/r/LangChain/comments/1aevsuu/in_the_era_of_gpt_building_an_effective_word/" /><updated>2024-01-30T18:42:19+00:00</updated><published>2024-01-30T18:42:19+00:00</published><title>In the era of GPT, building an effective word similarity search in 2023</title></entry><entry><author><name>/u/marcuss171</name><uri>https://www.reddit.com/user/marcuss171</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aey6gi/get_openai_callback_not_working_when_using_agent/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/2_9q3TSXV0C94uCFK3v7tn0X9sdrY5mnwzQK8rN1ZzY.jpg&quot; alt=&quot;get_openai_callback not working when using Agent Executor after updating to latest version of Langchain&quot; title=&quot;get_openai_callback not working when using Agent Executor after updating to latest version of Langchain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;h3&gt;Description&lt;/h3&gt; &lt;p&gt;I&amp;#39;m trying to use the get_openai_callback from langchain_community.callbacks to get the number of token and costs incurred in using the agent but I am getting zero on everything, as you can see here when I print.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/9lbv5ocaymfc1.png?width=412&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3d7282b8c88c39bdacf48a4a6ad867c0fdc574bd&quot;&gt;https://preview.redd.it/9lbv5ocaymfc1.png?width=412&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3d7282b8c88c39bdacf48a4a6ad867c0fdc574bd&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I have also set up a custom callback handler to go deep into the issue and what I found is that ChatOpenAI from langchain_openai does not call ainvoke as ChatOpenAI langchain.chat_models did.&lt;/p&gt; &lt;p&gt;THank you for your help&lt;/p&gt; &lt;h3&gt;Code&lt;/h3&gt; &lt;pre&gt;&lt;code&gt;import os import traceback from typing import Any, Dict, List, Optional from uuid import UUID from langchain_community.callbacks import get_openai_callback from langchain_core.agents import AgentFinish from langchain_openai import ChatOpenAI from langchain.prompts import PromptTemplate from langchain.tools.render import render_text_description from langchain.agents.format_scratchpad import format_log_to_str from langchain.agents.output_parsers import ReActSingleInputOutputParser from langchain.schema import HumanMessage, LLMResult from langchain.callbacks.base import AsyncCallbackHandler from langchain.agents import AgentExecutor from app.services.llm.prompt import prompt_raw from app.services.llm.tools.build_tools import tools from app.classes.CustomBuffer import CustomConversationBufferMemory memory = CustomConversationBufferMemory(memory_key=&amp;quot;chat_history&amp;quot;, return_messages=True) class MyCustomAsyncHandler(AsyncCallbackHandler): async def on_llm_end(self, response: LLMResult, **kwargs: Any) -&amp;gt; None: &amp;quot;&amp;quot;&amp;quot;Run when chain ends running.&amp;quot;&amp;quot;&amp;quot; print(&amp;quot;RESPONSE: &amp;quot;, response) print(&amp;quot;Hi! I just woke up. Your llm is ending&amp;quot;) async def ask_assistant(input: str) -&amp;gt; str: prompt = PromptTemplate.from_template(prompt_raw) prompt = prompt.partial( language=&amp;quot;Spanish&amp;quot;, tools=render_text_description(tools), tool_names=&amp;quot;, &amp;quot;.join([t.name for t in tools]), ) llm = ChatOpenAI( temperature=0, model_name=&amp;quot;gpt-4&amp;quot;, openai_api_key=os.environ[&amp;quot;OPENAI_API_KEY&amp;quot;], callbacks=[MyCustomAsyncHandler()], ) llm_with_stop = llm.bind(stop=[&amp;quot;\nObservation&amp;quot;]) agent = ( { &amp;quot;input&amp;quot;: lambda x: x[&amp;quot;input&amp;quot;], &amp;quot;agent_scratchpad&amp;quot;: lambda x: format_log_to_str(x[&amp;quot;intermediate_steps&amp;quot;]), &amp;quot;chat_history&amp;quot;: lambda x: x[&amp;quot;chat_history&amp;quot;], } | prompt | llm_with_stop | ReActSingleInputOutputParser() ) agent_executor = AgentExecutor( agent=agent, tools=tools, verbose=True, memory=memory, max_execution_time=60, handle_parsing_errors=True, ) with get_openai_callback() as cb: clara_ai_resp = await agent_executor.ainvoke({&amp;quot;input&amp;quot;: input}) clara_ai_output = clara_ai_resp[&amp;quot;output&amp;quot;] print(&amp;quot;CB: &amp;quot;, cb) return clara_ai_output, input, cb &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/marcuss171&quot;&gt; /u/marcuss171 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aey6gi/get_openai_callback_not_working_when_using_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aey6gi/get_openai_callback_not_working_when_using_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1aey6gi</id><media:thumbnail url="https://b.thumbs.redditmedia.com/2_9q3TSXV0C94uCFK3v7tn0X9sdrY5mnwzQK8rN1ZzY.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1aey6gi/get_openai_callback_not_working_when_using_agent/" /><updated>2024-01-30T20:18:08+00:00</updated><published>2024-01-30T20:18:08+00:00</published><title>get_openai_callback not working when using Agent Executor after updating to latest version of Langchain</title></entry><entry><author><name>/u/aniketmaurya</name><uri>https://www.reddit.com/user/aniketmaurya</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aet9j9/document_search_and_retrieval_using_rag_powered/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/duoat8J8634e4Rv2ZQhE_tm9r0z0kHVcItCWmCNZjF4.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3519deab9d721c281488cc974e88b2b288109bd0&quot; alt=&quot;Document Search And Retrieval Using RAG - powered by Langchain&quot; title=&quot;Document Search And Retrieval Using RAG - powered by Langchain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://lightning.ai/lightning-ai/studios/document-search-and-retrieval-using-rag&quot;&gt;This Studio&lt;/a&gt; is a minimal reproducible pipeline to retrieve semantically similar documents based on the input query. The next step for this Studio involves connecting an LLM and engaging in a chat with your document through the retrieval pipeline.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;The retriever pipeline in this Studio is composed of the following components:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Document Loader&lt;/strong&gt;: Load the document (.txt, .pdf, .docx, .ppt) and perform text cleaning &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Text Splitter&lt;/strong&gt;: Split the document texts into multiple chunks &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Embedding Generation&lt;/strong&gt;: Generate vector representation of text chunks&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Vector database&lt;/strong&gt;: Embed and store each of the chunks and store in a vector DB &lt;/li&gt; &lt;li&gt;&lt;strong&gt;Retriever and Reranking&lt;/strong&gt;: Retrieve data based on query similarity&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/idqetsa1zlfc1.png?width=3058&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a1b47eb6c477e7762bc745875cda45e9d08500e&quot;&gt;https://preview.redd.it/idqetsa1zlfc1.png?width=3058&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a1b47eb6c477e7762bc745875cda45e9d08500e&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://lightning.ai/lightning-ai/studios/document-search-and-retrieval-using-rag&quot;&gt;https://lightning.ai/lightning-ai/studios/document-search-and-retrieval-using-rag&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/aniketmaurya&quot;&gt; /u/aniketmaurya &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aet9j9/document_search_and_retrieval_using_rag_powered/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aet9j9/document_search_and_retrieval_using_rag_powered/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1aet9j9</id><media:thumbnail url="https://external-preview.redd.it/duoat8J8634e4Rv2ZQhE_tm9r0z0kHVcItCWmCNZjF4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3519deab9d721c281488cc974e88b2b288109bd0" /><link href="https://www.reddit.com/r/LangChain/comments/1aet9j9/document_search_and_retrieval_using_rag_powered/" /><updated>2024-01-30T17:01:10+00:00</updated><published>2024-01-30T17:01:10+00:00</published><title>Document Search And Retrieval Using RAG - powered by Langchain</title></entry><entry><author><name>/u/Fine-Firefighter-120</name><uri>https://www.reddit.com/user/Fine-Firefighter-120</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I&amp;#39;m curious as to how I can convert approximately 200,000 words of journaling that I have done into a book. It&amp;#39;s messy, unedited stuff that I&amp;#39;ve put down. I just want to throw it into a database somehow and ask chatgpt to make sense of it. Is that something that is possible now?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I think I need to put the content into a vector store database somehow and use langchain to query it? I wonder if there&amp;#39;s just a desktop app or a LLM wrapper somewhere that can already do this. Would love to be able to do this without having to learn python!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thanks for any wisdom you guys can provide!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fine-Firefighter-120&quot;&gt; /u/Fine-Firefighter-120 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aepyv5/convert_journal_into_a_book/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aepyv5/convert_journal_into_a_book/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aepyv5</id><link href="https://www.reddit.com/r/LangChain/comments/1aepyv5/convert_journal_into_a_book/" /><updated>2024-01-30T14:42:35+00:00</updated><published>2024-01-30T14:42:35+00:00</published><title>Convert journal into a book</title></entry><entry><author><name>/u/devinbost</name><uri>https://www.reddit.com/user/devinbost</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I noticed that GPT-4 turbo is great with tons of context. However, the output I get is too limited to rewrite all 100,000 input tokens. I&amp;#39;m trying to find a strategy that would allow me to take a legacy code base and have the LLM rewrite the entire thing. I tried a test to see if I could get ChatGPT to generate part of the result until it hits its token limit and then continue when I say next, but it doesn&amp;#39;t seem to totally follow the instructions. See the smoke test here: &lt;a href=&quot;https://chat.openai.com/share/19c19e6c-0adf-4087-b83b-affe5886498e&quot;&gt;https://chat.openai.com/share/19c19e6c-0adf-4087-b83b-affe5886498e&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I think it would be cool to use this approach to rewrite old code to use LCEL, for example.&lt;/p&gt; &lt;p&gt;Any ideas?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/devinbost&quot;&gt; /u/devinbost &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aedmys/looking_for_ideas_on_how_to_code_gen_a_100000/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1aedmys/looking_for_ideas_on_how_to_code_gen_a_100000/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1aedmys</id><link href="https://www.reddit.com/r/LangChain/comments/1aedmys/looking_for_ideas_on_how_to_code_gen_a_100000/" /><updated>2024-01-30T02:35:48+00:00</updated><published>2024-01-30T02:35:48+00:00</published><title>Looking for ideas on how to code gen a 100,000 token refactor</title></entry></feed>