<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-03T13:11:45+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Notchampa</name><uri>https://www.reddit.com/user/Notchampa</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on a student project that involves a FastAPI backend serving a RAG (Retrieval-Augmented Generation) application, which interfaces with a frontend already hosted on Netlify. The app leverages the LLaMA index, and I recently made some enhancements following the &amp;quot;small to big retrieval&amp;quot; strategies outlined &lt;a href=&quot;https://docs.llamaindex.ai/en/stable/optimizing/advanced_retrieval/advanced_retrieval.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;While these improvements have significantly boosted the app&amp;#39;s performance, they&amp;#39;ve also led to a new challenge: my current hosting solution on a Digital Ocean droplet isn&amp;#39;t cutting it anymore, as I&amp;#39;m consistently running into out-of-memory issues.&lt;/p&gt; &lt;p&gt;I&amp;#39;m now in the market for a hosting platform that can comfortably handle the heavier memory requirements of my updated backend. Key requirements include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Robust enough to support a memory-intensive FastAPI app.&lt;/li&gt; &lt;li&gt;HTTPS support for security.&lt;/li&gt; &lt;li&gt;Preferably developer-friendly and cost-effective, considering it&amp;#39;s for a student project.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Does anyone have recommendations for hosting providers or services that can meet these needs? Or, if you&amp;#39;ve worked on similar projects, I&amp;#39;d love to hear how you tackled the hosting challenges. Any insights, tips, or shared experiences would be greatly appreciated!&lt;/p&gt; &lt;p&gt;Thank you all in advance!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Notchampa&quot;&gt; /u/Notchampa &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xe8di/where_to_host_rag_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xe8di/where_to_host_rag_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18xe8di</id><link href="https://www.reddit.com/r/LangChain/comments/18xe8di/where_to_host_rag_app/" /><updated>2024-01-03T08:08:48+00:00</updated><published>2024-01-03T08:08:48+00:00</published><title>Where to host RAG app?</title></entry><entry><author><name>/u/qiu2022</name><uri>https://www.reddit.com/user/qiu2022</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xiya0/asisitsos_videopitch_for_entrepreneurs/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/Ubf_TugoXEgCSq-Z4Z04PUNpjGk_HyWbdto1Maa1Q0c.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c1e7d9e952a0d506d56f7d94ff97f3b1a7d852e1&quot; alt=&quot;AsisitsOS VideoPitch for Entrepreneurs&quot; title=&quot;AsisitsOS VideoPitch for Entrepreneurs&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/qiu2022&quot;&gt; /u/qiu2022 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=HgNlae3dHQk&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xiya0/asisitsos_videopitch_for_entrepreneurs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18xiya0</id><media:thumbnail url="https://external-preview.redd.it/Ubf_TugoXEgCSq-Z4Z04PUNpjGk_HyWbdto1Maa1Q0c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1e7d9e952a0d506d56f7d94ff97f3b1a7d852e1" /><link href="https://www.reddit.com/r/LangChain/comments/18xiya0/asisitsos_videopitch_for_entrepreneurs/" /><updated>2024-01-03T13:04:44+00:00</updated><published>2024-01-03T13:04:44+00:00</published><title>AsisitsOS VideoPitch for Entrepreneurs</title></entry><entry><author><name>/u/PrestigiousOne1253</name><uri>https://www.reddit.com/user/PrestigiousOne1253</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am using langchain VectorStore (currently QDrant and plain to use OpenSearch in future). &lt;/p&gt; &lt;p&gt;It works fine, but I have issues. If I run addDocument for the same doc twice - I have two copies of the doc in store. &lt;/p&gt; &lt;p&gt;Of course I can search for doc with a give is in qdrant before adding it (transactions?). But I wonder if there is standard way to ensure uniqueness? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/PrestigiousOne1253&quot;&gt; /u/PrestigiousOne1253 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xidx1/vectorstoreadddocuments_do_not_add_duplicates/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xidx1/vectorstoreadddocuments_do_not_add_duplicates/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18xidx1</id><link href="https://www.reddit.com/r/LangChain/comments/18xidx1/vectorstoreadddocuments_do_not_add_duplicates/" /><updated>2024-01-03T12:34:19+00:00</updated><published>2024-01-03T12:34:19+00:00</published><title>VectorStore.addDocuments - do not add duplicates</title></entry><entry><author><name>/u/ruhrohj</name><uri>https://www.reddit.com/user/ruhrohj</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all,&lt;/p&gt; &lt;p&gt;I currently have this codebase right here that uses &lt;code&gt;RetrievalQA&lt;/code&gt; to create a Q&amp;amp;A Chatbot. This current iteration uses &lt;code&gt;Chroma&lt;/code&gt; as the vectorstore, and works perfectly.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;vectorstore = Chroma(persist_directory=&amp;quot;./chroma_db&amp;quot;, embedding_function=OpenAIEmbeddings()) template = &amp;quot;&amp;quot;&amp;quot; Instructions here {context} Question: {question} Helpful Answer: &amp;quot;&amp;quot;&amp;quot; QA_CHAIN_PROMPT = PromptTemplate(input_variables=[&amp;quot;context&amp;quot;, &amp;quot;question&amp;quot;], template=template) llm = ChatOpenAI(model_name=&amp;quot;gpt-3.5-turbo&amp;quot;, temperature=0) qa = RetrievalQA.from_chain_type(llm, chain_type=&amp;#39;stuff&amp;#39;, retriever=vectorstore.as_retriever(), chain_type_kwargs={&amp;quot;prompt&amp;quot;: QA_CHAIN_PROMPT}) qa.run(query) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;However, I am required to migrate the vector database over to Azure CosmosDB (vCore). Following the documentations, I have created a function that converts my text document into embeddings, and writes them to CosmosDB.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;def CosmosEmbedder(): loader = TextLoader(&amp;quot;./data/file.txt&amp;quot;) data = loader.load() # Document Splitting text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0) all_splits = text_splitter.split_documents(data) CONNECTION_STRING = os.getenv(&amp;quot;MONGO_URI&amp;quot;) NAMESPACE = &amp;quot;testdb.testcollection&amp;quot; DB_NAME, COLLECTION_NAME = NAMESPACE.split(&amp;quot;.&amp;quot;) client: MongoClient = MongoClient(CONNECTION_STRING) collection = client[DB_NAME][COLLECTION_NAME] vectorstore = AzureCosmosDBVectorSearch(collection, OpenAIEmbeddings()) vectorstore.add_documents(all_splits) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And using a similar function, I am able to verify that the embeddings do exist within CosmosDB. Now here is where the documentation gets unclear to me. The documentation proceeds to use similarity search as a working example. But my goal is to use the CosmosDB as a vectorstore for &lt;code&gt;RetrievalQA&lt;/code&gt; instead. &lt;/p&gt; &lt;p&gt;Does anyone have any idea on how to implement this? For reference, the documentation I was referring to can be found &lt;a href=&quot;https://python.langchain.com/docs/integrations/vectorstores/azure_cosmos_db&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Greatly appreciate any inputs on the situation.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ruhrohj&quot;&gt; /u/ruhrohj &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xhjnu/integrating_azure_cosmosdb_as_vectorstore_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xhjnu/integrating_azure_cosmosdb_as_vectorstore_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18xhjnu</id><link href="https://www.reddit.com/r/LangChain/comments/18xhjnu/integrating_azure_cosmosdb_as_vectorstore_for/" /><updated>2024-01-03T11:46:25+00:00</updated><published>2024-01-03T11:46:25+00:00</published><title>Integrating Azure CosmosDB as vectorstore for RetrievalQA?</title></entry><entry><author><name>/u/theSavviestTechDude</name><uri>https://www.reddit.com/user/theSavviestTechDude</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xbb2u/anyone_experiencing_slow_openai/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/5KuqG5BfN6KBDYAvKSHoMnPM3Tat12K4cLo1hMXo06c.jpg&quot; alt=&quot;Anyone experiencing slow OpenAI responses/completions?&quot; title=&quot;Anyone experiencing slow OpenAI responses/completions?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I was trying out some LCEL chains on Jupyter Notebook, and all of a sudden, I realized that now my chat completions are taking four times longer than they were yesterday.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/4ac8dgews5ac1.png?width=737&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=84d5115a4d74a73779b9a2deb4f2c12ffd5ffad1&quot;&gt;https://preview.redd.it/4ac8dgews5ac1.png?width=737&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=84d5115a4d74a73779b9a2deb4f2c12ffd5ffad1&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/theSavviestTechDude&quot;&gt; /u/theSavviestTechDude &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xbb2u/anyone_experiencing_slow_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xbb2u/anyone_experiencing_slow_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18xbb2u</id><media:thumbnail url="https://b.thumbs.redditmedia.com/5KuqG5BfN6KBDYAvKSHoMnPM3Tat12K4cLo1hMXo06c.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/18xbb2u/anyone_experiencing_slow_openai/" /><updated>2024-01-03T05:15:45+00:00</updated><published>2024-01-03T05:15:45+00:00</published><title>Anyone experiencing slow OpenAI responses/completions?</title></entry><entry><author><name>/u/modularmindapp</name><uri>https://www.reddit.com/user/modularmindapp</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xh0em/nocode_aitools_chatgpt_openai_gpt4_ai_automation/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/ZzY2YjgwdWRrN2FjMcfajYwUhKQe1zXM0WQRT4GM_HFSo3BG7JZ-OYhEowhD.png?width=140&amp;amp;height=140&amp;amp;crop=140:140,smart&amp;amp;format=jpg&amp;amp;v=enabled&amp;amp;lthumb=true&amp;amp;s=8dcf9857d0ea75974ab6e2e9e3e56d9437e55ed5&quot; alt=&quot;#nocode #aitools #chatgpt #openai #gpt4 #ai #automation&quot; title=&quot;#nocode #aitools #chatgpt #openai #gpt4 #ai #automation&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/modularmindapp&quot;&gt; /u/modularmindapp &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/d8ods8fck7ac1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18xh0em/nocode_aitools_chatgpt_openai_gpt4_ai_automation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18xh0em</id><media:thumbnail url="https://external-preview.redd.it/ZzY2YjgwdWRrN2FjMcfajYwUhKQe1zXM0WQRT4GM_HFSo3BG7JZ-OYhEowhD.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=8dcf9857d0ea75974ab6e2e9e3e56d9437e55ed5" /><link href="https://www.reddit.com/r/LangChain/comments/18xh0em/nocode_aitools_chatgpt_openai_gpt4_ai_automation/" /><updated>2024-01-03T11:13:09+00:00</updated><published>2024-01-03T11:13:09+00:00</published><title>#nocode #aitools #chatgpt #openai #gpt4 #ai #automation</title></entry><entry><author><name>/u/Ill_Bodybuilder3499</name><uri>https://www.reddit.com/user/Ill_Bodybuilder3499</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;i have built a RAG app with Langchain locally. Now I want to host it in the cloud for a little demo showcase (less than 5 users), so that others can try out how well it is working. &lt;/p&gt; &lt;p&gt;What would be a cheap and efficient way to host a Langchain App in the cloud?&lt;/p&gt; &lt;p&gt;Fyi: I have used a quantized Mixtral 8x7b model (less rhan 30GB RAM required). Alternatively I can switch to smaller models like a quantized Mistral 7B model.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ill_Bodybuilder3499&quot;&gt; /u/Ill_Bodybuilder3499 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wzh73/rag_demo_cheapest_way_to_host/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wzh73/rag_demo_cheapest_way_to_host/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18wzh73</id><link href="https://www.reddit.com/r/LangChain/comments/18wzh73/rag_demo_cheapest_way_to_host/" /><updated>2024-01-02T20:31:36+00:00</updated><published>2024-01-02T20:31:36+00:00</published><title>Rag Demo - Cheapest way to host</title></entry><entry><author><name>/u/nouskiski</name><uri>https://www.reddit.com/user/nouskiski</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;ol&gt; &lt;li&gt;&amp;#x200B;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;There&amp;#39;s a **kwargs parameter in initialize_agent for additional keywords arguments for you agent. When i ask the LangChain chat which keywords are available for each agent, it doesn&amp;#39;t even know. Where can i find more detailed documentation for each agent? Is want to know which keywords are available for each agent, or am i misunderstanding? Thanks.&lt;/p&gt; &lt;p&gt;2.&lt;/p&gt; &lt;p&gt;Is langchain even worth it? Maybe it&amp;#39;s just me, but i think the documentation is very bad, but is there even a better alternative?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nouskiski&quot;&gt; /u/nouskiski &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18x4w1f/kwargs_in_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18x4w1f/kwargs_in_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18x4w1f</id><link href="https://www.reddit.com/r/LangChain/comments/18x4w1f/kwargs_in_agents/" /><updated>2024-01-03T00:11:15+00:00</updated><published>2024-01-03T00:11:15+00:00</published><title>*kwargs in Agents</title></entry><entry><author><name>/u/Background-Maybe-381</name><uri>https://www.reddit.com/user/Background-Maybe-381</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello people,&lt;/p&gt; &lt;p&gt;We&amp;#39;ve been at it for a long time and still are not understanding how to get a correct output from any model. So what we&amp;#39;re having problems understanding is how langchain expects the prompt template to be formated. THe thought flow. We are trying different Thought, Action, Action Input and Observation, Final Answer, etc.. methods and none seem to work with tools and regular conversations (and a mix of these).&lt;/p&gt; &lt;p&gt;What we really need is a manual to read that talks about how these keywords are supposed to be used. For example, which ones are important for the agent and which for the llm.&lt;/p&gt; &lt;p&gt;We&amp;#39;ve tried so many templates. Some stop responding at the Observation point, some include the whole thought process in the response, some don&amp;#39;t work at all. We are god at reading and understanding. We just need an official source to read from. If there is none, can someone help us here ?&lt;/p&gt; &lt;p&gt;Here is an example of our prompt template right now, but stalls :&lt;/p&gt; &lt;p&gt;&amp;lt;s&amp;gt; Today is {date}. Your name is Betty. You work for Shopping321 in Spain. Your duties involve helping our customer named {name} manage his online purchases.&lt;/p&gt; &lt;p&gt;TOOLS:&lt;/p&gt; &lt;p&gt;----&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;You have access to the following tools:&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;(LIST OF TOOLS I DELETED FOR PRIVACY, but they are working)&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;THOUGHT PROCESS:&lt;/p&gt; &lt;p&gt;----&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Start your thought process using the following format:&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thought: What´s the nature of the request? Does it involve using a specific tool?&lt;/p&gt; &lt;p&gt;Process: Understand the user&amp;#39;s request and determine if you need to use a tool or various tools.&lt;/p&gt; &lt;p&gt;Temporary Observation: Initial thoughts on how to proceed.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;If you need to use a tool, use the following thought process:&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thought: Do I need to use a tool? Yes.&lt;/p&gt; &lt;p&gt;Action: [Action to take, choose from tool list] like this example: &amp;quot;InvoiceSearch&amp;quot;&lt;/p&gt; &lt;p&gt;Action Input: the input for the action and {request_id}&lt;/p&gt; &lt;p&gt;Observation: the result of the action.&lt;/p&gt; &lt;p&gt;... (this Thought/Action/Action Input/Observation can repeat only N times)&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;If you do not need to use a tool, use the following thought process:&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thought: How can I respond with my own knowledge without using a tool?&lt;/p&gt; &lt;p&gt;Process: Handle the request using natural conversation, applying the abstraction&lt;/p&gt; &lt;p&gt;Temporary Observation: Observations about the handling process&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;CONCLUSIONS:&lt;/p&gt; &lt;p&gt;----&lt;/p&gt; &lt;p&gt;Before giving the final response, gather all of your thoughts and observations made with and without tool usage. Order the thoughts aligned with the user&amp;#39;s requests. Then prepare to give a final response following this thought process:&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thought: Does the response fullfil the user&amp;#39;s request based on all of the observations gathered thus far?&lt;/p&gt; &lt;p&gt;Process: Make final adjustments in order to fullfil user&amp;#39;s requests. Use more tools if necessary.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Betty: Deliver the comprehensive final response.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Begin!&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Previous conversation history:&lt;/p&gt; &lt;p&gt;{chat_history}&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Request ID: {request_id}&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;{agent_scratchpad}&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;[INST] {input} [/INST] &amp;lt;/s&amp;gt;&lt;/p&gt; &lt;p&gt;I am willing to pay via paypal for any personal assistance. Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Background-Maybe-381&quot;&gt; /u/Background-Maybe-381 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18x356k/struggling_understanding_conversationalchatagent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18x356k/struggling_understanding_conversationalchatagent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18x356k</id><link href="https://www.reddit.com/r/LangChain/comments/18x356k/struggling_understanding_conversationalchatagent/" /><updated>2024-01-02T22:58:09+00:00</updated><published>2024-01-02T22:58:09+00:00</published><title>Struggling understanding conversational-chat-agent and prompt template</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Learning about this quite extensively for over a month. Have always known that Llamaindex also exist and has the same purpose. &lt;/p&gt; &lt;p&gt;In which usecases or tools has Llamaindex been better or and vice versa for LangChain&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wooh1/in_your_experience_for_which_usecases_is/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wooh1/in_your_experience_for_which_usecases_is/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18wooh1</id><link href="https://www.reddit.com/r/LangChain/comments/18wooh1/in_your_experience_for_which_usecases_is/" /><updated>2024-01-02T12:49:20+00:00</updated><published>2024-01-02T12:49:20+00:00</published><title>In your experience for which usecases is LangChain better and for which LlamaIndex</title></entry><entry><author><name>/u/NetIcy6229</name><uri>https://www.reddit.com/user/NetIcy6229</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;When I use Postman to query the Hubspot endpoint: &lt;a href=&quot;https://api.hubapi.com/crm/v3/properties/contacts&quot;&gt;https://api.hubapi.com/crm/v3/properties/contacts&lt;/a&gt; using the authorisation below (where X is of course the censored token):&lt;/p&gt; &lt;pre&gt;&lt;code&gt; headers = { &amp;#39;Authorization&amp;#39;: &amp;#39;Bearer X&amp;#39; } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I get a working API response.&lt;/p&gt; &lt;p&gt;However, when I try to pass the above as part of natural language instructions to Langchain&amp;#39;s API Chain (see code below), authentication fails.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;HubSpotDocs = &amp;quot;&amp;quot;&amp;quot; The below is Hubspot API documentation showing how to create a contact. The endpoint is: &amp;quot;https://api.hubapi.com/crm/v3/properties/contacts&amp;quot;. ///Example request body to create a new contact { &amp;quot;properties&amp;quot;: { &amp;quot;email&amp;quot;: &amp;quot;example@hubspot.com&amp;quot;, &amp;quot;firstname&amp;quot;: &amp;quot;Jane&amp;quot;, &amp;quot;lastname&amp;quot;: &amp;quot;Doe&amp;quot;, &amp;quot;phone&amp;quot;: &amp;quot;(555) 555-5555&amp;quot;, &amp;quot;company&amp;quot;: &amp;quot;HubSpot&amp;quot;, &amp;quot;website&amp;quot;: &amp;quot;hubspot.com&amp;quot;, &amp;quot;lifecyclestage&amp;quot;: &amp;quot;marketingqualifiedlead&amp;quot; } } Use the below authorisation: headers = { &amp;#39;Authorization&amp;#39;: &amp;#39;Bearer X&amp;#39; } &amp;quot;&amp;quot;&amp;quot; llm = ChatOpenAI(temperature=0, model= &amp;#39;gpt-3.5-turbo-1106&amp;#39;, openai_api_key=&amp;quot;Y&amp;quot;) Test = APIChain.from_llm_and_api_docs(llm, HubSpotDocs,limit_to_domains=None, verbose=True) Test.run(&amp;quot;Create a new contact named Sara with email sara@google.com. She resides in Toronto.&amp;quot;) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The LLM responds with:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;gt; Entering new APIChain chain... https://api.hubapi.com/crm/v3/properties/contacts?properties={&amp;quot;email&amp;quot;:&amp;quot;sara@google.com&amp;quot;,&amp;quot;firstname&amp;quot;:&amp;quot;Sara&amp;quot;,&amp;quot;city&amp;quot;:&amp;quot;Toronto&amp;quot;} {&amp;quot;status&amp;quot;:&amp;quot;error&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;Authentication credentials not found. This API supports OAuth 2.0 authentication and you can find more details at https://developers.hubspot.com/docs/methods/auth/oauth-overview&amp;quot;,&amp;quot;correlationId&amp;quot;:&amp;quot;3a41a5c5-dbe9-4b19-8cc6-d6293290a52b&amp;quot;,&amp;quot;category&amp;quot;:&amp;quot;INVALID_AUTHENTICATION&amp;quot;} &amp;gt; Finished chain. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Clearly, the LLM is understanding the ask correctly as it maps e.g. &amp;quot;Toronto&amp;quot; to city. However, the authorisation is failing (even though it works in Postman). This means that the issue isn&amp;#39;t the authentication but more so the way Langchain/the LLM interprets (then passes to Hubspot) authorisation. How can I fix this? I am facing a similar issue with attempting to call the Google Calendar API using APIChain method/natural language.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/NetIcy6229&quot;&gt; /u/NetIcy6229 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wxfd2/calling_api_doesnt_work_when_using_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wxfd2/calling_api_doesnt_work_when_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18wxfd2</id><link href="https://www.reddit.com/r/LangChain/comments/18wxfd2/calling_api_doesnt_work_when_using_langchain/" /><updated>2024-01-02T19:10:15+00:00</updated><published>2024-01-02T19:10:15+00:00</published><title>Calling API doesn't work when using Langchain</title></entry><entry><author><name>/u/Spare_Cancel3205</name><uri>https://www.reddit.com/user/Spare_Cancel3205</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What are some of the trending tools that companies are looking for in the interns in the field of AI?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Spare_Cancel3205&quot;&gt; /u/Spare_Cancel3205 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wtxcy/trening_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wtxcy/trening_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18wtxcy</id><link href="https://www.reddit.com/r/LangChain/comments/18wtxcy/trening_tools/" /><updated>2024-01-02T16:50:43+00:00</updated><published>2024-01-02T16:50:43+00:00</published><title>Trening tools</title></entry><entry><author><name>/u/smileymileycoin</name><uri>https://www.reddit.com/user/smileymileycoin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/smileymileycoin&quot;&gt; /u/smileymileycoin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.secondstate.io/articles/mixtral-8-7b/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wjpck/easy_setup_selfhost_mixtral8x7b_across_devices/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18wjpck</id><link href="https://www.reddit.com/r/LangChain/comments/18wjpck/easy_setup_selfhost_mixtral8x7b_across_devices/" /><updated>2024-01-02T07:30:03+00:00</updated><published>2024-01-02T07:30:03+00:00</published><title>Easy Setup! Self-host Mixtral-8x7B across devices with a 2M inference app</title></entry><entry><author><name>/u/TheReaderIsStupid</name><uri>https://www.reddit.com/user/TheReaderIsStupid</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m using langchains conversation for creating a chatbot and this is the prompt its generated after few convos&lt;/p&gt; &lt;pre&gt;&lt;code&gt;The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. Current conversation: Human: Hi, my name is Andrew AI: Hello Andrew, it&amp;#39;s nice to meet you. My name is Bard, and I&amp;#39;m an AI chatbot. I&amp;#39;m still under development, but I&amp;#39;m learning more every day. I&amp;#39;m happy to chat with you about anything you like. What would you like to talk about? Human: What is 1+1? AI: 1 + 1 is 2. Human: What is my name? AI: I do not have access to your personal information, so I cannot answer that question. Human: What is my name? AI: I do not have access to your personal information, so I cannot answer that question. Human: Hi, i need to go grocery shopping tomorrow AI: That&amp;#39;s great! Grocery shopping can be a fun and rewarding experience. What kind of groceries do you need to buy? Human: What is 1+1? AI: 1 + 1 is 2. Human: when do i need to go grocery shopping? AI: &amp;#39;You did not specify when you need to go grocery shopping.&amp;#39; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;OpenAI answers the question correctly, but gemini isin&amp;#39;t using the history. Do langchain prompts works for openai only and I need to change it or is something else worng.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;llm = ChatGoogleGenerativeAI(model=&amp;quot;gemini-pro&amp;quot;, temperature=0) memory = ConversationBufferMemory() conversation = ConversationChain( llm=llm, memory = memory, verbose=True ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/TheReaderIsStupid&quot;&gt; /u/TheReaderIsStupid &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wgxvt/chatgooglegenerativeai_not_considering_history/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wgxvt/chatgooglegenerativeai_not_considering_history/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18wgxvt</id><link href="https://www.reddit.com/r/LangChain/comments/18wgxvt/chatgooglegenerativeai_not_considering_history/" /><updated>2024-01-02T04:50:43+00:00</updated><published>2024-01-02T04:50:43+00:00</published><title>ChatGoogleGenerativeAI not considering history, when asked to predict unlike openAI using langchain conversation</title></entry><entry><author><name>/u/modularmindapp</name><uri>https://www.reddit.com/user/modularmindapp</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wg52e/dive_into_the_world_of_aipowered_market_research/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/fcMe3MQijXdRwWpctGl73iohW5S4qVYaJeMq7C5TJns.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=20642b42169af4ae71531e7c45511c7434e53ba8&quot; alt=&quot;🚀 Dive into the world of AI-powered market research with our step-by-step guide using ModularMind #nocode #aitools #chatgpt #openai #gpt4&quot; title=&quot;🚀 Dive into the world of AI-powered market research with our step-by-step guide using ModularMind #nocode #aitools #chatgpt #openai #gpt4&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/modularmindapp&quot;&gt; /u/modularmindapp &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=YIz_0cWuDGM&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18wg52e/dive_into_the_world_of_aipowered_market_research/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18wg52e</id><media:thumbnail url="https://external-preview.redd.it/fcMe3MQijXdRwWpctGl73iohW5S4qVYaJeMq7C5TJns.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=20642b42169af4ae71531e7c45511c7434e53ba8" /><link href="https://www.reddit.com/r/LangChain/comments/18wg52e/dive_into_the_world_of_aipowered_market_research/" /><updated>2024-01-02T04:08:42+00:00</updated><published>2024-01-02T04:08:42+00:00</published><title>🚀 Dive into the world of AI-powered market research with our step-by-step guide using ModularMind #nocode #aitools #chatgpt #openai #gpt4</title></entry><entry><author><name>/u/Icy-Sorbet-9458</name><uri>https://www.reddit.com/user/Icy-Sorbet-9458</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18w2ms9/revolucionando_el_web_scraping_con_ia/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/OIntCWLQG6nmhkOAedh23dIr3z2W-6XGNSrmdOQJChQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ada9f28062924c1c276cf2cf4fe1e896af93d184&quot; alt=&quot;Revolucionando el Web Scraping con IA&quot; title=&quot;Revolucionando el Web Scraping con IA&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Todos sabemos lo &amp;quot;&lt;strong&gt;tedioso&lt;/strong&gt;&amp;quot; que es hacer web scrapping, entender la estructura de un sitio web para que nuestro código pueda obtener resultados, estar en constante mantenimiento por si el sitio web cambia su estructura o si agregan funcionalidad con java script para cargar dinámicamente la información. Pero &lt;strong&gt;¿Que pasaría si hubiera una manera de convertir este &amp;quot;tedioso&amp;quot; proceso en uno muy sencillo, adaptable a cualquier estructura?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;por ejemplo:&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/mmfiq0b8dv9c1.png?width=2232&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=377d8ff89ed3c0b16713a0c2f2dd742e27f5f9fa&quot;&gt;https://preview.redd.it/mmfiq0b8dv9c1.png?width=2232&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=377d8ff89ed3c0b16713a0c2f2dd742e27f5f9fa&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/g8rvpedadv9c1.png?width=1488&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=232b1858d1a70ffdff9d470dbfe279cc84e9bd86&quot;&gt;https://preview.redd.it/g8rvpedadv9c1.png?width=1488&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=232b1858d1a70ffdff9d470dbfe279cc84e9bd86&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Le asignamos la tarea a la IA que se adapte a cualquier estructura de cualquier sitio web y obtenga resultados orgánicos de calidad.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/s0jp125hdv9c1.png?width=1189&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2b59846330b114b9cf1b3aa0763024999a7d6dc9&quot;&gt;https://preview.redd.it/s0jp125hdv9c1.png?width=1189&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2b59846330b114b9cf1b3aa0763024999a7d6dc9&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Pueden leer el artículo completo en el siguiente enlace:Link: &lt;a href=&quot;https://es.linkedin.com/pulse/revolucionando-el-web-scraping-con-ia-jean-pierre-alvarez-8gmge?trk=public_post_feed-article-content&quot;&gt;https://es.linkedin.com/pulse/revolucionando-el-web-scraping-con-ia-jean-pierre-alvarez-8gmge?trk=public_post_feed-article-content&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Icy-Sorbet-9458&quot;&gt; /u/Icy-Sorbet-9458 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18w2ms9/revolucionando_el_web_scraping_con_ia/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18w2ms9/revolucionando_el_web_scraping_con_ia/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18w2ms9</id><media:thumbnail url="https://external-preview.redd.it/OIntCWLQG6nmhkOAedh23dIr3z2W-6XGNSrmdOQJChQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ada9f28062924c1c276cf2cf4fe1e896af93d184" /><link href="https://www.reddit.com/r/LangChain/comments/18w2ms9/revolucionando_el_web_scraping_con_ia/" /><updated>2024-01-01T18:14:45+00:00</updated><published>2024-01-01T18:14:45+00:00</published><title>Revolucionando el Web Scraping con IA</title></entry><entry><author><name>/u/todaysgamer</name><uri>https://www.reddit.com/user/todaysgamer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Langchain seems pretty messed up. &lt;/p&gt; &lt;p&gt;- The documentation is subpar compared to what one can expect from a tool that can be used in production. I tried searching for what&amp;#39;s the difference between chain and agent without getting a clear answer to it. &lt;/p&gt; &lt;p&gt;- The discord community is pretty inactive honestly so many unclosed queries still in the chat.&lt;/p&gt; &lt;p&gt;- There are so many ways of creating, for instance, an agent. and the document fails to provide a structured approach to incrementally introducing these different methods.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;So are people/companies actually using langchain in their products?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/todaysgamer&quot;&gt; /u/todaysgamer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v0s3k/is_anyone_actually_using_langchain_in_production/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v0s3k/is_anyone_actually_using_langchain_in_production/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18v0s3k</id><link href="https://www.reddit.com/r/LangChain/comments/18v0s3k/is_anyone_actually_using_langchain_in_production/" /><updated>2023-12-31T05:49:13+00:00</updated><published>2023-12-31T05:49:13+00:00</published><title>Is anyone actually using Langchain in production?</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi so here is what I want langchain to do. &lt;/p&gt; &lt;p&gt;Go to a website, submit some text in the text_search bar&lt;/p&gt; &lt;p&gt;wait for the search result to load, fetch some of the contents of the search back&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v6lqb/anyone_done_some_webscraping_using_langchain_can/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v6lqb/anyone_done_some_webscraping_using_langchain_can/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18v6lqb</id><link href="https://www.reddit.com/r/LangChain/comments/18v6lqb/anyone_done_some_webscraping_using_langchain_can/" /><updated>2023-12-31T12:15:36+00:00</updated><published>2023-12-31T12:15:36+00:00</published><title>Anyone done some webscraping using LangChain can guide me?</title></entry><entry><author><name>/u/Honest-Worth3677</name><uri>https://www.reddit.com/user/Honest-Worth3677</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v5kpn/serve_a_custom_llm_trained_with_rlhf_in_free_colab/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/GisUL3yAsXDY0BxvCDXNf17u6tQsjxCwgIZRzPIzTAc.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9c42231a8b3ac9d2276dc05acd931d1a1cc56c06&quot; alt=&quot;Serve a Custom LLM Trained with RLHF in - FREE COLAB 📓&quot; title=&quot;Serve a Custom LLM Trained with RLHF in - FREE COLAB 📓&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Honest-Worth3677&quot;&gt; /u/Honest-Worth3677 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=dX27661ZFWc&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18v5kpn/serve_a_custom_llm_trained_with_rlhf_in_free_colab/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_18v5kpn</id><media:thumbnail url="https://external-preview.redd.it/GisUL3yAsXDY0BxvCDXNf17u6tQsjxCwgIZRzPIzTAc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c42231a8b3ac9d2276dc05acd931d1a1cc56c06" /><link href="https://www.reddit.com/r/LangChain/comments/18v5kpn/serve_a_custom_llm_trained_with_rlhf_in_free_colab/" /><updated>2023-12-31T11:03:59+00:00</updated><published>2023-12-31T11:03:59+00:00</published><title>Serve a Custom LLM Trained with RLHF in - FREE COLAB 📓</title></entry><entry><author><name>/u/brianomars1123</name><uri>https://www.reddit.com/user/brianomars1123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m trying to just load a pdf from a URL. I&amp;#39;m confused how to do so using the &lt;a href=&quot;https://js.langchain.com/docs/integrations/document_loaders/web_loaders/pdf&quot;&gt;webPDFLoader&lt;/a&gt;. If anyone has a bit of time, please help explain how to implement this? I would appreciate any help pls.&lt;/p&gt; &lt;p&gt;I&amp;#39;m doing this in nextjs. Where in the webPDFloader section do I put the pdfUrl variable?&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;quot;use client&amp;quot;; import React, { useEffect } from &amp;quot;react&amp;quot;; import { WebPDFLoader } from &amp;quot;langchain/document_loaders/web/pdf&amp;quot;; import { guestPdfId } from &amp;quot;@/components/Hero&amp;quot;; import { Document } from &amp;quot;react-pdf&amp;quot;; const bucketId = process.env.NEXT_PUBLIC_APPWRITE_BUCKET_ID!; const fileId = guestPdfId; const projectId = process.env.NEXT_PUBLIC_APPWRITE_PROJECT_ID!; const pdfUrl = `https://cloud.appwrite.io/v1/storage/buckets/${bucketId}/files/${fileId}/view?project=${projectId}&amp;amp;mode=admin`; // webPDFLoader const blob = new Blob(); // e.g. from a file input const loader = new WebPDFLoader(blob, { // you may need to add `.then(m =&amp;gt; m.default)` to the end of the import pdfjs: () =&amp;gt; import(&amp;quot;pdfjs-dist/legacy/build/pdf.js&amp;quot;), }); docs = loader.load() const docLen = docs.length() const ProcessPdf = () =&amp;gt; { return &amp;lt;div&amp;gt; &amp;lt;button onClick={doclen}&amp;gt;Show PDF&amp;lt;/button&amp;gt; &amp;lt;/div&amp;gt;; }; export default ProcessPdf; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/brianomars1123&quot;&gt; /u/brianomars1123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18uwc21/any_alternatives_to_langchains_webpdfloader/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18uwc21/any_alternatives_to_langchains_webpdfloader/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18uwc21</id><link href="https://www.reddit.com/r/LangChain/comments/18uwc21/any_alternatives_to_langchains_webpdfloader/" /><updated>2023-12-31T01:57:36+00:00</updated><published>2023-12-31T01:57:36+00:00</published><title>Any alternatives to Langchain's webpdfloader?</title></entry><entry><author><name>/u/Zealousideal_Ad9966</name><uri>https://www.reddit.com/user/Zealousideal_Ad9966</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am new to the topic, and I want to build an assistant chatbot that can reference data from websites and docs. This can be achieved with OpenAI plugins and Cohere RAG connectors, just like using a framework like langchain. How do they compare?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zealousideal_Ad9966&quot;&gt; /u/Zealousideal_Ad9966 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18uojpr/how_langchain_or_llama_index_stack_against_native/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18uojpr/how_langchain_or_llama_index_stack_against_native/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18uojpr</id><link href="https://www.reddit.com/r/LangChain/comments/18uojpr/how_langchain_or_llama_index_stack_against_native/" /><updated>2023-12-30T20:13:48+00:00</updated><published>2023-12-30T20:13:48+00:00</published><title>How Langchain or Llama Index stack against “native” RAG solutions?</title></entry><entry><author><name>/u/sarthak_uchiha</name><uri>https://www.reddit.com/user/sarthak_uchiha</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am working on one of my clients project where the user will pass the drug name and url of a pdf , from that pdf we need to extract some fields , though chunk size kept is 2200 model is gpt-4-32k I see inconsistent results , how can I make results more consistent&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sarthak_uchiha&quot;&gt; /u/sarthak_uchiha &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18unseb/how_can_i_keep_my_outputs_consistent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18unseb/how_can_i_keep_my_outputs_consistent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18unseb</id><link href="https://www.reddit.com/r/LangChain/comments/18unseb/how_can_i_keep_my_outputs_consistent/" /><updated>2023-12-30T19:40:56+00:00</updated><published>2023-12-30T19:40:56+00:00</published><title>How can I keep my outputs consistent</title></entry><entry><author><name>/u/saymynamelol</name><uri>https://www.reddit.com/user/saymynamelol</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I work for a company that develops software to manage company operations, including freight management, interest, profits, inventory, and more. We used to provide each customer with a massive user&amp;#39;s manual as a reference for any questions they might have. However, this proved to be incredibly inefficient, so we decided to leverage the power of LLMs (Large Language Models) to create a personalized chat interface. This would allow clients to get answers directly from the manual in a more dynamic and user-friendly way.&lt;/p&gt; &lt;p&gt;Unfortunately, simply feeding the entire manual to the LLM resulted in chaotic and inaccurate outputs. Answers were often incoherent and meaningless. Thankfully, I discovered the techniques of chunking and embeddings.&lt;/p&gt; &lt;p&gt;Now, my question is: given that our company&amp;#39;s manual is already divided into smaller PDFs for each topic, should I further break down these sections into smaller chunks for LLM training, or would it be sufficient to just create embeddings from the existing PDFs? Additionally, can the LLM formulate answers by drawing information from multiple vectors (embeddings) at once? Or it only uses the info from the embedding it&amp;#39;s mostly similar to the user&amp;#39;s query?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/saymynamelol&quot;&gt; /u/saymynamelol &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18u77h9/would_it_be_smarter_to_use_chunks_of_just/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18u77h9/would_it_be_smarter_to_use_chunks_of_just/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18u77h9</id><link href="https://www.reddit.com/r/LangChain/comments/18u77h9/would_it_be_smarter_to_use_chunks_of_just/" /><updated>2023-12-30T04:46:36+00:00</updated><published>2023-12-30T04:46:36+00:00</published><title>Would it be smarter to use chunks of just embeddings in this situation?</title></entry><entry><author><name>/u/khaledmsm</name><uri>https://www.reddit.com/user/khaledmsm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hello folks &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;i hav an idea and i want start to build it but before i have question based on the nature of the project and data &lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;what should use to bulid it ? &lt;/p&gt; &lt;p&gt;when the data is static and its contains 50K document&amp;#39;s ,&lt;/p&gt; &lt;p&gt;should i use Chatgpt Api ? &lt;/p&gt; &lt;p&gt;or Langchain ? &lt;/p&gt; &lt;p&gt;or lamaindex ? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/khaledmsm&quot;&gt; /u/khaledmsm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tvsop/what_should_use_to_bulid_saas_for_chating_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tvsop/what_should_use_to_bulid_saas_for_chating_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18tvsop</id><link href="https://www.reddit.com/r/LangChain/comments/18tvsop/what_should_use_to_bulid_saas_for_chating_with/" /><updated>2023-12-29T19:55:01+00:00</updated><published>2023-12-29T19:55:01+00:00</published><title>what should use to bulid Saas for chating with static 50K document's , Chatgpt Api ? or Langchain ? or lamaindex ?</title></entry><entry><author><name>/u/DevotedToSuccess</name><uri>https://www.reddit.com/user/DevotedToSuccess</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m stuck deciding the infrastructure for my production RAG chat.&lt;/p&gt; &lt;p&gt;I am tyrying to decide between using a Fastapi server (langserve) in python, or try to create everything in the Nextjs project with Typescript.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;My thoughts so far:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;1) There is no ready-made Hybrid-search for Supabase in Python (but there is in JS)&lt;/p&gt; &lt;p&gt;2) The more advanced RAG features seem to be released in the Python version of Langchain first. like Cohere Reranking, Hyde, Query-expansion etc.&lt;/p&gt; &lt;p&gt;3) I already have the setup for the RAG in langserve, but I&amp;#39;m struggling working out how to keep a good chat history integrated against the nextjs frontend and the langserve server.&lt;/p&gt; &lt;p&gt;4) I leaning towards Supabase pgvector as my vector storage, since I feel it&amp;#39;s more cost-effective and safe in terms of control (the RAG chat will include that the user can upload files, and mix a lot of different businesses on the same index in Pinecone doesn&amp;#39;t seem like the best approach, maybe I&amp;#39;m wrong?)&lt;/p&gt; &lt;p&gt;Would appriciate some feedback so I can make the decision and move forwards.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DevotedToSuccess&quot;&gt; /u/DevotedToSuccess &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tpbcb/cant_decide_on_infrastructure_for_my_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/18tpbcb/cant_decide_on_infrastructure_for_my_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_18tpbcb</id><link href="https://www.reddit.com/r/LangChain/comments/18tpbcb/cant_decide_on_infrastructure_for_my_rag/" /><updated>2023-12-29T15:13:41+00:00</updated><published>2023-12-29T15:13:41+00:00</published><title>Can't decide on infrastructure for my RAG</title></entry></feed>