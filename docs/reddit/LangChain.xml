<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-02T18:19:10+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Healthy-Succotash458</name><uri>https://www.reddit.com/user/Healthy-Succotash458</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;br/&gt; I am creating an Agent RAG chatbot application which uses Tools.&lt;br/&gt; An example of the documents I expect to retrieve: &lt;/p&gt; &lt;p&gt;&lt;code&gt;Document(page_content=&amp;#39;Contents of lecture 1&amp;#39;, metadata={&amp;#39;source&amp;#39;: &amp;#39;Lecture-1.pdf&amp;#39;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;and the user&amp;#39;s request will look something like:&lt;/p&gt; &lt;p&gt;&lt;code&gt;Input(query=&amp;#39;summarize this lecture&amp;#39;,document_chosen=&amp;#39;Lecture-1.pdf&amp;#39;)&lt;/code&gt;&lt;/p&gt; &lt;p&gt;and I need to search ONLY on documents with the metadata source equal to &amp;#39;Lecture-1.pdf&amp;#39;.&lt;/p&gt; &lt;p&gt;I have seen in tutorials about VectorStoreRetrievers having this filtering functionality this way:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Use a filter to only retrieve documents from a specific metadata field db.as_retriever( search_kwargs={&amp;#39;filter&amp;#39;: {&amp;#39;source&amp;#39;:&amp;#39;Lecture-1.pdf&amp;#39;}} ) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and this would solve the issue if I was directly invoking the retrievers. However for Agent, I cannot use the retrievers directly, and I need to wrap the retriever in a Tool (using create_retriever_tool) in order to use the agent and run a query: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;from langchain.tools.retriever import create_retriever_tool search_tool = create_retriever_tool( lecture_retriever, &amp;quot;search_lecture_database&amp;quot;, &amp;quot;&amp;quot;&amp;quot;Searches and returns lecture information.&amp;quot;&amp;quot;&amp;quot;, ) tools = [search_tool] agent = create_react_agent(llm,tools,prompt) agent_executor = AgentExecutor(agent=agent, tools=tools) response = agent_executor.invoke({&amp;quot;input&amp;quot;:&amp;quot;Summarise this lecture&amp;quot;}) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;So with my setup, how can I pass the metadata (in this case, the name of the file) filter to the retrievers from the Agent, when the retrievers are converted to Tools? &lt;/p&gt; &lt;p&gt;Any help or comments would be much appreciated&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Healthy-Succotash458&quot;&gt; /u/Healthy-Succotash458 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciizv7/agents_rag_search_with_tools_using_metadata/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciizv7/agents_rag_search_with_tools_using_metadata/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ciizv7</id><link href="https://www.reddit.com/r/LangChain/comments/1ciizv7/agents_rag_search_with_tools_using_metadata/" /><updated>2024-05-02T15:47:25+00:00</updated><published>2024-05-02T15:47:25+00:00</published><title>Agents: RAG search with tools using Metadata Filtering</title></entry><entry><author><name>/u/machka_nip</name><uri>https://www.reddit.com/user/machka_nip</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’ve been researching Langchain Agents and really interested in the verbose feature to show chain of thought when script is running. The thing is, I’m lost over tools/toolkits and the examples I found seem to be just for tool/toolkits with an LLM. I didn’t find any examples that encompass loading documents (eg PDF, CSV, etc.), embedding and vectorizing with FAISS, using OpenAI to ask questions with the retriever. &lt;/p&gt; &lt;p&gt;Does Langchain Agents only do LLM and tool(/kits)? I’ve tried simple keyword search in Google. ChatGPT was not great because it doesn’t know the Langchain library. It would give a code snippet that wasn’t even valid when ran (like modules not existent). &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/machka_nip&quot;&gt; /u/machka_nip &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cilwu1/creating_agent_with_document_loader_retriever_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cilwu1/creating_agent_with_document_loader_retriever_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cilwu1</id><link href="https://www.reddit.com/r/LangChain/comments/1cilwu1/creating_agent_with_document_loader_retriever_llm/" /><updated>2024-05-02T17:46:35+00:00</updated><published>2024-05-02T17:46:35+00:00</published><title>Creating Agent with document loader, retriever, LLM, output parser?</title></entry><entry><author><name>/u/yadgire7</name><uri>https://www.reddit.com/user/yadgire7</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Task: Query a CSV file (without using built-in agents)&lt;/p&gt; &lt;p&gt;Input: CSV file&lt;/p&gt; &lt;p&gt;Output: JSON object like{&amp;quot;column&amp;quot;: , &amp;quot;value&amp;quot; , &amp;quot;row_ids&amp;quot;:}&lt;/p&gt; &lt;p&gt;If I embed the data and use a retriever on the vectorestore using similarity_search, I do not get all the matching instances in my result (as I cannot just use a very large k value). I used the &amp;#39;parser&amp;#39; approach and got decent results. Can anyone suggest a better approach to get more accurate results?&lt;/p&gt; &lt;p&gt;Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/yadgire7&quot;&gt; /u/yadgire7 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciltz6/chunk_csv_data_to_create_a_vectorstore/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciltz6/chunk_csv_data_to_create_a_vectorstore/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ciltz6</id><link href="https://www.reddit.com/r/LangChain/comments/1ciltz6/chunk_csv_data_to_create_a_vectorstore/" /><updated>2024-05-02T17:43:17+00:00</updated><published>2024-05-02T17:43:17+00:00</published><title>Chunk CSV Data to create a vectorstore</title></entry><entry><author><name>/u/AnEdgeLordWeeb</name><uri>https://www.reddit.com/user/AnEdgeLordWeeb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! So for context, I&amp;#39;m trying to develop a simple chatbot the offers personalized video games recommendations based on user input, by searching the internet for the top results and then use them as an answer to the user. Initially, I started this using one single agent, but as more ideas came into my mind, I think sticking with only one agent and try to implement those into code my result in some issues, specifically when it comes to the number of tokens. So I&amp;#39;ve decided instead to leverage LangGraph in order to adopt the multi-agent way and thus some myself from some trouble. Here is what I was thinking about when it comes to the agents I have thought of and their objective: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Input Agent (Agent 1)&lt;/strong&gt;: This agent receives the initial user input, interprets the user&amp;#39;s query, and dispatches tasks to other specialized agents.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Search Agent (Agent 2)&lt;/strong&gt;: Receives tasks from Agent 1 to perform initial searches for game titles.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Details Agent (Agent 3)&lt;/strong&gt;: Fetches detailed information for each game identified by Agent 2.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Posters and Trailers Agents (Agent 4 and 5)&lt;/strong&gt;: Responsible for fetching official posters and official video trailers for the games identified.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Then I was thinking of sending all the details from Agent 2, 3, 4 and 5 to a core agent responsible for formatting a response based on them and then display them to the user.&lt;/p&gt; &lt;p&gt;Problem is, so far, I keep failing in my attempt to move from LangChain to LangGraph whilst trying to implement these ideas into code.&lt;/p&gt; &lt;p&gt;Can anyone please help? I would really, really, appreciate some help with the implementation of this.&lt;/p&gt; &lt;p&gt;This is how my current LangChain code looks right now:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import os from dotenv import load_dotenv from langchain_openai import ChatOpenAI from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain.agents import AgentExecutor, create_openai_tools_agent, Tool from langchain_core.runnables.history import RunnableWithMessageHistory from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory from serpapi import GoogleSearch # Load environment variables for API keys load_dotenv() # SerpAPI and MongoDB configuration serpapi_key = os.getenv(&amp;quot;SERPAPI_API_KEY&amp;quot;) mongo_connection_string = &amp;quot;mongodb://localhost:27017&amp;quot; database_name = &amp;quot;chatbot_db&amp;quot; collection_name = &amp;quot;chat_histories&amp;quot; # Define the function that will use SerpApi to perform searches def perform_serpapi_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key, &amp;quot;num&amp;quot;: 5, } search = GoogleSearch(params) results = search.get_dict() return results # Create the SerpApi tool to pass to an agent serpapi_tool = Tool( name=&amp;quot;serpapi_search&amp;quot;, description=&amp;quot;Performs Google searches using SerpApi.&amp;quot;, func=perform_serpapi_search ) # Setup the ChatOpenAI model for conversational interactions chat = ChatOpenAI( model=&amp;#39;gpt-3.5-turbo-1106&amp;#39;, temperature=0 ) # Define a comprehensive prompt template for handling game recommendations game_recommendation_prompt = ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, &amp;quot;&amp;quot;&amp;quot; You are a sophisticated AI trained to recommend video games. Your tasks include: - Provide game suggestions similar to ones the user enjoys or mentions, covering various genres and platforms. - Recommend games based on specific genres or mentioned developers/publishers. - Identify and suggest top-trending and highly rated video games, including acclaimed titles from specific time periods. - Tailor recommendations according to user-defined preferences, such as complexity, time investment, and progression style. - Recommend games suitable for specified platforms (e.g., PlayStation, Xbox, PC, Switch) or fitting certain age ratings (e.g., E, T, M). - Replace played or unappealing games with suitable alternatives. - For each recommended game, provide: title, brief description, genre, platform, developer, publisher, release date, Metacritic score (if available), and purchase links from digital storefronts. - Politely request more specific information for ambiguous queries. - Guide users back to gaming-related topics for unrelated queries. - Maintain a friendly and engaging tone throughout interactions. - Utilize the SerpAPI search tool for up-to-date and accurate recommendations in each response to user queries. (VERY IMPORTANT!!!) Ensure clarity, conciseness, and engagement in your responses to enhance the user experience. &amp;quot;&amp;quot;&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;chat_history&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;), ] ) # Setup tools for agent tools = [serpapi_tool] # Create an OpenAI tools agent for handling game recommendations game_recommendation_agent = create_openai_tools_agent(chat, tools, game_recommendation_prompt) # Setup the agent executor for managing operations agent_executor = AgentExecutor(agent=game_recommendation_agent, tools=tools, verbose=True) # Function to manage MongoDB-based message history for each session def get_message_history(session_id): return MongoDBChatMessageHistory( session_id=session_id, connection_string=mongo_connection_string, database_name=database_name, collection_name=collection_name, ) # Function to handle user queries def handle_user_query(session_id, user_input): &amp;quot;&amp;quot;&amp;quot; Process user queries by wrapping the executor with RunnableWithMessageHistory which processes various types of game recommendation requests and manages user interaction, maintaining a history of the conversation in MongoDB. &amp;quot;&amp;quot;&amp;quot; history_manager = RunnableWithMessageHistory( agent_executor, lambda session_id: get_message_history(session_id), input_messages_key=&amp;quot;input&amp;quot;, output_messages_key=&amp;quot;output&amp;quot;, history_messages_key=&amp;quot;chat_history&amp;quot;, ) # Execute the query with history management response = history_manager.invoke( {&amp;quot;input&amp;quot;: user_input}, {&amp;quot;configurable&amp;quot;: {&amp;quot;session_id&amp;quot;: session_id}} ) return response[&amp;#39;output&amp;#39;] def main(): session_id = &amp;quot;unique_user_session_id&amp;quot; # This should be uniquely generated for each user session print(&amp;quot;Welcome to the Game Recommendation Chatbot!&amp;quot;) while True: user_input = input(&amp;quot;You: &amp;quot;) if user_input.lower() == &amp;#39;exit&amp;#39;: print(&amp;quot;Exiting chatbot...&amp;quot;) break response = handle_user_query(session_id, user_input) print(&amp;quot;Bot:&amp;quot;, response) if __name__ == &amp;quot;__main__&amp;quot;: main() import os from dotenv import load_dotenv from langchain_openai import ChatOpenAI from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain.agents import AgentExecutor, create_openai_tools_agent, Tool from langchain_core.runnables.history import RunnableWithMessageHistory from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory from serpapi import GoogleSearch # Load environment variables for API keys load_dotenv() # SerpAPI and MongoDB configuration serpapi_key = os.getenv(&amp;quot;SERPAPI_API_KEY&amp;quot;) mongo_connection_string = &amp;quot;mongodb://localhost:27017&amp;quot; database_name = &amp;quot;chatbot_db&amp;quot; collection_name = &amp;quot;chat_histories&amp;quot; # Define the function that will use SerpApi to perform searches def perform_serpapi_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key, &amp;quot;num&amp;quot;: 5, } search = GoogleSearch(params) results = search.get_dict() return results # Create the SerpApi tool to pass to an agent serpapi_tool = Tool( name=&amp;quot;serpapi_search&amp;quot;, description=&amp;quot;Performs Google searches using SerpApi.&amp;quot;, func=perform_serpapi_search ) # Setup the ChatOpenAI model for conversational interactions chat = ChatOpenAI( model=&amp;#39;gpt-3.5-turbo-1106&amp;#39;, temperature=0 ) # Define a comprehensive prompt template for handling game recommendations game_recommendation_prompt = ChatPromptTemplate.from_messages( [ (&amp;quot;system&amp;quot;, &amp;quot;&amp;quot;&amp;quot; You are a sophisticated AI trained to recommend video games. Your tasks include: - Provide game suggestions similar to ones the user enjoys or mentions, covering various genres and platforms. - Recommend games based on specific genres or mentioned developers/publishers. - Identify and suggest top-trending and highly rated video games, including acclaimed titles from specific time periods. - Tailor recommendations according to user-defined preferences, such as complexity, time investment, and progression style. - Recommend games suitable for specified platforms (e.g., PlayStation, Xbox, PC, Switch) or fitting certain age ratings (e.g., E, T, M). - Replace played or unappealing games with suitable alternatives. - For each recommended game, provide: title, brief description, genre, platform, developer, publisher, release date, Metacritic score (if available), and purchase links from digital storefronts. - Politely request more specific information for ambiguous queries. - Guide users back to gaming-related topics for unrelated queries. - Maintain a friendly and engaging tone throughout interactions. - Utilize the SerpAPI search tool for up-to-date and accurate recommendations in each response to user queries. (VERY IMPORTANT!!!) Ensure clarity, conciseness, and engagement in your responses to enhance the user experience. &amp;quot;&amp;quot;&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;chat_history&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;), ] ) # Setup tools for agent tools = [serpapi_tool] # Create an OpenAI tools agent for handling game recommendations game_recommendation_agent = create_openai_tools_agent(chat, tools, game_recommendation_prompt) # Setup the agent executor for managing operations agent_executor = AgentExecutor(agent=game_recommendation_agent, tools=tools, verbose=True) # Function to manage MongoDB-based message history for each session def get_message_history(session_id): return MongoDBChatMessageHistory( session_id=session_id, connection_string=mongo_connection_string, database_name=database_name, collection_name=collection_name, ) # Function to handle user queries def handle_user_query(session_id, user_input): &amp;quot;&amp;quot;&amp;quot; Process user queries by wrapping the executor with RunnableWithMessageHistory which processes various types of game recommendation requests and manages user interaction, maintaining a history of the conversation in MongoDB. &amp;quot;&amp;quot;&amp;quot; history_manager = RunnableWithMessageHistory( agent_executor, lambda session_id: get_message_history(session_id), input_messages_key=&amp;quot;input&amp;quot;, output_messages_key=&amp;quot;output&amp;quot;, history_messages_key=&amp;quot;chat_history&amp;quot;, ) # Execute the query with history management response = history_manager.invoke( {&amp;quot;input&amp;quot;: user_input}, {&amp;quot;configurable&amp;quot;: {&amp;quot;session_id&amp;quot;: session_id}} ) return response[&amp;#39;output&amp;#39;] def main(): session_id = &amp;quot;unique_user_session_id&amp;quot; # This should be uniquely generated for each user session print(&amp;quot;Welcome to the Game Recommendation Chatbot!&amp;quot;) while True: user_input = input(&amp;quot;You: &amp;quot;) if user_input.lower() == &amp;#39;exit&amp;#39;: print(&amp;quot;Exiting chatbot...&amp;quot;) break response = handle_user_query(session_id, user_input) print(&amp;quot;Bot:&amp;quot;, response) if __name__ == &amp;quot;__main__&amp;quot;: main() &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnEdgeLordWeeb&quot;&gt; /u/AnEdgeLordWeeb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cilpbt/need_help_to_convert_my_singleagent_project_into/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cilpbt/need_help_to_convert_my_singleagent_project_into/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cilpbt</id><link href="https://www.reddit.com/r/LangChain/comments/1cilpbt/need_help_to_convert_my_singleagent_project_into/" /><updated>2024-05-02T17:37:40+00:00</updated><published>2024-05-02T17:37:40+00:00</published><title>Need help to convert my single-agent project into a multi-agent one</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for a vectorDB for a RAG that am building. Needs to ingest a lot of data and should be optimized for retrieval. What are my options ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cijx8f</id><link href="https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/" /><updated>2024-05-02T16:24:21+00:00</updated><published>2024-05-02T16:24:21+00:00</published><title>What vectorDB do you all use?</title></entry><entry><author><name>/u/Brave-Guide-7470</name><uri>https://www.reddit.com/user/Brave-Guide-7470</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/e41kBpbrClfdwFjhQbFO0lBPyR2D-CYfc9oUqEt2ksQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3aa90a5396a7a8ad789e42874ec0066d7974dc44&quot; alt=&quot;Test your prompts through the terminal&quot; title=&quot;Test your prompts through the terminal&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys!&lt;/p&gt; &lt;p&gt;I&amp;#39;ve developed a helper CLI tool that allows you to test prompts on both ChatGPT and Anthropic models through a simple API.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/56s9aibuc0yc1.png?width=1597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d5408e2cd05ff382ea671c0816b67567cd53cbf0&quot;&gt;https://preview.redd.it/56s9aibuc0yc1.png?width=1597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d5408e2cd05ff382ea671c0816b67567cd53cbf0&lt;/a&gt;&lt;/p&gt; &lt;p&gt;To test it, just run:&lt;/p&gt; &lt;p&gt;pip install dialog-lib&lt;/p&gt; &lt;p&gt;export OPENAI_API_KEY=sk-YOUR_API_KEY&lt;/p&gt; &lt;p&gt;dialog openai --prompt &amp;quot;Your prompt that you want to test, here!&amp;quot;&lt;/p&gt; &lt;p&gt;Here is a link to a quick demo: &lt;a href=&quot;https://www.linkedin.com/feed/update/urn:li:activity:7191776208651489282/&quot;&gt;https://www.linkedin.com/feed/update/urn:li:activity:7191776208651489282/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Brave-Guide-7470&quot;&gt; /u/Brave-Guide-7470 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cielku</id><media:thumbnail url="https://external-preview.redd.it/e41kBpbrClfdwFjhQbFO0lBPyR2D-CYfc9oUqEt2ksQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3aa90a5396a7a8ad789e42874ec0066d7974dc44" /><link href="https://www.reddit.com/r/LangChain/comments/1cielku/test_your_prompts_through_the_terminal/" /><updated>2024-05-02T12:37:09+00:00</updated><published>2024-05-02T12:37:09+00:00</published><title>Test your prompts through the terminal</title></entry><entry><author><name>/u/aryanmadhavverma</name><uri>https://www.reddit.com/user/aryanmadhavverma</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have an agent with two tools. The tools are being used in a sequential way. The second tool queries the database and returns in a pydantic format I&amp;#39;ve defined myself. Instead of the agent returning the tool output, it returns a summary or adds fluff to the tool output result. I only want it to return the tool output! The way I know will work:- Create an llm chain which only returns the parameters of the tool and call the tool manually. But this reduces the agentic behaviour of my functionality. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;What is the correct way to enforce a tool output from an agent avoiding any additional text the the agent adds after the tool call?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/aryanmadhavverma&quot;&gt; /u/aryanmadhavverma &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cibpk9/correct_way_to_return_tool_output_of_an_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cibpk9/correct_way_to_return_tool_output_of_an_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cibpk9</id><link href="https://www.reddit.com/r/LangChain/comments/1cibpk9/correct_way_to_return_tool_output_of_an_agent/" /><updated>2024-05-02T09:55:29+00:00</updated><published>2024-05-02T09:55:29+00:00</published><title>Correct way to return tool output of an agent executor instance?</title></entry><entry><author><name>/u/mahadevbhakti</name><uri>https://www.reddit.com/user/mahadevbhakti</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can anyone please share any good references or cookbooks for a multi llm/agent chain using langgraph, langchain, routers to build a chatflow where we have a frontdesk to understand the query and then route it appropriately? &lt;/p&gt; &lt;p&gt;I am currently doing it in Dify.ai which has a UI but I assume it&amp;#39;s built on top of langchain and want to do similar chatflow set up&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mahadevbhakti&quot;&gt; /u/mahadevbhakti &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciidwi/langgraph_langchain_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ciidwi/langgraph_langchain_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ciidwi</id><link href="https://www.reddit.com/r/LangChain/comments/1ciidwi/langgraph_langchain_tools/" /><updated>2024-05-02T15:22:48+00:00</updated><published>2024-05-02T15:22:48+00:00</published><title>Langgraph + Langchain+ Tools</title></entry><entry><author><name>/u/CHvader</name><uri>https://www.reddit.com/user/CHvader</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey, was wondering if anyone had any tips for an API or general approach to automate grabbing of answers + citations/refs using an LLM.&lt;/p&gt; &lt;p&gt;For example, I would like to ask &amp;quot;How many members were on Instagram in the US in 2019?&amp;quot; and get both a number back and a link to the source. I would also like to be able to ask, for e.g. &amp;quot;How did X firm use AI and Data Science this year. Please cite a source from the firm X&amp;quot;.&lt;/p&gt; &lt;p&gt;These are just example use-cases of the flexibility I am looking for - I currently use &lt;a href=&quot;https://perplexity.ai/&quot;&gt;perplexity.ai&lt;/a&gt; for this kind of stuff, but their API doesn&amp;#39;t return citations immediately (which would be my primary use case). Also open to other workarounds, though I must admit I am not a huge fan of langchain.&lt;/p&gt; &lt;p&gt;Thanks for the tips!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/CHvader&quot;&gt; /u/CHvader &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cigfv9/any_apis_that_use_llms_to_grab_updated_citations/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cigfv9/any_apis_that_use_llms_to_grab_updated_citations/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cigfv9</id><link href="https://www.reddit.com/r/LangChain/comments/1cigfv9/any_apis_that_use_llms_to_grab_updated_citations/" /><updated>2024-05-02T14:01:05+00:00</updated><published>2024-05-02T14:01:05+00:00</published><title>Any APIs that use LLMs to grab updated citations or references from the web?</title></entry><entry><author><name>/u/loczngo</name><uri>https://www.reddit.com/user/loczngo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi y&amp;#39;all i was wondering, are there any other alternatives i could do my research on to stream the conversation between me and the LLMs such as Streamlit? i wanna stream the conversation using my own design on NodeJS and i still haven&amp;#39;t figured out which way to integrate the LLMs conversation with my UI.&lt;/p&gt; &lt;p&gt;Thanks for any help or insights y&amp;#39;all will give &amp;lt;3&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/loczngo&quot;&gt; /u/loczngo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cia5g2/streamlit_referrences_for_nodejs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cia5g2/streamlit_referrences_for_nodejs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cia5g2</id><link href="https://www.reddit.com/r/LangChain/comments/1cia5g2/streamlit_referrences_for_nodejs/" /><updated>2024-05-02T08:03:14+00:00</updated><published>2024-05-02T08:03:14+00:00</published><title>Streamlit referrences for NodeJS</title></entry><entry><author><name>/u/Omervx</name><uri>https://www.reddit.com/user/Omervx</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cifyrc/help_adding_memory_to_my_bot/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/k3mBdbLNpdJb-Nyw3FdVlfMqZ3Ba5gdbaosEtu259tU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=92584fd73a105d179e447610a6e967f9d7f33e12&quot; alt=&quot;Help adding memory to my bot&quot; title=&quot;Help adding memory to my bot&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;hi guys im a joniur developer and this is my first AI related project and i need some help adding a Simple memory to my chat bot can u pls help me&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Omervx&quot;&gt; /u/Omervx &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/oovaa/ChatPDF/blob/main/tools%2Fchain.js&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cifyrc/help_adding_memory_to_my_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cifyrc</id><media:thumbnail url="https://external-preview.redd.it/k3mBdbLNpdJb-Nyw3FdVlfMqZ3Ba5gdbaosEtu259tU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=92584fd73a105d179e447610a6e967f9d7f33e12" /><link href="https://www.reddit.com/r/LangChain/comments/1cifyrc/help_adding_memory_to_my_bot/" /><updated>2024-05-02T13:41:06+00:00</updated><published>2024-05-02T13:41:06+00:00</published><title>Help adding memory to my bot</title></entry><entry><author><name>/u/DancingDorritos</name><uri>https://www.reddit.com/user/DancingDorritos</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I’ve been trying to get [title] working using LangChain, azure OpenAI and chroma for storing embeddings. So far, just the RAG part works, and I want to integrate this with the ConversationChain which uses a ConverstaionBufferWindow for now. &lt;/p&gt; &lt;p&gt;My current method is to get the history of the conversation chain, supplement this with the context from the embeddings (from matching similarity), and then feed this into the llm to get a response. Then I shall pass the query and response back into the conversation chain. &lt;/p&gt; &lt;p&gt;However, I can’t find any proper documentation how I can combine the context and the conversation history properly to pass into the llm. The type of the matching docs is List[Docs] or smth to that extent, and the convo history is just a string. &lt;/p&gt; &lt;p&gt;Does anyone know a proper way of doing this? Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DancingDorritos&quot;&gt; /u/DancingDorritos &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cif179/rag_with_conversationchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cif179/rag_with_conversationchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cif179</id><link href="https://www.reddit.com/r/LangChain/comments/1cif179/rag_with_conversationchain/" /><updated>2024-05-02T12:59:30+00:00</updated><published>2024-05-02T12:59:30+00:00</published><title>RAG with ConversationChain</title></entry><entry><author><name>/u/Standard-Society-568</name><uri>https://www.reddit.com/user/Standard-Society-568</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am learning and facing issues as most of the Docs on it&amp;#39;s are for OpenAI and I am using Google Gemini API.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Standard-Society-568&quot;&gt; /u/Standard-Society-568 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidumu/any_discord_server_of_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidumu/any_discord_server_of_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cidumu</id><link href="https://www.reddit.com/r/LangChain/comments/1cidumu/any_discord_server_of_langchain/" /><updated>2024-05-02T11:59:11+00:00</updated><published>2024-05-02T11:59:11+00:00</published><title>Any Discord server of Langchain?</title></entry><entry><author><name>/u/H3nrik123</name><uri>https://www.reddit.com/user/H3nrik123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, &lt;/p&gt; &lt;p&gt;Does someone have experience in running a script using Langchain in Azure Function App?&lt;br/&gt; For a while I was doing development and running the script locally and the results I was getting when analyzing a dataframe using a pandas_dataframe_agent were 10/10.&lt;br/&gt; Now when I published the same script to Azure Function App the quality of the results is 1/10. &lt;/p&gt; &lt;p&gt;The requirements.txt file has the same versions of python libraries as I have locally. &lt;/p&gt; &lt;p&gt;I am not that familiar with function apps and I am wondering if there are some limitations to whether langchain and openai can be run there?&lt;/p&gt; &lt;p&gt;All help is appreciated :) &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/H3nrik123&quot;&gt; /u/H3nrik123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidrmj/langchain_in_azure_function_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidrmj/langchain_in_azure_function_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cidrmj</id><link href="https://www.reddit.com/r/LangChain/comments/1cidrmj/langchain_in_azure_function_app/" /><updated>2024-05-02T11:54:38+00:00</updated><published>2024-05-02T11:54:38+00:00</published><title>Langchain in Azure Function App</title></entry><entry><author><name>/u/Aware-Damage-6906</name><uri>https://www.reddit.com/user/Aware-Damage-6906</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidfrs/hindilanguage_ai_chatbot_for_enterprises_using/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/s5T4cSPLd6TxUKmOlP3k_4Zk-nx3EK6BhH5JrTT42wg.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4d6ed93b53ad517b42bec6ca61021fe128dd33d0&quot; alt=&quot;Hindi-Language AI Chatbot for Enterprises Using Qdrant, MLFlow, and LangChain&quot; title=&quot;Hindi-Language AI Chatbot for Enterprises Using Qdrant, MLFlow, and LangChain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Aware-Damage-6906&quot;&gt; /u/Aware-Damage-6906 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://quamernasim.hashnode.dev/hindi-language-ai-chatbot-for-enterprises-using-qdrant-mlflow-and-langchain&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidfrs/hindilanguage_ai_chatbot_for_enterprises_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cidfrs</id><media:thumbnail url="https://external-preview.redd.it/s5T4cSPLd6TxUKmOlP3k_4Zk-nx3EK6BhH5JrTT42wg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4d6ed93b53ad517b42bec6ca61021fe128dd33d0" /><link href="https://www.reddit.com/r/LangChain/comments/1cidfrs/hindilanguage_ai_chatbot_for_enterprises_using/" /><updated>2024-05-02T11:37:18+00:00</updated><published>2024-05-02T11:37:18+00:00</published><title>Hindi-Language AI Chatbot for Enterprises Using Qdrant, MLFlow, and LangChain</title></entry><entry><author><name>/u/Sweaty-Minimum5423</name><uri>https://www.reddit.com/user/Sweaty-Minimum5423</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, I have a few questions related langgraph.&lt;/p&gt; &lt;p&gt;The structure I’m planning is as follows:&lt;/p&gt; &lt;p&gt;One frontdesk agent(supervisor) is responsible to route query and answer customer questions. Frontdesk agent doesn’t have any RAG system linked to it. It’s just a customer facing agent.&lt;/p&gt; &lt;p&gt;Frontdesk agent has some “lower level” agents to help. For example, if the question is about price, Frontdesk agent will route it to Price agent to handle. The Price agent will be linked to a RAG system to retrieve the price. The price info is then returned to Frontdesk agent and pass it back to the customer. This is more like what I see in the traditional agent flow.&lt;/p&gt; &lt;p&gt;Here’s my question. Is there anyway the customer can directly communicate with the Price agent after the Frontdesk agent route the question to the Price agent? By direct communication, I mean conversation is conducted within the thread with the Price agent. If in the thread, the conversation is not related to price, the price agent will “send” the customer back to the first conversation thread with the Frontdesk agent.&lt;/p&gt; &lt;p&gt;I would love to see if there is any langchain or langgraph projects or resources related to this. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sweaty-Minimum5423&quot;&gt; /u/Sweaty-Minimum5423 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidcip/conversation_chatbot_in_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cidcip/conversation_chatbot_in_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cidcip</id><link href="https://www.reddit.com/r/LangChain/comments/1cidcip/conversation_chatbot_in_langgraph/" /><updated>2024-05-02T11:32:25+00:00</updated><published>2024-05-02T11:32:25+00:00</published><title>Conversation Chatbot in Langgraph</title></entry><entry><author><name>/u/kalintsov</name><uri>https://www.reddit.com/user/kalintsov</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello,&lt;/p&gt; &lt;p&gt;I have a CSV file containing a historical log of my conversations with my partner. The file is organized into three columns: datetime, sent_by, and message. I would like to use a LLM to ask questions about our discussions (e.g &amp;quot;When is the wedding of A and B?&amp;quot;).&lt;/p&gt; &lt;p&gt;I&amp;#39;m looking for some advices on the most effective way to process and vectorize these conversations. I want the LLM to understand the metadata within the context of the discussions—for instance, identifying that if Person A wrote &amp;quot;Happy Birthday,&amp;quot; it likely indicates Person B&amp;#39;s birthday on that date.&lt;/p&gt; &lt;p&gt;What do you think is the best approach to handling chat logs in this scenario? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kalintsov&quot;&gt; /u/kalintsov &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci8hwh/efficient_rag_on_chat_logs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci8hwh/efficient_rag_on_chat_logs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci8hwh</id><link href="https://www.reddit.com/r/LangChain/comments/1ci8hwh/efficient_rag_on_chat_logs/" /><updated>2024-05-02T06:13:01+00:00</updated><published>2024-05-02T06:13:01+00:00</published><title>Efficient RAG on chat logs</title></entry><entry><author><name>/u/Original_Job6327</name><uri>https://www.reddit.com/user/Original_Job6327</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let’s say i’m using openai gpt3.5. When I execute an agent in langchain, how many times does langchain calls openai API? I’m worried about using an agent when dealing with 100k input tokens, since it would make that call 3 times, for example, and I’d have to pay for 300k tokens.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Original_Job6327&quot;&gt; /u/Original_Job6327 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci7hqx/how_many_api_calls_does_an_agent_make_for_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci7hqx/how_many_api_calls_does_an_agent_make_for_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci7hqx</id><link href="https://www.reddit.com/r/LangChain/comments/1ci7hqx/how_many_api_calls_does_an_agent_make_for_a/" /><updated>2024-05-02T05:10:46+00:00</updated><published>2024-05-02T05:10:46+00:00</published><title>How many API calls does an agent make for a single input?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1ci6vod/google_gemini_api_key_for_free/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci6we7/google_gemini_api_key_for_free/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci6we7</id><link href="https://www.reddit.com/r/LangChain/comments/1ci6we7/google_gemini_api_key_for_free/" /><updated>2024-05-02T04:37:02+00:00</updated><published>2024-05-02T04:37:02+00:00</published><title>Google Gemini API key for free</title></entry><entry><author><name>/u/krschacht</name><uri>https://www.reddit.com/user/krschacht</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m an experienced engineer and have been doing a lot of work interacting directly with LLM APIs (using simple SDKs). Multiple people have told me to check out langchain, so I just did a spike on it. I skimmed the docs, I get the core concept of chains and agents. It&amp;#39;s cool but this seems like a set of pretty basic abstractions. But I&amp;#39;m scratching my head wondering: what about langchain are people finding most helpful? Given how popular this library is, I feel like I&amp;#39;m missing something key...&lt;/p&gt; &lt;p&gt;I&amp;#39;m not trying to be snarky at all. I am assuming that I probably should be using LangChain and it probably could be saving me a bunch of time, so I genuinely want to grasp the biggest benefits of it since I don&amp;#39;t think I&amp;#39;m getting it.&lt;/p&gt; &lt;p&gt;Maybe the core problem is that we all inevitably end up using multiple LLMs eventually (OpenAI, Anthropic, etc) so the biggest benefit of LangChain is that you have a sort of universal SDK — a common interface between all the LLMs. Is that the biggest benefit of langchain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/krschacht&quot;&gt; /u/krschacht &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chpywv/what_makes_langchain_so_useful_im_new_to_it_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chpywv/what_makes_langchain_so_useful_im_new_to_it_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1chpywv</id><link href="https://www.reddit.com/r/LangChain/comments/1chpywv/what_makes_langchain_so_useful_im_new_to_it_and/" /><updated>2024-05-01T16:09:37+00:00</updated><published>2024-05-01T16:09:37+00:00</published><title>What makes langchain so useful? I'm new to it and don't get it</title></entry><entry><author><name>/u/transwarpconduit1</name><uri>https://www.reddit.com/user/transwarpconduit1</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;d like to be able to ask for human confirmation before the agent executor invokes a certain tool. For example, let&amp;#39;s say I have a&lt;code&gt;send_email&lt;/code&gt;tool, and I&amp;#39;d like to confirm before it is run.&lt;/p&gt; &lt;p&gt;Does the Langchain agent framework provide a way to hook into the lifecycle in order to do this? Ideally, a hook that would run before the invocation, has tool name and arguments passed in, and then you can return True or False (or an *Exception for an error). I could have the email displayed to standard out there, and collect input. &lt;/p&gt; &lt;p&gt;It doesn&amp;#39;t seem like callback handlers work, and they weren&amp;#39;t intended for that anyway. They are for introspection (like logging, instrumentation, etc.).&lt;/p&gt; &lt;p&gt;I can actually put the confirmation logic in the tool function itself and get it to work, but that doesn&amp;#39;t seem right. I could create a special wrapper function &amp;quot;add_human_approval(tool_func)&amp;quot; that returns a new function that asks for human approval, and if it passes invokes the passed in func, otherwise returns. Again, that&amp;#39;s still at the tool level, instead as part of the lifecycle.&lt;/p&gt; &lt;p&gt;Thoughts?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/transwarpconduit1&quot;&gt; /u/transwarpconduit1 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci3m0k</id><link href="https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/" /><updated>2024-05-02T01:43:51+00:00</updated><published>2024-05-02T01:43:51+00:00</published><title>Tool-calling agents: Human approval before tool invocation?</title></entry><entry><author><name>/u/WompTune</name><uri>https://www.reddit.com/user/WompTune</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everyone,&lt;br/&gt; Was wondering if anyone has moved from Assistants API to Langchain + Langsmith and how that felt?&lt;br/&gt; I loveeee OpenAI Assistants API because it manages conversation history + context for me, and has the dashboard to see messages in the thread. &lt;/p&gt; &lt;p&gt;But unfortunately OpenAI has been super slow lately...&lt;/p&gt; &lt;p&gt;So I was wondering if Langchain (with an open source model like Llama 3) + Langsmith gives an equivalent vibe where I don&amp;#39;t have to manage conversation history / context management myself?&lt;/p&gt; &lt;p&gt;Appreciate it!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/WompTune&quot;&gt; /u/WompTune &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci1umo/moving_from_openai_assistants_api_to_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci1umo/moving_from_openai_assistants_api_to_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci1umo</id><link href="https://www.reddit.com/r/LangChain/comments/1ci1umo/moving_from_openai_assistants_api_to_langchain/" /><updated>2024-05-02T00:19:59+00:00</updated><published>2024-05-02T00:19:59+00:00</published><title>Moving from OpenAI Assistants API to Langchain + Langsmith?</title></entry><entry><author><name>/u/RoboCoachTech</name><uri>https://www.reddit.com/user/RoboCoachTech</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chtidn/an_agentic_approach_to_robot_software_generation/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/-zAlWZClj_CLxJRRkJ8gIQ3yeqm97H9YlyuUdqNzu-o.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=84be01462537709f49707dba68c0af0cdb5a2bd9&quot; alt=&quot;An agentic approach to robot software generation using LangChain&quot; title=&quot;An agentic approach to robot software generation using LangChain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RoboCoachTech&quot;&gt; /u/RoboCoachTech &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=iIIxcBJARDQ&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chtidn/an_agentic_approach_to_robot_software_generation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1chtidn</id><media:thumbnail url="https://external-preview.redd.it/-zAlWZClj_CLxJRRkJ8gIQ3yeqm97H9YlyuUdqNzu-o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=84be01462537709f49707dba68c0af0cdb5a2bd9" /><link href="https://www.reddit.com/r/LangChain/comments/1chtidn/an_agentic_approach_to_robot_software_generation/" /><updated>2024-05-01T18:32:55+00:00</updated><published>2024-05-01T18:32:55+00:00</published><title>An agentic approach to robot software generation using LangChain</title></entry><entry><author><name>/u/ThickDoctor007</name><uri>https://www.reddit.com/user/ThickDoctor007</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone successfully implemented function calling with agents based on open source LLMs?&lt;/p&gt; &lt;p&gt;Would be glad to learn about your experiences.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ThickDoctor007&quot;&gt; /u/ThickDoctor007 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci6afc/function_calling_with_open_source_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ci6afc/function_calling_with_open_source_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ci6afc</id><link href="https://www.reddit.com/r/LangChain/comments/1ci6afc/function_calling_with_open_source_llms/" /><updated>2024-05-02T04:01:53+00:00</updated><published>2024-05-02T04:01:53+00:00</published><title>Function calling with open source LLMs</title></entry><entry><author><name>/u/Advanced_Art_8216</name><uri>https://www.reddit.com/user/Advanced_Art_8216</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello, I recently started learning langchain and trying to build a chat bot with sequence such as in first step it collects some info from user and then based on if else condition can either move to sequence 2 or sequence 3. It stays on sequence 1 until it has the required info. Each of the sequence has a new prompt and temperature control. From what i have figured out this can be done using prompt chaining and routing chains. Am i on the correct path or missing something? I am trying to do in javascript and unable to find any good examples. Any help will be appreciated. Thank You.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Advanced_Art_8216&quot;&gt; /u/Advanced_Art_8216 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chwv9w/conditional_multiple_sequence_chat_bot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1chwv9w/conditional_multiple_sequence_chat_bot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1chwv9w</id><link href="https://www.reddit.com/r/LangChain/comments/1chwv9w/conditional_multiple_sequence_chat_bot/" /><updated>2024-05-01T20:50:24+00:00</updated><published>2024-05-01T20:50:24+00:00</published><title>Conditional Multiple sequence chat bot</title></entry></feed>