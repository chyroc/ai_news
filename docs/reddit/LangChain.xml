<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-07-23T10:24:31+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Direct-Station9581</name><uri>https://www.reddit.com/user/Direct-Station9581</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;from langgraph_state import GraphState from langgraph.graph import END, StateGraph from langgraph.checkpoint.memory import MemorySaver from nodes import build_strategy, human_feedback, decision_node, rag_node, database_search, web_search_node, sql_search_node, state_printer from edges import rag_database_websearch_sqlseqrch, strategy_decision workflow = StateGraph(GraphState) workflow.add_node(&amp;quot;build_strategy&amp;quot;, build_strategy) workflow.add_node(&amp;quot;human_feedback&amp;quot;, human_feedback) workflow.add_node(&amp;quot;decision_node&amp;quot;, decision_node) workflow.add_node(&amp;quot;rag_node&amp;quot;, rag_node) workflow.add_node(&amp;quot;database_search&amp;quot;, database_search) workflow.add_node(&amp;quot;web_search_node&amp;quot;, web_search_node) workflow.add_node(&amp;quot;sql_search_node&amp;quot;, sql_search_node) workflow.add_node(&amp;quot;state_printer&amp;quot;, state_printer) workflow.set_entry_point(&amp;quot;build_strategy&amp;quot;) workflow.add_edge(&amp;quot;build_strategy&amp;quot;, &amp;quot;human_feedback&amp;quot;) workflow.add_conditional_edges( &amp;quot;human_feedback&amp;quot;, strategy_decision, { &amp;quot;yes&amp;quot;: &amp;quot;decision_node&amp;quot;, &amp;quot;no&amp;quot;: &amp;quot;build_strategy&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;decision_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;rag_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;database_search&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;web_search_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_conditional_edges( &amp;quot;sql_search_node&amp;quot;, rag_database_websearch_sqlseqrch, { &amp;quot;rag&amp;quot;: &amp;quot;rag_node&amp;quot;, &amp;quot;database_search&amp;quot;: &amp;quot;database_search&amp;quot;, &amp;quot;web_search&amp;quot;: &amp;quot;web_search_node&amp;quot;, &amp;quot;sql_search&amp;quot;: &amp;quot;sql_search_node&amp;quot;, &amp;quot;state_printer&amp;quot;: &amp;quot;state_printer&amp;quot; }, ) workflow.add_edge(&amp;quot;state_printer&amp;quot;, END) memory = MemorySaver() app = workflow.compile(checkpointer=memory, interrupt_before=[&amp;quot;human_feedback&amp;quot;]) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I have created a graph with human feedback using langgraph. After &lt;strong&gt;strategy node&lt;/strong&gt; is executed. It should interrupt before &lt;strong&gt;human_feedback node&lt;/strong&gt; and ask from the user that if the strategy made by the agent is correct or wrong in case if it is correct it will proceed to the next nodes and if not then it will go to strategy node again.&lt;/p&gt; &lt;p&gt;For my first condition in case it is correct it is working fine. But when it is wrong the strategy node executes but donot go to the next nodes and the program terminates.&lt;/p&gt; &lt;p&gt;This is the issue if anyone can help. Thanks&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Direct-Station9581&quot;&gt; /u/Direct-Station9581 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea3p2i/human_in_the_loop_in_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea3p2i/human_in_the_loop_in_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea3p2i</id><link href="https://www.reddit.com/r/LangChain/comments/1ea3p2i/human_in_the_loop_in_langgraph/" /><updated>2024-07-23T09:40:10+00:00</updated><published>2024-07-23T09:40:10+00:00</published><title>Human In The Loop In Langgraph</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;GraphRAG has been the talk of the town since Microsoft released the viral gitrepo on GraphRAG, which uses Knowledge Graphs for the RAG framework to talk to external resources compared to vector DBs as in the case of standard RAG. The below YouTube playlist covers the following tutorials to get started on GraphRAG&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;What is GraphRAG?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;How GraphRAG works?&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;GraphRAG using LangChain&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;GraphRAG for CSV data&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;GraphRAG for JSON&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Knowledge Graphs using LangChain&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;RAG vs GraphRAG&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLnH2pfPCPZsIaT48BT9zmLmkhYa_R1PhN&quot;&gt;https://www.youtube.com/playlist?list=PLnH2pfPCPZsIaT48BT9zmLmkhYa_R1PhN&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9wc8q/graphrag_tutorials_using_langchain_for_beginners/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9wc8q/graphrag_tutorials_using_langchain_for_beginners/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9wc8q</id><link href="https://www.reddit.com/r/LangChain/comments/1e9wc8q/graphrag_tutorials_using_langchain_for_beginners/" /><updated>2024-07-23T02:11:52+00:00</updated><published>2024-07-23T02:11:52+00:00</published><title>GraphRAG tutorials (using LangChain) for beginners</title></entry><entry><author><name>/u/nshefeek</name><uri>https://www.reddit.com/user/nshefeek</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all,&lt;/p&gt; &lt;p&gt;This is my first take on something that is related to LLM and RAG systems. I&amp;#39;ve been working on a Retrieval-Augmented Generation (RAG) based question answering system which generate answers to the queries from uploaded documents, and I&amp;#39;d love to get your feedback, suggestions, and ideas for improvements. The system uses FastAPI, LangChain and Streamlit for a minimal UI.&lt;/p&gt; &lt;p&gt;Key features of the system:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Document upload and processing&lt;/li&gt; &lt;li&gt;Directory processing for batch document addition&lt;/li&gt; &lt;li&gt;FAISS vector store for efficient document retrieval&lt;/li&gt; &lt;li&gt;GPT4All for generating embeddings and answering questions&lt;/li&gt; &lt;li&gt;Asynchronous operations for improved performance&lt;/li&gt; &lt;li&gt;WebSocket support for real-time question answering&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;GitHub Repository: &lt;a href=&quot;https://github.com/nshefeek/docGPT.git&quot;&gt;docGPT&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Some specific areas I&amp;#39;m looking for feedback on:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Code quality and best practices.&lt;/li&gt; &lt;li&gt;Usage of LangChain.&lt;/li&gt; &lt;li&gt;The approach to improve query response timing.&lt;/li&gt; &lt;li&gt;A better approach to splitting the documents in such a way that the embeddings generated maintains a metadata that can be used to trace back to the original source doument.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Current state of the project:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Able to upload a PDF, TXT or CSV document.&lt;/li&gt; &lt;li&gt;Able to upload a directory of PDF documents. But since Streamlit has no widget for folder upload, the folder path has to be input as text.&lt;/li&gt; &lt;li&gt;Queries return somewhat relevant answers, but the returned metadata can&amp;#39;t be used to backtrack to the exact source location (like the paragraph from which the answer was inferred etc.).&lt;/li&gt; &lt;li&gt;Query times vary between 120-180 seconds.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Thank you in advance for your time and expertise. I&amp;#39;m looking forward to your insights and suggestions to help improve this project!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nshefeek&quot;&gt; /u/nshefeek &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9j3cq/built_a_rag_system_for_internal_documents_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9j3cq/built_a_rag_system_for_internal_documents_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9j3cq</id><link href="https://www.reddit.com/r/LangChain/comments/1e9j3cq/built_a_rag_system_for_internal_documents_using/" /><updated>2024-07-22T16:50:25+00:00</updated><published>2024-07-22T16:50:25+00:00</published><title>Built a RAG system for internal documents using LangChain, FastAPI, and a frontend with Streamlit. What could have been done better?</title></entry><entry><author><name>/u/ha1lyeah</name><uri>https://www.reddit.com/user/ha1lyeah</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, Need help in finding a docker image containing both Ollama and langchain to ease the creation/development of use cases. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ha1lyeah&quot;&gt; /u/ha1lyeah &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea4ccw/docker_image_with_ollama_and_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea4ccw/docker_image_with_ollama_and_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea4ccw</id><link href="https://www.reddit.com/r/LangChain/comments/1ea4ccw/docker_image_with_ollama_and_langchain/" /><updated>2024-07-23T10:21:37+00:00</updated><published>2024-07-23T10:21:37+00:00</published><title>Docker image with Ollama and langchain</title></entry><entry><author><name>/u/kingai404</name><uri>https://www.reddit.com/user/kingai404</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone! Iâ€™m excited to share a new project: an Investment Research Project leveraging CrewAI and Composio to conduct investment research, analyze data, and provide investment recommendations.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Objectives&lt;/strong&gt;&lt;br/&gt; This project sets up a system of agents to streamline investment research and analysis, ultimately generating insightful investment recommendations.&lt;br/&gt; Implementation Details&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Tools Used&lt;/strong&gt;&lt;br/&gt; Composio, CrewAI, SERP, Python&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Setup&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Navigate to the project directory.&lt;/li&gt; &lt;li&gt;Run the setup file.&lt;/li&gt; &lt;li&gt;Fill in the &lt;code&gt;.env&lt;/code&gt; file with your secrets.&lt;/li&gt; &lt;li&gt;Run the Python script.&lt;/li&gt; &lt;li&gt;Alternatively, run the IPython Notebook &lt;code&gt;investment_analyst.ipynb&lt;/code&gt; in Jupyter for an interactive experience.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;br/&gt; The system will populate your Notion page with comprehensive investment data and analysis.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Repo&lt;/strong&gt;: &lt;a href=&quot;https://git.new/Invest&quot;&gt;GitHub Repository&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Feel free to explore the project, give it a star if you find it useful, and let me know your thoughts or suggestions for improvements!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kingai404&quot;&gt; /u/kingai404 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9ys5f/make_your_own_intelligent_investment_analyst_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9ys5f/make_your_own_intelligent_investment_analyst_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9ys5f</id><link href="https://www.reddit.com/r/LangChain/comments/1e9ys5f/make_your_own_intelligent_investment_analyst_agent/" /><updated>2024-07-23T04:20:03+00:00</updated><published>2024-07-23T04:20:03+00:00</published><title>Make your own Intelligent Investment Analyst Agent</title></entry><entry><author><name>/u/Both_Acadia_6598</name><uri>https://www.reddit.com/user/Both_Acadia_6598</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all,&lt;/p&gt; &lt;p&gt;I&amp;#39;m using the LangChain React agent infrastructure and encountering various string-related issues.&lt;br/&gt; For instance, I often get errors like:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&amp;quot;The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.&amp;quot;&lt;/li&gt; &lt;li&gt;&amp;quot;Could not parse LLM output.&amp;quot;&lt;/li&gt; &lt;li&gt;&amp;quot;An output parsing error occurred.&amp;quot;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Currently, I have some ad-hoc methods to fix the outputs, which involve a lot of string manipulation. I&amp;#39;m wondering if this is the right approach to handle these issues.&lt;/p&gt; &lt;p&gt;I tried using the handle_parsing_errors argument, but it doesn&amp;#39;t seem to be a good solution.&lt;/p&gt; &lt;p&gt;What do you think?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Both_Acadia_6598&quot;&gt; /u/Both_Acadia_6598 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea2inm/troubleshooting_string_errors_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea2inm/troubleshooting_string_errors_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea2inm</id><link href="https://www.reddit.com/r/LangChain/comments/1ea2inm/troubleshooting_string_errors_in_langchain/" /><updated>2024-07-23T08:20:08+00:00</updated><published>2024-07-23T08:20:08+00:00</published><title>Troubleshooting string Errors in LangChain</title></entry><entry><author><name>/u/sidharth_07</name><uri>https://www.reddit.com/user/sidharth_07</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I would love to get your expertise and advice on building a RAG chatbot for an e-commerce company. I&amp;#39;m currently exploring Graph-RAG and hybrid search, but I&amp;#39;m feeling overwhelmed by the amount of data. The company has about 100 products, along with data such as blogs, articles, FAQs, etc., which sometimes reference specific products. I would like to know how I can move forward with this project. Any help is much appreciated.&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sidharth_07&quot;&gt; /u/sidharth_07 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea0qw5/cs_rag_chatbot_for_a_hardware_ecom_company/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ea0qw5/cs_rag_chatbot_for_a_hardware_ecom_company/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ea0qw5</id><link href="https://www.reddit.com/r/LangChain/comments/1ea0qw5/cs_rag_chatbot_for_a_hardware_ecom_company/" /><updated>2024-07-23T06:22:45+00:00</updated><published>2024-07-23T06:22:45+00:00</published><title>CS RAG CHATBOT for a hardware e-com company</title></entry><entry><author><name>/u/nicolashoferer</name><uri>https://www.reddit.com/user/nicolashoferer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;What are you using to evaluate and monitor your RAG applications? &lt;/p&gt; &lt;p&gt;I&amp;#39;ve been using LangSmith, but I&amp;#39;m not satisfied with it so far. In my opinion, the UX is bad and it lacks an effective way to compare different prompts. I&amp;#39;m now considering experimenting with PromptLayer, as it seems to offer better features. &lt;/p&gt; &lt;p&gt;Our situation is a bit complex, though. We&amp;#39;re experimenting with two different approaches: a multi-chain setup and one based on function calling. So we&amp;#39;re really looking to compare entire workflows rather than just individual prompts.&lt;/p&gt; &lt;p&gt;Has anyone found a good solution for monitoring, and more importantly, evaluating these kinds of setups? I&amp;#39;d appreciate any insights or recommendations.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/nicolashoferer&quot;&gt; /u/nicolashoferer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9e3lb/automatic_rag_evaluation_monitoring/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9e3lb/automatic_rag_evaluation_monitoring/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9e3lb</id><link href="https://www.reddit.com/r/LangChain/comments/1e9e3lb/automatic_rag_evaluation_monitoring/" /><updated>2024-07-22T13:18:34+00:00</updated><published>2024-07-22T13:18:34+00:00</published><title>Automatic RAG Evaluation + Monitoring</title></entry><entry><author><name>/u/thedabking123</name><uri>https://www.reddit.com/user/thedabking123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I noticed that it didn&amp;#39;t always call the vectorstore when asked a q- and for those answers it was always giving generic answers&lt;/p&gt; &lt;p&gt;react agent documentation: &lt;a href=&quot;https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/#code&quot;&gt;https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/#code&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thedabking123&quot;&gt; /u/thedabking123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9sc59/is_there_a_way_to_force_the_prebuilt_react_agent/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9sc59/is_there_a_way_to_force_the_prebuilt_react_agent/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9sc59</id><link href="https://www.reddit.com/r/LangChain/comments/1e9sc59/is_there_a_way_to_force_the_prebuilt_react_agent/" /><updated>2024-07-22T23:06:01+00:00</updated><published>2024-07-22T23:06:01+00:00</published><title>Is there a way to force the prebuilt react agent to call tools (vector store) for each question asked? If not what's a good alternative?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Knowledge Graph is the buzz word since GraphRAG has came in which is quite useful for Graph Analytics over unstructured data. This video demonstrates how to use LangChain to build a stand alone Knowledge Graph from text : &lt;a href=&quot;https://youtu.be/YnhG_arZEj0&quot;&gt;https://youtu.be/YnhG_arZEj0&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9etyn/knowledge_graph_using_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9etyn/knowledge_graph_using_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9etyn</id><link href="https://www.reddit.com/r/LangChain/comments/1e9etyn/knowledge_graph_using_langchain/" /><updated>2024-07-22T13:52:04+00:00</updated><published>2024-07-22T13:52:04+00:00</published><title>Knowledge Graph using LangChain</title></entry><entry><author><name>/u/Cautious-External177</name><uri>https://www.reddit.com/user/Cautious-External177</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am developing a chatbot app where I am using Langchain to feed it documents. I have completed the backend logic for the app, including controllers, tables and real-time chat (using pusher) in Laravel. I plan to use Flutter for the frontend. How can I integrate the model in Laravel?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Cautious-External177&quot;&gt; /u/Cautious-External177 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9s7iw/langchain_chatbot_integration_in_laravel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9s7iw/langchain_chatbot_integration_in_laravel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9s7iw</id><link href="https://www.reddit.com/r/LangChain/comments/1e9s7iw/langchain_chatbot_integration_in_laravel/" /><updated>2024-07-22T23:00:49+00:00</updated><published>2024-07-22T23:00:49+00:00</published><title>Langchain chatbot integration in Laravel</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This tutorial explains how to use GraphRAG using JSON file and LangChain. This involves 1. Converting json to text 2. Create Knowledge Graph 3. Create GraphQA chain&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://youtu.be/wXTs3cmZuJA?si=dnwTo6BHbK8WgGEF&quot;&gt;https://youtu.be/wXTs3cmZuJA?si=dnwTo6BHbK8WgGEF&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e967n3/graphrag_using_json_and_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e967n3/graphrag_using_json_and_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e967n3</id><link href="https://www.reddit.com/r/LangChain/comments/1e967n3/graphrag_using_json_and_langchain/" /><updated>2024-07-22T05:11:53+00:00</updated><published>2024-07-22T05:11:53+00:00</published><title>GraphRAG using JSON and LangChain</title></entry><entry><author><name>/u/mallerius</name><uri>https://www.reddit.com/user/mallerius</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey I&amp;#39;m developing a customer service chatbot that answers questions on a specific topic based on knowledge provided to the bot. In my system prompt I tell it to only answer related questions and refuse to answer unrelated stuff. However it still answers questions like &amp;quot;why is the sky blue?&amp;quot; and so on. Do you guys have any tips on how to improve this? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mallerius&quot;&gt; /u/mallerius &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9jii5/how_to_restrict_chatbot_from_answering_unrelated/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9jii5/how_to_restrict_chatbot_from_answering_unrelated/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9jii5</id><link href="https://www.reddit.com/r/LangChain/comments/1e9jii5/how_to_restrict_chatbot_from_answering_unrelated/" /><updated>2024-07-22T17:07:24+00:00</updated><published>2024-07-22T17:07:24+00:00</published><title>How to restrict chatbot from answering unrelated questions?</title></entry><entry><author><name>/u/julio_oa</name><uri>https://www.reddit.com/user/julio_oa</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m building a chatbot with RAG system for a school, and they want to have all the courses and classes as &lt;em&gt;knowledge,&lt;/em&gt; so students can ask &lt;em&gt;anything&lt;/em&gt; and the bot should get the answer from all this knowledge&lt;em&gt;.&lt;/em&gt; I&amp;#39;m having a hard time figuring out how to tackle this, at the moment it&amp;#39;s like 50 pdfs, with a lot of pages, for 5 courses, and with many different topics. So if a students asks &amp;quot;What is the best way to do X&amp;quot;, the system should somehow look through all these pdfs and get the answer, or somehow know which pdfs are the most appropriates to go look for an answer. Not all the documents are relevant for a particular question, most likely just one/two/three documents will be relevant.&lt;/p&gt; &lt;p&gt;What I&amp;#39;m doing now is adding &amp;quot;tags&amp;quot;, so the people uploading these documents should add one or more tags: &amp;quot;course 1, tool X, some-other-keyword&amp;quot;, so when someone asks a question, I first try to see if the question matches some of the tags, and then just go get the pdfs with those tags.&lt;/p&gt; &lt;p&gt;tldr: how to implement RAG when the knowledge is a lot of different files talking about different topics.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/julio_oa&quot;&gt; /u/julio_oa &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9c81i/how_to_best_tackle_rag_for_multiple_documents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9c81i/how_to_best_tackle_rag_for_multiple_documents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9c81i</id><link href="https://www.reddit.com/r/LangChain/comments/1e9c81i/how_to_best_tackle_rag_for_multiple_documents/" /><updated>2024-07-22T11:46:29+00:00</updated><published>2024-07-22T11:46:29+00:00</published><title>How to best tackle RAG for multiple documents with multiple topics?</title></entry><entry><author><name>/u/Intelligent-Try-4558</name><uri>https://www.reddit.com/user/Intelligent-Try-4558</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;When I populate my chromadb, it takes a long time. To add ~3,000 docs can take upwards of 10 minutes, and adding any more docs afterwards will take much longer. When adding to the db, it is only using ~10% GPU and CPU usage. Is there any way to speed this process up or use more resources when populating the DB?&lt;/p&gt; &lt;p&gt;For context, I&amp;#39;m using random textbooks to populate the DB with rn, but this issue happens no matter the content I&amp;#39;m adding to the DB.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;#Embedding function I use embeddings = OllamaEmbeddings(model=&amp;quot;nomic-embed-text&amp;quot;) #This block is what takes forever new_chunk_ids = [chunk.metadata[&amp;quot;id&amp;quot;] for chunk in new_chunks] db.add_documents(new_chunks, ids=new_chunk_ids) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Intelligent-Try-4558&quot;&gt; /u/Intelligent-Try-4558 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9h5dq/chroma_db_taking_long_time_to_populate/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9h5dq/chroma_db_taking_long_time_to_populate/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9h5dq</id><link href="https://www.reddit.com/r/LangChain/comments/1e9h5dq/chroma_db_taking_long_time_to_populate/" /><updated>2024-07-22T15:30:03+00:00</updated><published>2024-07-22T15:30:03+00:00</published><title>Chroma DB taking long time to populate</title></entry><entry><author><name>/u/Sea-Sorbet-6134</name><uri>https://www.reddit.com/user/Sea-Sorbet-6134</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We use json formatted output from OpenAIs GPT-4o. We have a rather (single) big prompt for table extraction.&lt;/p&gt; &lt;p&gt;What are your approaches to achieve consistency in formatting.. especially regarding punctuation of numbers when processing various language formats like Englisch, French, German, Polish, Chinese&lt;/p&gt; &lt;p&gt;Example:&lt;/p&gt; &lt;p&gt;Task 1 Extract all unit prices for all line items and return them as an array where each value is formatted as double (xxx.xx)&lt;/p&gt; &lt;p&gt;Task 2 Extract all quantities for all line items and return them as an array where each value is formatted as double (xxx.xx)&lt;/p&gt; &lt;p&gt;Task 3 ..&lt;/p&gt; &lt;p&gt;Problem is: when doing this for multiple parts of the table in a single prompt, the formatting gets messed up.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sea-Sorbet-6134&quot;&gt; /u/Sea-Sorbet-6134 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9meao/how_to_achieve_consistency_in_formatting/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9meao/how_to_achieve_consistency_in_formatting/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9meao</id><link href="https://www.reddit.com/r/LangChain/comments/1e9meao/how_to_achieve_consistency_in_formatting/" /><updated>2024-07-22T19:03:22+00:00</updated><published>2024-07-22T19:03:22+00:00</published><title>How to achieve consistency in formatting?</title></entry><entry><author><name>/u/bferreira85</name><uri>https://www.reddit.com/user/bferreira85</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I see different implementations of Langggraph online, usually the most complex use toolnodes and the agents can only request a tool to be used, not using the tool themselves (i.e. they use bind_tools).&lt;br/&gt; The approach with tool_node seem to make the graph more complex and bureaucratic. Is there any use case in which we shouldn&amp;#39;t just give the tools to the agent? What is the advantage of the ToolNode approach?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bferreira85&quot;&gt; /u/bferreira85 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9ap85/langgraph_what_is_the_advantage_of_use_toolnodes/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9ap85/langgraph_what_is_the_advantage_of_use_toolnodes/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9ap85</id><link href="https://www.reddit.com/r/LangChain/comments/1e9ap85/langgraph_what_is_the_advantage_of_use_toolnodes/" /><updated>2024-07-22T10:15:32+00:00</updated><published>2024-07-22T10:15:32+00:00</published><title>Langgraph: what is the advantage of use Toolnodes with llm.bind_tools vs just using an agent with tools?</title></entry><entry><author><name>/u/BigYesterday2785</name><uri>https://www.reddit.com/user/BigYesterday2785</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am deciding between different vector databases to add. &lt;/p&gt; &lt;p&gt;I would prefer a vector database which could already give me confidence score. &lt;/p&gt; &lt;p&gt;So that when the chunk is found, there is also similarity score (confidence score) provided, and I do not have to implement it manually later on. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BigYesterday2785&quot;&gt; /u/BigYesterday2785 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e98owl/which_vector_database_already_provides_confidence/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e98owl/which_vector_database_already_provides_confidence/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e98owl</id><link href="https://www.reddit.com/r/LangChain/comments/1e98owl/which_vector_database_already_provides_confidence/" /><updated>2024-07-22T07:58:36+00:00</updated><published>2024-07-22T07:58:36+00:00</published><title>Which Vector Database already provides confidence scoring to us?</title></entry><entry><author><name>/u/tim-r</name><uri>https://www.reddit.com/user/tim-r</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;ol&gt; &lt;li&gt;Nextjs / React&lt;/li&gt; &lt;li&gt;Streamit&lt;/li&gt; &lt;li&gt;Python/Django/Flask&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;What do you use?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/tim-r&quot;&gt; /u/tim-r &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9mhmn/who_is_using_nextjs_for_their_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9mhmn/who_is_using_nextjs_for_their_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9mhmn</id><link href="https://www.reddit.com/r/LangChain/comments/1e9mhmn/who_is_using_nextjs_for_their_rag/" /><updated>2024-07-22T19:07:08+00:00</updated><published>2024-07-22T19:07:08+00:00</published><title>Who is using nextjs for their RAG?</title></entry><entry><author><name>/u/Gullible-Being-8595</name><uri>https://www.reddit.com/user/Gullible-Being-8595</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am facing a problem, I am using:&lt;/p&gt; &lt;p&gt;&lt;code&gt;from langgraph.prebuilt import create_react_agent&lt;/code&gt;&lt;/p&gt; &lt;p&gt;to create a react agent but this react agent is already complied &lt;code&gt;langgraph.graph.state.CompiledStateGraph&lt;/code&gt;&lt;/p&gt; &lt;p&gt;And now, I wanna have two more react agents and add those agents in the graph but there is no way to the best of my knowledge. &lt;/p&gt; &lt;pre&gt;&lt;code&gt;react_agent_1 = create_react_agent(model, tools=tools, messages_modifier=prompt) react_agent_2 = create_react_agent(model, tools=tools, messages_modifier=prompt) react_agent_3 = create_react_agent(model, tools=tools, messages_modifier=prompt) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now I wanna have the &lt;code&gt;react_agent_1&lt;/code&gt; as the parent/supervisor agent and&lt;code&gt;react_agent_2&lt;/code&gt; and and&lt;code&gt;react_agent_3&lt;/code&gt;as child agents. Now, how can I add these two agents in the already compiled graph as the other two are agents are also the complied graphs. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Gullible-Being-8595&quot;&gt; /u/Gullible-Being-8595 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9bnwm/multreactagents_workflow_using_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9bnwm/multreactagents_workflow_using_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9bnwm</id><link href="https://www.reddit.com/r/LangChain/comments/1e9bnwm/multreactagents_workflow_using_langgraph/" /><updated>2024-07-22T11:14:49+00:00</updated><published>2024-07-22T11:14:49+00:00</published><title>Mult-React-agents workflow using Langgraph</title></entry><entry><author><name>/u/behitek</name><uri>https://www.reddit.com/user/behitek</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;ðŸš€ Exciting News! ðŸš€&lt;/p&gt; &lt;p&gt;Just published my latest blog post on the Behitek blog: &amp;quot;RAG in Production: Best Practices for Robust and Scalable Systems&amp;quot; ðŸŒŸ&lt;/p&gt; &lt;p&gt;In this article, I explore how to effectively implement Retrieval-Augmented Generation (RAG) models in production environments. From reducing hallucinations to maintaining document hierarchy and optimizing chunking strategies, this guide covers all you need to know for robust and efficient RAG deployments.&lt;/p&gt; &lt;p&gt;Check it out and share your thoughts or experiences! I&amp;#39;d love to hear your feedback and any additional tips you might have. ðŸ‘‡&lt;/p&gt; &lt;p&gt;ðŸ”— &lt;a href=&quot;https://behitek.com/blog/2024/07/18/rag-in-production&quot;&gt;https://behitek.com/blog/2024/07/18/rag-in-production&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/behitek&quot;&gt; /u/behitek &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8oct1/rag_in_production_best_practices_for_robust_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e8oct1/rag_in_production_best_practices_for_robust_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e8oct1</id><link href="https://www.reddit.com/r/LangChain/comments/1e8oct1/rag_in_production_best_practices_for_robust_and/" /><updated>2024-07-21T15:05:36+00:00</updated><published>2024-07-21T15:05:36+00:00</published><title>RAG in Production: Best Practices for Robust and Scalable Systems</title></entry><entry><author><name>/u/The_Wolfiee</name><uri>https://www.reddit.com/user/The_Wolfiee</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to build an LLM powered evaluation application using LangChain where human users answer a set of pre-defined questions and an LLM checks the correctness of the answers and assign a percentage of how correct the answer is and how the answers can be improved. Assume that correct answers are stored in a database&lt;/p&gt; &lt;p&gt;Can someone provide a guide or a tutorial for this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/The_Wolfiee&quot;&gt; /u/The_Wolfiee &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e96ndq/llm_that_evaluates_human_answers/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e96ndq/llm_that_evaluates_human_answers/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e96ndq</id><link href="https://www.reddit.com/r/LangChain/comments/1e96ndq/llm_that_evaluates_human_answers/" /><updated>2024-07-22T05:40:06+00:00</updated><published>2024-07-22T05:40:06+00:00</published><title>LLM that evaluates human answers</title></entry><entry><author><name>/u/Muurda2</name><uri>https://www.reddit.com/user/Muurda2</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I trained a Llama2 7b chat model with QLoRA on customer support discussions (Instruction/Output format), and i&amp;#39;m trying to find a way to insert knowledge in the model, mainly about fixed information (Products in the store, customer service phone number, store opening hours...). Would implementing RAG would be a good idea ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Muurda2&quot;&gt; /u/Muurda2 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9c226/would_rag_be_useful_in_this_caes/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e9c226/would_rag_be_useful_in_this_caes/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e9c226</id><link href="https://www.reddit.com/r/LangChain/comments/1e9c226/would_rag_be_useful_in_this_caes/" /><updated>2024-07-22T11:37:23+00:00</updated><published>2024-07-22T11:37:23+00:00</published><title>Would RAG be useful in this caes ?</title></entry><entry><author><name>/u/Alert_Monitor4490</name><uri>https://www.reddit.com/user/Alert_Monitor4490</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am an intern and I&amp;#39;m trying to create a RAG app for my company so it will be easier for them to get access to their test test data. But when I look at how frequently things change in the RAG world, like modules moving from langchain to langchain_community, and calls being changed. Do you guys think it&amp;#39;s a good idea I go ahead with it? Cos if I leave and there is an update or anything like that no one apart from me can do it. So in the end it becomes useless a few months after. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Alert_Monitor4490&quot;&gt; /u/Alert_Monitor4490 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e95do2/updates_on_rag_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e95do2/updates_on_rag_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e95do2</id><link href="https://www.reddit.com/r/LangChain/comments/1e95do2/updates_on_rag_app/" /><updated>2024-07-22T04:20:30+00:00</updated><published>2024-07-22T04:20:30+00:00</published><title>Updates on RAG app</title></entry><entry><author><name>/u/ashishjadon</name><uri>https://www.reddit.com/user/ashishjadon</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m developing a mental health assessment tool using LangChain and OpenAI. The goal is to analyze user inputs and answer predefined questions about their mental state based solely on the information explicitly stated in their input.&lt;/p&gt; &lt;p&gt;My current implementation uses a ChatPromptTemplate with system and human messages, followed by a ChatOpenAI model and JsonOutputParser. However, I&amp;#39;m getting mixed results. The model sometimes infers information not explicitly stated in the input.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s a simplified version of my questions.json. There are around 30 questions in my json.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;[ { &amp;quot;name&amp;quot;: &amp;quot;Age&amp;quot;, &amp;quot;question_text&amp;quot;: &amp;quot;Select your age group:&amp;quot;, &amp;quot;displayOptions&amp;quot;: [ &amp;quot;12 to 21&amp;quot;, &amp;quot;21 to 30&amp;quot;, &amp;quot;30 to 50&amp;quot;, &amp;quot;60 and above&amp;quot; ] }, { &amp;quot;name&amp;quot;: &amp;quot;Gender&amp;quot;, &amp;quot;question_text&amp;quot;: &amp;quot;Select your gender:&amp;quot;, &amp;quot;displayOptions&amp;quot;: [ &amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;, &amp;quot;Others&amp;quot; ] }, { &amp;quot;name&amp;quot;: &amp;quot;StressRecently&amp;quot;, &amp;quot;question_text&amp;quot;: &amp;quot;Have you been stressed about something recently?&amp;quot;, &amp;quot;displayOptions&amp;quot;: [ &amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot; ] }, ] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Sample user input is: &lt;/p&gt; &lt;pre&gt;&lt;code&gt;I&amp;#39;m 32 year old guy.i&amp;#39;ve been working 10-12 hours in office although i am working from home. I&amp;#39;ve trouble sleeping. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;the response i&amp;#39;m getting is &lt;/p&gt; &lt;pre&gt;&lt;code&gt;{ &amp;quot;analysis&amp;quot;: { &amp;quot;AbnormalDailyActivity&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;AbnormalDisinterested&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;AbnormalDistraction&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;AbnormalEating&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;AbnormalMindMaking&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;AbnormalWeightGain&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;Age&amp;quot;: &amp;quot;30 to 50&amp;quot;, &amp;quot;ChronicHealth&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;CurrentChallenges&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;CurrentSituation&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;Employment&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;EnergyLevel&amp;quot;: &amp;quot;Yes&amp;quot;, &amp;quot;EngageActivities&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;EnjoyNormalDay&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;Gender&amp;quot;: &amp;quot;Male&amp;quot;, &amp;quot;GoodHealth&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;ServiceType&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;Staylocation&amp;quot;: &amp;quot;Home or at relatives&amp;quot;, &amp;quot;StressAge&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;StressLoss&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;StressRecently&amp;quot;: &amp;quot;Yes&amp;quot;, &amp;quot;StressShared1&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;WellBeingHealth&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;WellBeingNormal&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;WellBeingSatisfy&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;WorklifeBalance&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;Workstress&amp;quot;: &amp;quot;Unknown&amp;quot;, &amp;quot;lackofMotivation&amp;quot;: &amp;quot;Yes&amp;quot; }, &amp;quot;response_time&amp;quot;: &amp;quot;3.45 seconds&amp;quot; } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;now the issue is that i am getting and answer for StressRecently as Yes but the user&amp;#39;s input doesn&amp;#39;t has anything related to the stress. I&amp;#39;ve tried to change the prompt as per my requirement but the LLM is inferring the data from the user&amp;#39;s input. I need it to answer only those questions which are explicitly mentioned in the user&amp;#39;s input. &lt;/p&gt; &lt;p&gt;here&amp;#39;s the code i am using for my prompting. &lt;/p&gt; &lt;pre&gt;&lt;code&gt;system_template = &amp;#39;&amp;#39;&amp;#39;You are a highly precise mental health assessment assistant. Your role is to analyze user inputs and respond to a set of predefined questions about their mental state and well-being. Follow these strict guidelines: 1. Only use information explicitly stated in the user&amp;#39;s input. 2. DO NOT make inferences, assumptions, or guesses about unstated information. 3. Respond with &amp;quot;Unknown&amp;quot; for any question that cannot be directly answered from the given information. 4. Be extremely cautious: it&amp;#39;s better to answer &amp;quot;Unknown&amp;quot; than to potentially provide incorrect information. 5. Focus solely on the content of the user&amp;#39;s statement, not on interpreting or diagnosing their condition. 6. DO NOT interpret or diagnose. Only report what is directly stated. Remember, this is a critical assessment tool dealing with real patients&amp;#39; mental health. Accuracy and caution are paramount. &amp;#39;&amp;#39;&amp;#39; human_template = &amp;#39;&amp;#39;&amp;#39;Carefully read the following user input: User&amp;#39;s statement: {text} Based solely on this input, provide answers to the following questions. Use &amp;quot;Unknown&amp;quot; for any question that cannot be answered with absolute certainty based on the explicit content of the user&amp;#39;s statement. Questions: {questions} While answering the questions, use the question_text field to answer the question. don;t rely on just the name field. Provide your answers in JSON format. Include all questions, using &amp;quot;Unknown&amp;quot; for any that cannot be confidently answered based solely on the given information.&amp;#39;&amp;#39;&amp;#39; prompt_template = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, system_template), (&amp;quot;human&amp;quot;, human_template) ]) chain = prompt_template | model | parser def analyze_situation( text ): start_time = time.time() result = chain.invoke({ &amp;quot;questions&amp;quot;: json.dumps(questions_json, indent =2), &amp;quot;text&amp;quot;: text }) end_time = time.time() elapsed_time = end_time - start_time return result, elapsed_time &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Can i get any pointers or guidance on &lt;/p&gt; &lt;ul&gt; &lt;li&gt;How to improve my prompt to ensure the model only uses explicitly stated information?&lt;br/&gt;&lt;/li&gt; &lt;li&gt;Are there better LangChain components or techniques I should consider for this task? &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;As a LangChain novice, any guidance on best practices would be greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ashishjadon&quot;&gt; /u/ashishjadon &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e95iug/need_some_help_to_optimize_the_performance_of_my/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1e95iug/need_some_help_to_optimize_the_performance_of_my/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1e95iug</id><link href="https://www.reddit.com/r/LangChain/comments/1e95iug/need_some_help_to_optimize_the_performance_of_my/" /><updated>2024-07-22T04:29:23+00:00</updated><published>2024-07-22T04:29:23+00:00</published><title>Need some help to optimize the performance of my first ever langchain application.</title></entry></feed>