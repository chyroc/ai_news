<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-07-03T14:39:42+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/coolcloud</name><uri>https://www.reddit.com/user/coolcloud</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtr49t/agent_rag_parallel_quotes_how_we_built_rag_on/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/bMd79q8bCS6eIl2j-osvJEQzKD5Q0MMW8-q6edsGYHc.jpg&quot; alt=&quot;Agent RAG (Parallel Quotes) - How we built RAG on 10,000's of docs with extremely high accuracy&quot; title=&quot;Agent RAG (Parallel Quotes) - How we built RAG on 10,000's of docs with extremely high accuracy&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Edit - for some reason the prompts weren&amp;#39;t showing up. Added them.&lt;/p&gt; &lt;p&gt;Hey all -&lt;/p&gt; &lt;p&gt;Today I want to walk through how we&amp;#39;ve been able to get extremely high accuracy recall on thousands of documents by taking advantage of splitting retrieval into an &amp;quot;Agent&amp;quot; approach.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;As we built RAG, we continued to notice hallucinations or incorrect answers. we realized three key issues:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;There wasn&amp;#39;t enough data in the vector to provide a coherent answer. i.e. vector was 2 sentences, but the answer was the entire paragraph or multiple paragraphs.&lt;/li&gt; &lt;li&gt;LLM&amp;#39;s try to merge an answer from multiple different vectors which made an answer that looked right but wasn&amp;#39;t.&lt;/li&gt; &lt;li&gt;End users couldn&amp;#39;t figure out where the doc came from and if it was accurate.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;We solved this problem by doing the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Figure out document layout (&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dpbc4g/how_we_chunk_turning_pdfs_into_hierarchical/&quot;&gt;we posted about it a few days ago.&lt;/a&gt;) This will make issue one much less common.&lt;/li&gt; &lt;li&gt;Split each &amp;quot;chunk&amp;quot; into separate prompts (Agent approach) to find exact quotes that may be important to answering the question. This fixes issue 2.&lt;/li&gt; &lt;li&gt;Ask the LLM to only give direct quotes with references to the document it came from, both in step one and step two of the LLM answer generation. This solves issue 3.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;What does it look like?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/otf9dbau05ad1.png?width=1625&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=72a7fe9349a9499a32ff5f6b6a245623e1d91102&quot;&gt;https://preview.redd.it/otf9dbau05ad1.png?width=1625&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=72a7fe9349a9499a32ff5f6b6a245623e1d91102&lt;/a&gt;&lt;/p&gt; &lt;p&gt;We found these improvements, along with our prompt give us extremely high retrieval even on complex questions, or large corpuses of data.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Why do we believe it works so well?&lt;/strong&gt; - LLM&amp;#39;s still seem better to deal with a single task at a time, and LLM&amp;#39;s still struggle with large token counts on random data glued together with a prompt (i.e. a ton of random chunks). Because we are only providing a single Chunk, or relevant information, we found huge improvements in recall and accuracy.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Workflow:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/8aso1i7y05ad1.png?width=1109&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e115ee50b70fbf790e78af365ce96f7d2e16a020&quot;&gt;https://preview.redd.it/8aso1i7y05ad1.png?width=1109&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e115ee50b70fbf790e78af365ce96f7d2e16a020&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Step by step with example on above workflow&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Query:&lt;/strong&gt; What are the recent advancements in self-supervised object detection technique&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Reconstruct document.&lt;/strong&gt; (highlighted would be the vector that came back) Then we&amp;#39;d reconstruct the doc until we get to a header.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/ztj8q1f415ad1.png?width=1122&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ab3805273bf3320d7478c3619c3c0df8dcdc98d9&quot;&gt;https://preview.redd.it/ztj8q1f415ad1.png?width=1122&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ab3805273bf3320d7478c3619c3c0df8dcdc98d9&lt;/a&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Input the reconstructed document chunk into the LLM. &lt;strong&gt;(Parallel Quotes)&lt;/strong&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Prompt #1:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;_______&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;You are an expert research assistant. Here is a document you will find relevant quotes to the question asked:&lt;/p&gt; &lt;p&gt; &amp;lt;doc&amp;gt;&lt;/p&gt; &lt;p&gt; ${chunk}&lt;/p&gt; &lt;p&gt; &amp;lt;/doc&amp;gt;&lt;/p&gt; &lt;p&gt;Find the quotes from the document that are most relevant to answering the question, and then print them in numbered order. Quotes should be relatively short.&lt;/p&gt; &lt;p&gt;The format of your overall response should look like what&amp;#39;s shown below. Make sure to follow the formatting and spacing exactly.&lt;/p&gt; &lt;p&gt; Example:&lt;/p&gt; &lt;p&gt; [1] &amp;quot;Company X reported revenue of $12 million in 2021.&amp;quot;&lt;/p&gt; &lt;p&gt; [2] &amp;quot;Almost 90% of revenue came from widget sales, with gadget sales making up the remaining 10%.&amp;quot;&lt;/p&gt; &lt;p&gt; Do not write anything that&amp;#39;s not a quote direct quote.&lt;/p&gt; &lt;p&gt; If there are no quotes, please only print, &amp;quot;N/a&amp;quot;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;_______&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Response&lt;/strong&gt; from the LLM:&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;[1.0]&amp;quot;Recent advancements have seen the development of end-to-end self-supervised object detection models like UP-DETR and DETReg, as well as backbone pre-training strategies such as Self-EMD and Odin .&amp;quot;&lt;/p&gt; &lt;p&gt;[1.1] &amp;quot;Despite the remarkable success of supervised object detection techniques such as Mask RCNN , Yolo , Retinanet , and DETR , their self-supervised alternatives have been somewhat limited in scope until recently.&lt;/p&gt; &lt;p&gt;Notes:&lt;/p&gt; &lt;p&gt;I deleted the internal references to make it less confusing&lt;/p&gt; &lt;p&gt;If there&amp;#39;s more than 1 doc/chunk we start each new one with a new number i.e. [2.0] which makes it easier to find which quote relates to which doc.&lt;/p&gt; &lt;p&gt;We put the query in the user prompt and the above in the system prompt&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Give the LLM that will be generating the answer the &lt;strong&gt;document name &amp;amp; quotes&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Prompt #2:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;_______&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;All quotes are relevant to the question, please use them to answer the question:&lt;/p&gt; &lt;p&gt;When answering questions:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Make references to quotes relevant to each section of the answer solely by adding their bracketed numbers at the end of relevant sentences.&lt;/li&gt; &lt;li&gt; Feel free to shorten quotes or merge quotes together as long as you reference them.&lt;/li&gt; &lt;li&gt; Focus on making short, readable answers.&lt;/li&gt; &lt;li&gt; Bold headers, bold general topics, bullet point, list, etc. if needed to make it easier to read.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;DocName: UnSupDLA: Towards Unsupervised Document Layout Analysis&lt;/p&gt; &lt;p&gt;Quotes:&lt;/p&gt; &lt;p&gt;[1.0]&amp;quot;Recent advancements have seen the development of end-to-end self-supervised object detection models like UP-DETR and DETReg, as well as backbone pre-training strategies such as Self-EMD and Odin .&amp;quot;&lt;/p&gt; &lt;p&gt;[1.1] &amp;quot;Despite the remarkable success of supervised object detection techniques such as Mask RCNN , Yolo , Retinanet , and DETR , their self-supervised alternatives have been somewhat limited in scope until recently.&amp;quot;&lt;/p&gt; &lt;p&gt;DocName: &amp;#39;doc2&amp;#39;&lt;/p&gt; &lt;p&gt;Quotes:&lt;/p&gt; &lt;p&gt;[2.0]&amp;quot;example quote2&amp;quot;&lt;/p&gt; &lt;p&gt;[2.1]&amp;quot;example&amp;quot;&lt;/p&gt; &lt;p&gt;If there isn&amp;#39;t information to answer this question, please write:&lt;/p&gt; &lt;p&gt;I&amp;#39;m sorry, but there is no documentation available.&lt;/p&gt; &lt;p&gt;________&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Final LLM &lt;strong&gt;Response&lt;/strong&gt;:&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;End-to-End Self-Supervised Models&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;UP-DETR&lt;/strong&gt;: This model is a recent development in self-supervised object detection, aiming to enhance detection capabilities without relying on labeled data [1.0].&lt;/li&gt; &lt;li&gt;&lt;strong&gt;DETReg&lt;/strong&gt;: Another advanced model, DETReg, also focuses on self-supervised object detection, providing improvements in training and detection accuracy without requiring extensive labeled datasets [1.0].&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Backbone Pre-Training Strategies&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Self-EMD&lt;/strong&gt;: This strategy is utilized to pre-train the backbone of detection models, helping in learning robust representations from unlabeled data [1.0].&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Odin&lt;/strong&gt;: Similar to Self-EMD, Odin is a pre-training strategy that enhances the performance of detection models through self-supervised learning techniques [1.0].&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Comparison with Supervised Techniques&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Scope and Limitations&lt;/strong&gt;: Despite the success of supervised techniques like Mask RCNN, Yolo, Retinanet, and DETR, their self-supervised alternatives have only recently started to expand in scope and effectiveness [1.1].&lt;/p&gt; &lt;p&gt;_________________________________&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Real world examples of where this comes into use:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A lot of internal company documents are made with human workflows in mind only. For example, often see a document named &amp;quot;integrations&amp;quot; or &amp;quot;partners&amp;quot; and then just a list of 500 companies they integrate/partner with. If a vector came back from within that document, the LLM would not be able to know it was regarding integrations or partnership because it&amp;#39;s only the document name.&lt;/li&gt; &lt;li&gt;Some documents will talk about the product, idea, or topic in the header. Then not discuss it by that name again. Meaning if you only get the relevant chunk back, you will not know which product it&amp;#39;s referencing.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Based on our experience with internal documents, about 15% of queries fall into one of the above scenarios.&lt;/p&gt; &lt;p&gt;Notes - Yes, we plan on open sourcing this at some point but don&amp;#39;t currently have the bandwidth (we built it as a production product first so we have to rip out some things before doing so)&lt;/p&gt; &lt;p&gt;Happy to answer any questions!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Video:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://reddit.com/link/1dtr49t/video/o196uuch15ad1/player&quot;&gt;https://reddit.com/link/1dtr49t/video/o196uuch15ad1/player&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/coolcloud&quot;&gt; /u/coolcloud &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtr49t/agent_rag_parallel_quotes_how_we_built_rag_on/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtr49t/agent_rag_parallel_quotes_how_we_built_rag_on/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dtr49t</id><media:thumbnail url="https://b.thumbs.redditmedia.com/bMd79q8bCS6eIl2j-osvJEQzKD5Q0MMW8-q6edsGYHc.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1dtr49t/agent_rag_parallel_quotes_how_we_built_rag_on/" /><updated>2024-07-02T17:11:30+00:00</updated><published>2024-07-02T17:11:30+00:00</published><title>Agent RAG (Parallel Quotes) - How we built RAG on 10,000's of docs with extremely high accuracy</title></entry><entry><author><name>/u/hackermud</name><uri>https://www.reddit.com/user/hackermud</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been working on developing an enterprise platform for the past 2 months. This platform allows our clients to connect multiple data sources and create customized features powered by LLM for their products. The main issue I&amp;#39;m encountering is creating an appropriate query to retrieve relevant information from a large database with over 200 tables, each containing approximately 30-50 columns. I&amp;#39;ve experimented with various approaches such as Langgraph, custom LCEL, retriever with Langgraph, and different LLMs, but I&amp;#39;m still not getting the desired response. If anyone has experience with this type of problem, I would greatly appreciate it if you could share your knowledge. Thank you in advance.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hackermud&quot;&gt; /u/hackermud &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dudch2/is_there_a_better_approach_for_generating_proper/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dudch2/is_there_a_better_approach_for_generating_proper/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dudch2</id><link href="https://www.reddit.com/r/LangChain/comments/1dudch2/is_there_a_better_approach_for_generating_proper/" /><updated>2024-07-03T12:39:37+00:00</updated><published>2024-07-03T12:39:37+00:00</published><title>Is there a better approach for generating proper SQL queries for large databases to retrieve relevant information?</title></entry><entry><author><name>/u/Pitiful_Yak_390</name><uri>https://www.reddit.com/user/Pitiful_Yak_390</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;AI agents are all around but they lack real-world exposure. Asking them can be kinda hit-or-miss.&lt;/p&gt; &lt;p&gt;I found a way to make them way more useful. I built an AI agent with Perplexity search capabilities, and now it can look stuff up on the internet and has access to memory and knowledge. It can be used for research, financial analysis, recipe finding, emailing and so on.&lt;/p&gt; &lt;p&gt;The agent is built using Phidata (a framework to build agents with access to knowledge, memory and tools). Here’s a quick guide on how to do it using Portkey&amp;#39;s AI Gateway. Link- &lt;a href=&quot;https://git.new/Portkey-Phidata&quot;&gt;https://git.new/Portkey-Phidata&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Let me know your thoughts on this&lt;/p&gt; &lt;p&gt;Cheers!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Pitiful_Yak_390&quot;&gt; /u/Pitiful_Yak_390 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1duaiwv/i_built_useful_ai_agents_with_perplexity_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1duaiwv/i_built_useful_ai_agents_with_perplexity_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1duaiwv</id><link href="https://www.reddit.com/r/LangChain/comments/1duaiwv/i_built_useful_ai_agents_with_perplexity_search/" /><updated>2024-07-03T09:53:36+00:00</updated><published>2024-07-03T09:53:36+00:00</published><title>I built *useful* AI agents with perplexity search and knowledge access. (Here's how)</title></entry><entry><author><name>/u/Pflimlin</name><uri>https://www.reddit.com/user/Pflimlin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;HI !&lt;/p&gt; &lt;p&gt;I&amp;#39;m trying to POC a little project.&lt;/p&gt; &lt;p&gt;I have a BigQuery table that looks like this:&lt;/p&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th align=&quot;left&quot;&gt;conversation_id&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;message_id&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;message_content&lt;/th&gt; &lt;th align=&quot;left&quot;&gt;created_at&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;1&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;1&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;Hello !&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;2014-11-19 06:14:03 UTC&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;1&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;2&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;Hey, nice to meet you !&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;2014-11-19 06:14:05 UTC&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;2&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;1&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;Hello, I have a problem&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;2015-04-10 11:25:50 UTC&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=&quot;left&quot;&gt;2&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;2&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;What is your problem ?&lt;/td&gt; &lt;td align=&quot;left&quot;&gt;2015-04-10 11:25:55 UTC&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;This table has millions of rows of conversations / messages.&lt;/p&gt; &lt;p&gt;I would like to configure an LLM around that table, so I could ask data analysis questions like:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What were the main problems encountered by the users during the month of November 2014 ?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;What would you recommend ? Having such a large amount of data makes this a little tricky for me.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Pflimlin&quot;&gt; /u/Pflimlin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dubb96/llm_agent_around_a_bigquery_table/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dubb96/llm_agent_around_a_bigquery_table/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dubb96</id><link href="https://www.reddit.com/r/LangChain/comments/1dubb96/llm_agent_around_a_bigquery_table/" /><updated>2024-07-03T10:45:24+00:00</updated><published>2024-07-03T10:45:24+00:00</published><title>LLM Agent around a BigQuery table</title></entry><entry><author><name>/u/Electronic-Letter592</name><uri>https://www.reddit.com/user/Electronic-Letter592</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I would like to use an LLM (Llama3 or Mistral for example) for a multilabel-classification task. I have a few 1000 examples to train the model on, but not sure what&amp;#39;s the best way and library to do that. Is there any best practice how to fine-tune LLMs for classification tasks?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Electronic-Letter592&quot;&gt; /u/Electronic-Letter592 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1duedyv/finetune_llms_for_classification_task/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1duedyv/finetune_llms_for_classification_task/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1duedyv</id><link href="https://www.reddit.com/r/LangChain/comments/1duedyv/finetune_llms_for_classification_task/" /><updated>2024-07-03T13:29:14+00:00</updated><published>2024-07-03T13:29:14+00:00</published><title>Fine-tune LLMs for classification task</title></entry><entry><author><name>/u/SuccessfulStorm5342</name><uri>https://www.reddit.com/user/SuccessfulStorm5342</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1duebe1/how_to_counter_error_importerror_dependencies_for/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/ZG84OHpwMTMyYmFkMS6IVQGOudITRZW1OYBETCTWyjnvFdqo5v5Ltt23HGpL.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6465f5511c8591776b67b03125818bb69cae13cc&quot; alt=&quot;How to counter error : ImportError: Dependencies for InstructorEmbedding not found.&quot; title=&quot;How to counter error : ImportError: Dependencies for InstructorEmbedding not found.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SuccessfulStorm5342&quot;&gt; /u/SuccessfulStorm5342 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/e7yd3p132bad1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1duebe1/how_to_counter_error_importerror_dependencies_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1duebe1</id><media:thumbnail url="https://external-preview.redd.it/ZG84OHpwMTMyYmFkMS6IVQGOudITRZW1OYBETCTWyjnvFdqo5v5Ltt23HGpL.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6465f5511c8591776b67b03125818bb69cae13cc" /><link href="https://www.reddit.com/r/LangChain/comments/1duebe1/how_to_counter_error_importerror_dependencies_for/" /><updated>2024-07-03T13:25:54+00:00</updated><published>2024-07-03T13:25:54+00:00</published><title>How to counter error : ImportError: Dependencies for InstructorEmbedding not found.</title></entry><entry><author><name>/u/ravediamond000</name><uri>https://www.reddit.com/user/ravediamond000</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone,&lt;/p&gt; &lt;p&gt;Here&amp;#39;s a new post on how to add cost monitoring to all your Langchain apps that use AWS Bedrock using Langfuse. This is actually what I&amp;#39;m using in production and I recommand it!&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the link: &lt;a href=&quot;https://www.metadocs.co/2024/07/03/monitor-your-langchain-app-cost-using-bedrock-with-langfuse/&quot;&gt;link&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Have a nice read!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ravediamond000&quot;&gt; /u/ravediamond000 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1du8aue/cost_monitoring_for_langchain_apps_using_aws/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1du8aue/cost_monitoring_for_langchain_apps_using_aws/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1du8aue</id><link href="https://www.reddit.com/r/LangChain/comments/1du8aue/cost_monitoring_for_langchain_apps_using_aws/" /><updated>2024-07-03T07:14:35+00:00</updated><published>2024-07-03T07:14:35+00:00</published><title>Cost monitoring for Langchain apps using AWS Bedrock with Langfuse</title></entry><entry><author><name>/u/yareyaretf</name><uri>https://www.reddit.com/user/yareyaretf</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;For about a month or more, I&amp;#39;ve been trying to build an RAG system and understand the tools used for a project, which involves dealing with Excel data. I&amp;#39;ve encountered issues with the standard method like split and embedding the data ,especially when dealing with excel file containing multiple sheets or pages. After researching, I found a few solutions including Langchain Agent, but encountered errors when trying to use it. Any solutions, suggestions, or resources that could help me? Thank you.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/yareyaretf&quot;&gt; /u/yareyaretf &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1du8uem/rag_system_with_excel_sheets/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1du8uem/rag_system_with_excel_sheets/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1du8uem</id><link href="https://www.reddit.com/r/LangChain/comments/1du8uem/rag_system_with_excel_sheets/" /><updated>2024-07-03T07:52:08+00:00</updated><published>2024-07-03T07:52:08+00:00</published><title>RAG system with excel sheets</title></entry><entry><author><name>/u/jscraft</name><uri>https://www.reddit.com/user/jscraft</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Everyone, I&amp;#39;ve made a short example of Routing in LangChain JS by using LLM Classifiers to call different prompts based on the content of the query:&lt;br/&gt; &lt;a href=&quot;https://www.js-craft.io/blog/routing-langchain-js-different-prompts-based-on-query-type/&quot;&gt;https://www.js-craft.io/blog/routing-langchain-js-different-prompts-based-on-query-type/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In case someone may find it useful :) &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jscraft&quot;&gt; /u/jscraft &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1duc2qb/routing_in_langchain_js_use_llm_classifiers_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1duc2qb/routing_in_langchain_js_use_llm_classifiers_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1duc2qb</id><link href="https://www.reddit.com/r/LangChain/comments/1duc2qb/routing_in_langchain_js_use_llm_classifiers_to/" /><updated>2024-07-03T11:31:25+00:00</updated><published>2024-07-03T11:31:25+00:00</published><title>Routing in LangChain JS – Use LLM Classifiers to Call Different Prompts</title></entry><entry><author><name>/u/grassyface19</name><uri>https://www.reddit.com/user/grassyface19</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently testing the RAG (Retrieval-Augmented Generation) pipeline with RAGAS, but I&amp;#39;m facing some challenges. The results aren&amp;#39;t as good as expected. Could someone please help me with evaluating the RAG pipeline effectively? Any tips or advice would be greatly appreciated &lt;/p&gt; &lt;h1&gt;langchain&lt;/h1&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/grassyface19&quot;&gt; /u/grassyface19 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dubm7s/rag_pipline_test/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dubm7s/rag_pipline_test/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dubm7s</id><link href="https://www.reddit.com/r/LangChain/comments/1dubm7s/rag_pipline_test/" /><updated>2024-07-03T11:04:01+00:00</updated><published>2024-07-03T11:04:01+00:00</published><title>RAG pipline test</title></entry><entry><author><name>/u/theogswami</name><uri>https://www.reddit.com/user/theogswami</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1du89s6/langchain_and_supabase_causing_errors/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/hr8q0WIMay7ZUFmbKJU6004bwUopRqVK0mTZaoTHvtY.jpg&quot; alt=&quot;LangChain and supabase causing errors&quot; title=&quot;LangChain and supabase causing errors&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Trying to make my first Chatbot using LLM,&lt;br/&gt; I have imported langchain and it came up with no troubles. used text-splitter to check its functioning and everything. then i try to import supabase and get this error&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/snywi44f69ad1.png?width=609&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f00bea359e7fb9c50cd4352711003ea7446903ff&quot;&gt;https://preview.redd.it/snywi44f69ad1.png?width=609&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f00bea359e7fb9c50cd4352711003ea7446903ff&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Running npm audit gave me this:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/t6trkrxi69ad1.png?width=895&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2fa08df9f9de56820547f38b4d45d75533c833ca&quot;&gt;https://preview.redd.it/t6trkrxi69ad1.png?width=895&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2fa08df9f9de56820547f38b4d45d75533c833ca&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Solutions i have tried:&lt;br/&gt; - Cache clearing&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;npm fix force &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;removing package.json/package-lock.json and reinstalling it &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;updating the packages( langchain, supabase)&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Links to Codes:&lt;br/&gt; index.js: &lt;a href=&quot;https://codeshare.io/4YjjPj&quot;&gt;https://codeshare.io/4YjjPj&lt;/a&gt;&lt;/p&gt; &lt;p&gt;package.json: &lt;a href=&quot;https://codeshare.io/ApQQvE&quot;&gt;https://codeshare.io/ApQQvE&lt;/a&gt;&lt;/p&gt; &lt;p&gt;FYI, i dont use ladash.set, langsmith anywhere for my chatbot.&lt;/p&gt; &lt;p&gt;Any Help is appreciated! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/theogswami&quot;&gt; /u/theogswami &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1du89s6/langchain_and_supabase_causing_errors/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1du89s6/langchain_and_supabase_causing_errors/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1du89s6</id><media:thumbnail url="https://b.thumbs.redditmedia.com/hr8q0WIMay7ZUFmbKJU6004bwUopRqVK0mTZaoTHvtY.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1du89s6/langchain_and_supabase_causing_errors/" /><updated>2024-07-03T07:12:27+00:00</updated><published>2024-07-03T07:12:27+00:00</published><title>LangChain and supabase causing errors</title></entry><entry><author><name>/u/HomunMage</name><uri>https://www.reddit.com/user/HomunMage</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtklxf/nodeedge_based_gui_editor_for_langgraph/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/exY9_QSiBsqruos_Vl-FOO-GjU9HPiDkmZLuuE9TZPA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=34272cbdfb4a33eb9ee505cd85f9d900b0ef7af5&quot; alt=&quot;node-edge based GUI editor for LangGraph&quot; title=&quot;node-edge based GUI editor for LangGraph&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I’m excited to share that I’ve created a node-edge based GUI editor for LangGraph!&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/1uf35sfym3ad1.jpg?width=1850&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=59f0728b3381b8a68d83f27137075587f13bb033&quot;&gt;https://preview.redd.it/1uf35sfym3ad1.jpg?width=1850&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=59f0728b3381b8a68d83f27137075587f13bb033&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This tool provides an intuitive interface for creating and managing workflows, making it easier than ever to visualize and execute tasks. Whether you&amp;#39;re working with complex workflows or just getting started, LangGraph-GUI simplifies the process.&lt;/p&gt; &lt;p&gt;Check it out here: &lt;a href=&quot;https://github.com/LangGraph-GUI/LangGraph-GUI&quot;&gt;LangGraph-GUI on GitHub&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Some key features include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;User-Friendly Interface:&lt;/strong&gt; Easily create and edit workflows with a visual editor.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Seamless Integration:&lt;/strong&gt; Supports local execution with language models like Mistral.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;JSON Support:&lt;/strong&gt; Read and write JSON files for your workflows, ensuring compatibility and easy sharing.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To get started, follow the setup instructions in the repository. I’ve also included a guide on how to build the front-end GUI into a standalone executable.&lt;/p&gt; &lt;p&gt;If you want to learn LangGraph, we have LangGraph for dummy learning: &lt;a href=&quot;https://github.com/LangGraph-GUI/LangGraph-learn&quot;&gt;LangGraph-learn&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I’d love to hear your feedback and see how you’re using LangGraph-GUI in your projects. Feel free to contribute or raise issues on GitHub.&lt;/p&gt; &lt;p&gt;Happy graphing!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HomunMage&quot;&gt; /u/HomunMage &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtklxf/nodeedge_based_gui_editor_for_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtklxf/nodeedge_based_gui_editor_for_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dtklxf</id><media:thumbnail url="https://external-preview.redd.it/exY9_QSiBsqruos_Vl-FOO-GjU9HPiDkmZLuuE9TZPA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=34272cbdfb4a33eb9ee505cd85f9d900b0ef7af5" /><link href="https://www.reddit.com/r/LangChain/comments/1dtklxf/nodeedge_based_gui_editor_for_langgraph/" /><updated>2024-07-02T12:28:06+00:00</updated><published>2024-07-02T12:28:06+00:00</published><title>node-edge based GUI editor for LangGraph</title></entry><entry><author><name>/u/AaronPhilip0401</name><uri>https://www.reddit.com/user/AaronPhilip0401</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey Everyone, I made a Resume Chatbot, I&amp;#39;d Love for you&amp;#39;ll to read my article linked below. Thank you!&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://medium.com/@aaronphilip2003/r%C3%A9sum%C3%A9-chatbot-abccc89de23b&quot;&gt;https://medium.com/@aaronphilip2003/r%C3%A9sum%C3%A9-chatbot-abccc89de23b&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AaronPhilip0401&quot;&gt; /u/AaronPhilip0401 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtwsfv/resume_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtwsfv/resume_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dtwsfv</id><link href="https://www.reddit.com/r/LangChain/comments/1dtwsfv/resume_chatbot/" /><updated>2024-07-02T21:08:53+00:00</updated><published>2024-07-02T21:08:53+00:00</published><title>Resume Chatbot</title></entry><entry><author><name>/u/muditjps</name><uri>https://www.reddit.com/user/muditjps</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtouei/hey_rlangchain_heres_an_app_template_for_dynamic/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/bYJYJn7AFjU1MEAbBCE0nu4skG965Xj3xtDa5916dgQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=637d4004e9e41de0bcc24f9e3014b8350b12a54b&quot; alt=&quot;Hey r/langchain, here's an app template for Dynamic RAG using Pathway vector store within LangChain. This integration ensures your applications always have up-to-date knowledge by syncing with real-time data changes. Run it on your data in minutes using Google Colab.&quot; title=&quot;Hey r/langchain, here's an app template for Dynamic RAG using Pathway vector store within LangChain. This integration ensures your applications always have up-to-date knowledge by syncing with real-time data changes. Run it on your data in minutes using Google Colab.&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/muditjps&quot;&gt; /u/muditjps &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://pathway.com/developers/templates/langchain-integration&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtouei/hey_rlangchain_heres_an_app_template_for_dynamic/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dtouei</id><media:thumbnail url="https://external-preview.redd.it/bYJYJn7AFjU1MEAbBCE0nu4skG965Xj3xtDa5916dgQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=637d4004e9e41de0bcc24f9e3014b8350b12a54b" /><link href="https://www.reddit.com/r/LangChain/comments/1dtouei/hey_rlangchain_heres_an_app_template_for_dynamic/" /><updated>2024-07-02T15:38:18+00:00</updated><published>2024-07-02T15:38:18+00:00</published><title>Hey r/langchain, here's an app template for Dynamic RAG using Pathway vector store within LangChain. This integration ensures your applications always have up-to-date knowledge by syncing with real-time data changes. Run it on your data in minutes using Google Colab.</title></entry><entry><author><name>/u/Chussboi96</name><uri>https://www.reddit.com/user/Chussboi96</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am currently working on a project that involves developing a text-to-SQL system. The goal is to allow users to input natural language, and the system will generate SQL queries. I have reference documents (PDFs) containing SQL queries and their descriptions (of schemas as well). I am considering using a Retrieval-Augmented Generation (RAG) system for this task. The idea is to use the provided documents to help generate the SQL queries. However, I am unsure if this is the best approach. Alternatively, I am thinking about fine-tuning a model specifically for this purpose. Also, is sqlcoder2-7b the sql code generator out there?&lt;/p&gt; &lt;p&gt;I would greatly appreciate guidance on the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Is the RAG system the best solution for this problem?&lt;/li&gt; &lt;li&gt;Would fine-tuning a model be more effective for generating accurate SQL queries?&lt;/li&gt; &lt;li&gt;Is there a better approach that I should consider?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;All your insights and suggestions will be invaluable in helping me determine the best course of action for this project. Thank you&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Chussboi96&quot;&gt; /u/Chussboi96 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtjafd/texttosql_system_using_llm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtjafd/texttosql_system_using_llm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dtjafd</id><link href="https://www.reddit.com/r/LangChain/comments/1dtjafd/texttosql_system_using_llm/" /><updated>2024-07-02T11:14:40+00:00</updated><published>2024-07-02T11:14:40+00:00</published><title>Text-to-sql system using LLM</title></entry><entry><author><name>/u/gabbom_XCII</name><uri>https://www.reddit.com/user/gabbom_XCII</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Suppose I use langchain’s ChatOpenAI as a model, ChatPromptTemplate to build a prompt and build myself a chain like that:&lt;/p&gt; &lt;p&gt;chain = prompt | model&lt;/p&gt; &lt;p&gt;I’m trying to use LangGraph along with it’s memory capabilities to orchestrate chains built like these. Is this the right way? Or should I be starting to build the chain with langgraph?&lt;/p&gt; &lt;p&gt;Looks like my chain has some kind of amnesia between messages.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gabbom_XCII&quot;&gt; /u/gabbom_XCII &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtw8rr/is_it_possible_to_use_langgraph_to_orchestrate/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtw8rr/is_it_possible_to_use_langgraph_to_orchestrate/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dtw8rr</id><link href="https://www.reddit.com/r/LangChain/comments/1dtw8rr/is_it_possible_to_use_langgraph_to_orchestrate/" /><updated>2024-07-02T20:45:15+00:00</updated><published>2024-07-02T20:45:15+00:00</published><title>Is it possible to use LangGraph to orchestrate LangChain chains?</title></entry><entry><author><name>/u/Least_Suspect_7256</name><uri>https://www.reddit.com/user/Least_Suspect_7256</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Should I use Async or not? &lt;/p&gt; &lt;p&gt;I am building a Fast api RAG app that uses LLMs to generate responses using langchain but I am confused if it needs async. &lt;/p&gt; &lt;p&gt;The user flow goes something like this: 1. User provides a link/ links to a text/pdf document in the form of a url.&lt;br/&gt; 2. Langchain document loaders are used to load text or pdf from the remote public url. 3. Character splitter is used to split and chunk the documents which is saved into a vector db. 4. Langchain chain library is used to invoke LLMs via the asynchronous ainvoke(). &lt;/p&gt; &lt;p&gt;My question is whether the document loading step via langchain and character splitting text via langchain would need to be made async? Langchain doesn’t support async for the libraries I am using. Would I need to implement them myself? If so, what are some options to implement? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Least_Suspect_7256&quot;&gt; /u/Least_Suspect_7256 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtvnw0/langchain_async_for_document_loader_and_character/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtvnw0/langchain_async_for_document_loader_and_character/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dtvnw0</id><link href="https://www.reddit.com/r/LangChain/comments/1dtvnw0/langchain_async_for_document_loader_and_character/" /><updated>2024-07-02T20:20:10+00:00</updated><published>2024-07-02T20:20:10+00:00</published><title>Langchain async for document loader and character splitter</title></entry><entry><author><name>/u/neuralmancer86</name><uri>https://www.reddit.com/user/neuralmancer86</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We’re building an internal RAG LLM chatbot where the queries are augmented by a large volume of files we have in SharePoint and some pages in Confluence. How would you maintain the existing RBAC of these files in the results from the chatbot when different employees are querying? Is there a tool that would allow the results to adhere to the existing permissions of these data sources?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/neuralmancer86&quot;&gt; /u/neuralmancer86 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtyunx/how_are_you_maintaining_existing_access_control/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtyunx/how_are_you_maintaining_existing_access_control/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dtyunx</id><link href="https://www.reddit.com/r/LangChain/comments/1dtyunx/how_are_you_maintaining_existing_access_control/" /><updated>2024-07-02T22:40:05+00:00</updated><published>2024-07-02T22:40:05+00:00</published><title>How are you maintaining existing access control permissions for a RAG LLM chatbot?</title></entry><entry><author><name>/u/AGI-is-coming</name><uri>https://www.reddit.com/user/AGI-is-coming</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks,&lt;/p&gt; &lt;p&gt;I&amp;#39;ve been building AI assistants using Phidata which uses Langchain Knowledge Base. I needed better observability for my assistants to track metrics such as costs, response latency, caching, etc.&lt;/p&gt; &lt;p&gt;To solve these issues I integrated Portkey with Phidata. I decided to create a simple cookbook. It integrates Phidata seamlessly with Portkey&amp;#39;s AI gateway in 3 lines of code, giving me clear insights into how my assistants perform.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s the link to the google collab notebook- &lt;a href=&quot;https://git.new/Phidata-Portkey&quot;&gt;https://git.new/Phidata-Portkey&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Let me know what you think or if you have any tips to improve!&lt;/p&gt; &lt;p&gt;Cheers!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AGI-is-coming&quot;&gt; /u/AGI-is-coming &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtjipf/how_i_built_observability_for_my_ai_assistant/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtjipf/how_i_built_observability_for_my_ai_assistant/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dtjipf</id><link href="https://www.reddit.com/r/LangChain/comments/1dtjipf/how_i_built_observability_for_my_ai_assistant/" /><updated>2024-07-02T11:28:10+00:00</updated><published>2024-07-02T11:28:10+00:00</published><title>How I built observability for my AI assistant</title></entry><entry><author><name>/u/External_Ad_11</name><uri>https://www.reddit.com/user/External_Ad_11</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;With the growing popularity of large language models, Agents are becoming a topic of discussion. In this article, we will explore Autonomous Agents, cover the components of building an Agentic workflow, and discuss the practical implementation of a Content creation agent using Langhchain Groq and crewAI.&lt;/p&gt; &lt;p&gt;Code Implementation and article in comment:&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/External_Ad_11&quot;&gt; /u/External_Ad_11 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dth36y/building_an_agentic_workflow_with_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dth36y/building_an_agentic_workflow_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dth36y</id><link href="https://www.reddit.com/r/LangChain/comments/1dth36y/building_an_agentic_workflow_with_langchain/" /><updated>2024-07-02T08:47:49+00:00</updated><published>2024-07-02T08:47:49+00:00</published><title>Building an Agentic Workflow with Langchain CrewAI and Groq</title></entry><entry><author><name>/u/Individual-Car6754</name><uri>https://www.reddit.com/user/Individual-Car6754</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, I need your help with my project. I have two problems:&lt;br/&gt; 1 - I&amp;#39;d like the user to be able to upload a csv file directly instead of putting the route to the file&lt;br/&gt; 2 - I don&amp;#39;t know why, but in csv/playground/, there&amp;#39;s no output displayed&lt;br/&gt; I&amp;#39;m trying to make an askyourcsv project but in this project, the user has to set the file path instead of uploading the file. What can I do to enable the user to upload the file and how can I improve my code? And what&amp;#39;s wrong with the code so that the output isn&amp;#39;t displayed in the playground?&lt;/p&gt; &lt;pre&gt;&lt;code&gt;#chain.py def loaddata(filepath: str) -&amp;gt; List[Document]: loader = CSVLoader(filepath=filepath) documents = loader.load() return documents class QuestionRequest(BaseModel): file_path: str question: str class Rag_chain(Runnable): def invoke(self, input: Any, config: Dict[str, Any] = None) : if isinstance(input, dict): input = QuestionRequest(**input) question = input.question file_path = input.file_path data = load_data(file_path) text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) documents = text_splitter.split_documents(data) vectorstore = Chroma.from_documents( documents, embedding=OpenAIEmbeddings(model=&amp;quot;text-embedding-ada-002&amp;quot;), ) retriever = RunnableLambda(vectorstore.similarity_search).bind(k=5) llm = ChatOpenAI(model=&amp;quot;gpt-3.5-turbo&amp;quot;, temperature=0.6) template = &amp;quot;&amp;quot;&amp;quot;Answer the question based only on the following context: {context} Question: {question} &amp;quot;&amp;quot;&amp;quot; prompt = ChatPromptTemplate.from_template(template) chain = ( # Extract the question text from the QuestionRequest object RunnableParallel({&amp;quot;context&amp;quot;: retriever, &amp;quot;question&amp;quot;: RunnablePassthrough()}) | prompt | llm | StrOutputParser() ) response = chain.invoke(question) return response &amp;#39;&amp;#39;&amp;#39; &amp;#39;&amp;#39;&amp;#39; #server.py app = FastAPI() chain_instance = Rag_chain() add_routes(app, chain_instance, path=&amp;quot;/csv&amp;quot;, input_type=QuestionRequest) if __name == &amp;quot;__main&amp;quot;: import uvicorn uvicorn.run(app, host=&amp;quot;0.0.0.0&amp;quot;, port=8000) &amp;#39;&amp;#39;&amp;#39; &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Individual-Car6754&quot;&gt; /u/Individual-Car6754 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtugcl/how_do_i_upload_a_file_and_display_the_output_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtugcl/how_do_i_upload_a_file_and_display_the_output_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dtugcl</id><link href="https://www.reddit.com/r/LangChain/comments/1dtugcl/how_do_i_upload_a_file_and_display_the_output_in/" /><updated>2024-07-02T19:29:44+00:00</updated><published>2024-07-02T19:29:44+00:00</published><title>How do I upload a file and display the output in the langserve playground?</title></entry><entry><author><name>/u/northwolf56</name><uri>https://www.reddit.com/user/northwolf56</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtuell/verify_chatgpt_statement_truth_using_anthropic/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/jfwglg973yQPBsIJUtCilujX4HW6TWYqeyJwNlB8L0Y.jpg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=07435abb6e4cbcfcf8580ac2d8d78721e60a1033&quot; alt=&quot;Verify ChatGPT Statement Truth Using Anthropic Claude Model&quot; title=&quot;Verify ChatGPT Statement Truth Using Anthropic Claude Model&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://youtu.be/18zTQv25qlk&quot;&gt;https://youtu.be/18zTQv25qlk&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I built this in like 5 minutes using &lt;a href=&quot;https://visualagents.ai&quot;&gt;https://visualagents.ai&lt;/a&gt; fully event driven data flow RAG graph built on top of js.langchain.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/qcp1brqap5ad1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=abae1244e70defe0c1301286cbdd5dfddc8ef8d2&quot;&gt;https://preview.redd.it/qcp1brqap5ad1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=abae1244e70defe0c1301286cbdd5dfddc8ef8d2&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/northwolf56&quot;&gt; /u/northwolf56 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtuell/verify_chatgpt_statement_truth_using_anthropic/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtuell/verify_chatgpt_statement_truth_using_anthropic/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dtuell</id><media:thumbnail url="https://external-preview.redd.it/jfwglg973yQPBsIJUtCilujX4HW6TWYqeyJwNlB8L0Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=07435abb6e4cbcfcf8580ac2d8d78721e60a1033" /><link href="https://www.reddit.com/r/LangChain/comments/1dtuell/verify_chatgpt_statement_truth_using_anthropic/" /><updated>2024-07-02T19:27:40+00:00</updated><published>2024-07-02T19:27:40+00:00</published><title>Verify ChatGPT Statement Truth Using Anthropic Claude Model</title></entry><entry><author><name>/u/ml_dnn</name><uri>https://www.reddit.com/user/ml_dnn</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Published in ICML 2024&lt;/p&gt; &lt;p&gt;Paper: &lt;a href=&quot;https://huggingface.co/papers/2406.16979&quot;&gt;https://huggingface.co/papers/2406.16979&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ml_dnn&quot;&gt; /u/ml_dnn &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtly3h/deep_reinforcement_learning/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtly3h/deep_reinforcement_learning/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dtly3h</id><link href="https://www.reddit.com/r/LangChain/comments/1dtly3h/deep_reinforcement_learning/" /><updated>2024-07-02T13:32:40+00:00</updated><published>2024-07-02T13:32:40+00:00</published><title>Deep Reinforcement Learning</title></entry><entry><author><name>/u/morifo</name><uri>https://www.reddit.com/user/morifo</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I might be overlooking something quite simple but I&amp;#39;m trying to follow the RAG from Scratch tutorial by Lance Martin but by using a local LLM (Mistral 7B Instruct v0.3). The Runnable Sequence has a HuggingFacePipeline section which has a &amp;quot;Prompt &amp;amp; Completion&amp;quot; header and has the entire prompt, context and query, then the answer. The answer itself has the prompt, context, query and answer embedded within it:&lt;/p&gt; &lt;p&gt;``` ...&lt;/p&gt; &lt;p&gt;metadata={&amp;#39;source&amp;#39;: &amp;#39;&lt;a href=&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&amp;#x27;%7D)%5C&quot;&gt;https://lilianweng.github.io/posts/2023-06-23-agent/&amp;#39;})\&lt;/a&gt;]&lt;br/&gt; Answer: [/INST] &lt;/p&gt; &lt;p&gt;&amp;lt;s&amp;gt; [INST] You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don&amp;#39;t know the answer, just say that you don&amp;#39;t know. Use three sentences maximum and keep the answer concise. [/INST] &amp;lt;/s&amp;gt; &lt;/p&gt; &lt;p&gt;... &lt;/p&gt; &lt;p&gt;&amp;#39;&lt;a href=&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&amp;#x27;%7D)%5C&quot;&gt;https://lilianweng.github.io/posts/2023-06-23-agent/&amp;#39;})\&lt;/a&gt;]&lt;br/&gt; Answer: [/INST]&lt;br/&gt; Task Decomposition is a method used in autonomous agent systems where a complex task is broken down into smaller, manageable steps. This is often achieved by instructing a Language Model (LLM) to &amp;quot;think step by step&amp;quot; or by using specific instructions tailored to the task at hand. For example, it could involve asking &amp;quot;What are the subgoals for achieving XYZ?&amp;quot; or &amp;quot;Steps for XYZ.&amp;quot; The goal is to simplify complex tasks and provide insights into the model&amp;#39;s thought process. ```&lt;/p&gt; &lt;p&gt;Instead, his -- using OpenAI -- has a proper chat with input and output headers that are easily readable. Is there something straightforward I can change to get the same output on LangSmith?&lt;/p&gt; &lt;p&gt;My rag chain looks like this:&lt;/p&gt; &lt;p&gt;```&lt;/p&gt; &lt;h1&gt;Prompt&lt;/h1&gt; &lt;p&gt;prompt = hub.pull(&amp;quot;rlm/rag-prompt-mistral&amp;quot;)&lt;/p&gt; &lt;h1&gt;Chain&lt;/h1&gt; &lt;p&gt;rag_chain = ( {&amp;quot;context&amp;quot;: retriever, &amp;quot;question&amp;quot;: RunnablePassthrough()} | prompt | mistral_llm | StrOutputParser() )&lt;/p&gt; &lt;h1&gt;Question&lt;/h1&gt; &lt;p&gt;response = rag_chain.invoke(&amp;quot;What is Task Decomposition?&amp;quot;) ```&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/morifo&quot;&gt; /u/morifo &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtnri2/langsmith_configuring_hf_pipeline_to_display/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtnri2/langsmith_configuring_hf_pipeline_to_display/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dtnri2</id><link href="https://www.reddit.com/r/LangChain/comments/1dtnri2/langsmith_configuring_hf_pipeline_to_display/" /><updated>2024-07-02T14:53:07+00:00</updated><published>2024-07-02T14:53:07+00:00</published><title>LangSmith: configuring HF pipeline to display output as Chat?</title></entry><entry><author><name>/u/Dramatic_Suspect9470</name><uri>https://www.reddit.com/user/Dramatic_Suspect9470</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can you suggest some good projects to build and good open source repo to contribute for getting AI Engineer Job. I am fresher and I have 1 year to build my portfolio&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Dramatic_Suspect9470&quot;&gt; /u/Dramatic_Suspect9470 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtio2u/aspiring_ai_engineer/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dtio2u/aspiring_ai_engineer/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dtio2u</id><link href="https://www.reddit.com/r/LangChain/comments/1dtio2u/aspiring_ai_engineer/" /><updated>2024-07-02T10:36:59+00:00</updated><published>2024-07-02T10:36:59+00:00</published><title>Aspiring AI Engineer</title></entry></feed>