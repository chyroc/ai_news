<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-06T00:55:02+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/AnEdgeLordWeeb</name><uri>https://www.reddit.com/user/AnEdgeLordWeeb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! Before I begin, thanks to those that took the time to read my post and hopefully respond, it&amp;#39;s really much appreciated. Now onto our topic; I&amp;#39;m trying to build a conversation chatbot which objective is to offer to the user game recommendations that fit different criteria and preferences that could be found in his initial query.&lt;/p&gt; &lt;p&gt;What I want the chatbot to do, is first evaluate the query, have it better understand. See if the query is on the topic of asking for game recommendations, or whether his input is clear enough, which in the case of them not meeting one of the requirements, have the chatbot ask from the user to input a proper one.&lt;/p&gt; &lt;p&gt;After making sure that his input is alright and is done with reviewing it, make calls to various tools that rely on SerpApi. such as the Google search one for finding suitable titles to be chosen as candidate for the final answer and gather more additional information for each game, or the Google images and Youtube one for gathering multimedia content, such as games&amp;#39; posters and official trailers.&lt;/p&gt; &lt;p&gt;Once the chatbot is done with browsing the web in order to fetch what it needs, let it formulate a response to the user. One important functionality that I want present in this chatbot is that, if the user asks from the chatbot to find alternatives to some of the titles found in the response, it should be able to remember that response in the first to be able and apply modifications to it, such as the replacing actions of certain mentioned titles with other ones.&lt;/p&gt; &lt;p&gt;Now that the requirements of this chatbot are somewhat clear, how would you recommend me to go on developing such project? What key factors should I take into consideration and make use of in order to achieve the desired results?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnEdgeLordWeeb&quot;&gt; /u/AnEdgeLordWeeb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cl522l/what_is_the_most_proper_way_to_develop_this/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cl522l/what_is_the_most_proper_way_to_develop_this/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cl522l</id><link href="https://www.reddit.com/r/LangChain/comments/1cl522l/what_is_the_most_proper_way_to_develop_this/" /><updated>2024-05-05T23:45:29+00:00</updated><published>2024-05-05T23:45:29+00:00</published><title>What is the most proper way to develop this chatbot?</title></entry><entry><author><name>/u/xandie985</name><uri>https://www.reddit.com/user/xandie985</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a use case, where I have textual data. I have to extract information from it. Some of the data is direct and can be assigned directly. Others are not so-direct, like total weight, total quantity, these values are supposed to be calculated after extracting individual data from the data. &lt;/p&gt; &lt;p&gt;Since RAG provides contextual information, so I am planning to inform the LLM about the labels to be extracted. I am also planning to fine-tune Llama3 on annotations so model learns about what how information extraction is actually taking place. &lt;/p&gt; &lt;p&gt;What else can be done to improve the output performance of model. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/xandie985&quot;&gt; /u/xandie985 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cl4mx6/llm_use_case_for_qa_and_reasoning/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cl4mx6/llm_use_case_for_qa_and_reasoning/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cl4mx6</id><link href="https://www.reddit.com/r/LangChain/comments/1cl4mx6/llm_use_case_for_qa_and_reasoning/" /><updated>2024-05-05T23:25:29+00:00</updated><published>2024-05-05T23:25:29+00:00</published><title>LLM use case for QA and reasoning.</title></entry><entry><author><name>/u/Plus_Dinner_9494</name><uri>https://www.reddit.com/user/Plus_Dinner_9494</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi Guy i need your help! &lt;/p&gt; &lt;p&gt;i want to build a chatbot service that is a cartoon character that helps people with their body transformation journey , its has a database with relevant products, it offers products to users when they ask body transformation questions using the database .&lt;br/&gt; for example :&lt;br/&gt; &amp;quot;i want to gain weight , how do i do it ?&amp;quot;&lt;br/&gt; &amp;quot;im 178cm and 78kg and i want to gain 10kg &amp;quot;&lt;br/&gt; &amp;quot;if im looking to lose 5% body fat , what should i do ?&amp;quot; &lt;/p&gt; &lt;p&gt;to do so i build a number of chatbots each with a different exaction approach but each has its own issues and i cant find the execution that will satisfy me . &lt;/p&gt; &lt;p&gt;1st approach:&lt;br/&gt; using langchain and added a custom tool , that holds the products in a vector database . &lt;/p&gt; &lt;p&gt;the problems with this approach: it doesnt always go to the tool , sometimes it does and sometimes it doesnt .&lt;br/&gt; and i cant control it , the llm decides by itself if to look in the tool or not , this leads to unstable results of similar conversations &lt;/p&gt; &lt;p&gt;2nd approach :&lt;br/&gt; i used the openai wrapper and used groq llm service , without langchain , were i added a custom tool , here the process is different .&lt;br/&gt; process:&lt;br/&gt; - get user input&lt;br/&gt; - created a llm call to determine if the function would be called by looking at the user input&lt;br/&gt; - if the function is to call then i call the function with the user input and get the products&lt;br/&gt; - create a llm call with a system prompt and user input plus the relevant products&lt;br/&gt; -if the function is not to call , then ill create a llm call with a different system prompt and use only the user input&lt;br/&gt; - also introduce the user and chatbot summary chat history to give the llm context &lt;/p&gt; &lt;p&gt;the problems with this approach :&lt;br/&gt; again not always it goes to the tool so its a problem , here it performs better then the first approach , but i feel its hard to keep the context of the conversation and the history is getting bigger and bigger very fast and then the llm looses understanding of the user input &lt;/p&gt; &lt;p&gt;3rd approach:&lt;br/&gt; - get user input&lt;br/&gt; - always use user input to look for relevant products in the vector database&lt;br/&gt; - summary the conversation until now&lt;br/&gt; - do a llm call using the system prompt , user input , the relevant products , and conversation summary &lt;/p&gt; &lt;p&gt;the problem with this approach :&lt;br/&gt; from all of the approaches this preforms the best but it still has issues , because i use a lot of information in each llm call , and i ask it to respond to the user input and use the products only if they are relevant . when the user wants to end the conversation and say &amp;quot;thank you&amp;quot; or &amp;quot;great&amp;quot; inside the llm call it gets lots of information and the respond misses the point , and it answers like the user is still looking for help and doesnt understand the context of where we are right now &lt;/p&gt; &lt;p&gt;i want to know what is the best approach to create a chat bot that users can talk to , get relevant products for their body transformation journey , but also talk to the llm regularly and for it to respond only to the relevant message . please tell me from your experience what is the best approach . &lt;/p&gt; &lt;p&gt;i really appreciate any help. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Plus_Dinner_9494&quot;&gt; /u/Plus_Dinner_9494 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckoupq/help_in_creating_a_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckoupq/help_in_creating_a_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckoupq</id><link href="https://www.reddit.com/r/LangChain/comments/1ckoupq/help_in_creating_a_rag_chatbot/" /><updated>2024-05-05T11:09:40+00:00</updated><published>2024-05-05T11:09:40+00:00</published><title>help in creating a RAG chatbot</title></entry><entry><author><name>/u/Fun_Highlight9147</name><uri>https://www.reddit.com/user/Fun_Highlight9147</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi I am currently struglling with how to approach error handling with a JSON output parser. Can it do retries? I feel like every output parser should just allow retry by default, because often the result can be bad for 1 - 2 requests and that is it.&lt;/p&gt; &lt;p&gt;If not then is it possible to use retryOutput parser with LCEL?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fun_Highlight9147&quot;&gt; /u/Fun_Highlight9147 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckzzfs/do_output_parser_like_the_json_one_have_a_retry/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckzzfs/do_output_parser_like_the_json_one_have_a_retry/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckzzfs</id><link href="https://www.reddit.com/r/LangChain/comments/1ckzzfs/do_output_parser_like_the_json_one_have_a_retry/" /><updated>2024-05-05T20:01:14+00:00</updated><published>2024-05-05T20:01:14+00:00</published><title>Do Output Parser like the JSON one, have a retry option?</title></entry><entry><author><name>/u/mahadevbhakti</name><uri>https://www.reddit.com/user/mahadevbhakti</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is it a good idea to fine tune a cheaper model like chatgpt 3.5 and train it on your function calling samples where the tool is basically a http fetch request to get data from API based on parameters in the user&amp;#39;s query?&lt;/p&gt; &lt;p&gt;I am currently using gpt 4 2024 model, and the cons are 1) it&amp;#39;s expensive 2) I have to add examples in my system prompt 3) It still fails at times with mapping the parameters (more than 4 different parameters such as region, duration, price etc)&lt;/p&gt; &lt;p&gt;I am considering this but posting this to check if someone found this viable? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mahadevbhakti&quot;&gt; /u/mahadevbhakti &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckpwg4/fine_tuning_for_function_calling/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckpwg4/fine_tuning_for_function_calling/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckpwg4</id><link href="https://www.reddit.com/r/LangChain/comments/1ckpwg4/fine_tuning_for_function_calling/" /><updated>2024-05-05T12:13:58+00:00</updated><published>2024-05-05T12:13:58+00:00</published><title>Fine tuning for Function Calling</title></entry><entry><author><name>/u/Alarming-East1193</name><uri>https://www.reddit.com/user/Alarming-East1193</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;We are creating a rag based ChatBot for our company but due to some infosec concerns we have to use only local llms and database.&lt;/p&gt; &lt;p&gt;Due to this reason we are not using openAI/Gemini or any API based models and instead we are using Ollama for our local models and using LLAMA 3 as our LLM. &lt;/p&gt; &lt;p&gt;Now the issue is when we are using local Embeddings model like nomic-embed it&amp;#39;s not producing very good results. What should i do to overcome this issue and i have tried different local Embeddings model of ollama but they aren&amp;#39;t producing very good results.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Alarming-East1193&quot;&gt; /u/Alarming-East1193 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cktopp/local_model_based_rag_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cktopp/local_model_based_rag_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cktopp</id><link href="https://www.reddit.com/r/LangChain/comments/1cktopp/local_model_based_rag_chatbot/" /><updated>2024-05-05T15:22:47+00:00</updated><published>2024-05-05T15:22:47+00:00</published><title>Local model based RAG ChatBot</title></entry><entry><author><name>/u/Constant_Fun_5643</name><uri>https://www.reddit.com/user/Constant_Fun_5643</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;br/&gt; Does anyone have any good tutorials or blogpost about how to use weaviate as a vector store and use Langchain to perform activities like, creating new collections, adding document, performing similarity search etc. The official documentation from Langchain work when I perform all these actions sequentially. However, when loading the persisted vector store, I am unable to perform similarity search.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Constant_Fun_5643&quot;&gt; /u/Constant_Fun_5643 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckszg1/using_weaviate_langchain_together/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckszg1/using_weaviate_langchain_together/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckszg1</id><link href="https://www.reddit.com/r/LangChain/comments/1ckszg1/using_weaviate_langchain_together/" /><updated>2024-05-05T14:51:14+00:00</updated><published>2024-05-05T14:51:14+00:00</published><title>Using Weaviate &amp; Langchain together</title></entry><entry><author><name>/u/bhrdwj10</name><uri>https://www.reddit.com/user/bhrdwj10</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey , I have been dabbling with a few methods to extract data from a corpus of documents in structured format and have been experimenting with pydantic classes and even agents. But still, I am not able to achieve the desired result. I followed the Langchain documentation for extracting data but the method where we use Reference examples is not working.&lt;/p&gt; &lt;p&gt;To specify my use case, I want to extract data from legal documents in a chronological method. Would love to get some tips/ ideas or your methods if you have been doing something like this. Here is a fellow company doing the same www . tryabel. com.&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/bhrdwj10&quot;&gt; /u/bhrdwj10 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckt04y/need_help_in_structured_extraction_of_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckt04y/need_help_in_structured_extraction_of_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckt04y</id><link href="https://www.reddit.com/r/LangChain/comments/1ckt04y/need_help_in_structured_extraction_of_data/" /><updated>2024-05-05T14:52:06+00:00</updated><published>2024-05-05T14:52:06+00:00</published><title>Need help in Structured Extraction of data</title></entry><entry><author><name>/u/ichig0_kurosaki</name><uri>https://www.reddit.com/user/ichig0_kurosaki</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I’m trying to build a Chat bot for our org using langchain. The knowledge base is primarily Wordpress blogs, books and YouTube videos. The YouTube videos happen to be in English and Hindi(language of India). How should I go about data ingestion? Should I translate the Hindi video transcripts to English and then embed them or should I embed all the transcripts irrespective of language using a multi lingual model from something like cohere?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ichig0_kurosaki&quot;&gt; /u/ichig0_kurosaki &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckmuq2/question_on_multi_lingual_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckmuq2/question_on_multi_lingual_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckmuq2</id><link href="https://www.reddit.com/r/LangChain/comments/1ckmuq2/question_on_multi_lingual_data/" /><updated>2024-05-05T08:46:34+00:00</updated><published>2024-05-05T08:46:34+00:00</published><title>Question on Multi lingual data</title></entry><entry><author><name>/u/ToeIntelligent4472</name><uri>https://www.reddit.com/user/ToeIntelligent4472</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Not looking to build my own system per se, just looking for something open source (doesn&amp;#39;t have to use langchain) that can use tools (code interp, web browsing, make google drive files, sending emails, replying to github issues) and perform RAG across all my google drive documents, emails, and code.&lt;/p&gt; &lt;p&gt;Apologies if this is too ambitious or too much to ask for with the current state of things.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ToeIntelligent4472&quot;&gt; /u/ToeIntelligent4472 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckbmf0/is_there_any_agent_that_can_do_rag_across_my/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckbmf0/is_there_any_agent_that_can_do_rag_across_my/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckbmf0</id><link href="https://www.reddit.com/r/LangChain/comments/1ckbmf0/is_there_any_agent_that_can_do_rag_across_my/" /><updated>2024-05-04T21:56:45+00:00</updated><published>2024-05-04T21:56:45+00:00</published><title>Is there any agent that can do RAG across my GDrive, Gmail, &amp; GitHub?</title></entry><entry><author><name>/u/Glittering_Class_333</name><uri>https://www.reddit.com/user/Glittering_Class_333</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am newbie interested in training LLMs on csv dataset that contains text data (few sentences about a product) and numeric data(its ratings). I have around 200k rows and would to like to train an LLM but I am unable to do it. Can anyone here guide me or share any resource which could help me.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering_Class_333&quot;&gt; /u/Glittering_Class_333 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckapb8/how_to_train_an_llm_with_data_that_contains_text/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckapb8/how_to_train_an_llm_with_data_that_contains_text/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckapb8</id><link href="https://www.reddit.com/r/LangChain/comments/1ckapb8/how_to_train_an_llm_with_data_that_contains_text/" /><updated>2024-05-04T21:14:15+00:00</updated><published>2024-05-04T21:14:15+00:00</published><title>How to train an LLM with data that contains text and numeric modality</title></entry><entry><author><name>/u/AnEdgeLordWeeb</name><uri>https://www.reddit.com/user/AnEdgeLordWeeb</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! I&amp;#39;m trying to create a conversation chatbot the specializes in offering video games recommendations based on the user preferences found in his input. Though, right now, when I&amp;#39;m trying to run it, I&amp;#39;m being faced with the error above, does anybody have any idea as to what the problem may be?&lt;/p&gt; &lt;p&gt;Also, is there any way to make sure that an execution of an agent does not move to the other until all the requirements are met? For e.g., I have an input agent that&amp;#39;s tasked to collect the user&amp;#39;s prompt and extract the important info from there. But how would I manage a case where the user might input a query that talks about something completely different?&lt;/p&gt; &lt;p&gt;Thank you guys!&lt;/p&gt; &lt;p&gt;Here is my code too:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import os from dotenv import load_dotenv from langchain_openai import ChatOpenAI from langchain_core.messages import HumanMessage, BaseMessage from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain.agents import create_openai_tools_agent, Tool from langgraph.graph import StateGraph, END from typing import Annotated, Sequence, TypedDict import operator from serpapi import GoogleSearch # Load environment variables for API keys load_dotenv() # Configuration serpapi_key = os.getenv(&amp;quot;SERPAPI_API_KEY&amp;quot;) # Define tools using SerpAPI def google_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key, &amp;quot;num&amp;quot;: 5 } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;organic_results&amp;#39;] def youtube_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;youtube&amp;quot;, &amp;quot;search_query&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;video_results&amp;#39;] def images_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google_images&amp;quot;, &amp;quot;google_domain&amp;quot;: &amp;quot;google.com&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;images_results&amp;#39;] # Define tools search_tool = Tool(name=&amp;quot;google_search&amp;quot;, description=&amp;quot;Performs Google searches.&amp;quot;, func=google_search) youtube_tool = Tool(name=&amp;quot;youTube_search&amp;quot;, description=&amp;quot;Searches for YouTube videos.&amp;quot;, func=youtube_search) images_tool = Tool(name=&amp;quot;images_search&amp;quot;, description=&amp;quot;Searches for images on Google Images.&amp;quot;, func=images_search) # Setup the ChatOpenAI model for conversational interactions chat_model = ChatOpenAI(model=&amp;#39;gpt-3.5-turbo-1106&amp;#39;, temperature=0) # Define agent prompts input_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;You are the initial contact point for users. Your role is to gather information about the user&amp;#39;s preferences and interests in video games and make sure you understand their requirements. In case of any ambiguity, ask for clarification or in the case of the query not being related to video games, ask for a different query.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) search_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Your main task is to search for game titles that best match the user&amp;#39;s interest. Use the details from the Input Agent to guide your search. Provide a list of relevant game titles.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) details_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Retrieve detailed information for each game identified by the Search Agent. Focus on obtaining the game&amp;#39;s description, genre, platform availability, developer, publisher, release date, Metacritic score if available and links to digital stores that sell the game.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) posters_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Your responsibility is to fetch the official posters for the games provided by the Search Agent. Ensure the images are high quality and relevant.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) trailers_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Obtain the official game trailers for the titles identified by the Search Agent. Ensure that the trailers are current and of high quality.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) recommendation_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;You are responsible for compiling the outputs from all other agents into a cohesive and well-formatted response. Synthesize the game details, images, and trailers into a compelling presentation of game recommendations.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) # Create agents using the prompts input_agent = create_openai_tools_agent(chat_model, [], input_agent_prompt) search_agent = create_openai_tools_agent(chat_model, [search_tool], search_agent_prompt) details_agent = create_openai_tools_agent(chat_model, [search_tool], details_agent_prompt) posters_agent = create_openai_tools_agent(chat_model, [images_tool], posters_agent_prompt) trailers_agent = create_openai_tools_agent(chat_model, [youtube_tool], trailers_agent_prompt) recommendation_agent = create_openai_tools_agent(chat_model, [], recommendation_agent_prompt) # State definition for agents class AgentState(TypedDict): messages: Annotated[Sequence[BaseMessage], operator.add] intermediate_steps: Annotated[Sequence[BaseMessage], operator.add] agent_scratchpad: Annotated[Sequence[BaseMessage], operator.add] input: str # Graph setup state_graph = StateGraph(schema=AgentState) # Add nodes for each agent state_graph.add_node(&amp;quot;input_agent&amp;quot;, input_agent) state_graph.add_node(&amp;quot;search_agent&amp;quot;, search_agent) state_graph.add_node(&amp;quot;details_agent&amp;quot;, details_agent) state_graph.add_node(&amp;quot;posters_agent&amp;quot;, posters_agent) state_graph.add_node(&amp;quot;trailers_agent&amp;quot;, trailers_agent) state_graph.add_node(&amp;quot;recommendation_agent&amp;quot;, recommendation_agent) # Define edges to flow between agents state_graph.add_edge(&amp;quot;input_agent&amp;quot;, &amp;quot;search_agent&amp;quot;) state_graph.add_edge(&amp;quot;search_agent&amp;quot;, &amp;quot;details_agent&amp;quot;) state_graph.add_edge(&amp;quot;details_agent&amp;quot;, &amp;quot;posters_agent&amp;quot;) state_graph.add_edge(&amp;quot;posters_agent&amp;quot;, &amp;quot;trailers_agent&amp;quot;) state_graph.add_edge(&amp;quot;trailers_agent&amp;quot;, &amp;quot;recommendation_agent&amp;quot;) state_graph.add_edge(&amp;quot;recommendation_agent&amp;quot;, END) # Set the entry point to start the agent workflow state_graph.set_entry_point(&amp;quot;input_agent&amp;quot;) # Complete the graph app = state_graph.compile() def main(): print(&amp;quot;Welcome to the Game Recommendation Chatbot!&amp;quot;) while True: user_input = input(&amp;quot;You: &amp;quot;) if user_input.lower() == &amp;#39;exit&amp;#39;: print(&amp;quot;Exiting chatbot...&amp;quot;) break # Initialize the state with the necessary structures state = { &amp;quot;messages&amp;quot;: [HumanMessage(content=user_input)], &amp;quot;agent_scratchpad&amp;quot;: [], # ensure this is always a list &amp;quot;intermediate_steps&amp;quot;: [], # ensure this is always initialized as a list &amp;quot;input&amp;quot;: user_input # this is your actual input string } response = app.invoke(state) print(&amp;quot;Bot:&amp;quot;, response[&amp;quot;messages&amp;quot;][-1].content) if __name__ == &amp;quot;__main__&amp;quot;: main() import os from dotenv import load_dotenv from langchain_openai import ChatOpenAI from langchain_core.messages import HumanMessage, BaseMessage from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder from langchain.agents import create_openai_tools_agent, Tool from langgraph.graph import StateGraph, END from typing import Annotated, Sequence, TypedDict import operator from serpapi import GoogleSearch # Load environment variables for API keys load_dotenv() # Configuration serpapi_key = os.getenv(&amp;quot;SERPAPI_API_KEY&amp;quot;) # Define tools using SerpAPI def google_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key, &amp;quot;num&amp;quot;: 5 } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;organic_results&amp;#39;] def youtube_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;youtube&amp;quot;, &amp;quot;search_query&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;video_results&amp;#39;] def images_search(query): params = { &amp;quot;engine&amp;quot;: &amp;quot;google_images&amp;quot;, &amp;quot;google_domain&amp;quot;: &amp;quot;google.com&amp;quot;, &amp;quot;q&amp;quot;: query, &amp;quot;api_key&amp;quot;: serpapi_key } search = GoogleSearch(params) results = search.get_dict() return results[&amp;#39;images_results&amp;#39;] # Define tools search_tool = Tool(name=&amp;quot;google_search&amp;quot;, description=&amp;quot;Performs Google searches.&amp;quot;, func=google_search) youtube_tool = Tool(name=&amp;quot;youTube_search&amp;quot;, description=&amp;quot;Searches for YouTube videos.&amp;quot;, func=youtube_search) images_tool = Tool(name=&amp;quot;images_search&amp;quot;, description=&amp;quot;Searches for images on Google Images.&amp;quot;, func=images_search) # Setup the ChatOpenAI model for conversational interactions chat_model = ChatOpenAI(model=&amp;#39;gpt-3.5-turbo-1106&amp;#39;, temperature=0) # Define agent prompts input_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;You are the initial contact point for users. Your role is to gather information about the user&amp;#39;s preferences and interests in video games and make sure you understand their requirements. In case of any ambiguity, ask for clarification or in the case of the query not being related to video games, ask for a different query.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) search_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Your main task is to search for game titles that best match the user&amp;#39;s interest. Use the details from the Input Agent to guide your search. Provide a list of relevant game titles.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) details_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Retrieve detailed information for each game identified by the Search Agent. Focus on obtaining the game&amp;#39;s description, genre, platform availability, developer, publisher, release date, Metacritic score if available and links to digital stores that sell the game.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) posters_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Your responsibility is to fetch the official posters for the games provided by the Search Agent. Ensure the images are high quality and relevant.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) trailers_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;Obtain the official game trailers for the titles identified by the Search Agent. Ensure that the trailers are current and of high quality.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) recommendation_agent_prompt = ChatPromptTemplate.from_messages([ (&amp;quot;system&amp;quot;, &amp;quot;You are responsible for compiling the outputs from all other agents into a cohesive and well-formatted response. Synthesize the game details, images, and trailers into a compelling presentation of game recommendations.&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;messages&amp;quot;), MessagesPlaceholder(variable_name=&amp;quot;agent_scratchpad&amp;quot;), (&amp;quot;human&amp;quot;, &amp;quot;{input}&amp;quot;) ]) # Create agents using the prompts input_agent = create_openai_tools_agent(chat_model, [], input_agent_prompt) search_agent = create_openai_tools_agent(chat_model, [search_tool], search_agent_prompt) details_agent = create_openai_tools_agent(chat_model, [search_tool], details_agent_prompt) posters_agent = create_openai_tools_agent(chat_model, [images_tool], posters_agent_prompt) trailers_agent = create_openai_tools_agent(chat_model, [youtube_tool], trailers_agent_prompt) recommendation_agent = create_openai_tools_agent(chat_model, [], recommendation_agent_prompt) # State definition for agents class AgentState(TypedDict): messages: Annotated[Sequence[BaseMessage], operator.add] intermediate_steps: Annotated[Sequence[BaseMessage], operator.add] agent_scratchpad: Annotated[Sequence[BaseMessage], operator.add] input: str # Graph setup state_graph = StateGraph(schema=AgentState) # Add nodes for each agent state_graph.add_node(&amp;quot;input_agent&amp;quot;, input_agent) state_graph.add_node(&amp;quot;search_agent&amp;quot;, search_agent) state_graph.add_node(&amp;quot;details_agent&amp;quot;, details_agent) state_graph.add_node(&amp;quot;posters_agent&amp;quot;, posters_agent) state_graph.add_node(&amp;quot;trailers_agent&amp;quot;, trailers_agent) state_graph.add_node(&amp;quot;recommendation_agent&amp;quot;, recommendation_agent) # Define edges to flow between agents state_graph.add_edge(&amp;quot;input_agent&amp;quot;, &amp;quot;search_agent&amp;quot;) state_graph.add_edge(&amp;quot;search_agent&amp;quot;, &amp;quot;details_agent&amp;quot;) state_graph.add_edge(&amp;quot;details_agent&amp;quot;, &amp;quot;posters_agent&amp;quot;) state_graph.add_edge(&amp;quot;posters_agent&amp;quot;, &amp;quot;trailers_agent&amp;quot;) state_graph.add_edge(&amp;quot;trailers_agent&amp;quot;, &amp;quot;recommendation_agent&amp;quot;) state_graph.add_edge(&amp;quot;recommendation_agent&amp;quot;, END) # Set the entry point to start the agent workflow state_graph.set_entry_point(&amp;quot;input_agent&amp;quot;) # Complete the graph app = state_graph.compile() def main(): print(&amp;quot;Welcome to the Game Recommendation Chatbot!&amp;quot;) while True: user_input = input(&amp;quot;You: &amp;quot;) if user_input.lower() == &amp;#39;exit&amp;#39;: print(&amp;quot;Exiting chatbot...&amp;quot;) break # Initialize the state with the necessary structures state = { &amp;quot;messages&amp;quot;: [HumanMessage(content=user_input)], &amp;quot;agent_scratchpad&amp;quot;: [], # ensure this is always a list &amp;quot;intermediate_steps&amp;quot;: [], # ensure this is always initialized as a list &amp;quot;input&amp;quot;: user_input # this is your actual input string } response = app.invoke(state) print(&amp;quot;Bot:&amp;quot;, response[&amp;quot;messages&amp;quot;][-1].content) if __name__ == &amp;quot;__main__&amp;quot;: main() &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnEdgeLordWeeb&quot;&gt; /u/AnEdgeLordWeeb &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckd61h/error_code_400_error_message_is_too_short_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ckd61h/error_code_400_error_message_is_too_short_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ckd61h</id><link href="https://www.reddit.com/r/LangChain/comments/1ckd61h/error_code_400_error_message_is_too_short_tools/" /><updated>2024-05-04T23:08:55+00:00</updated><published>2024-05-04T23:08:55+00:00</published><title>Error code: 400 - {'error': {'message': &quot;[] is too short - 'tools'&quot;, 'type': 'invalid_request_error', 'param': None, 'code': None}}</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for some tried and tested ways to measure and improve my RAGs retrieval strategy.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck3k84</id><link href="https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/" /><updated>2024-05-04T15:57:55+00:00</updated><published>2024-05-04T15:57:55+00:00</published><title>What are some ways to test and improve my RAGs retrieval strategy?</title></entry><entry><author><name>/u/Legionnairesgeek</name><uri>https://www.reddit.com/user/Legionnairesgeek</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I am new to LangChain and I am developing a application that uses a Pandas Dataframe as document original a Microsoft Excel sheet. I need it answer questions based on it. &lt;/p&gt; &lt;p&gt;How should I proceed? Should I ditch the DataFrame approach and interface it directly ?&lt;/p&gt; &lt;p&gt;How should I use approach it?&lt;/p&gt; &lt;p&gt;How should I add history as i need to have GUI.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Legionnairesgeek&quot;&gt; /u/Legionnairesgeek &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck54cw/how_should_i_develop_a_rag_chatbot_that_uses_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck54cw/how_should_i_develop_a_rag_chatbot_that_uses_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck54cw</id><link href="https://www.reddit.com/r/LangChain/comments/1ck54cw/how_should_i_develop_a_rag_chatbot_that_uses_a/" /><updated>2024-05-04T17:05:47+00:00</updated><published>2024-05-04T17:05:47+00:00</published><title>How should I develop a RAG ChatBot that uses a Pandas Dataframe as a source?</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looking for some tried and tested ways to measure and improve my RAGs retrieval strategy.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck3k49</id><link href="https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/" /><updated>2024-05-04T15:57:46+00:00</updated><published>2024-05-04T15:57:46+00:00</published><title>What are some ways to test and improve my RAGs retrieval strategy?</title></entry><entry><author><name>/u/phicreative1997</name><uri>https://www.reddit.com/user/phicreative1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjyiww/generate_powerpoints_using_llama3_a_first_step_in/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/kTSFHuwiwJ0qxPFejuEtCfKnLN42fnt_kIVuZy8HWNM.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b519accc5730b7cdf08908f9c12395c5a9410f79&quot; alt=&quot;Generate PowerPoints using Llama-3 — A first step in automating slide decks&quot; title=&quot;Generate PowerPoints using Llama-3 — A first step in automating slide decks&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/phicreative1997&quot;&gt; /u/phicreative1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://medium.com/firebird-technologies/generate-powerpoints-using-llama-3-a-first-step-in-automating-slide-decks-536f5fcb6e0e&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjyiww/generate_powerpoints_using_llama3_a_first_step_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cjyiww</id><media:thumbnail url="https://external-preview.redd.it/kTSFHuwiwJ0qxPFejuEtCfKnLN42fnt_kIVuZy8HWNM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b519accc5730b7cdf08908f9c12395c5a9410f79" /><link href="https://www.reddit.com/r/LangChain/comments/1cjyiww/generate_powerpoints_using_llama3_a_first_step_in/" /><updated>2024-05-04T11:52:17+00:00</updated><published>2024-05-04T11:52:17+00:00</published><title>Generate PowerPoints using Llama-3 — A first step in automating slide decks</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Has anyone used PGVector with HuggingFaceEmbeddings? I&amp;#39;m encountering an error message: &amp;#39;psycopg2.errors.DataException: different vector dimensions 384 and 1536&amp;#39;.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck8mj0/integrating_pgvector_with_hugging_face_embeddings/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck8mj0/integrating_pgvector_with_hugging_face_embeddings/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck8mj0</id><link href="https://www.reddit.com/r/LangChain/comments/1ck8mj0/integrating_pgvector_with_hugging_face_embeddings/" /><updated>2024-05-04T19:40:59+00:00</updated><published>2024-05-04T19:40:59+00:00</published><title>Integrating PGVector with Hugging Face Embeddings: Addressing Dimension Mismatch Errors</title></entry><entry><author><name>/u/AI_technologies</name><uri>https://www.reddit.com/user/AI_technologies</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt; let’s outline &lt;em&gt;what&lt;/em&gt; VAs even do. As a creator yourself, you balance big projects with smaller, repetitive tasks like answering emails, scheduling meetings &amp;amp; writing smaller pieces of content.&lt;/p&gt; &lt;p&gt;And that’s where your partner in time, your VA comes in — they handle all of the tedious tasks on your behalf, giving you the freedom to concentrate fully on the important things in your life &amp;amp; business.&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Recent stats show Virtual assistants save companies up to 78% in operating costs per year, and the VA market is projected to grow 22.3% annually, reaching $8.6B by 2028 — this is definitely a sector to pay close attention to.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;As the demand for efficiency in our workflows increases, it&amp;#39;s worth knowing the potential of AI assistants, because why wouldn’t you want to get more time back? Here are the core reasons why AI assistants are better than traditional VAs:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Cost-Effectiveness&lt;/strong&gt; – traditional VAs are invaluable but come with recurring costs — salaries, benefits, and more. AI assistants, on the other hand, involve a one-time setup fee and minimal ongoing costs.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;24/7 Availability&lt;/strong&gt; – your business needs don’t stop at 5 PM, and neither does an AI assistant. Unlike human VAs who clock out, AI can work round-the-clock, able to complete any given task at any time.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Consistency &amp;amp; Accuracy&lt;/strong&gt; – AI minimizes human errors in data entry, scheduling, and customer communication, maintaining high consistency in performance.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;blockquote&gt; &lt;p&gt;This reliability is key in managing operations that demand precision, like tailored content creation or responding to an important business email, for example.&lt;/p&gt; &lt;/blockquote&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Adaptability&lt;/strong&gt; – training a new assistant takes time and resources. AI assistants, however, can be quickly trained to manage new tasks, adapting &amp;amp; evolving alongside your business.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Accessibility&lt;/strong&gt; – with numerous AI tools available, starting is as easy as signing up and setting up — no lengthy recruitment or training is required (if you aren’t creating your very own AI assistant, in which case it’s a tad more complex). &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;However, we must mention the main negative of artificial intelligence – it lacks the human aspect, and therefore AI Assistants could &lt;strong&gt;&lt;em&gt;never&lt;/em&gt;&lt;/strong&gt; replace real VAs.&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;The human element is crucial, as it brings empathy, creativity, and intuitive problem-solving to tasks that AI simply can&amp;#39;t replicate, and the best way to get the best of both worlds is to integrate AI tools in your virtual assistant’s workflow — we’ll show you how to turn your VA into a cyborg very soon!&lt;/p&gt; &lt;/blockquote&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AI_technologies&quot;&gt; /u/AI_technologies &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck67xs/why_ai_assistants_can_be_better_than_human_vas/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck67xs/why_ai_assistants_can_be_better_than_human_vas/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck67xs</id><link href="https://www.reddit.com/r/LangChain/comments/1ck67xs/why_ai_assistants_can_be_better_than_human_vas/" /><updated>2024-05-04T17:55:12+00:00</updated><published>2024-05-04T17:55:12+00:00</published><title>Why AI Assistants Can Be Better Than Human VAs</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So far, I&amp;#39;ve been using the OpenAI API to build a RAG application with Langchain. Now, I&amp;#39;m exploring LLama 3/LLama-2 with GPU support. Can anyone suggest a tutorial for this with Langchain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck4sy9/how_to_use_llama_3llama2_model_on_nvidia_gpu/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck4sy9/how_to_use_llama_3llama2_model_on_nvidia_gpu/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck4sy9</id><link href="https://www.reddit.com/r/LangChain/comments/1ck4sy9/how_to_use_llama_3llama2_model_on_nvidia_gpu/" /><updated>2024-05-04T16:51:45+00:00</updated><published>2024-05-04T16:51:45+00:00</published><title>How to use LLama -3/LLama-2 Model on Nvidia GPU?</title></entry><entry><author><name>/u/runrabbit007</name><uri>https://www.reddit.com/user/runrabbit007</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let&amp;#39;s say we have two chain , like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;prompt1 = &amp;quot;some prompts here 1&amp;quot; prompt2 = &amp;quot;some prompts here 2&amp;quot; chain1 = prompt1 | model chain2 = prompt2 | model combine_chain = chain1 | chain2 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;My question is how to add memory to combine_chain with RunnableWithMessageHistory? &lt;/p&gt; &lt;p&gt;The official document just show how to add it in single chain . I tried that way for combine_chain, but it doesn&amp;#39;t work. Because prompt2 always need to pass the parameter of &amp;quot;history&amp;quot; which I don&amp;#39;t how to pass it. （suppose we have history_messages_key=&amp;quot;history&amp;quot;).&lt;/p&gt; &lt;p&gt;I&amp;#39;m stuck on this problem. I will be very thankful to anyone who can help on it. &lt;/p&gt; &lt;p&gt;For reference here, the office document show how to add memory to single chain with RunnableWithMessageHistory: &lt;a href=&quot;https://python.langchain.com/docs/expression_language/how_to/message_history/&quot;&gt;https://python.langchain.com/docs/expression_language/how_to/message_history/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/runrabbit007&quot;&gt; /u/runrabbit007 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck2zy8/how_to_add_memory_to_multi_chain_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ck2zy8/how_to_add_memory_to_multi_chain_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ck2zy8</id><link href="https://www.reddit.com/r/LangChain/comments/1ck2zy8/how_to_add_memory_to_multi_chain_with/" /><updated>2024-05-04T15:32:39+00:00</updated><published>2024-05-04T15:32:39+00:00</published><title>How to add memory to multi- chain with RunnableWithMessageHistory?</title></entry><entry><author><name>/u/Tiny-Ad-5694</name><uri>https://www.reddit.com/user/Tiny-Ad-5694</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve built a code search tool for anyone using LangChain to search its source code and find LangChain actual use case code examples. This isn&amp;#39;t an AI chat bot;&lt;br/&gt; I built this because when I first used LangChain, I constantly needed to search for and utilize sample code blocks and delve into the LangChain source code for insights into my project&lt;/p&gt; &lt;p&gt;Currently it can only search LangChain related content. Let me know your thoughts&lt;br/&gt; Here is link: &lt;a href=&quot;http://solidsearchportal.azurewebsites.net&quot;&gt;solidsearchportal.azurewebsites.net&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Tiny-Ad-5694&quot;&gt; /u/Tiny-Ad-5694 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjncxr/a_code_search_tool_for_langchain_developer/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjncxr/a_code_search_tool_for_langchain_developer/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjncxr</id><link href="https://www.reddit.com/r/LangChain/comments/1cjncxr/a_code_search_tool_for_langchain_developer/" /><updated>2024-05-04T00:19:34+00:00</updated><published>2024-05-04T00:19:34+00:00</published><title>A code search tool for LangChain developer</title></entry><entry><author><name>/u/furyacer</name><uri>https://www.reddit.com/user/furyacer</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A lot of vector dbs are available for RAG and LLM based projects. How will you choose the best one for your use-case? Is there a set of criteria to follow for choosing a specific vector db for your project? Lmk what you think&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/furyacer&quot;&gt; /u/furyacer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjz0lt/vector_dbs_to_use_for_specific_usecase/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjz0lt/vector_dbs_to_use_for_specific_usecase/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjz0lt</id><link href="https://www.reddit.com/r/LangChain/comments/1cjz0lt/vector_dbs_to_use_for_specific_usecase/" /><updated>2024-05-04T12:19:27+00:00</updated><published>2024-05-04T12:19:27+00:00</published><title>Vector dbs to use for specific use-case</title></entry><entry><author><name>/u/Calm_Pea_2428</name><uri>https://www.reddit.com/user/Calm_Pea_2428</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In version 1.5.0 of MyScale, we introduced an upgraded full-text search feature powered by &lt;a href=&quot;https://github.com/quickwit-oss/tantivy&quot;&gt;Tantivy&lt;/a&gt;. Tantivy have lower latency rate and it&amp;#39;s written in Rust. &lt;/p&gt; &lt;p&gt;In the latest update, MyScaleDB now supports:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Supports full-text search&lt;/li&gt; &lt;li&gt;Supports fuzzy and wildcard searches along with rich tokenizers&lt;/li&gt; &lt;li&gt;Utilizes BM25 for relevance scoring similar to Elasticsearch&lt;/li&gt; &lt;li&gt;Query times over 5M rows are 300x faster than ClickHouse&amp;#39;s built-in inverted index&lt;/li&gt; &lt;li&gt;Real-time searching without manual reindexing&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For more detailed explanation, you can read this blog: &lt;a href=&quot;https://myscale.com/blog/text-search-and-hybrid-search-in-myscale/&quot;&gt;Introducing MyScale&amp;#39;s Powerful Full-Text and Hybrid Search Capabilities&lt;/a&gt;&lt;/p&gt; &lt;p&gt;or take a look at these documents: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://myscale.com/docs/en/text-search/&quot;&gt;Full-Text Search in MyScale&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://myscale.com/docs/en/hybrid-search/&quot;&gt;Hybrid Search in MyScale&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Calm_Pea_2428&quot;&gt; /u/Calm_Pea_2428 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjy7f5/myscaledb_now_supports_fulltext_and_hybrid_search/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjy7f5/myscaledb_now_supports_fulltext_and_hybrid_search/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjy7f5</id><link href="https://www.reddit.com/r/LangChain/comments/1cjy7f5/myscaledb_now_supports_fulltext_and_hybrid_search/" /><updated>2024-05-04T11:33:25+00:00</updated><published>2024-05-04T11:33:25+00:00</published><title>MyScaleDB now supports Full-Text and Hybrid Search</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1cjqb4f/llms_cant_play_tictactoe_why_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjqbn4/llms_cant_play_tictactoe_why_explained_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cjqbn4</id><link href="https://www.reddit.com/r/LangChain/comments/1cjqbn4/llms_cant_play_tictactoe_why_explained_langgraph/" /><updated>2024-05-04T02:57:15+00:00</updated><published>2024-05-04T02:57:15+00:00</published><title>LLMs can't play tic-tac-toe. Why? Explained (LangGraph experiment)</title></entry><entry><author><name>/u/UpvoteBeast</name><uri>https://www.reddit.com/user/UpvoteBeast</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjr0xy/how_rag_architecture_overcomes_llm_limitations/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/dQl7-TauXBI9Vl5SEA2wORLVhC6T_s1Q4Vhw-WmKfC4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2c756b18e6de96109083b4e4ceab0f2aff65b413&quot; alt=&quot;How RAG Architecture Overcomes LLM Limitations&quot; title=&quot;How RAG Architecture Overcomes LLM Limitations&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UpvoteBeast&quot;&gt; /u/UpvoteBeast &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://dly.to/CkHPBlwHuPo&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cjr0xy/how_rag_architecture_overcomes_llm_limitations/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1cjr0xy</id><media:thumbnail url="https://external-preview.redd.it/dQl7-TauXBI9Vl5SEA2wORLVhC6T_s1Q4Vhw-WmKfC4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2c756b18e6de96109083b4e4ceab0f2aff65b413" /><link href="https://www.reddit.com/r/LangChain/comments/1cjr0xy/how_rag_architecture_overcomes_llm_limitations/" /><updated>2024-05-04T03:36:38+00:00</updated><published>2024-05-04T03:36:38+00:00</published><title>How RAG Architecture Overcomes LLM Limitations</title></entry></feed>