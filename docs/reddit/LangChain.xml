<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-05-17T15:38:41+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/gswithai</name><uri>https://www.reddit.com/user/gswithai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;As a disclaimer: I personally think LangChain is awesome. It lets you cut your dev time by a lot. But since I&amp;#39;ve been toying around with many frameworks, tools, and models I compiled a list of five basic (but important) questions every dev or person looking to integrate AI must ask themselves.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/strong&gt; &lt;a href=&quot;https://youtu.be/uG0cs8AlnHw&quot;&gt;&lt;strong&gt;Watch on YouTube&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I&amp;#39;d love to know your thoughts and/or suggestions!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/gswithai&quot;&gt; /u/gswithai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cu6wjg/do_you_even_need_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cu6wjg/do_you_even_need_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cu6wjg</id><link href="https://www.reddit.com/r/LangChain/comments/1cu6wjg/do_you_even_need_langchain/" /><updated>2024-05-17T14:40:20+00:00</updated><published>2024-05-17T14:40:20+00:00</published><title>Do you even need LangChain?</title></entry><entry><author><name>/u/Republicanism</name><uri>https://www.reddit.com/user/Republicanism</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Republicanism&quot;&gt; /u/Republicanism &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://useturret.com&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cu5fib/new_tool_to_monitor_agents_built_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cu5fib</id><link href="https://www.reddit.com/r/LangChain/comments/1cu5fib/new_tool_to_monitor_agents_built_with_langchain/" /><updated>2024-05-17T13:39:16+00:00</updated><published>2024-05-17T13:39:16+00:00</published><title>New tool to monitor agents built with Langchain, catch mistakes, manage costs</title></entry><entry><author><name>/u/Unrealnooob</name><uri>https://www.reddit.com/user/Unrealnooob</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on developing a chatbot that uses Neo4j as the database. I&amp;#39;ve created a knowledge graph by importing a corpus of data into Neo4j.&lt;br/&gt; how to effectively leverage both the knowledge graph aspect and the semantic capabilities of Neo4j for this chatbot project?&lt;/p&gt; &lt;p&gt;Has anyone worked on a similar project? What strategies or approaches did you employ to optimize the retrieval from Neo4j? I&amp;#39;m open to any suggestions or insights that could help improve the chatbot&amp;#39;s performance and make the most out of Neo4j&amp;#39;s unique features.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Unrealnooob&quot;&gt; /u/Unrealnooob &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cu2ozt/utilizing_neo4js_knowledge_graph_and_semantics/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cu2ozt/utilizing_neo4js_knowledge_graph_and_semantics/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cu2ozt</id><link href="https://www.reddit.com/r/LangChain/comments/1cu2ozt/utilizing_neo4js_knowledge_graph_and_semantics/" /><updated>2024-05-17T11:20:57+00:00</updated><published>2024-05-17T11:20:57+00:00</published><title>Utilizing Neo4j's Knowledge Graph and Semantics for a RAG - Chatbot</title></entry><entry><author><name>/u/srvking</name><uri>https://www.reddit.com/user/srvking</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Guys,&lt;/p&gt; &lt;p&gt;Checkout this PR &lt;a href=&quot;https://github.com/langchain-ai/langchain/pull/21553&quot;&gt;[https://github.com/langchain-ai/langchain/pull/21553]&lt;/a&gt; that implements something similar to sentence window retrieval. I have named in chunk window retrieval because based on the window size, this method would fetch those many chunks above and below the current chunk. &lt;/p&gt; &lt;p&gt;Important point to note here is that when creating a chunk for Qdrant, you MUST have integer based chunk id for this to work. Have added that support in Qdrant.add_texts(..) as well. &lt;/p&gt; &lt;p&gt;Hope it helps.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/srvking&quot;&gt; /u/srvking &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cu44i1/sentence_chunk_window_retrieval_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cu44i1/sentence_chunk_window_retrieval_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cu44i1</id><link href="https://www.reddit.com/r/LangChain/comments/1cu44i1/sentence_chunk_window_retrieval_in_langchain/" /><updated>2024-05-17T12:39:31+00:00</updated><published>2024-05-17T12:39:31+00:00</published><title>Sentence / chunk window retrieval in Langchain using Qdrant</title></entry><entry><author><name>/u/Artistic_Beyond_6231</name><uri>https://www.reddit.com/user/Artistic_Beyond_6231</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i am building a hotel room booking chatbot using OpenAI API , currently it is able to look up available rooms from the database using langchains SQL agent , i want to add room booking functionality in it for that i want receive payments from the user and thus i need chatbot to generate payments links. i know payments links can be generated using stripe or razorpay api but how to make chatbot call those api functions to get paymnets link, does anyone has any expeiences with it or know how to do this? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Artistic_Beyond_6231&quot;&gt; /u/Artistic_Beyond_6231 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctypfm/how_to_generate_payments_links_in_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctypfm/how_to_generate_payments_links_in_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctypfm</id><link href="https://www.reddit.com/r/LangChain/comments/1ctypfm/how_to_generate_payments_links_in_chatbot/" /><updated>2024-05-17T06:39:30+00:00</updated><published>2024-05-17T06:39:30+00:00</published><title>How to generate payments links in chatbot ?</title></entry><entry><author><name>/u/SquiffyUnicorn</name><uri>https://www.reddit.com/user/SquiffyUnicorn</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi- I have followed a few simple RAG tutorials with langchain but don‚Äôt seem to be getting anywhere - either my agent exits before a final answer or my chain just exits with nothing.&lt;/p&gt; &lt;p&gt;I‚Äôm a newbie to RAG and LLMs in general so I wanted to check a few things that I haven‚Äôt managed to learn from online tutorials.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;I assume choice of vector DB makes very little difference for these small toy projects with only &amp;lt;50 PDFs being ingested - each not large.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;I don‚Äôt understand if the embeddings function in between PDF and DB needs to be matched with anything else later in the toolchain- can I use pretty much anything with impunity? I‚Äôm using the langchain pypdfloader, load_and_split and langchain.embeddings.HuggingFaceEmbeddings. This is perhaps a mishmash from different tutorials‚Ä¶&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Is there a ‚Äòbest‚Äô way to run a LLM locally? I have tried straight python and llamacpp from langchain but it doesn‚Äôt seem to recognise my GPU. I‚Äôm thinking of moving to running the llm on LMStudio and accessing the API in python but that‚Äôs additional complexity I would rather avoid at this stage. (Or is it super easy?)&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;I‚Äôm sure I will have more questions later but this is enough to keep me going for now! Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SquiffyUnicorn&quot;&gt; /u/SquiffyUnicorn &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctztvf/basic_rag_chat_bot_minimum/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctztvf/basic_rag_chat_bot_minimum/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctztvf</id><link href="https://www.reddit.com/r/LangChain/comments/1ctztvf/basic_rag_chat_bot_minimum/" /><updated>2024-05-17T08:00:32+00:00</updated><published>2024-05-17T08:00:32+00:00</published><title>Basic RAG chat bot minimum</title></entry><entry><author><name>/u/Wooden-Ad-8680</name><uri>https://www.reddit.com/user/Wooden-Ad-8680</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey there üññ Im participating in a national contest for NLP sentiment analysis Im planning on using langchain. Wanted to ask you guys if you have any open source LLM recommendations for me to use or check, the model should be local so 70b llama is not the best choice.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Wooden-Ad-8680&quot;&gt; /u/Wooden-Ad-8680 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctzmfo/open_source_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctzmfo/open_source_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctzmfo</id><link href="https://www.reddit.com/r/LangChain/comments/1ctzmfo/open_source_llms/" /><updated>2024-05-17T07:44:39+00:00</updated><published>2024-05-17T07:44:39+00:00</published><title>Open source LLMs</title></entry><entry><author><name>/u/Primary-Share-7471</name><uri>https://www.reddit.com/user/Primary-Share-7471</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks,&lt;/p&gt; &lt;p&gt;I am working on a project to develop a specific question-answer system based on RAG for scientific research. The questions could be &amp;quot;What province, city or town were the samples collected from?&amp;quot;. &lt;/p&gt; &lt;p&gt;The RAG pipeline I built now does not perform well because of many reasons. One reason is that the contents in the introduction and/or discussion sections may confuse the pipeline. So one way I am thinking is to just extract the method section or method and results sections for the vector store (ignoring the other sections). I have explored different options, but none of them worked. I even tried the openai file search (&lt;a href=&quot;https://platform.openai.com/docs/assistants/tools/file-search&quot;&gt;https://platform.openai.com/docs/assistants/tools/file-search&lt;/a&gt;), but it was not able to extract the complete section. &lt;/p&gt; &lt;p&gt;I used pypdfloader to get all text from a pdf file first, and then asked openai file-search to extract the methods section. Is pypdfloader a good one to extract text in good order?&lt;/p&gt; &lt;p&gt;Anyone knows a good way to extract a specific section from a PDF file?&lt;/p&gt; &lt;p&gt;Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Primary-Share-7471&quot;&gt; /u/Primary-Share-7471 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctz1jf/how_to_extract_the_methods_section_out_of_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctz1jf/how_to_extract_the_methods_section_out_of_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctz1jf</id><link href="https://www.reddit.com/r/LangChain/comments/1ctz1jf/how_to_extract_the_methods_section_out_of_a/" /><updated>2024-05-17T07:02:39+00:00</updated><published>2024-05-17T07:02:39+00:00</published><title>How to extract the &quot;Methods&quot; section out of a scientific article</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am reviewing the pricing for the OpenAI GPT-4-Turbo model and have noticed that using memory with it on RAG Task incurs high costs. I am working for an organization. Is anyone using the AWS OpenAI API? Is it a bit cheaper to use?&amp;quot;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctyz7h/exploring_cost_efficiency_openai_gpt4turbo_model/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctyz7h/exploring_cost_efficiency_openai_gpt4turbo_model/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctyz7h</id><link href="https://www.reddit.com/r/LangChain/comments/1ctyz7h/exploring_cost_efficiency_openai_gpt4turbo_model/" /><updated>2024-05-17T06:58:39+00:00</updated><published>2024-05-17T06:58:39+00:00</published><title>Exploring Cost Efficiency: OpenAI GPT-4-Turbo Model vs. AWS OpenAI API</title></entry><entry><author><name>/u/Dry_Football_3128</name><uri>https://www.reddit.com/user/Dry_Football_3128</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have to find a way to determine the format of a pdf document like its plain or having paragraphs or title-definition format etc. By knowing the format i can chunk the document efficiently without losing the context/semantics. Is there any way to do so?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Dry_Football_3128&quot;&gt; /u/Dry_Football_3128 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctyslg/chunking_text_documents_in_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctyslg/chunking_text_documents_in_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctyslg</id><link href="https://www.reddit.com/r/LangChain/comments/1ctyslg/chunking_text_documents_in_langchain/" /><updated>2024-05-17T06:45:37+00:00</updated><published>2024-05-17T06:45:37+00:00</published><title>Chunking text documents in langchain</title></entry><entry><author><name>/u/Beginning_Rock_1906</name><uri>https://www.reddit.com/user/Beginning_Rock_1906</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi folks, it seems to me that the current sentiment around AI agents is very negative as in that they&amp;#39;re useless but I don&amp;#39;t quite understand why. Could anybody explain to me why this view persists?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Beginning_Rock_1906&quot;&gt; /u/Beginning_Rock_1906 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctfepy/ai_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctfepy/ai_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctfepy</id><link href="https://www.reddit.com/r/LangChain/comments/1ctfepy/ai_agents/" /><updated>2024-05-16T15:19:11+00:00</updated><published>2024-05-16T15:19:11+00:00</published><title>AI Agents</title></entry><entry><author><name>/u/R4Y_animation</name><uri>https://www.reddit.com/user/R4Y_animation</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone! I would like to have some help for a problem i have I want to extract two parameters: date_from: the start of the period date_to: the end of the period&lt;/p&gt; &lt;p&gt;I tried using this &lt;a href=&quot;https://python.langchain.com/v0.1/docs/use_cases/extraction/&quot;&gt;example&lt;/a&gt; but it sometimes misses at simple prompts&lt;/p&gt; &lt;p&gt;What can i add to make it better? Here‚Äôs the &lt;a href=&quot;https://hastebin.skyra.pw/yehokamuqo.py&quot;&gt;code&lt;/a&gt; i made&lt;/p&gt; &lt;p&gt;Basically i want it to get from the user‚Äôs prompt the correct date or period&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/R4Y_animation&quot;&gt; /u/R4Y_animation &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctr9h5/how_to_extract_date_period_from_user_prompt/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctr9h5/how_to_extract_date_period_from_user_prompt/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctr9h5</id><link href="https://www.reddit.com/r/LangChain/comments/1ctr9h5/how_to_extract_date_period_from_user_prompt/" /><updated>2024-05-16T23:37:44+00:00</updated><published>2024-05-16T23:37:44+00:00</published><title>How to extract date period from user prompt</title></entry><entry><author><name>/u/leamecmy</name><uri>https://www.reddit.com/user/leamecmy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hii community I have a dataset with keys like name,description,why it matters,what to look for. Basically all these contains 1 line information(avg 10 words) ,I want to embedd these dataset using open ai models what are different ways for embedding these dataset . My puropse is when user give some query i can give him top k matched results.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/leamecmy&quot;&gt; /u/leamecmy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctv5au/embeddings_of_certain_dataset/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctv5au/embeddings_of_certain_dataset/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctv5au</id><link href="https://www.reddit.com/r/LangChain/comments/1ctv5au/embeddings_of_certain_dataset/" /><updated>2024-05-17T03:00:26+00:00</updated><published>2024-05-17T03:00:26+00:00</published><title>Embeddings of certain dataset</title></entry><entry><author><name>/u/deusebio</name><uri>https://www.reddit.com/user/deusebio</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I‚Äôm trying to set something up where a user can upload a pdf and have it classified based on a resource I converted into a vector database. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/deusebio&quot;&gt; /u/deusebio &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctqz2c/classify_pdf_based_on_separate_rag_database/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctqz2c/classify_pdf_based_on_separate_rag_database/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctqz2c</id><link href="https://www.reddit.com/r/LangChain/comments/1ctqz2c/classify_pdf_based_on_separate_rag_database/" /><updated>2024-05-16T23:23:41+00:00</updated><published>2024-05-16T23:23:41+00:00</published><title>Classify PDF based on separate RAG database</title></entry><entry><author><name>/u/Puzzleheaded_Bee5489</name><uri>https://www.reddit.com/user/Puzzleheaded_Bee5489</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there any way in LangChain where we can get the responses for multiple queries/prompts in LangChain?&lt;/p&gt; &lt;p&gt;Suppose I have a function in python: ```python def function(...): prompt_1 = &amp;quot;...&amp;quot; prompt_2 = &amp;quot;...&amp;quot;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# make these API calls in parallel - use multithreading? response_1 = llm.invoke(prompt_1) reponse_2 = llm.invoke(prompt_2) # rest of the code &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;```&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Puzzleheaded_Bee5489&quot;&gt; /u/Puzzleheaded_Bee5489 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctgq91/sending_multiple_prompts_in_parallel_to_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctgq91/sending_multiple_prompts_in_parallel_to_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctgq91</id><link href="https://www.reddit.com/r/LangChain/comments/1ctgq91/sending_multiple_prompts_in_parallel_to_openai/" /><updated>2024-05-16T16:15:56+00:00</updated><published>2024-05-16T16:15:56+00:00</published><title>Sending multiple prompts in parallel to OpenAI</title></entry><entry><author><name>/u/Responsible-Dog-4134</name><uri>https://www.reddit.com/user/Responsible-Dog-4134</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I‚Äôm working on a project for a client who needs single summaries of games for a game recommender app they‚Äôre creating. I‚Äôve been trying to test out a pipeline of prompts to see what inputs generate the best summaries, but I‚Äôm struggling üòì &lt;/p&gt; &lt;p&gt;It‚Äôs easy to view and edit one prompt at a time, but I need a tool that can handle these more complex, chained prompt scenarios effectively. It feels like there are tools out there that could potentially help, but none seem fully integrated into a seamless prompt management workflow. I want to look across multiple sample output examples (from several sample inputs), and see what‚Äôs working and what‚Äôs not. &lt;/p&gt; &lt;p&gt;Anyone else facing the same struggles? How are you managing more complex prompt scenarios / how are you integrating multiple tools to get the job done? &lt;/p&gt; &lt;p&gt;Maybe it&amp;#39;s just part of the job, but I can&amp;#39;t help but think there&amp;#39;s got to be a better way to manage and streamline this whole process. Any insights or tips would be super helpful! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Responsible-Dog-4134&quot;&gt; /u/Responsible-Dog-4134 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctk5l5/struggling_with_prompt_management_tools/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctk5l5/struggling_with_prompt_management_tools/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctk5l5</id><link href="https://www.reddit.com/r/LangChain/comments/1ctk5l5/struggling_with_prompt_management_tools/" /><updated>2024-05-16T18:37:40+00:00</updated><published>2024-05-16T18:37:40+00:00</published><title>Struggling with prompt management tools</title></entry><entry><author><name>/u/Trick-Asparagus-9260</name><uri>https://www.reddit.com/user/Trick-Asparagus-9260</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for ways to effectively chunk csv/excel files. In a meaningful manner. I looked into loaders but they have unstructuredCSV/Excel Loaders which are nothing but from Unstructured. Is there something in Langchain that I can use to chunk these formats meaningfully for my RAG?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Trick-Asparagus-9260&quot;&gt; /u/Trick-Asparagus-9260 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct97ix/how_to_effectively_chunk_csv_and_xlsx_files_excel/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct97ix/how_to_effectively_chunk_csv_and_xlsx_files_excel/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ct97ix</id><link href="https://www.reddit.com/r/LangChain/comments/1ct97ix/how_to_effectively_chunk_csv_and_xlsx_files_excel/" /><updated>2024-05-16T09:50:33+00:00</updated><published>2024-05-16T09:50:33+00:00</published><title>How to effectively chunk csv and xlsx files? Excel file can contain text/tables.</title></entry><entry><author><name>/u/BenMan_</name><uri>https://www.reddit.com/user/BenMan_</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I‚Äôm trying to figure out if it‚Äôs possible to create a Multi Agent application with LangGraph, where the agents can work in parallel (if needed).&lt;/p&gt; &lt;p&gt;Let‚Äôs say I have three agents (stupid example): 1. Supervisor 2. Agent specialized in tech conferences 3. Agent specialized in medical conferences&lt;/p&gt; &lt;p&gt;Each agent has its own tools.&lt;/p&gt; &lt;p&gt;The user query is ‚ÄúWhat are the main tech conferences and medical conferences in San Francisco in November?‚Äù.&lt;/p&gt; &lt;p&gt;This query can be obviously split in two different questions and each one can be addressed separately: 1. What are the main tech conferences in San Francisco in November? 2. What are the main medical conferences in San Francisco in November?&lt;/p&gt; &lt;p&gt;The Supervisor is able to process the original query, to produce these two questions and to route them separately to the correct Agent.&lt;/p&gt; &lt;p&gt;Is there a way to run these two agents in parallel and to have a fourth Agent (or the supervisor itself) that waits for the two answers and puts all together to produce a single final answer?&lt;/p&gt; &lt;p&gt;Does anyone have experience with such a use case?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/BenMan_&quot;&gt; /u/BenMan_ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cthrqz/agents_working_in_parallel_with_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cthrqz/agents_working_in_parallel_with_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cthrqz</id><link href="https://www.reddit.com/r/LangChain/comments/1cthrqz/agents_working_in_parallel_with_langgraph/" /><updated>2024-05-16T17:00:08+00:00</updated><published>2024-05-16T17:00:08+00:00</published><title>Agents working in parallel with LangGraph</title></entry><entry><author><name>/u/Zheng_SJ</name><uri>https://www.reddit.com/user/Zheng_SJ</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Zheng_SJ&quot;&gt; /u/Zheng_SJ &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://pluto-lang.vercel.app/blogs/240515-develop-ai-app-in-new-paradigm&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctga74/bridging_the_last_mile_in_langchain_application/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctga74</id><link href="https://www.reddit.com/r/LangChain/comments/1ctga74/bridging_the_last_mile_in_langchain_application/" /><updated>2024-05-16T15:57:28+00:00</updated><published>2024-05-16T15:57:28+00:00</published><title>Bridging the Last Mile in LangChain Application Development</title></entry><entry><author><name>/u/Longjumping-Buddy501</name><uri>https://www.reddit.com/user/Longjumping-Buddy501</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;After having worked with Anthropic API and Gemini 1.5 Pro &amp;amp; Flash APIs. OpenAI API seems to be the only reliable API service available.&lt;br/&gt; With Anthropic - I am unable to add credits to their console, even after multiple mails to the customer support I have received no resolution. So I finally have to give up hope and just use Open AI.&lt;br/&gt; With Google Gemini - The APIs are absolutely unreliable, you are not sure when the APIs will return an answer and when they will not. I keep encountering error from the API something like: StopCandidateException: finish_reason: RECITATION&lt;br/&gt; So again no point in using Gemini, just switch to Open AI.&lt;/p&gt; &lt;p&gt;Hoping this experience will benefit the community.&lt;/p&gt; &lt;p&gt;Anyone else having these issues.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Longjumping-Buddy501&quot;&gt; /u/Longjumping-Buddy501 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrtc3/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrtc3/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csrtc3</id><link href="https://www.reddit.com/r/LangChain/comments/1csrtc3/open_ai_apis_are_the_only_reliable_apis_in/" /><updated>2024-05-15T18:21:45+00:00</updated><published>2024-05-15T18:21:45+00:00</published><title>Open AI APIs are the only reliable APIs in production</title></entry><entry><author><name>/u/Such-Maintenance9199</name><uri>https://www.reddit.com/user/Such-Maintenance9199</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i need a suggestion on a situation at work.&lt;/p&gt; &lt;p&gt;I am writing code for an application. i have 2 options, that is, either choose an existing python framework that is available in the market or write my own python code.&lt;/p&gt; &lt;p&gt;Existing framework: LangChain, LlamaIndex&lt;/p&gt; &lt;p&gt;Pros:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;used a lot outside in the market. just in case if i want to shift another company. i can easily adapt and can earn more money&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;I can create Agents (AI) with little ease as i dont have to implement everything from scratch (usually research work and strategies are implemented in this framework). implementing features becomes faster&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;as knowledge workers are more aware of this framework - hiring them and getting them to understand the code becomes easy &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Cons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt; So many abstractions in this framework and i fully dont understand it. few months back i tried to use this framework and i couldn&amp;#39;t customize it for our situation. I am worried if i use this and make some progress and later realize that it is not customizable. i will be screwed. lot of work will be wasted.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Own Code:&lt;/p&gt; &lt;p&gt;Pros:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;i can implement all the functionalities by myself. i can design code base and write everything from scratch. this skill is valued in lot of places especially in startups as you have literally implemented lot of things from scratch. this way i can get a hang over the language and my skill improves drastically&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;i get to do research and implement them with my own code.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;i can customize it for my specific scenario&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;the company will have a lot of dependency on me &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Cons:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;lot of work&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;development might not be as fast paced as i would have liked it to be.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;i might get stuck and not find any solution as i am the only person available who has knowledge on this in this company.&lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Any suggestions are appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Such-Maintenance9199&quot;&gt; /u/Such-Maintenance9199 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cstpmx/llm_orchestration_framework_or_own_python_code/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1cstpmx/llm_orchestration_framework_or_own_python_code/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1cstpmx</id><link href="https://www.reddit.com/r/LangChain/comments/1cstpmx/llm_orchestration_framework_or_own_python_code/" /><updated>2024-05-15T19:38:46+00:00</updated><published>2024-05-15T19:38:46+00:00</published><title>LLM Orchestration framework or own python code, which is better?</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Checkout this short video to understand the difference between two major Generative AI packages i.e. LangChain and LlamaIndex and what to use when : &lt;a href=&quot;https://youtu.be/Oy8UZp3potw?si=9mp9M5UrBjR-FX5G&quot;&gt;https://youtu.be/Oy8UZp3potw?si=9mp9M5UrBjR-FX5G&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctgx1l/langchain_vs_llamaindex_differences_explained/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ctgx1l/langchain_vs_llamaindex_differences_explained/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ctgx1l</id><link href="https://www.reddit.com/r/LangChain/comments/1ctgx1l/langchain_vs_llamaindex_differences_explained/" /><updated>2024-05-16T16:23:58+00:00</updated><published>2024-05-16T16:23:58+00:00</published><title>LangChain vs LlamaIndex differences explained</title></entry><entry><author><name>/u/Longjumping-Buddy501</name><uri>https://www.reddit.com/user/Longjumping-Buddy501</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;After having worked with Anthropic API and Gemini 1.5 Pro &amp;amp; Flash APIs. OpenAI API seems to be the only reliable API service available.&lt;br/&gt; With Anthropic - I am unable to add credits to their console, even after multiple mails to the customer support I have received no resolution. So I finally have to give up hope and just use Open AI.&lt;br/&gt; With Google Gemini - The APIs are absolutely unreliable, you are not sure when the APIs will return an answer and when they will not. I keep encountering error from the API something like: StopCandidateException: finish_reason: RECITATION&lt;br/&gt; So again no point in using Gemini, just switch to Open AI.&lt;/p&gt; &lt;p&gt;Hoping this experience will benefit the community.&lt;/p&gt; &lt;p&gt;Anyone else having these issues.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Longjumping-Buddy501&quot;&gt; /u/Longjumping-Buddy501 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrta9/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1csrta9/open_ai_apis_are_the_only_reliable_apis_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1csrta9</id><link href="https://www.reddit.com/r/LangChain/comments/1csrta9/open_ai_apis_are_the_only_reliable_apis_in/" /><updated>2024-05-15T18:21:41+00:00</updated><published>2024-05-15T18:21:41+00:00</published><title>Open AI APIs are the only reliable APIs in production</title></entry><entry><author><name>/u/mehul_gupta1997</name><uri>https://www.reddit.com/user/mehul_gupta1997</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/mehul_gupta1997&quot;&gt; /u/mehul_gupta1997 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;/r/ArtificialInteligence/comments/1ct1sja/creating_proxy_server_for_llms/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct1thu/creating_proxy_server_for_llms/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ct1thu</id><link href="https://www.reddit.com/r/LangChain/comments/1ct1thu/creating_proxy_server_for_llms/" /><updated>2024-05-16T01:50:35+00:00</updated><published>2024-05-16T01:50:35+00:00</published><title>Creating proxy server for llms</title></entry><entry><author><name>/u/hesitantelephant</name><uri>https://www.reddit.com/user/hesitantelephant</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;TLDR: I made a platform to make it easy to switch between LLMs, find the best one for your specific needs, analyze their performance, and test different providers in production. Check it out at&lt;/strong&gt; &lt;a href=&quot;https://optimix.app/?lang&quot;&gt;&lt;strong&gt;optimix.app&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Figuring out whether or not you should switch to Llama 3, Gemini 1.5 Flash, or GPT-4o can be hard. And knowing if the prompt change you just made will be good or bad is even harder.&lt;/p&gt; &lt;p&gt;A key focus of Optimix is to make experimentation easy. You can run A/B tests and other experiments to figure out how your changes impacted your core metrics like cost, speed, and user satisfaction. You can also test and compare different models in our playground and make requests through our API.&lt;/p&gt; &lt;p&gt;It also dynamically selects the most suitable model for each request, and helps manage fallbacks for outages and rate limits. Facing an OpenAI outage? Switch to Llama 3. Need superior coding assistance? We can auto switch you to the best one.&lt;/p&gt; &lt;p&gt;I&amp;#39;d love any feedback or suggestions on the platform, and hope this can be helpful for you all with all the new models coming out!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/hesitantelephant&quot;&gt; /u/hesitantelephant &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct4m4z/experiment_and_test_the_reliability_of_different/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ct4m4z/experiment_and_test_the_reliability_of_different/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ct4m4z</id><link href="https://www.reddit.com/r/LangChain/comments/1ct4m4z/experiment_and_test_the_reliability_of_different/" /><updated>2024-05-16T04:23:44+00:00</updated><published>2024-05-16T04:23:44+00:00</published><title>Experiment and test the reliability of different LLMs in prod and pre-prod!</title></entry></feed>