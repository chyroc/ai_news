<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-06-15T15:39:21+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/sarthakai</name><uri>https://www.reddit.com/user/sarthakai</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;First, how it works:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;Memory Tuning fine-tunes millions of LoRA adapters (memory experts) on any open-source LLM to ensure accurate fact recall.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;During inference, the model retrieves and integrates the most relevant experts, (a lot like information retrieval). This gives much high accuracy and reduced hallucinations.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;This approach maintains the model&amp;#39;s ability to generalise — while at the same time focusing on zero error for specified facts.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Why is this better than RAG?&lt;/p&gt; &lt;p&gt;RAG shifts probabilities without eliminating errors — while Memory Tuning fully corrects inaccuracies.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/company/lamini-ai/&quot;&gt;Lamini&lt;/a&gt; released their Memory Tuning solution for enterprises with case studies showing amazing accuracy boosts for text-to-sql, labelling, and even recommendation tasks.&lt;/p&gt; &lt;p&gt;Paper: &lt;a href=&quot;https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf&quot;&gt;https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I share high quality AI updates and tutorials daily on my LinkedIn: &lt;a href=&quot;https://www.linkedin.com/in/sarthakrastogi/&quot;&gt;https://www.linkedin.com/in/sarthakrastogi/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;If you like this post and want to stay updated on latest AI research, you can check out: &lt;a href=&quot;https://linktr.ee/sarthakrastogi&quot;&gt;https://linktr.ee/sarthakrastogi&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/sarthakai&quot;&gt; /u/sarthakai &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgi0vj/whats_memory_tuning_and_how_does_it_give_higher/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgi0vj/whats_memory_tuning_and_how_does_it_give_higher/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dgi0vj</id><link href="https://www.reddit.com/r/LangChain/comments/1dgi0vj/whats_memory_tuning_and_how_does_it_give_higher/" /><updated>2024-06-15T13:30:01+00:00</updated><published>2024-06-15T13:30:01+00:00</published><title>What’s Memory Tuning and how does it give higher accuracy + speed than RAG and prompting?</title></entry><entry><author><name>/u/Sweaty-Minimum5423</name><uri>https://www.reddit.com/user/Sweaty-Minimum5423</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello all, OpenAI assistant should support streaming. But I am not sure why the current OpenAIAssistantV2Runnable do not supports it. Is there a solution to this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Sweaty-Minimum5423&quot;&gt; /u/Sweaty-Minimum5423 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgfsmg/streaming_of_openaiassistant_v2/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dgfsmg/streaming_of_openaiassistant_v2/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dgfsmg</id><link href="https://www.reddit.com/r/LangChain/comments/1dgfsmg/streaming_of_openaiassistant_v2/" /><updated>2024-06-15T11:23:04+00:00</updated><published>2024-06-15T11:23:04+00:00</published><title>Streaming of OpenAIAssistant v2</title></entry><entry><author><name>/u/filet_mign0n</name><uri>https://www.reddit.com/user/filet_mign0n</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Wondering if anyone here has dealt with passing private information from end user inputs to your LLM, later to interact with an external API? I&amp;#39;m not talking about authentication data per se, just private information (e.g PII) people wouldn&amp;#39;t normally want to share on the internet.&lt;br/&gt; What solution have you come up with to ensure some privacy for your users?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/filet_mign0n&quot;&gt; /u/filet_mign0n &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfyz50/how_to_securely_pass_private_data/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfyz50/how_to_securely_pass_private_data/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfyz50</id><link href="https://www.reddit.com/r/LangChain/comments/1dfyz50/how_to_securely_pass_private_data/" /><updated>2024-06-14T19:23:46+00:00</updated><published>2024-06-14T19:23:46+00:00</published><title>How to securely pass private data?</title></entry><entry><author><name>/u/RaeudigerRaffi</name><uri>https://www.reddit.com/user/RaeudigerRaffi</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m excited to share an updated open-source resource we’ve been working on—an improved version of the Spider dataset originally published by Yale University for Text2SQL tasks. You can check it out here: &lt;a href=&quot;https://huggingface.co/datasets/RaffaSch121/fixed_spider&quot;&gt;https://huggingface.co/datasets/RaffaSch121/fixed_spider&lt;/a&gt;&lt;/p&gt; &lt;p&gt;During our own model training at &lt;a href=&quot;http://www.turbular.com&quot;&gt;Turbular&lt;/a&gt; we identified several issues in the original dataset. To help the community and give back, we decided to address these problems and release a corrected version. We hope this enhanced dataset will benefit everyone working on Text2SQL and similar projects.&lt;/p&gt; &lt;p&gt;Feel free to download, experiment, and contribute back if you find ways to make it even better!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/RaeudigerRaffi&quot;&gt; /u/RaeudigerRaffi &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsdbw/improved_text2sql_dataset_now_available_on/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsdbw/improved_text2sql_dataset_now_available_on/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfsdbw</id><link href="https://www.reddit.com/r/LangChain/comments/1dfsdbw/improved_text2sql_dataset_now_available_on/" /><updated>2024-06-14T14:37:24+00:00</updated><published>2024-06-14T14:37:24+00:00</published><title>Improved Text2SQL Dataset Now Available on Huggingface!</title></entry><entry><author><name>/u/FunInformation2332</name><uri>https://www.reddit.com/user/FunInformation2332</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfxwga/evaluating_with_ragas/&quot;&gt; &lt;img src=&quot;https://a.thumbs.redditmedia.com/XCOcROHXeB7lrz95uNOAiGKakHooUXoHIPXAQ38I2n0.jpg&quot; alt=&quot;Evaluating with Ragas&quot; title=&quot;Evaluating with Ragas&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve finished my rag job, and performed a evaluation on my rag. results given below&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/pt0khqy10l6d1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4979a08f0e648937407d23feeb494f02a8e793ba&quot;&gt;ragas output&lt;/a&gt;&lt;/p&gt; &lt;p&gt;context_precision is better than good but why the other metrics sucks and how to improve them?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FunInformation2332&quot;&gt; /u/FunInformation2332 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfxwga/evaluating_with_ragas/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfxwga/evaluating_with_ragas/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dfxwga</id><media:thumbnail url="https://a.thumbs.redditmedia.com/XCOcROHXeB7lrz95uNOAiGKakHooUXoHIPXAQ38I2n0.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1dfxwga/evaluating_with_ragas/" /><updated>2024-06-14T18:36:01+00:00</updated><published>2024-06-14T18:36:01+00:00</published><title>Evaluating with Ragas</title></entry><entry><author><name>/u/UnderstandLingAI</name><uri>https://www.reddit.com/user/UnderstandLingAI</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;We are in early stages of developing our project so keen feedback. RAG Me Up is a robust layer on top of Langchain designed to make RAG easy and also not prone to simple issues like document re-retrieval, performance for rephrasind and perhaps most importantly: make Langchain work well with Instruct/Chat models&amp;#39; templates.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/AI-Commandos/RAGMeUp&quot;&gt;https://github.com/AI-Commandos/RAGMeUp &lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/UnderstandLingAI&quot;&gt; /u/UnderstandLingAI &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfx2di/rag_me_up_rag_for_chat_w_langchain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfx2di/rag_me_up_rag_for_chat_w_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfx2di</id><link href="https://www.reddit.com/r/LangChain/comments/1dfx2di/rag_me_up_rag_for_chat_w_langchain/" /><updated>2024-06-14T18:00:18+00:00</updated><published>2024-06-14T18:00:18+00:00</published><title>RAG Me Up - RAG for chat /w Langchain</title></entry><entry><author><name>/u/MoronSlayer42</name><uri>https://www.reddit.com/user/MoronSlayer42</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have implementing streaming with a chain based runnable which gives token by token output ( word by word), making UI similar to how ChatGPT has its UI. But while implementing the same with an Agent based runnable I see that it gives 3 outputs in order, actions, steps and, output which contains answer. All three come as a whole, one after the other, not word by word.&lt;/p&gt; &lt;p&gt;I want to get word by word streaming for the agent&amp;#39;s final answer.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/MoronSlayer42&quot;&gt; /u/MoronSlayer42 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsv2t/streaming_with_agents/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsv2t/streaming_with_agents/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfsv2t</id><link href="https://www.reddit.com/r/LangChain/comments/1dfsv2t/streaming_with_agents/" /><updated>2024-06-14T14:59:04+00:00</updated><published>2024-06-14T14:59:04+00:00</published><title>Streaming with agents</title></entry><entry><author><name>/u/ANil1729</name><uri>https://www.reddit.com/user/ANil1729</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have written an article on how to create a Text to Video AI generator which generates video from a topic by collecting relevant stock videos and stitching them together. &lt;/p&gt; &lt;p&gt;The code is completely open-source and uses free to use tools to generate videos&lt;/p&gt; &lt;p&gt;Link to article :- &lt;a href=&quot;https://medium.com/@anilmatcha/text-to-video-ai-how-to-create-videos-for-free-a-complete-guide-a25c91de50b8&quot;&gt;https://medium.com/@anilmatcha/text-to-video-ai-how-to-create-videos-for-free-a-complete-guide-a25c91de50b8&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ANil1729&quot;&gt; /u/ANil1729 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsc15/a_tutorial_on_creating_video_from_text_using_ai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsc15/a_tutorial_on_creating_video_from_text_using_ai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfsc15</id><link href="https://www.reddit.com/r/LangChain/comments/1dfsc15/a_tutorial_on_creating_video_from_text_using_ai/" /><updated>2024-06-14T14:35:53+00:00</updated><published>2024-06-14T14:35:53+00:00</published><title>A tutorial on creating video from text using AI</title></entry><entry><author><name>/u/profsartor</name><uri>https://www.reddit.com/user/profsartor</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;As the title reads, I&amp;#39;m building a side project to chat with my google calendar + assignments from Canvas (learning management system). I&amp;#39;m using GCP to practice working with the cloud. &lt;/p&gt; &lt;p&gt;As of April 2024, Cloud SQL for MySQL now supports vector embeddings. Essentially, I have all of my coursework and assignments in an events table. At first I embedded at the row level but this lost the understanding of columns. Now, I have a new column that is JSON representation of all the relevant columns for my eventual retrieval (event_title, start_time, end_time, tag (Assignment, Discussion, Quiz, Study Times, Personal Events)). In a new column, I&amp;#39;ve successfully embedded all of these JSON&amp;#39;s. What I&amp;#39;ve described above is pretty much the extent of what I&amp;#39;ve done. &lt;/p&gt; &lt;p&gt;My end goal is to develop a streamlit UI to query this vector column in my SQL database. I have a few different paths I can go down, but I&amp;#39;m intentionally keeping this at a high level to hear diverse responses. &lt;/p&gt; &lt;p&gt;Any advice? All thoughts are greatly appreciated. &lt;/p&gt; &lt;p&gt;Cheers&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/profsartor&quot;&gt; /u/profsartor &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsjwl/newbie_seeking_advice_on_side_project_chat_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfsjwl/newbie_seeking_advice_on_side_project_chat_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfsjwl</id><link href="https://www.reddit.com/r/LangChain/comments/1dfsjwl/newbie_seeking_advice_on_side_project_chat_with/" /><updated>2024-06-14T14:45:29+00:00</updated><published>2024-06-14T14:45:29+00:00</published><title>Newbie Seeking Advice on Side Project - Chat with Calendar</title></entry><entry><author><name>/u/alcatraz0411</name><uri>https://www.reddit.com/user/alcatraz0411</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all, How do I get the token count for chain.astream_events()&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/alcatraz0411&quot;&gt; /u/alcatraz0411 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfpjpr/token_count_and_cost_for_chainastream_events/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfpjpr/token_count_and_cost_for_chainastream_events/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfpjpr</id><link href="https://www.reddit.com/r/LangChain/comments/1dfpjpr/token_count_and_cost_for_chainastream_events/" /><updated>2024-06-14T12:23:23+00:00</updated><published>2024-06-14T12:23:23+00:00</published><title>Token count and cost for chain.astream_events().</title></entry><entry><author><name>/u/Convhay</name><uri>https://www.reddit.com/user/Convhay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi i am new to the framework of langchain and i want to search for some information in contract documents regarding total m2 area for a partner. The problem is that the main partner contract can have several newer appendices where the old total m2 area in the old original contract is now replaced. Now i only want to extract the new total m2 area. Is there a clever way to sort or filter this?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Convhay&quot;&gt; /u/Convhay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfp7xf/ragchain_searching_for_similar_prompts/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfp7xf/ragchain_searching_for_similar_prompts/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dfp7xf</id><link href="https://www.reddit.com/r/LangChain/comments/1dfp7xf/ragchain_searching_for_similar_prompts/" /><updated>2024-06-14T12:05:06+00:00</updated><published>2024-06-14T12:05:06+00:00</published><title>RAGchain searching for similar prompts</title></entry><entry><author><name>/u/EscapedLaughter</name><uri>https://www.reddit.com/user/EscapedLaughter</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfp2z5/project_compare_top_10_lmsys_models_with_a/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/vrQ98WHCObyIKaUSsC_cjzHZfMprk1y9ugKJTbGEQhc.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4b33690b47fabd60a6ce3e21bdf3b238eaebdb8f&quot; alt=&quot;[Project] Compare Top 10 LMSYS Models with a Universal LLM API Library&quot; title=&quot;[Project] Compare Top 10 LMSYS Models with a Universal LLM API Library&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello Langchain community!&lt;/p&gt; &lt;p&gt;I&amp;#39;m excited to share a project we&amp;#39;ve been working on - an open-source &amp;quot;AI Gateway&amp;quot; library that allows you to access and compare 200+ language models from multiple providers using a simple, unified API.&lt;/p&gt; &lt;p&gt;To showcase the capabilities of this library, I&amp;#39;ve created a Google Colab notebook that demonstrates how you can easily compare the top 10 models from the LMSYS leaderboard with just a few lines of code.&lt;/p&gt; &lt;p&gt;Here&amp;#39;s a snippet:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/lcqhryzx0j6d1.png?width=1822&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cf7d055fa0e79117fed5dd8f8dc37498fe43b9e3&quot;&gt;https://preview.redd.it/lcqhryzx0j6d1.png?width=1822&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cf7d055fa0e79117fed5dd8f8dc37498fe43b9e3&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The library handles all the complexities of authenticating and communicating with different provider APIs behind the scenes, allowing you to focus on experimenting with and comparing the models themselves.&lt;/p&gt; &lt;p&gt;Some key features of the AI Gateway library:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Unified API for accessing 200+ LLMs from OpenAI, Anthropic, Google, Ollama, Cohere, Together AI, and more&lt;/li&gt; &lt;li&gt;Compatible with existing OpenAI client libraries for easy integration&lt;/li&gt; &lt;li&gt;Routing capabilities like fallbacks, load balancing, retries&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I believe this library could be incredibly useful for researchers and developers in the Langchain community who want to easily compare and benchmark different LLMs, or build applications that leverage multiple models.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve put the demo notebook link below, I&amp;#39;d love to get your feedback, suggestions, and contributions:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/Portkey-AI/gateway/blob/main/cookbook/use-cases/LMSYS%20Series/comparing-top10-LMSYS-models-with-Portkey.ipynb&quot;&gt;https://github.com/Portkey-AI/gateway/blob/main/cookbook/use-cases/LMSYS%20Series/comparing-top10-LMSYS-models-with-Portkey.ipynb&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EscapedLaughter&quot;&gt; /u/EscapedLaughter &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfp2z5/project_compare_top_10_lmsys_models_with_a/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfp2z5/project_compare_top_10_lmsys_models_with_a/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dfp2z5</id><media:thumbnail url="https://external-preview.redd.it/vrQ98WHCObyIKaUSsC_cjzHZfMprk1y9ugKJTbGEQhc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4b33690b47fabd60a6ce3e21bdf3b238eaebdb8f" /><link href="https://www.reddit.com/r/LangChain/comments/1dfp2z5/project_compare_top_10_lmsys_models_with_a/" /><updated>2024-06-14T11:57:45+00:00</updated><published>2024-06-14T11:57:45+00:00</published><title>[Project] Compare Top 10 LMSYS Models with a Universal LLM API Library</title></entry><entry><author><name>/u/vT_Raven</name><uri>https://www.reddit.com/user/vT_Raven</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone, I mean no disrespect to anyone but I am having trouble seeing the appeal of using the lang chain. In my opinion I&amp;#39;am at best a beginner there for my view coulde be too shalow. I am hoping to find an anweser to where my blind spots are and what use cases the lang chain is useful for. For example, if I want to build a rag chatbot. I would use Ollama with Chromadb without any libery except for chromadb and requests. I have to admit that it is nice to try different things with lang chain. It is also easier to handle complex files like PDF. &lt;/p&gt; &lt;p&gt;If some of you say I don&amp;#39;t have enough experience, that&amp;#39;s why I don&amp;#39;t get it, the answer is fair enough for me to take a agaib a look at Lang Chain.&lt;/p&gt; &lt;p&gt;But I have already tried to work with the framework 3 times and it always seems too complex for what I want to achieve. All those time i build an Chatbot that allows to interact with an modell with some litte custmasation over envs. And the last time was a Rag Chatbot that allows me to index Websites to get answers about their content.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/vT_Raven&quot;&gt; /u/vT_Raven &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df95xz/why_should_i_use_lang_chain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df95xz/why_should_i_use_lang_chain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1df95xz</id><link href="https://www.reddit.com/r/LangChain/comments/1df95xz/why_should_i_use_lang_chain/" /><updated>2024-06-13T20:41:52+00:00</updated><published>2024-06-13T20:41:52+00:00</published><title>Why should i use lang chain?</title></entry><entry><author><name>/u/cryptokaykay</name><uri>https://www.reddit.com/user/cryptokaykay</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfaquj/run_evaluations_with_langtrace/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/OlQpvPg6C80CPbeQqL74YpdIgrAULdbnNlYTTliAWPg.jpg&quot; alt=&quot;Run Evaluations with Langtrace&quot; title=&quot;Run Evaluations with Langtrace&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all,&lt;/p&gt; &lt;p&gt;Its been a while from me, but just wanted to share that we have added support for running automated evals with Langtrace. As a reminder, Langtrace is an open source LLM application observability and evaluations tool. It is open telemetry compatible so no vendor lock-in. You can also self-host and run Langtrace.&lt;/p&gt; &lt;p&gt;We integrated langtrace with inspect AI (&lt;a href=&quot;https://github.com/UKGovernmentBEIS/inspect%5C_ai&quot;&gt;https://github.com/UKGovernmentBEIS/inspect\_ai&lt;/a&gt;). Inspect is an open source evluations tool from the developers of RStudio - you should definitely check it out. I love it.&lt;br/&gt; With langtrace, you can now&lt;/p&gt; &lt;ul&gt; &lt;li&gt;set up tracing in 2 lines of code&lt;/li&gt; &lt;li&gt;annotate and curate datasets&lt;/li&gt; &lt;li&gt;run evaluations against this dataset using Inspect&lt;/li&gt; &lt;li&gt;view results, compare the outputs against models and understand the performance of your app&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So, you can now establish this feedback loop with langtrace.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/qrwn7r1kte6d1.png?width=2304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3c2d7c82abbb329518b35c133c0e7a0e73a6d53d&quot;&gt;https://preview.redd.it/qrwn7r1kte6d1.png?width=2304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3c2d7c82abbb329518b35c133c0e7a0e73a6d53d&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Shown below are some screenshots:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/t45vq2xute6d1.png?width=3156&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c15fc71499ba5c5ccbf0aa566fc78c82730e209&quot;&gt;https://preview.redd.it/t45vq2xute6d1.png?width=3156&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c15fc71499ba5c5ccbf0aa566fc78c82730e209&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/0gwmyz0xte6d1.png?width=3150&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2713ba619e903d2db227d5922e8e9c7a562fb9b7&quot;&gt;https://preview.redd.it/0gwmyz0xte6d1.png?width=3150&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2713ba619e903d2db227d5922e8e9c7a562fb9b7&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Would love get any feedback. Please do try it out and let me know.&lt;/p&gt; &lt;p&gt;Link: &lt;a href=&quot;https://github.com/Scale3-Labs/langtrace&quot;&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/cryptokaykay&quot;&gt; /u/cryptokaykay &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfaquj/run_evaluations_with_langtrace/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dfaquj/run_evaluations_with_langtrace/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dfaquj</id><media:thumbnail url="https://b.thumbs.redditmedia.com/OlQpvPg6C80CPbeQqL74YpdIgrAULdbnNlYTTliAWPg.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/1dfaquj/run_evaluations_with_langtrace/" /><updated>2024-06-13T21:50:44+00:00</updated><published>2024-06-13T21:50:44+00:00</published><title>Run Evaluations with Langtrace</title></entry><entry><author><name>/u/chaitu9701</name><uri>https://www.reddit.com/user/chaitu9701</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;To set the context we have 4 environments predev, dev, testing and production. Our RAG uses langchain for PDF extraction, qdrant(self hosted on kubernetes) for vectorstore and gpt-3.5-turbo-16k for the llm.&lt;/p&gt; &lt;p&gt;We have built a RAG, which worked well(gave correct answers from PDF) on predev. When we moved it to dev, in the initial days its performance(correctness) was bad and eventually got good without any changes, except for minor document update. Then it moved to testing environment where again the same behaviour. Now it&amp;#39;s in prod and again behaves the same. Facing a lot of backlash from client due to this strange behaviour.&lt;/p&gt; &lt;p&gt;It&amp;#39;s the same document, same gpt, but different qdrant hosted different for different environments.&lt;/p&gt; &lt;p&gt;Did anyone experience similar issue? Can anyone explain why the warmup time.&lt;/p&gt; &lt;p&gt;Any help is greatly appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/chaitu9701&quot;&gt; /u/chaitu9701 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df1wnb/rag_performs_differently_in_different_environments/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df1wnb/rag_performs_differently_in_different_environments/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1df1wnb</id><link href="https://www.reddit.com/r/LangChain/comments/1df1wnb/rag_performs_differently_in_different_environments/" /><updated>2024-06-13T15:35:41+00:00</updated><published>2024-06-13T15:35:41+00:00</published><title>RAG performs differently in different environments</title></entry><entry><author><name>/u/ChallengeOk6437</name><uri>https://www.reddit.com/user/ChallengeOk6437</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am trying to build a model to take in 5-10 PDFs and answer questions based on them.&lt;/p&gt; &lt;p&gt;This is my flow ==&amp;gt; LlamaParse-&amp;gt;OpenAI ada embeddings -&amp;gt; FAISS vector store -&amp;gt; multi query retriever -&amp;gt; cohere reranker -&amp;gt; OpenAI gpt4o -&amp;gt; results&lt;/p&gt; &lt;p&gt;I also have a part in my retriever stage where I get citations and chunking is done page wise&lt;/p&gt; &lt;p&gt;The questions I ask take anywhere between 25-50 seconds to get an answer and also I am missing out on information, I have made the retriever send back all relevant pages, not just the top 3 relevant pages&lt;/p&gt; &lt;p&gt;Is there anyway to get this under 20 seconds and extract all relevant chunks with keeping in mind I need citations?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ChallengeOk6437&quot;&gt; /u/ChallengeOk6437 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df0apu/rag_model_too_slow/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df0apu/rag_model_too_slow/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1df0apu</id><link href="https://www.reddit.com/r/LangChain/comments/1df0apu/rag_model_too_slow/" /><updated>2024-06-13T14:26:24+00:00</updated><published>2024-06-13T14:26:24+00:00</published><title>RAG Model TOO SLOW</title></entry><entry><author><name>/u/Glittering-Bear5748</name><uri>https://www.reddit.com/user/Glittering-Bear5748</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello guys&lt;/p&gt; &lt;p&gt;i am creating chat bot with QA retrieval using vector DB and i want to add one more feature that is follow up question along with response to current question&lt;br/&gt; can anybody provide me example how implement it ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Glittering-Bear5748&quot;&gt; /u/Glittering-Bear5748 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df5lc7/suggest_5_followup_question_based_on_previous/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1df5lc7/suggest_5_followup_question_based_on_previous/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1df5lc7</id><link href="https://www.reddit.com/r/LangChain/comments/1df5lc7/suggest_5_followup_question_based_on_previous/" /><updated>2024-06-13T18:11:38+00:00</updated><published>2024-06-13T18:11:38+00:00</published><title>suggest 5 follow-up question based on previous asked</title></entry><entry><author><name>/u/milkomeda22</name><uri>https://www.reddit.com/user/milkomeda22</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m looking for recommendations on tools for chemists that can be implemented using LLM and LangChain agents. What useful tools or applications do you think can be created with these technologies? I would appreciate any ideas and suggestions.&lt;/p&gt; &lt;p&gt;Which LLMs do you recommend for laboratory automation solutions, and what data processing life cycles can be implemented by agents?&lt;/p&gt; &lt;p&gt;I&amp;#39;m particularly interested in how to work with the Canonical SMILES format using chatbots and modify it through agents.&lt;/p&gt; &lt;p&gt;I&amp;#39;m exploring this topic as a theoretical preparation for a long-term hackathon focused on the automation of chemical laboratories. All solutions will be &lt;strong&gt;published&lt;/strong&gt; and &lt;strong&gt;open source&lt;/strong&gt; after our team’s presentation.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/milkomeda22&quot;&gt; /u/milkomeda22 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dewg6w/seeking_recommendations_tools_for_chemists_using/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dewg6w/seeking_recommendations_tools_for_chemists_using/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1dewg6w</id><link href="https://www.reddit.com/r/LangChain/comments/1dewg6w/seeking_recommendations_tools_for_chemists_using/" /><updated>2024-06-13T11:11:53+00:00</updated><published>2024-06-13T11:11:53+00:00</published><title>Seeking Recommendations: Tools for Chemists Using Large Language Models and Agents</title></entry><entry><author><name>/u/Capital_learner</name><uri>https://www.reddit.com/user/Capital_learner</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have to make llm chatbit using open ai on flask. Help me to make this. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Capital_learner&quot;&gt; /u/Capital_learner &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1deh52g/need_help_to_make_langchain_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1deh52g/need_help_to_make_langchain_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1deh52g</id><link href="https://www.reddit.com/r/LangChain/comments/1deh52g/need_help_to_make_langchain_chatbot/" /><updated>2024-06-12T20:48:11+00:00</updated><published>2024-06-12T20:48:11+00:00</published><title>Need Help to make langchain chatbot</title></entry><entry><author><name>/u/Borfecao</name><uri>https://www.reddit.com/user/Borfecao</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone,&lt;/p&gt; &lt;p&gt;I&amp;#39;m working on a Supervisor with LangGraph for a company internship. My mentor has asked me to create three Agents: &amp;quot;Question Agent&amp;quot;, &amp;quot;Answer Agent&amp;quot;, and &amp;quot;Summarizer Agent&amp;quot;. The input is a PDF, which I need to split by page and add each page to a vectorial database for later use. Each agent will also save its outputs in the vectorial POSTGRES database. Here&amp;#39;s a rough idea of the structure:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Questions Table&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;id (Primary Key)&lt;/li&gt; &lt;li&gt;question (Text)&lt;/li&gt; &lt;li&gt;embedding (Vector)&lt;/li&gt; &lt;li&gt;document_id (Integer)&lt;/li&gt; &lt;li&gt;page_number (Integer)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Answers Table&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;id (Primary Key)&lt;/li&gt; &lt;li&gt;answer (Text)&lt;/li&gt; &lt;li&gt;embedding (Vector)&lt;/li&gt; &lt;li&gt;document_id (Integer)&lt;/li&gt; &lt;li&gt;page_number (Integer)&lt;/li&gt; &lt;li&gt;question_id (Foreign Key to Questions table)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Summaries Table&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;id (Primary Key)&lt;/li&gt; &lt;li&gt;summary (Text)&lt;/li&gt; &lt;li&gt;embedding (Vector)&lt;/li&gt; &lt;li&gt;document_id (Integer)&lt;/li&gt; &lt;li&gt;page_number (Integer)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Documents Table&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;id (Primary Key)&lt;/li&gt; &lt;li&gt;summary (Text)&lt;/li&gt; &lt;li&gt;document_id (Integer)&lt;/li&gt; &lt;li&gt;number_of_pages (Integer)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The workflow is something like this:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Load the document (sanitize the text, embed it, save in &amp;quot;Documents&amp;quot;)&lt;/li&gt; &lt;li&gt;Make a summary of each page (save in &amp;quot;Summaries&amp;quot;)&lt;/li&gt; &lt;li&gt;Generate questions for each page (save in &amp;quot;Questions&amp;quot;)&lt;/li&gt; &lt;li&gt;Answer all the questions generated by the Question Agent, considering the context of the page (save in &amp;quot;Answers&amp;quot;)&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;My biggest question is:&lt;/strong&gt; what tools and agents should I implement for this? Most resources I&amp;#39;ve found online use tools like Tavily Search and Python REPL, which aren&amp;#39;t really helpful for my case. I need to use the Supervisor since it&amp;#39;s a project requirement, and I&amp;#39;m a bit confused about the implementation details, since this would be very easy to implement with simple chains, and the only solution I could come up with is tooless agents...?&lt;/p&gt; &lt;p&gt;Any advice or pointers would be greatly appreciated! Thanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Borfecao&quot;&gt; /u/Borfecao &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1deaviw/need_help_implementing_supervisor_with_langgraph/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1deaviw/need_help_implementing_supervisor_with_langgraph/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1deaviw</id><link href="https://www.reddit.com/r/LangChain/comments/1deaviw/need_help_implementing_supervisor_with_langgraph/" /><updated>2024-06-12T16:28:31+00:00</updated><published>2024-06-12T16:28:31+00:00</published><title>Need Help Implementing Supervisor with LangGraph</title></entry><entry><author><name>/u/huseyinbabal</name><uri>https://www.reddit.com/user/huseyinbabal</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dec8ls/building_devops_ai_assistant_with_langchain/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/3eIYPb9fvv3T8yM1RCQU_MSfK9DpDf_d-D2eAbkLPPE.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c229377b890822b72774120bb4ab72f62d353aa2&quot; alt=&quot;Building Devops AI Assistant with Langchain, Ollama, and PostgreSQL&quot; title=&quot;Building Devops AI Assistant with Langchain, Ollama, and PostgreSQL&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/huseyinbabal&quot;&gt; /u/huseyinbabal &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://docs.rapidapp.io/blog/building-devops-ai-assistant-with-langchain-ollama-and-postgresql&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1dec8ls/building_devops_ai_assistant_with_langchain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1dec8ls</id><media:thumbnail url="https://external-preview.redd.it/3eIYPb9fvv3T8yM1RCQU_MSfK9DpDf_d-D2eAbkLPPE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c229377b890822b72774120bb4ab72f62d353aa2" /><link href="https://www.reddit.com/r/LangChain/comments/1dec8ls/building_devops_ai_assistant_with_langchain/" /><updated>2024-06-12T17:25:33+00:00</updated><published>2024-06-12T17:25:33+00:00</published><title>Building Devops AI Assistant with Langchain, Ollama, and PostgreSQL</title></entry><entry><author><name>/u/These-Butterfly8819</name><uri>https://www.reddit.com/user/These-Butterfly8819</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have been given a requirement from my company to look into and try to comeup with a chatbot that would be integrated into the web application. Specifically, we have a list of Companies and their details like name, what they do, their revenues, etc. and some uploaded pdf files that contain more information regarding the company. So the chatbot will be integrated into the details page of the companies. User could then ask any question regarding the company and the chatbot should provide a relevant answer for that company.&lt;/p&gt; &lt;p&gt;I am fairly new to this, but was able to find out that we can use RAG for achieving this, wherein we take all the data and embed it in a vector database. Then fetch relevant vectors per the question asked and provide it as context to the LLM for answer.&lt;/p&gt; &lt;p&gt;However the issue is that some of the data of the company can change with time.&lt;/p&gt; &lt;p&gt;Is there a way to do it so that the pdf data can use vector store, but the rest of the data can be obtained from API calls? That way, we will always have the most recent data of the company, but also have the additional data from the pdf docs?&lt;/p&gt; &lt;p&gt;How would all these things fit? How would the decision be made when to use data from vector database or when to fetch data from API?&lt;/p&gt; &lt;p&gt;Do you guys have any experience with something like this or any recommendations or resources where I can look into for this project?&lt;/p&gt; &lt;p&gt;That would be very helpful.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/These-Butterfly8819&quot;&gt; /u/These-Butterfly8819 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1de6133/help_regarding_application_specific_chatbot/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1de6133/help_regarding_application_specific_chatbot/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1de6133</id><link href="https://www.reddit.com/r/LangChain/comments/1de6133/help_regarding_application_specific_chatbot/" /><updated>2024-06-12T12:58:22+00:00</updated><published>2024-06-12T12:58:22+00:00</published><title>Help regarding application specific chatbot</title></entry><entry><author><name>/u/thumbsdrivesmecrazy</name><uri>https://www.reddit.com/user/thumbsdrivesmecrazy</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In Feb 2024, Meta published a paper introducing TestGen-LLM, a tool for automated unit test generation using LLMs, but didn’t release the TestGen-LLM code.The following blog shows how CodiumAI created the first open-source implementation - Cover-Agent, based on Meta&amp;#39;s approach: &lt;a href=&quot;https://www.codium.ai/blog/we-created-the-first-open-source-implementation-of-metas-testgen-llm/&quot;&gt;We created the first open-source implementation of Meta’s TestGen–LLM&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The tool is implemented as follows:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Receive the following user inputs (Source File for code under test, Existing Test Suite to enhance, Coverage Report, Build/Test Command Code coverage target and maximum iterations to run, Additional context and prompting options)&lt;/li&gt; &lt;li&gt;Generate more tests in the same style&lt;/li&gt; &lt;li&gt;Validate those tests using your runtime environment - Do they build and pass?&lt;/li&gt; &lt;li&gt;Ensure that the tests add value by reviewing metrics such as increased code coverage&lt;/li&gt; &lt;li&gt;Update existing Test Suite and Coverage Report&lt;/li&gt; &lt;li&gt;Repeat until code reaches criteria: either code coverage threshold met, or reached the maximum number of iterations&lt;/li&gt; &lt;/ol&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thumbsdrivesmecrazy&quot;&gt; /u/thumbsdrivesmecrazy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1deals9/opensource_implementation_of_metas_testgenllm/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1deals9/opensource_implementation_of_metas_testgenllm/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1deals9</id><link href="https://www.reddit.com/r/LangChain/comments/1deals9/opensource_implementation_of_metas_testgenllm/" /><updated>2024-06-12T16:17:22+00:00</updated><published>2024-06-12T16:17:22+00:00</published><title>Open-source implementation of Meta’s TestGen–LLM - CodiumAI</title></entry><entry><author><name>/u/migkapa</name><uri>https://www.reddit.com/user/migkapa</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, &lt;/p&gt; &lt;p&gt;I get an &amp;quot;An error occurred: Multiple function calls are not currently supported&amp;quot; while using Gemini Pro .&lt;br/&gt; Anyone had the same issue?&lt;/p&gt; &lt;p&gt;Using:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;llm = ChatGoogleGenerativeAI(temperature=0, model=&amp;quot;gemini-pro&amp;quot;) llm.bind_tools(tools) &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/migkapa&quot;&gt; /u/migkapa &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1de99jx/error_with_tool_calling_while_using_gemini_pro/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1de99jx/error_with_tool_calling_while_using_gemini_pro/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1de99jx</id><link href="https://www.reddit.com/r/LangChain/comments/1de99jx/error_with_tool_calling_while_using_gemini_pro/" /><updated>2024-06-12T15:20:37+00:00</updated><published>2024-06-12T15:20:37+00:00</published><title>Error with tool calling while using Gemini Pro</title></entry><entry><author><name>/u/Disneyskidney</name><uri>https://www.reddit.com/user/Disneyskidney</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m working on a use case that relies on very robust knowledge graph construction and I wanted to know if any startups/companies/open-source have built either free or paid production ready solutions for the unstructured text to knowledge graph pipeline.&lt;/p&gt; &lt;p&gt;UPDATE:&lt;/p&gt; &lt;p&gt;Diffbot seems to have a pretty good API that is compatiable with Llama Index and Langchain&lt;/p&gt; &lt;p&gt;this tutorial for Llama Index was released the same day I posted this and looks promising: &lt;a href=&quot;https://www.llamaindex.ai/blog/customizing-property-graph-index-in-llamaindex&quot;&gt;https://www.llamaindex.ai/blog/customizing-property-graph-index-in-llamaindex&lt;/a&gt;​&lt;/p&gt; &lt;p&gt;And Here is one for Langchain &lt;a href=&quot;https://python.langchain.com/v0.1/docs/integrations/graphs/diffbot/&quot;&gt;Diffbot | 🦜️🔗 LangChain&lt;/a&gt;​&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Disneyskidney&quot;&gt; /u/Disneyskidney &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddvywe/production_ready_unstructured_text_to_knowledge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1ddvywe/production_ready_unstructured_text_to_knowledge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1ddvywe</id><link href="https://www.reddit.com/r/LangChain/comments/1ddvywe/production_ready_unstructured_text_to_knowledge/" /><updated>2024-06-12T02:29:12+00:00</updated><published>2024-06-12T02:29:12+00:00</published><title>Production Ready Unstructured Text to Knowledge Graph</title></entry></feed>