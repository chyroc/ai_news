<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LangChain" label="r/LangChain"/><updated>2024-01-20T04:24:19+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LangChain.rss</id><link rel="self" href="https://www.reddit.com/r/LangChain.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LangChain" type="text/html" /><subtitle>LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.</subtitle><title>LangChain</title><entry><author><name>/u/zchaarm</name><uri>https://www.reddit.com/user/zchaarm</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;A place for members of &lt;a href=&quot;/r/LangChain&quot;&gt;r/LangChain&lt;/a&gt; to chat with each other&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/zchaarm&quot;&gt; /u/zchaarm &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ljho9</id><link href="https://www.reddit.com/r/LangChain/comments/10ljho9/rlangchain_lounge/" /><updated>2023-01-26T04:33:05+00:00</updated><published>2023-01-26T04:33:05+00:00</published><title>r/LangChain Lounge</title></entry><entry><author><name>/u/Top_Raccoon_1493</name><uri>https://www.reddit.com/user/Top_Raccoon_1493</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am into creating an interactive chatbot that can take inputs from multiple data sources like pdf, word file, text file, excel files etc. I am using Pinecone retriever with Langchain wrapper on top of it. When I go for DirectoryLoader using glob function, I’m unable to load other file types except PDF and convert it to vector embeddings. Need a way to load rest of the documents and process it further for embeddings.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Top_Raccoon_1493&quot;&gt; /u/Top_Raccoon_1493 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19b2ivj/is_there_any_common_loaders_in_langchain_to_load/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19b2ivj/is_there_any_common_loaders_in_langchain_to_load/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19b2ivj</id><link href="https://www.reddit.com/r/LangChain/comments/19b2ivj/is_there_any_common_loaders_in_langchain_to_load/" /><updated>2024-01-20T03:45:00+00:00</updated><published>2024-01-20T03:45:00+00:00</published><title>Is there any common loaders in langchain to load all types of documents??</title></entry><entry><author><name>/u/Money_Mycologist4939</name><uri>https://www.reddit.com/user/Money_Mycologist4939</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi everybody I was wondering how would it be like a typical Dockerfile for running a langchain pipeline. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Money_Mycologist4939&quot;&gt; /u/Money_Mycologist4939 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19amgmz/how_to_dockerise_a_langchain_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19amgmz/how_to_dockerise_a_langchain_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19amgmz</id><link href="https://www.reddit.com/r/LangChain/comments/19amgmz/how_to_dockerise_a_langchain_app/" /><updated>2024-01-19T16:04:39+00:00</updated><published>2024-01-19T16:04:39+00:00</published><title>How to dockerise a Langchain app</title></entry><entry><author><name>/u/SensitiveFel</name><uri>https://www.reddit.com/user/SensitiveFel</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I want to realize such a scenario: Let&amp;#39;s say I have a &lt;code&gt;name&lt;/code&gt; field stored in my db, and when the user asks for bob, I may have Bob, Boe... in the db. If there is no exact match for bob, I want the bot to guide the user: do you want to query Bob or boe?&lt;/p&gt; &lt;p&gt;What I understand is that it&amp;#39;s actually how to make the bot stop to continue the query and output the result under certain circumstances during the execution, how should I implement this using langChain? Can I do it by &lt;code&gt;bind(stop=&amp;#39;xx&amp;#39;)&lt;/code&gt;?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SensitiveFel&quot;&gt; /u/SensitiveFel &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ambyh/using_agent_in_langchain_i_want_to_abort_in/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19ambyh/using_agent_in_langchain_i_want_to_abort_in/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19ambyh</id><link href="https://www.reddit.com/r/LangChain/comments/19ambyh/using_agent_in_langchain_i_want_to_abort_in/" /><updated>2024-01-19T15:59:21+00:00</updated><published>2024-01-19T15:59:21+00:00</published><title>Using Agent in langChain I want to abort in specific situations, how should I design it</title></entry><entry><author><name>/u/Wild-Market9571</name><uri>https://www.reddit.com/user/Wild-Market9571</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I found langchain to be overly complex for my needs, leading me to opt for coding from scratch. It seemed like langchain created vectordb per table, rather than consolidating them within one table, which wasn&amp;#39;t efficient according to my preferences.&lt;/p&gt; &lt;p&gt;Despite the complexities, I required a tool like langchain for splitting my documents into chunks. This quest took up more of my time, and I couldn&amp;#39;t fully comprehend the hype surrounding langchain as the epitome of freedom.&lt;/p&gt; &lt;p&gt;Nonetheless, I took matters into my own hands and devised my splitting technique. While it may not be the most optimal solution, it suits my requirements perfectly. I leveraged the spaCy Library and its NLP capabilities to separate my documents into sentences, providing me with the desired outcome and a sense of freedom.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Wild-Market9571&quot;&gt; /u/Wild-Market9571 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a5flh/langchain_appears_to_be_a_library_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a5flh/langchain_appears_to_be_a_library_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19a5flh</id><link href="https://www.reddit.com/r/LangChain/comments/19a5flh/langchain_appears_to_be_a_library_with/" /><updated>2024-01-19T00:19:11+00:00</updated><published>2024-01-19T00:19:11+00:00</published><title>Langchain appears to be a library with unnecessary complexities.</title></entry><entry><author><name>/u/SensitiveFel</name><uri>https://www.reddit.com/user/SensitiveFel</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;When a user asks a question, in what way can I achieve the display of similar questions. For example: the user asks for Bob&amp;#39;s age? I will give 4 related questions: who is Bob, Bob&amp;#39;s gender,.... But these questions are not random, they are given based on my profile&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/SensitiveFel&quot;&gt; /u/SensitiveFel &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19an810/how_to_achieve_relevance_question_leading/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19an810/how_to_achieve_relevance_question_leading/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19an810</id><link href="https://www.reddit.com/r/LangChain/comments/19an810/how_to_achieve_relevance_question_leading/" /><updated>2024-01-19T16:35:50+00:00</updated><published>2024-01-19T16:35:50+00:00</published><title>How to achieve relevance question leading</title></entry><entry><author><name>/u/Capable_Juice98</name><uri>https://www.reddit.com/user/Capable_Juice98</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello People I&amp;#39;ve joined this community very recently, I&amp;#39;m working on a project, where I&amp;#39;m creating a QnA model on existing magazines of my college. I&amp;#39;m experimenting between different embeddings (openai, bge, gte..), vector stores (FAISS, Chroma db,...), document chunking ... Finally I have to deploy all of this into a webpage Can you suggest a way forward?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Capable_Juice98&quot;&gt; /u/Capable_Juice98 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19adx5s/deployment_of_rag_based_qna_model/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19adx5s/deployment_of_rag_based_qna_model/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19adx5s</id><link href="https://www.reddit.com/r/LangChain/comments/19adx5s/deployment_of_rag_based_qna_model/" /><updated>2024-01-19T07:54:27+00:00</updated><published>2024-01-19T07:54:27+00:00</published><title>Deployment of RAG Based QNA Model</title></entry><entry><author><name>/u/Mediocre-Card8046</name><uri>https://www.reddit.com/user/Mediocre-Card8046</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi,&lt;/p&gt; &lt;p&gt;I am using Llamacpp to load my models and streaming in the terminal works with the &lt;code&gt;StreamingStdOutCallbackHandler()&lt;/code&gt; and the parameter &lt;code&gt;streaming=True&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Now I want to enable Streaming in FastAPI responses, but didn&amp;#39;t find a solution that satisfies my requirements. Many tutorials wait until the response from the LLM is ready and then streaming it. But I want to see a &amp;quot;live&amp;quot; streaming of the tokens, otherwise it will take too long until the user gets a response (especially for longer texts).&lt;/p&gt; &lt;p&gt;So does anyone know to do this with Llamacpp and FastAPI?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;(I am NOT using any OpenAI model, I am using GGUF models locally)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Mediocre-Card8046&quot;&gt; /u/Mediocre-Card8046 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19aevbz/streaming_with_llamacpp_langchain_and_fastapi/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19aevbz/streaming_with_llamacpp_langchain_and_fastapi/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19aevbz</id><link href="https://www.reddit.com/r/LangChain/comments/19aevbz/streaming_with_llamacpp_langchain_and_fastapi/" /><updated>2024-01-19T09:01:11+00:00</updated><published>2024-01-19T09:01:11+00:00</published><title>Streaming with Llamacpp, Langchain and FastAPI</title></entry><entry><author><name>/u/marcuss171</name><uri>https://www.reddit.com/user/marcuss171</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys! I am developing a expense chatbot on WhatsApp but the cost per customer is very high. Each request is about 0.0884 and we are expecting each customer to do at least 100 request per month. Which would mean $8 per customer.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;We have a set of tools that is elevating the cost because it is passed as context, so my idea was to store the tools in a db, use GPT-3.5 to decide which tool to use. Pass just one tool to GPT 4 in the prompt and reduce the cost. But the costs would still be high at $0.025 per request. &lt;/p&gt; &lt;p&gt;I have two questions: &lt;/p&gt; &lt;ol&gt; &lt;li&gt;What do you think about my solution?&lt;/li&gt; &lt;li&gt;Do you think using Llama2 would be a good idea to create a chatbot? And if so do you have any docs on how to do so.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;THanks!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/marcuss171&quot;&gt; /u/marcuss171 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a4pxq/cost_x_prompt_too_high_using_gpt_4/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a4pxq/cost_x_prompt_too_high_using_gpt_4/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_19a4pxq</id><link href="https://www.reddit.com/r/LangChain/comments/19a4pxq/cost_x_prompt_too_high_using_gpt_4/" /><updated>2024-01-18T23:47:38+00:00</updated><published>2024-01-18T23:47:38+00:00</published><title>Cost x Prompt too high using GPT 4</title></entry><entry><author><name>/u/ubertodev</name><uri>https://www.reddit.com/user/ubertodev</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a4s0n/apichain/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/f576w3wcdadc1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=26f01ce0ada53b935afb38d72436073b69803f16&quot; alt=&quot;Apichain&quot; title=&quot;Apichain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;when streaming apichain, it prepends the api url to a streaming text response. Any ideas why it would do this ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ubertodev&quot;&gt; /u/ubertodev &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/f576w3wcdadc1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/19a4s0n/apichain/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_19a4s0n</id><media:thumbnail url="https://preview.redd.it/f576w3wcdadc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=26f01ce0ada53b935afb38d72436073b69803f16" /><link href="https://www.reddit.com/r/LangChain/comments/19a4s0n/apichain/" /><updated>2024-01-18T23:50:16+00:00</updated><published>2024-01-18T23:50:16+00:00</published><title>Apichain</title></entry><entry><author><name>/u/AbbreviationsPale867</name><uri>https://www.reddit.com/user/AbbreviationsPale867</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey I was using langhchain before the 0.1.0 update and I&amp;#39;m using it in a project that will go live soon, however I want to move to 0.1.0 but my custom agent completely breaks and I feel like LangSmith is my only option. Is there a way to get an invite code as I have been on the wait list for a bit.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AbbreviationsPale867&quot;&gt; /u/AbbreviationsPale867 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199nbwa/langsmith/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199nbwa/langsmith/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199nbwa</id><link href="https://www.reddit.com/r/LangChain/comments/199nbwa/langsmith/" /><updated>2024-01-18T10:42:18+00:00</updated><published>2024-01-18T10:42:18+00:00</published><title>Langsmith</title></entry><entry><author><name>/u/Icy-Employee6667</name><uri>https://www.reddit.com/user/Icy-Employee6667</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m reaching out because I&amp;#39;m having a frustrating issue with LangChain and ChromaDB, and I could really use some help from those more experienced than myself. Here&amp;#39;s my situation:&lt;/p&gt; &lt;p&gt;I have thousands of text documents that contain detailed information, and I&amp;#39;m trying to utilize LangChain and ChromaDB (BAAI/bge-large-en-v1.5) to extract meaningful insights from them. The problem I&amp;#39;m encountering is that when I run the pipeline, it keeps fetching the wrong details for certain cases.&lt;/p&gt; &lt;p&gt;For example, let&amp;#39;s say I have a case number &amp;quot;P L D 1949 Dacca 13&amp;quot;. Instead of retrieving the relevant information for that specific case, the model returns the details for &amp;quot;P L D 1949 Dacca 30&amp;quot; instead. This is happening consistently across many documents, and I&amp;#39;m at a loss as to why this is occurrcing.&lt;/p&gt; &lt;p&gt;Here are some additional details about my setup and process:&lt;/p&gt; &lt;p&gt;* I&amp;#39;m relatively new to LangChain, so please bear with me if my mistake is obvious.&lt;/p&gt; &lt;p&gt;* I&amp;#39;ve followed the instructions provided by the LangChain team for setting up the environment and running the pipeline.&lt;/p&gt; &lt;p&gt;* My dataset consists of plain text files containing various types of legal documents.&lt;/p&gt; &lt;p&gt;* I&amp;#39;m using the BAAI/bge-large-en-v1.5 model for text embedding&lt;/p&gt; &lt;p&gt;Thank you in advance for taking the time to read through my post and offer assistance. Your expertise means a lot to me, and I look forward to hearing your thoughts and suggestions.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Icy-Employee6667&quot;&gt; /u/Icy-Employee6667 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199ne8a/struggling_with_langchain_and_chromadb_help_needed/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199ne8a/struggling_with_langchain_and_chromadb_help_needed/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199ne8a</id><link href="https://www.reddit.com/r/LangChain/comments/199ne8a/struggling_with_langchain_and_chromadb_help_needed/" /><updated>2024-01-18T10:46:28+00:00</updated><published>2024-01-18T10:46:28+00:00</published><title>Struggling with LangChain and ChromaDB - Help Needed!</title></entry><entry><author><name>/u/confidant_dude</name><uri>https://www.reddit.com/user/confidant_dude</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;from langchain_community.vectorstores import Pinecone from langchain_openai import OpenAIEmbeddings from pinecone import Pinecone as PineconeClient pinecone=PineconeClient( api_key= {API KEY} ) embeddings = OpenAIEmbeddings( model=&amp;quot;text-embedding-ada-002&amp;quot;, openai_api_key={open_ai_api_key} ) vectorstore = Pinecone.from_existing_index(index_name, embeddings) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This gives the following error: &lt;/p&gt; &lt;p&gt;raise PineconeConfigurationError(&amp;quot;You haven&amp;#39;t specified an Api-Key.&amp;quot;)&lt;/p&gt; &lt;p&gt;pinecone.exceptions.PineconeConfigurationError: You haven&amp;#39;t specified an Api-Key. &lt;/p&gt; &lt;p&gt;Although I provided all the required api keys in line #5 and line #9&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/confidant_dude&quot;&gt; /u/confidant_dude &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199mklo/langchain_011_is_not_working_with_pineconeclient/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199mklo/langchain_011_is_not_working_with_pineconeclient/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199mklo</id><link href="https://www.reddit.com/r/LangChain/comments/199mklo/langchain_011_is_not_working_with_pineconeclient/" /><updated>2024-01-18T09:51:14+00:00</updated><published>2024-01-18T09:51:14+00:00</published><title>Langchain 0.1.1 is not working with pinecone-client 3.0.0</title></entry><entry><author><name>/u/Vegetable-Scene-6365</name><uri>https://www.reddit.com/user/Vegetable-Scene-6365</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199rxcn/getting_value_is_not_a_valid_dict_typetype/&quot;&gt; &lt;img src=&quot;https://b.thumbs.redditmedia.com/oc4Odb2FOMKa_qTu6wou2wUQQRVu7UknFFCnFuB93sQ.jpg&quot; alt=&quot;Getting &amp;quot;value is not a valid dict (type=type_error.dict)&amp;quot;&quot; title=&quot;Getting &amp;quot;value is not a valid dict (type=type_error.dict)&amp;quot;&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;pre&gt;&lt;code&gt;docsearch_in_os = OpenSearchVectorSearch( &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;opensearch_url=os.environ.get(&amp;quot;OPENSEARCH_URL&amp;quot;), index_name=index_name, embedding_function=bedrock_embeddings, http_auth=auth, timeout=30, use_ssl=True, verify_certs=True, connection_class=RequestsHttpConnection, is_aoss=True, ) print(user_input) print(docsearch_in_os) chain = RetrievalQA.from_chain_type( llm=llm, chain_type=&amp;quot;stuff&amp;quot;, retriever=docsearch_in_os.as_retriever(), return_source_documents=False, chain_type_kwargs={&amp;quot;prompt&amp;quot;: PROMPT}, ) result = chain({&amp;quot;query&amp;quot;: user_input}) print(result) answer = result[&amp;quot;result&amp;quot;]&lt;/p&gt; &lt;p&gt;The above block of code is working fine with the opensearch vector store I created manually via Sagemaker. But somehow, the same piece of code isn&amp;#39;t working when the Opensearch vector store is created via The AWS Bedrock Console. I am getting error:&lt;br/&gt; &amp;quot;value is not a valid dict (type=type_error.dict)&amp;quot;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/qd5en8unp7dc1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=af4809165591a12514aa05ade0a8eef29de23e1d&quot;&gt;https://preview.redd.it/qd5en8unp7dc1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=af4809165591a12514aa05ade0a8eef29de23e1d&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Vegetable-Scene-6365&quot;&gt; /u/Vegetable-Scene-6365 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199rxcn/getting_value_is_not_a_valid_dict_typetype/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199rxcn/getting_value_is_not_a_valid_dict_typetype/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_199rxcn</id><media:thumbnail url="https://b.thumbs.redditmedia.com/oc4Odb2FOMKa_qTu6wou2wUQQRVu7UknFFCnFuB93sQ.jpg" /><link href="https://www.reddit.com/r/LangChain/comments/199rxcn/getting_value_is_not_a_valid_dict_typetype/" /><updated>2024-01-18T14:54:13+00:00</updated><published>2024-01-18T14:54:13+00:00</published><title>Getting &quot;value is not a valid dict (type=type_error.dict)&quot;</title></entry><entry><author><name>/u/3RiversAINexus</name><uri>https://www.reddit.com/user/3RiversAINexus</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I noticed that in the langchain documentation there was no happy medium where it&amp;#39;s explained how to add a memory to both the AgentExecutor and the chat itself. If you don&amp;#39;t have it in the AgentExecutor, it doesn&amp;#39;t see previous steps. In the custom agent example, it has you managing the chat history manually.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve created an example based on the langchain docs that does this here: &lt;a href=&quot;https://github.com/ThreeRiversAINexus/sample-langchain-agents/blob/main/structured_chat.py&quot;&gt;https://github.com/ThreeRiversAINexus/sample-langchain-agents/blob/main/structured_chat.py&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Please let me know what you think and if there are any other agents you need help with.&lt;/p&gt; &lt;p&gt;Edit: I&amp;#39;ve added a string splitting tool and gave an example using it to prove that it has memory of the chats as well as the agent executor steps.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/3RiversAINexus&quot;&gt; /u/3RiversAINexus &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199edvi/example_structured_chat_agent_with_complete/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199edvi/example_structured_chat_agent_with_complete/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199edvi</id><link href="https://www.reddit.com/r/LangChain/comments/199edvi/example_structured_chat_agent_with_complete/" /><updated>2024-01-18T01:52:35+00:00</updated><published>2024-01-18T01:52:35+00:00</published><title>Example Structured Chat Agent with Complete History</title></entry><entry><author><name>/u/Dealwap1337</name><uri>https://www.reddit.com/user/Dealwap1337</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am building a RAG app with langhain, how do you ensure you get the optimal results from your vector store so that the extracted documents and prompt sent to the LLM contain all the relevant information? I had to increase topK to as high as 50 before getting a good result.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Dealwap1337&quot;&gt; /u/Dealwap1337 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199ejhc/how_do_i_improve_rag_extracted_document_list/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199ejhc/how_do_i_improve_rag_extracted_document_list/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199ejhc</id><link href="https://www.reddit.com/r/LangChain/comments/199ejhc/how_do_i_improve_rag_extracted_document_list/" /><updated>2024-01-18T01:59:58+00:00</updated><published>2024-01-18T01:59:58+00:00</published><title>How do I improve RAG extracted document list</title></entry><entry><author><name>/u/Classic_essays</name><uri>https://www.reddit.com/user/Classic_essays</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello. &lt;/p&gt; &lt;p&gt;I&amp;#39;m creating a social media app and I intend to use AI for post recommendations. How do I use Lang Chain to achieve that? Any suggestions?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Classic_essays&quot;&gt; /u/Classic_essays &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1995ips/how_do_i_use_lang_chain_for_ai_recommendations_on/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1995ips/how_do_i_use_lang_chain_for_ai_recommendations_on/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1995ips</id><link href="https://www.reddit.com/r/LangChain/comments/1995ips/how_do_i_use_lang_chain_for_ai_recommendations_on/" /><updated>2024-01-17T19:38:08+00:00</updated><published>2024-01-17T19:38:08+00:00</published><title>How do I use Lang Chain for AI Recommendations on my app?</title></entry><entry><author><name>/u/DBAdvice123</name><uri>https://www.reddit.com/user/DBAdvice123</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I saw that DataStax/Astra DB &lt;a href=&quot;https://www.datastax.com/blog/general-availability-data-api-for-enhanced-developer-experience&quot;&gt;just released a new Data API to help with building production GenAI and RAG applications&lt;/a&gt;. This API makes the proven petabyte-scale of Apache Cassandra easy to use and available to any JavaScript, Python, or full-stack application developer.&lt;/p&gt; &lt;p&gt;There will also be a joint webinar with LangChain available for registration here: &lt;a href=&quot;https://www.datastax.com/events/wikichat-build-a-real-time-rag-app-on-wikipedia-with-langchain-and-vercel&quot;&gt;https://www.datastax.com/events/wikichat-build-a-real-time-rag-app-on-wikipedia-with-langchain-and-vercel&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DBAdvice123&quot;&gt; /u/DBAdvice123 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1990scx/new_data_api_for_astra/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1990scx/new_data_api_for_astra/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1990scx</id><link href="https://www.reddit.com/r/LangChain/comments/1990scx/new_data_api_for_astra/" /><updated>2024-01-17T16:33:54+00:00</updated><published>2024-01-17T16:33:54+00:00</published><title>New Data API for Astra</title></entry><entry><author><name>/u/Ok-Image-8343</name><uri>https://www.reddit.com/user/Ok-Image-8343</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Im struggling to understand a massive code base with not many comments. &lt;/p&gt; &lt;p&gt;Could lang chain plus gpt4 actually be useful for asking things like &amp;quot;what do you think this data structure does in the context its in?&amp;quot; Or &amp;quot;can you describe what this code block is doing in plain English?&amp;quot;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Ok-Image-8343&quot;&gt; /u/Ok-Image-8343 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1993938/is_langchain_useful_for_code_bases/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1993938/is_langchain_useful_for_code_bases/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1993938</id><link href="https://www.reddit.com/r/LangChain/comments/1993938/is_langchain_useful_for_code_bases/" /><updated>2024-01-17T18:08:17+00:00</updated><published>2024-01-17T18:08:17+00:00</published><title>Is langchain useful for code bases?</title></entry><entry><author><name>/u/thewhitelynx</name><uri>https://www.reddit.com/user/thewhitelynx</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey folks-&lt;/p&gt; &lt;p&gt;I&amp;#39;m building an agent with memory and authentication. &lt;/p&gt; &lt;p&gt;I have a solution for chat memory and would rather not use a platform which also manages memory to avoid data synchronization complexity.&lt;/p&gt; &lt;p&gt;I tried ChainLit first, but didn&amp;#39;t like that it largely requires using ChainLit&amp;#39;s own data model and preferably ChainLit cloud.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;I&amp;#39;m currently using StreamLit, and it&amp;#39;s OK - I like the flexibility, but it&amp;#39;s kinda slow for rendering and getting persistent authentication is proving challenging due to limited cookie support. It also seems like it was acquired by Snowflake and it&amp;#39;s maybe not as well supported as pre-acquisition.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Ideally, I want something where I can host with a single Python application binary like these two using some standard but customizable React components and just have a relatively simple interface for providing data (e.g. chat history, chat response, etc) as needed.&lt;/p&gt; &lt;p&gt;Any recommended solutions here? One thing I&amp;#39;m starting to wonder is if I should just switch over to pure TypeScript with NextJS and the JS version of LangChain so I can use React more natively &amp;amp; directly without having to maintain a bunch of distinct Python business logic &amp;amp; serving code.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/thewhitelynx&quot;&gt; /u/thewhitelynx &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199299c/modern_chat_frontend_for_pythonpowered_llm_chat/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/199299c/modern_chat_frontend_for_pythonpowered_llm_chat/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_199299c</id><link href="https://www.reddit.com/r/LangChain/comments/199299c/modern_chat_frontend_for_pythonpowered_llm_chat/" /><updated>2024-01-17T17:29:39+00:00</updated><published>2024-01-17T17:29:39+00:00</published><title>Modern chat frontend for Python-powered LLM Chat apps?</title></entry><entry><author><name>/u/Fr4nkWh1te</name><uri>https://www.reddit.com/user/Fr4nkWh1te</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Any idea why the &lt;code&gt;page_url&lt;/code&gt; is not available? According to the documentation of &lt;code&gt;createStuffDocumentsChain&lt;/code&gt;, this should automatically be populated from the documents&amp;#39; metadata. And the value definitely exists in the metadata.&lt;/p&gt; &lt;p&gt;``&lt;code&gt; const historyAwareCombineDocsChain = await createStuffDocumentsChain({ llm: streamingModel, prompt: ChatPromptTemplate.fromMessages([ [ &amp;quot;system&amp;quot;, &lt;/code&gt;Answer the user&amp;#39;s questions based on the below context. When it makes sense, provide a link to the source in markdown format.&lt;/p&gt; &lt;pre&gt;&lt;code&gt; Context: {context}`, ], new MessagesPlaceholder(&amp;quot;chat_history&amp;quot;), [&amp;quot;user&amp;quot;, &amp;quot;{input}&amp;quot;], &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;]), documentPrompt: PromptTemplate.fromTemplate( &amp;quot;Source: {page_url}\n\nPage content:\n{page_content}&amp;quot; ), documentSeparator: &amp;quot;\n------\n&amp;quot;, });&lt;/p&gt; &lt;p&gt;const retriever = (await getVectorStore()).asRetriever();&lt;/p&gt; &lt;p&gt;const historyAwareRetrieverChain = await createHistoryAwareRetriever({ llm: nonStreamingModel, retriever, rephrasePrompt: ChatPromptTemplate.fromMessages([ new MessagesPlaceholder(&amp;quot;chat_history&amp;quot;), [&amp;quot;user&amp;quot;, &amp;quot;{input}&amp;quot;], [ &amp;quot;user&amp;quot;, &amp;quot;Given the above conversation, generate a search query to look up in order to get information relevant to the conversation&amp;quot;, ], ]), });&lt;/p&gt; &lt;p&gt;const conversationalRetrievalChain = await createRetrievalChain({ retriever: historyAwareRetrieverChain, combineDocsChain: historyAwareCombineDocsChain, }); ```&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Fr4nkWh1te&quot;&gt; /u/Fr4nkWh1te &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1990ckx/inject_metadata_into_the_prompt_with/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/1990ckx/inject_metadata_into_the_prompt_with/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1990ckx</id><link href="https://www.reddit.com/r/LangChain/comments/1990ckx/inject_metadata_into_the_prompt_with/" /><updated>2024-01-17T16:17:07+00:00</updated><published>2024-01-17T16:17:07+00:00</published><title>Inject metadata into the prompt with createStuffDocumentsChain</title></entry><entry><author><name>/u/smileymileycoin</name><uri>https://www.reddit.com/user/smileymileycoin</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198qs86/use_wasm_as_a_crossplatform_llm_backend_for/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/yJQP8pCNK0zOtma-sQ1ZaVaMIWpxxr5u9_rIilBu3l4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0b2cedb5e76a0adae93d1a250fdb2c076324b6be&quot; alt=&quot;Use WASM as a cross-platform LLM backend for LangChain: Any LLMs on any device&quot; title=&quot;Use WASM as a cross-platform LLM backend for LangChain: Any LLMs on any device&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/smileymileycoin&quot;&gt; /u/smileymileycoin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/langchain-ai/langchain/pull/14787&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198qs86/use_wasm_as_a_crossplatform_llm_backend_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_198qs86</id><media:thumbnail url="https://external-preview.redd.it/yJQP8pCNK0zOtma-sQ1ZaVaMIWpxxr5u9_rIilBu3l4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0b2cedb5e76a0adae93d1a250fdb2c076324b6be" /><link href="https://www.reddit.com/r/LangChain/comments/198qs86/use_wasm_as_a_crossplatform_llm_backend_for/" /><updated>2024-01-17T07:16:24+00:00</updated><published>2024-01-17T07:16:24+00:00</published><title>Use WASM as a cross-platform LLM backend for LangChain: Any LLMs on any device</title></entry><entry><author><name>/u/theodormarcu</name><uri>https://www.reddit.com/user/theodormarcu</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi there! We were early users of LangChain (in March 2023), but we ended up moving away from it because we felt it was too early to support more complex use cases. We&amp;#39;re looking at it again and it looks like it&amp;#39;s come a long way! &lt;/p&gt; &lt;p&gt;What are the pros/cons of using LangChain in January 2024 vs going vanilla? What does LangChain help you the most with vs going vanilla? &lt;/p&gt; &lt;p&gt;Our use cases are:&lt;br/&gt; - Using multiple models using hosted and on-prem LLMs (both OSS and OpenAI/Anthropic/etc.)&lt;br/&gt; - Support for complex RAG.&lt;br/&gt; - Support chat and non-chat use cases.&lt;br/&gt; - Support for both private and non-private endpoints.&lt;br/&gt; - Outputting both structured and unstructured data. &lt;/p&gt; &lt;p&gt;We&amp;#39;re a quite experienced dev team, and it feels like we could get away without using LangChain. That being said, we hear a lot about it, so we&amp;#39;re curious if we&amp;#39;re missing out! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/theodormarcu&quot;&gt; /u/theodormarcu &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198csjd/why_should_i_use_langchain_for_my_new_app/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198csjd/why_should_i_use_langchain_for_my_new_app/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198csjd</id><link href="https://www.reddit.com/r/LangChain/comments/198csjd/why_should_i_use_langchain_for_my_new_app/" /><updated>2024-01-16T20:20:59+00:00</updated><published>2024-01-16T20:20:59+00:00</published><title>Why should I use LangChain for my new app?</title></entry><entry><author><name>/u/qa_anaaq</name><uri>https://www.reddit.com/user/qa_anaaq</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all--&lt;/p&gt; &lt;p&gt;I want to design a chatbot that:&lt;/p&gt; &lt;p&gt;A) has a set of guidelines (via a long pdf) that it &amp;quot;uses&amp;quot; to inform its&lt;/p&gt; &lt;p&gt;B) Analysis of website content&lt;/p&gt; &lt;p&gt;Basically, a user would submit (website) content via the chat interface, and the bot would analyze it based on the guidelines to which it has access. The user can ask questions in order to understand why the bot analyzed the content the way that it did. &lt;/p&gt; &lt;p&gt;I thought embedding the guidelines and using a retriever would be suitable, but it doesn&amp;#39;t seem like it&amp;#39;s the right way to go. When I ask it, &amp;quot;Provide examples from the text where negative language is being used,&amp;quot; it returns a list of negative language from the guidelines rather than applying the question to the website content and &lt;em&gt;using&lt;/em&gt; the guidelines to inform its answer.&lt;/p&gt; &lt;p&gt;I think some type of chain might be ideal, but I&amp;#39;m not sure what this would look like. &lt;/p&gt; &lt;p&gt;Really appreciate the ideas. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/qa_anaaq&quot;&gt; /u/qa_anaaq &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198mbhg/trying_to_figure_out_design_for_different_kind_of/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198mbhg/trying_to_figure_out_design_for_different_kind_of/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198mbhg</id><link href="https://www.reddit.com/r/LangChain/comments/198mbhg/trying_to_figure_out_design_for_different_kind_of/" /><updated>2024-01-17T03:08:56+00:00</updated><published>2024-01-17T03:08:56+00:00</published><title>Trying to figure out design for different kind of chatbot</title></entry><entry><author><name>/u/K0N1GST1G3R</name><uri>https://www.reddit.com/user/K0N1GST1G3R</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey there.&lt;/p&gt; &lt;p&gt;(Tell me if this is not the right place to ask such questions)&lt;/p&gt; &lt;p&gt;I tried out langchain for a little project, nothing too big. My goal was to be able to use langchain to ask LLMs to generate stuff for my project, and maybe implement some stuff like answers based on local documents.&lt;/p&gt; &lt;p&gt;But I&amp;#39;ve had a very hard time to find a free llm, and when I found how I can make this stuff work with some hugging face models (that I didn&amp;#39;t run locally) I was so disappointed how bad their answer were.&lt;/p&gt; &lt;p&gt;That&amp;#39;s why I am asking for suggestions and answer:&lt;/p&gt; &lt;p&gt;- should I run locally the llms ? which ones ?&lt;/p&gt; &lt;p&gt;- how can I manage all the settings of the llm. I don&amp;#39;t get what token and temperature are, and I wonder if they are the reason why the llm doesn&amp;#39;t respond as I would want it to.&lt;/p&gt; &lt;p&gt;- is hugging face a good choice ?&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Thanks a lot by advance, don&amp;#39;t hesitate to tell me if I was not specific enough.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/K0N1GST1G3R&quot;&gt; /u/K0N1GST1G3R &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198dky0/want_to_use_langchain_with_a_free_llm_model_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198dky0/want_to_use_langchain_with_a_free_llm_model_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198dky0</id><link href="https://www.reddit.com/r/LangChain/comments/198dky0/want_to_use_langchain_with_a_free_llm_model_and/" /><updated>2024-01-16T20:52:32+00:00</updated><published>2024-01-16T20:52:32+00:00</published><title>Want to use langchain with a free llm model ... and strugling</title></entry><entry><author><name>/u/Apart-Damage143</name><uri>https://www.reddit.com/user/Apart-Damage143</uri></author><category term="LangChain" label="r/LangChain"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m currently using &lt;code&gt;get_openai_callback()&lt;/code&gt; to monitor token consumption per call. However, when streaming the response, I&amp;#39;m receiving all zeros. I&amp;#39;m curious if anyone utilizing streaming in their application has successfully tracked token usage. Any insights?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Apart-Damage143&quot;&gt; /u/Apart-Damage143 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198g73w/struggling_to_track_token_usage_with_get_openai/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LangChain/comments/198g73w/struggling_to_track_token_usage_with_get_openai/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_198g73w</id><link href="https://www.reddit.com/r/LangChain/comments/198g73w/struggling_to_track_token_usage_with_get_openai/" /><updated>2024-01-16T22:36:57+00:00</updated><published>2024-01-16T22:36:57+00:00</published><title>Struggling to Track Token Usage with get_openai_callback() in Streaming – Seeking Advice from Fellow Developers</title></entry></feed>